
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>智子</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="zhizi">
    

    
    <meta name="description" content="IT技术、编程、web开发以及新兴的技术翻译与总结">
<meta property="og:type" content="website">
<meta property="og:title" content="智子">
<meta property="og:url" content="https://www.tracholar.top/page/122/index.html">
<meta property="og:site_name" content="智子">
<meta property="og:description" content="IT技术、编程、web开发以及新兴的技术翻译与总结">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="智子">
<meta name="twitter:description" content="IT技术、编程、web开发以及新兴的技术翻译与总结">

    
    <link rel="alternative" href="/atom.xml" title="智子" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">

    <!-- ad start -->
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-6300557868920774",
    enable_page_level_ads: true
  });
</script>

    <!-- ad end -->

    <!--  stat -->
    <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?4036f580b1119e720db871571faa68cc";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-78529611-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-78529611-1');
</script>

    <!-- end stat -->
</head>

  <body>
    <header>
      
<div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="智子">智子</a></h1>
				<h2 class="blog-motto">智子之家</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:www.tracholar.top">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main">


   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/embedding/" title="的嵌入" itemprop="url">的嵌入</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="的嵌入">的嵌入</span></h1><p>本文档介绍了嵌入的概念，给出了一个简单的例子 如何在TensorFlow中训练嵌入，并解释如何查看嵌入<br>与TensorBoard嵌入式投影仪。前两部分针对新人 机器学习或TensorFlow，和嵌入式投影机的方法是 各级用户。</p>
<p>嵌入是从离散对象（例如单词）到矢量的映射 的实数。例如，一个300维嵌入英文单词 可能包括：</p>
<pre><code>blue:  (0.01359, 0.00075997, 0.24608, ..., -0.2524, 1.0048, 0.06259)
blues:  (0.01396, 0.11887, -0.48963, ..., 0.033483, -0.10007, 0.1158)
orange:  (-0.24776, -0.12359, 0.20986, ..., 0.079717, 0.23865, -0.014213)
oranges:  (-0.35609, 0.21854, 0.080944, ..., -0.35413, 0.38511, -0.070976)
</code></pre><p>这些向量中的各个维度通常没有固有的意义。 相反，它是矢量之间的位置和距离的整体模式 机器学习利用。</p>
<p>嵌入对于机器学习的输入非常重要。分类器和神经 更普遍的网络，工作向量的实数。他们训练得最好 密集的向量，其中所有的值都有助于定义一个对象。但是，很多<br>机器学习的重要投入，如文字的话，没有一个 自然向量表示。嵌入功能是标准和 有效的方法将这些离散的输入对象转化为有用的 连续矢量。</p>
<p>嵌入作为机器学习的输出也是有价值的。因为嵌入 将对象映射到向量，应用程序可以使用向量空间中的相似性（for 欧几里德距离或矢量之间的夹角）作为一个鲁棒的和<br>对象相似度的灵活度量。一个常见的用途是找到最近的 邻居。例如，使用与上面相同的词嵌入，这里是 每个单词的三个最近的邻居和相应的角度：</p>
<pre><code>blue:  (red, 47.6°), (yellow, 51.9°), (purple, 52.4°)
blues:  (jazz, 53.3°), (folk, 59.1°), (bluegrass, 60.6°)
orange:  (yellow, 53.5°), (colored, 58.0°), (bright, 59.9°)
oranges:  (apples, 45.3°), (lemons, 48.3°), (mangoes, 50.4°)
</code></pre><p>这将告诉一个应用程序，苹果和橙子在某种程度上更多 与柠檬和桔子（间隔48.3°）相似（相距45.3°）。</p>
<h2><span id="在tensorflow中嵌入">在TensorFlow中嵌入</span></h2><p>为了在TensorFlow中创建词嵌入，我们首先将文本分成单词 然后为词汇表中的每个单词分配一个整数。让我们假设<br>这已经完成了，<code>word_ids</code>是这些整数的向量。 例如，“我有一只猫”这个句子可以被分成两部分 <code>[&quot;I&quot;, &quot;have&quot;, &quot;a&quot;, &quot;cat&quot;,
&quot;.&quot;]</code>和相应的<code>word_ids</code>张量 将形成<code>[5]</code>并由5个整数组成。映射这些单词ID 对于向量，我们需要创建嵌入变量并使用<br><code>tf.nn.embedding_lookup</code>的功能如下：</p>
<pre><code>word_embeddings = tf.get_variable(&quot;word_embeddings&quot;,
    [vocabulary_size, embedding_size])
embedded_word_ids = tf.nn.embedding_lookup(word_embeddings, word_ids)
</code></pre><p>在此之后，张量器<code>embedded_word_ids</code>将具有形状<code>[5, embedding_size]</code> 在我们的例子中，并包含每个5的嵌入（密集向量）<br>话。在训练结束时，<code>word_embeddings</code>将包含嵌入 为词汇中的所有单词。</p>
<p>嵌入可以训练许多网络类型，并有各种损失 功能和数据集。例如，可以使用循环神经网络 来预测下一个词从前一个给定的大语料库<br>句子，或者可以训练两个网络进行多语言翻译。 这些方法在“矢量表示”中有描述 教程。</p>
<h2><span id="可视化嵌入">可视化嵌入</span></h2><p>TensorBoard包括嵌入式投影仪，这个工具可以让你 交互式地显示嵌入。这个工具可以读取你的嵌入 模型并在二维或三维中渲染它们。</p>
<p>嵌入式投影机有三个面板：</p>
<p>在左上方的数据面板中，您可以选择运行，嵌入   可变数据列和数据列来为点添加颜色和标签。 在左下角的投影面板，您可以在其中选择类型   投影。<br>在右侧的检查面板，在那里你可以搜索特定的   点，看看最近的邻居列表。</p>
<h3><span id="预测">预测</span></h3><p>嵌入式投影机提供三种方法来降低a 数据集。</p>
<p>T-SNE：   非线性非确定性算法（T-分布随机邻居）   嵌入），试图在数据中保存当地的社区，通常在   扭曲全球结构的代价。你可以选择是否计算<br>二维或三维投影。 PCA：   线性确定性算法（主成分分析）试图   在尽可能少的维度上捕获尽可能多的数据可变性。 PCA<br>往往会突出数据的大规模结构，但会扭曲局部   邻里。嵌入式投影机计算前10名委托人   组件，您可以从中选择两个或三个来查看。<br>自定义：对您的水平和垂直轴进行线性投影   在数据中指定使用标签。你可以定义水平轴   实例，通过给“左”和“右”的文本模式。嵌入<br>投影机查找标签与“左”模式相匹配的所有点   计算该集合的质心;类似的“右”。线路通过   通过这两个质心定义横轴。垂直轴是<br>同样根据与“上”和“下”匹配的点的质心计算，   文本模式。</p>
<p>其他有用的文章是 如何有效地使用t-SNE 主成分分析直观解释。</p>
<h3><span id="勘探">勘探</span></h3><p>您可以通过使用自然缩放，旋转和平移进行视觉探索 点击并拖动手势。将鼠标悬停在某个点上会显示任何内容 这一点的元数据。你也可以检查最近的邻居<br>子集。单击一个点会导致右窗格列出最近的 邻居，以及与当前点的距离。最近的邻居 在投影中也突出了点。</p>
<p>将视图限制为点的一个子集并执行有时是有用的 只在这些点上进行预测。为此，您可以选择多个点 方法：</p>
<p>点击一个点后，最近的邻居也被选中。 搜索后，选择与查询匹配的点。 启用选择，单击一个点并拖动定义一个选择   领域。</p>
<p>然后单击“检查器”窗格顶部的“隔离nnn点”按钮 在右手侧。下图显示了101个已选择和准备好的点 供用户点击“隔离101分”：</p>
<p><img src="https://www.tensorflow.org/images/embedding-
nearest-points.png" alt="Selection of nearest neighbors"></p>
<p>在嵌入数据集的单词中选择“重要”的最近邻居。</p>
<p>高级提示：使用自定义投影进行过滤可能会很强大下面，我们 过滤了“政治”最近的100个邻居，并把它们投射到了“ “最差” - “最好”的矢量作为x轴。<br>y轴是随机的。结果，一个 找到右边的“思想”，“科学”，“视角”，“新闻”等等 左“危机”，“暴力”和“冲突”。</p>
<p><img src="https://www.tensorflow.org/images/embedding-custom-
controls.png" alt="Custom controls panel"> |  <img src="https://www.tensorflow.org/images
/embedding-custom-projection.png" alt="Custom projection"><br>—|—<br>Custom projection controls.  |  Custom projection of neighbors of “politics”<br>onto “best” - “worst” vector.  </p>
<p>要分享您的发现，您可以使用右下方的书签面板 保存当前状态（包括计算出的坐标） 投影）作为一个小文件。投影机可以被指向一组<br>或更多这些文件，生产下面的面板。其他用户可以走 通过一系列书签。</p>
<p><img src="https://www.tensorflow.org/images/embedding-bookmark.png" alt="Bookmark panel"></p>
<h3><span id="元数据">元数据</span></h3><p>如果你正在使用嵌入，你可能会想要附加 标签/图像到数据点。您可以通过生成元数据文件来完成此操作 包含每个点的标签并点击数据面板中的“加载数据” 嵌入式投影机</p>
<p>元数据可以是标签或图像，也可以是 存储在一个单独的文件。对于标签，格式应该 成为TSV文件 （制表符以红色显示），其第一行包含列标题<br>（以粗体显示）和后续行包含元数据值。例如：</p>
<p>Word \ Frequency Airplane \ t345 Car \ t241 …</p>
<p>元数据文件中行的顺序被假定为匹配顺序 嵌入变量中的矢量，除了标题。因此， （i + 1）行对应于嵌入的第i行<br>变量。如果TSV元数据文件只有一个列，那么我们不这样做 期望一个标题行，并假设每行是嵌入的标签。我们 包括这个例外，因为它匹配了常用的“vocab文件”<br>格式。</p>
<p>要将图像用作元数据，您必须生成一个 精灵图像， 由小缩略图组成，每个矢量在嵌入中一个。该 精灵应该按行先存储缩略图：放置第一个数据点<br>在左上角，最后一个数据点在右下角，尽管是最后一个 行不必填写，如下所示。</p>
<table>
<thead>
<tr>
<th>0</th>
<th>1</th>
<th>2  </th>
</tr>
</thead>
<tbody>
<tr>
<td>3</td>
<td>4</td>
<td>5  </td>
</tr>
<tr>
<td>6</td>
<td>7</td>
<td></td>
</tr>
</tbody>
</table>
<p>按照这个链接 在嵌入式投影仪中查看缩略图的有趣示例。</p>
<h2><span id="迷你常见问题解答">迷你常见问题解答</span></h2><p>是“嵌入”一个行动还是一个事物？ 都。人们谈论嵌入在向量空间（行动）和关于词 产生词嵌入（东西）。两者共同的是嵌入的概念<br>作为从离散对象到矢量的映射。创建或应用它 映射是一个动作，但映射本身是一件事情。</p>
<p>是嵌入高维或低维？ 这取决于。例如，单词和短语的300维向量空间， 通常被称为低维（和密集）相比，数百万 它可以包含的单词和短语。但数学上它是高维的，<br>展示了许多与我们的人类大不相同的特性 直觉了解了二维和三维空间。</p>
<p>嵌入层是否与嵌入层相同？ 没有。嵌入层是神经网络的一部分，但嵌入是一个更多 一般的概念。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  
      <ins class="adsbygoogle"
     style="display:block;  overflow:hidden;"
     data-ad-format="fluid"
     data-ad-layout-key="-ej+6f-q-c7+ou"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="5206371097"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/datasets/" title="导入数据" itemprop="url">导入数据</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="导入数据">导入数据</span></h1><p><code>Dataset</code> API使您能够构建复杂的输入管道 简单，可重复使用的作品。例如，图像模型的管道可能会 从分布式文件系统中的文件汇总数据，随机应用<br>扰动每个图像，并将随机选择的图像合并为一批 为了训练。文本模型的管道可能涉及提取符号 从原始文本数据，将其转换为查找嵌入标识符<br>表，并将不同长度的序列分配在一起。 <code>Dataset</code> API 可以轻松处理大量的数据，不同的数据格式 复杂的转变。</p>
<p><code>Dataset</code> API为TensorFlow引入了两个新的抽象：</p>
<p><code>tf.data.Dataset</code>代表一系列元素，其中   每个元素包含一个或多个<code>Tensor</code>对象。例如，在一个图像<br>管道，一个元素可能是一个训练的例子，有一对   张量表示图像数据和标签。有两个截然不同的   创建数据集的方法：<br>创建一个源（例如<code>Dataset.from_tensor_slices()</code>）构建一个     数据集     一个或多个<code>tf.Tensor</code>对象。<br>应用转换（例如<code>Dataset.batch()</code>）构建数据集     来自一个或多个<code>tf.data.Dataset</code>对象。<br>一个<code>tf.data.Iterator</code>提供了从一个提取元素的主要方法   数据集。由<code>Iterator.get_next()</code>返回的操作产生下一个<br><code>Dataset</code>的元件在执行时通常用作接口   输入管道代码和你的模型之间。最简单的迭代器是a   “一次迭代器”，它与一个特定的<code>Dataset</code>和<br>迭代一次。对于更复杂的用途，   <code>Iterator.initializer</code>操作使您能够重新初始化和参数化   一个具有不同数据集的迭代器，以便您可以迭代<br>在同一个程序中多次训练和验证数据。</p>
<h2><span id="基本力学">基本力学</span></h2><p>本指南的这一部分描述了创建不同种类的基础知识 <code>Dataset</code>和<code>Iterator</code>的对象，以及如何从中提取数据。</p>
<p>要启动输入管道，您必须定义一个源。例如， 从记忆中的一些张量构建一个<code>Dataset</code>，就可以使用<br><code>tf.data.Dataset.from_tensors()</code>或<br><code>tf.data.Dataset.from_tensor_slices()</code>。或者，如果你的输入 数据在推荐的TFRecord格式磁盘上，你可以构造一个<br><code>tf.data.TFRecordDataset</code>。</p>
<p>一旦你有一个<code>Dataset</code>的对象，你可以转换成一个新的<code>Dataset</code> 链接方法调用<code>tf.data.Dataset</code>对象。例如，你<br>可以应用每元素转换，如<code>Dataset.map()</code>（申请一个 函数到每个元素）和多元素转换，如<br><code>Dataset.batch()</code>。请参阅<code>tf.data.Dataset</code>的文档 为完整的转换列表。</p>
<p>从<code>Dataset</code>中消费数值的最常用方法是制作一个 迭代器对象，一次提供对数据集的一个元素的访问<br>（例如，通过调用<code>Dataset.make_one_shot_iterator()</code>）。一个<br><code>tf.data.Iterator</code>提供两种操作：<code>Iterator.initializer</code>， 它使您能够（重新）初始化迭代器的状态;和<br><code>Iterator.get_next()</code>，它返回对应的<code>tf.Tensor</code>对象 象征性的下一个元素。根据你的用例，你可能会选择一个不同的<br>迭代器类型，下面列出了选项。</p>
<h3><span id="数据集结构">数据集结构</span></h3><p>数据集包含各自具有相同结构的元素。一个元素 包含一个或多个称为组件的<code>tf.Tensor</code>对象。每个组件 <code>tf.DType</code>代表张量中元素的类型，a<br><code>tf.TensorShape</code>代表（可能部分指定）的静态形状 每个元素。<br><code>Dataset.output_types</code>和<code>Dataset.output_shapes</code>属性 允许您检查a的每个组件的推断类型和形状<br>数据集元素。这些属性的嵌套结构映射到结构 一个元素，它可能是单张量，张量元组或嵌套 张量元组。例如：</p>
<pre><code>dataset1 = tf.data.Dataset.from_tensor_slices(tf.random_uniform([4, 10]))
print(dataset1.output_types)  # ==&gt; &quot;tf.float32&quot;
print(dataset1.output_shapes)  # ==&gt; &quot;(10,)&quot;

dataset2 = tf.data.Dataset.from_tensor_slices(
   (tf.random_uniform([4]),
    tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)))
print(dataset2.output_types)  # ==&gt; &quot;(tf.float32, tf.int32)&quot;
print(dataset2.output_shapes)  # ==&gt; &quot;((), (100,))&quot;

dataset3 = tf.data.Dataset.zip((dataset1, dataset2))
print(dataset3.output_types)  # ==&gt; (tf.float32, (tf.float32, tf.int32))
print(dataset3.output_shapes)  # ==&gt; &quot;(10, ((), (100,)))&quot;
</code></pre><p>为一个元素的每个元素命名通常很方便 例如，如果它们表示训练示例的不同特征。此外<br>到元组，可以使用<code>collections.namedtuple</code>或字典映射字符串 张量来代表<code>Dataset</code>的单个元素。</p>
<pre><code>dataset = tf.data.Dataset.from_tensor_slices(
   {&quot;a&quot;: tf.random_uniform([4]),
    &quot;b&quot;: tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)})
print(dataset.output_types)  # ==&gt; &quot;{&apos;a&apos;: tf.float32, &apos;b&apos;: tf.int32}&quot;
print(dataset.output_shapes)  # ==&gt; &quot;{&apos;a&apos;: (), &apos;b&apos;: (100,)}&quot;
</code></pre><p><code>Dataset</code>转换支持任何结构的数据集。使用时<br><code>Dataset.map()</code>，<code>Dataset.flat_map()</code>和<code>Dataset.filter()</code>转化，<br>它将一个函数应用到每个元素，元素的结构决定了 函数的参数：</p>
<pre><code>dataset1 = dataset1.map(lambda x: ...)

dataset2 = dataset2.flat_map(lambda x, y: ...)

# Note: Argument destructuring is not available in Python 3.
dataset3 = dataset3.filter(lambda x, (y, z): ...)
</code></pre><h3><span id="创建一个迭代器">创建一个迭代器</span></h3><p>一旦你建立了一个<code>Dataset</code>来表示你的输入数据，下一步就是 创建一个<code>Iterator</code>来访问该数据集中的元素。 <code>Dataset</code> API<br>目前支持以下迭代器，在增加级别 成熟：</p>
<p>一次性的， initializable， 可重新初始化和 可补给。</p>
<p>一次迭代器是仅支持的最简单的迭代器形式 迭代一次数据集，而不需要显式的初始化。 一次迭代器处理几乎所有现有的基于队列的情况<br>输入管道支持，但不支持参数化。使用 <code>Dataset.range()</code>的示例：</p>
<pre><code>dataset = tf.data.Dataset.range(100)
iterator = dataset.make_one_shot_iterator()
next_element = iterator.get_next()

for i in range(100):
  value = sess.run(next_element)
  assert i == value
</code></pre><p>注意：目前，一次迭代器是唯一可以轻松使用的类型 与<code>Estimator</code>。</p>
<p>一个可初始化的迭代器需要你运行一个显式的 <code>iterator.initializer</code>的使用方法。作为交换 不方便，它使您能够参数化数据集的定义，<br>使用一个或多个可在您喂食的<code>tf.placeholder()</code>张量 初始化迭代器。继续<code>Dataset.range()</code>示例：</p>
<pre><code>max_value = tf.placeholder(tf.int64, shape=[])
dataset = tf.data.Dataset.range(max_value)
iterator = dataset.make_initializable_iterator()
next_element = iterator.get_next()

# Initialize an iterator over a dataset with 10 elements.
sess.run(iterator.initializer, feed_dict={max_value: 10})
for i in range(10):
  value = sess.run(next_element)
  assert i == value

# Initialize the same iterator over a dataset with 100 elements.
sess.run(iterator.initializer, feed_dict={max_value: 100})
for i in range(100):
  value = sess.run(next_element)
  assert i == value
</code></pre><p>可重新初始化的迭代器可以从多个不同的初始化 <code>Dataset</code>物体。例如，您可能有一个培训输入管道 对输入图像使用随机扰动来改善泛化，<br>验证输入管道，用于评估未修改数据的预测。这些 管道通常会使用具有相同的不同<code>Dataset</code>对象 结构（即，每个部件的相同类型和相容的形状）。</p>
<pre><code># Define training and validation datasets with the same structure.
training_dataset = tf.data.Dataset.range(100).map(
    lambda x: x + tf.random_uniform([], -10, 10, tf.int64))
validation_dataset = tf.data.Dataset.range(50)

# A reinitializable iterator is defined by its structure. We could use the
# `output_types` and `output_shapes` properties of either `training_dataset`
# or `validation_dataset` here, because they are compatible.
iterator = Iterator.from_structure(training_dataset.output_types,
                                   training_dataset.output_shapes)
next_element = iterator.get_next()

training_init_op = iterator.make_initializer(training_dataset)
validation_init_op = iterator.make_initializer(validation_dataset)

# Run 20 epochs in which the training dataset is traversed, followed by the
# validation dataset.
for _ in range(20):
  # Initialize an iterator over the training dataset.
  sess.run(training_init_op)
  for _ in range(100):
    sess.run(next_element)

  # Initialize an iterator over the validation dataset.
  sess.run(validation_init_op)
  for _ in range(50):
    sess.run(next_element)
</code></pre><p>可馈入迭代器可与<code>tf.placeholder</code>一起使用进行选择 <code>Iterator</code>在每次<code>tf.Session.run</code>呼叫中使用什么<br><code>feed_dict</code>机制。它提供了与可重新初始化相同的功能 迭代器，但它不要求你从头开始初始化迭代器 在迭代器之间切换时，数据集的数据集。例如，使用相同的<br>从上面的培训和验证的例子，你可以使用 <code>tf.data.Iterator.from_string_handle</code>定义一个可馈送的迭代器<br>这使您可以在两个数据集之间切换：</p>
<pre><code># Define training and validation datasets with the same structure.
training_dataset = tf.data.Dataset.range(100).map(
    lambda x: x + tf.random_uniform([], -10, 10, tf.int64)).repeat()
validation_dataset = tf.data.Dataset.range(50)

# A feedable iterator is defined by a handle placeholder and its structure. We
# could use the `output_types` and `output_shapes` properties of either
# `training_dataset` or `validation_dataset` here, because they have
# identical structure.
handle = tf.placeholder(tf.string, shape=[])
iterator = tf.data.Iterator.from_string_handle(
    handle, training_dataset.output_types, training_dataset.output_shapes)
next_element = iterator.get_next()

# You can use feedable iterators with a variety of different kinds of iterator
# (such as one-shot and initializable iterators).
training_iterator = training_dataset.make_one_shot_iterator()
validation_iterator = validation_dataset.make_initializable_iterator()

# The `Iterator.string_handle()` method returns a tensor that can be evaluated
# and used to feed the `handle` placeholder.
training_handle = sess.run(training_iterator.string_handle())
validation_handle = sess.run(validation_iterator.string_handle())

# Loop forever, alternating between training and validation.
while True:
  # Run 200 steps using the training dataset. Note that the training dataset is
  # infinite, and we resume from where we left off in the previous `while` loop
  # iteration.
  for _ in range(200):
    sess.run(next_element, feed_dict={handle: training_handle})

  # Run one pass over the validation dataset.
  sess.run(validation_iterator.initializer)
  for _ in range(50):
    sess.run(next_element, feed_dict={handle: validation_handle})
</code></pre><h3><span id="从迭代器中消费值">从迭代器中消费值</span></h3><p><code>Iterator.get_next()</code>方法返回一个或多个<code>tf.Tensor</code>对象 对应于迭代器的符号下一个元素。每次这些张量<br>被评估，他们采取底层的下一个元素的值 数据集。 （请注意，像TensorFlow中的其他有状态对象一样，调用<br><code>Iterator.get_next()</code>不会立即推进迭代器。相反，你 必须在TensorFlow表达式中使用返回的<code>tf.Tensor</code>对象，并通过<br><code>tf.Session.run()</code>的表达结果得到下一个元素和 推进迭代器。）</p>
<p>如果迭代器到达数据集的末尾，则执行 <code>Iterator.get_next()</code>将提升<code>tf.errors.OutOfRangeError</code>。<br>在这一点之后，迭代器将处于不可用状态，并且您必须 如果你想进一步使用它，再次初始化它。</p>
<pre><code>dataset = tf.data.Dataset.range(5)
iterator = dataset.make_initializable_iterator()
next_element = iterator.get_next()

# Typically `result` will be the output of a model, or an optimizer&apos;s
# training operation.
result = tf.add(next_element, next_element)

sess.run(iterator.initializer)
print(sess.run(result))  # ==&gt; &quot;0&quot;
print(sess.run(result))  # ==&gt; &quot;2&quot;
print(sess.run(result))  # ==&gt; &quot;4&quot;
print(sess.run(result))  # ==&gt; &quot;6&quot;
print(sess.run(result))  # ==&gt; &quot;8&quot;
try:
  sess.run(result)
except tf.errors.OutOfRangeError:
  print(&quot;End of dataset&quot;)  # ==&gt; &quot;End of dataset&quot;
</code></pre><p><code>try</code>-<code>except</code>程序段中包含“训练循环”的常用模式：</p>
<pre><code>sess.run(iterator.initializer)
while True:
  try:
    sess.run(result)
  except tf.errors.OutOfRangeError:
    break
</code></pre><p>如果数据集的每个元素都有嵌套结构，则返回值为 <code>Iterator.get_next()</code>将是同一个或多个<code>tf.Tensor</code>物件 嵌套结构：</p>
<pre><code>dataset1 = tf.data.Dataset.from_tensor_slices(tf.random_uniform([4, 10]))
dataset2 = tf.data.Dataset.from_tensor_slices((tf.random_uniform([4]), tf.random_uniform([4, 100])))
dataset3 = tf.data.Dataset.zip((dataset1, dataset2))

iterator = dataset3.make_initializable_iterator()

sess.run(iterator.initializer)
next1, (next2, next3) = iterator.get_next()
</code></pre><p>请注意，对<code>next1</code>，<code>next2</code>或<code>next3</code>进行评估将推动 所有组件的迭代器。一个迭代器的典型消费者将包括所有 组件在一个单一的表达。</p>
<h2><span id="读取输入数据">读取输入数据</span></h2><h3><span id="使用numpy数组">使用NumPy数组</span></h3><p>如果所有的输入数据都适合内存，那么创建一个<code>Dataset</code>的最简单的方法就是使用它 从他们是把它们转换成<code>tf.Tensor</code>对象并使用<br><code>Dataset.from_tensor_slices()</code>。</p>
<pre><code># Load the training data into two NumPy arrays, for example using `np.load()`.
with np.load(&quot;/var/data/training_data.npy&quot;) as data:
  features = data[&quot;features&quot;]
  labels = data[&quot;labels&quot;]

# Assume that each row of `features` corresponds to the same row as `labels`.
assert features.shape[0] == labels.shape[0]

dataset = tf.data.Dataset.from_tensor_slices((features, labels))
</code></pre><p>请注意，上面的代码片段将嵌入<code>features</code>和<code>labels</code>阵列 在您的TensorFlow图中作为<code>tf.constant()</code>的操作。这适用于一个<br>小数据集，但浪费内存—因为数组的内容将是 复制多次—可以达到<code>tf.GraphDef</code>的2GB限制 协议缓冲区。</p>
<p>作为替代，您可以根据<code>Dataset</code>定义<code>tf.placeholder()</code> 张量，并在您初始化<code>Iterator</code>时提供NumPy阵列 数据集。</p>
<pre><code># Load the training data into two NumPy arrays, for example using `np.load()`.
with np.load(&quot;/var/data/training_data.npy&quot;) as data:
  features = data[&quot;features&quot;]
  labels = data[&quot;labels&quot;]

# Assume that each row of `features` corresponds to the same row as `labels`.
assert features.shape[0] == labels.shape[0]

features_placeholder = tf.placeholder(features.dtype, features.shape)
labels_placeholder = tf.placeholder(labels.dtype, labels.shape)

dataset = tf.data.Dataset.from_tensor_slices((features_placeholder, labels_placeholder))
# [Other transformations on `dataset`...]
dataset = ...
iterator = dataset.make_initializable_iterator()

sess.run(iterator.initializer, feed_dict={features_placeholder: features,
                                          labels_placeholder: labels})
</code></pre><h3><span id="消费tfrecord数据">消费TFRecord数据</span></h3><p><code>Dataset</code> API支持多种文件格式，以便进行处理 大数据集不适合内存。例如，TFRecord文件格式<br>是许多TensorFlow应用程序使用的简单的面向记录的二进制格式 用于训练数据。 <code>tf.data.TFRecordDataset</code>级可以让您<br>将一个或多个TFRecord文件的内容作为输入的一部分进行流式传输 管道。</p>
<pre><code># Creates a dataset that reads all of the examples from two files.
filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
</code></pre><p><code>filenames</code>初始化程序的<code>TFRecordDataset</code>参数可以是 字符串，字符串列表或<code>tf.Tensor</code>字符串。因此，如果你有<br>两套文件供培训和验证之用，可以使用一个 <code>tf.placeholder(tf.string)</code>来表示文件名，并初始化一个 迭代器从适当的文件名：</p>
<pre><code>filenames = tf.placeholder(tf.string, shape=[None])
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(...)  # Parse the record into tensors.
dataset = dataset.repeat()  # Repeat the input indefinitely.
dataset = dataset.batch(32)
iterator = dataset.make_initializable_iterator()

# You can feed the initializer with the appropriate filenames for the current
# phase of execution, e.g. training vs. validation.

# Initialize `iterator` with training data.
training_filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
sess.run(iterator.initializer, feed_dict={filenames: training_filenames})

# Initialize `iterator` with validation data.
validation_filenames = [&quot;/var/data/validation1.tfrecord&quot;, ...]
sess.run(iterator.initializer, feed_dict={filenames: validation_filenames})
</code></pre><h3><span id="消费文本数据">消费文本数据</span></h3><p>许多数据集分布为一个或多个文本文件。该 <code>tf.data.TextLineDataset</code>提供了一个简单的方法来提取线路<br>一个或多个文本文件。给定一个或多个文件名，<code>TextLineDataset</code>将 产生这些文件的每行一个字符串值的元素。像一个<br><code>TFRecordDataset</code>，<code>TextLineDataset</code>可接受<code>filenames</code>作为<code>tf.Tensor</code><br>您可以通过传递<code>tf.placeholder(tf.string)</code>来进行参数化。</p>
<pre><code>filenames = [&quot;/var/data/file1.txt&quot;, &quot;/var/data/file2.txt&quot;]
dataset = tf.data.TextLineDataset(filenames)
</code></pre><p>默认情况下，<code>TextLineDataset</code>会产生每个文件的每一行，这可能是 不是所希望的，例如，如果文件以标题行或包含开始<br>注释。这些线可以使用<code>Dataset.skip()</code>和 <code>Dataset.filter()</code>转换。将这些转换应用于每个转换<br>我们使用<code>Dataset.flat_map()</code>创建一个嵌套的<code>Dataset</code> 每个文件。</p>
<pre><code>filenames = [&quot;/var/data/file1.txt&quot;, &quot;/var/data/file2.txt&quot;]

dataset = tf.data.Dataset.from_tensor_slices(filenames)

# Use `Dataset.flat_map()` to transform each file as a separate nested dataset,
# and then concatenate their contents sequentially into a single &quot;flat&quot; dataset.
# * Skip the first line (header row).
# * Filter out lines beginning with &quot;#&quot; (comments).
dataset = dataset.flat_map(
    lambda filename: (
        tf.data.TextLineDataset(filename)
        .skip(1)
        .filter(lambda line: tf.not_equal(tf.substr(line, 0, 1), &quot;#&quot;))))
</code></pre><p>有关使用数据集解析CSV文件的完整示例，请参阅<code>imports85.py</code> 在回归的例子。</p>
<h2><span id="用datasetmap预处理数据">用<code>Dataset.map()</code>预处理数据</span></h2><p><code>Dataset.map(f)</code>转换通过应用给定的方法产生一个新的数据集 功能<code>f</code>到输入数据集的每个元素。它基于 该 <code>map()</code>功能<br>这是通常适用于功能列表（和其他结构） 编程语言。功能<code>f</code>使用<code>tf.Tensor</code>对象 表示输入中的单个元素，并返回<code>tf.Tensor</code>对象<br>这将代表新数据集中的单个元素。它的实现使用 标准的TensorFlow操作将一个元素转换成另一个元素。</p>
<p>本节介绍如何使用<code>Dataset.map()</code>的常用示例。</p>
<h3><span id="解析tfexample协议缓冲区信息">解析<code>tf.Example</code>协议缓冲区信息</span></h3><p>许多输入流水线从a中提取<code>tf.train.Example</code>协议缓冲区消息 TFRecord格式的文件（例如，使用<br><code>tf.python_io.TFRecordWriter</code>）。每个<code>tf.train.Example</code>记录包含一个或者一个<br>更多的“功能”，输入管道通常将这些功能转换成 张量。</p>
<pre><code># Transforms a scalar string `example_proto` into a pair of a scalar string and
# a scalar integer, representing an image and its label, respectively.
def _parse_function(example_proto):
  features = {&quot;image&quot;: tf.FixedLenFeature((), tf.string, default_value=&quot;&quot;),
              &quot;label&quot;: tf.FixedLenFeature((), tf.int32, default_value=0)}
  parsed_features = tf.parse_single_example(example_proto, features)
  return parsed_features[&quot;image&quot;], parsed_features[&quot;label&quot;]

# Creates a dataset that reads all of the examples from two files, and extracts
# the image and label features.
filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(_parse_function)
</code></pre><h3><span id="解码图像数据并调整大小">解码图像数据并调整大小</span></h3><p>当在真实世界的图像数据上训练神经网络时，通常是必要的 把不同大小的图像转换成一个通用的大小，以便它们可以 分批成一个固定的大小。</p>
<pre><code># Reads an image from a file, decodes it into a dense tensor, and resizes it
# to a fixed shape.
def _parse_function(filename, label):
  image_string = tf.read_file(filename)
  image_decoded = tf.image.decode_image(image_string)
  image_resized = tf.image.resize_images(image_decoded, [28, 28])
  return image_resized, label

# A vector of filenames.
filenames = tf.constant([&quot;/var/data/image1.jpg&quot;, &quot;/var/data/image2.jpg&quot;, ...])

# `labels[i]` is the label for the image in `filenames[i].
labels = tf.constant([0, 37, ...])

dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))
dataset = dataset.map(_parse_function)
</code></pre><h3><span id="应用tfpy_func的任意python逻辑">应用<code>tf.py_func()</code>的任意Python逻辑</span></h3><p>出于性能原因，我们鼓励您使用TensorFlow操作 尽可能预处理您的数据。但是，它有时是有用的 解析输入数据时调用外部Python库。为此，<br>调用<code>tf.py_func()</code>转换中的<code>Dataset.map()</code>操作。</p>
<pre><code>import cv2

# Use a custom OpenCV function to read the image, instead of the standard
# TensorFlow `tf.read_file()` operation.
def _read_py_function(filename, label):
  image_decoded = cv2.imread(image_string, cv2.IMREAD_GRAYSCALE)
  return image_decoded, label

# Use standard TensorFlow operations to resize the image to a fixed shape.
def _resize_function(image_decoded, label):
  image_decoded.set_shape([None, None, None])
  image_resized = tf.image.resize_images(image_decoded, [28, 28])
  return image_resized, label

filenames = [&quot;/var/data/image1.jpg&quot;, &quot;/var/data/image2.jpg&quot;, ...]
labels = [0, 37, 29, 1, ...]

dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))
dataset = dataset.map(
    lambda filename, label: tuple(tf.py_func(
        _read_py_function, [filename, label], [tf.uint8, label.dtype])))
dataset = dataset.map(_resize_function)
</code></pre><h2><span id="批处理数据集元素">批处理数据集元素</span></h2><h3><span id="简单的配料">简单的配料</span></h3><p><code>n</code>连续数据集元素的最简单的批处理形式 一个单一的元素。 <code>Dataset.batch()</code>转换就是这样做的<br>与<code>tf.stack()</code>操作员相同的约束适用于每个组件 的元素：即对于每个元素i，所有元素必须具有张量 完全相同的形状。</p>
<pre><code>inc_dataset = tf.data.Dataset.range(100)
dec_dataset = tf.data.Dataset.range(0, -100, -1)
dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))
batched_dataset = dataset.batch(4)

iterator = batched_dataset.make_one_shot_iterator()
next_element = iterator.get_next()

print(sess.run(next_element))  # ==&gt; ([0, 1, 2,   3],   [ 0, -1,  -2,  -3])
print(sess.run(next_element))  # ==&gt; ([4, 5, 6,   7],   [-4, -5,  -6,  -7])
print(sess.run(next_element))  # ==&gt; ([8, 9, 10, 11],   [-8, -9, -10, -11])
</code></pre><h3><span id="用填料分批张量">用填料分批张量</span></h3><p>上面的配方适用于所有尺寸相同的张量。但是，很多 模型（例如序列模型）与可能具有不同大小的输入数据一起工作 （例如不同长度的序列）。为了处理这种情况，<br><code>Dataset.padded_batch()</code>转换使您能够批量张量 通过指定一个或多个维度来指定不同的形状 填充。</p>
<pre><code>dataset = tf.data.Dataset.range(100)
dataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))
dataset = dataset.padded_batch(4, padded_shapes=[None])

iterator = dataset.make_one_shot_iterator()
next_element = iterator.get_next()

print(sess.run(next_element))  # ==&gt; [[0, 0, 0], [1, 0, 0], [2, 2, 0], [3, 3, 3]]
print(sess.run(next_element))  # ==&gt; [[4, 4, 4, 4, 0, 0, 0],
                               #      [5, 5, 5, 5, 5, 0, 0],
                               #      [6, 6, 6, 6, 6, 6, 0],
                               #      [7, 7, 7, 7, 7, 7, 7]]
</code></pre><p><code>Dataset.padded_batch()</code>转换允许您设置不同的填充 为每个组件的每个维度，它可能是可变长度（表示<br>在上面的例子中由<code>None</code>）或恒定长度。也有可能 重写填充值，默认为0。</p>
<h2><span id="培训工作流程">培训工作流程</span></h2><h3><span id="处理多个时代">处理多个时代</span></h3><p><code>Dataset</code> API提供了两种主要的方法来处理多个相同的历元 数据。</p>
<p>在多个时期迭代数据集的最简单方法是使用 <code>Dataset.repeat()</code>转换。例如，创建重复的数据集 它的输入为10个时期：</p>
<pre><code>filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(...)
dataset = dataset.repeat(10)
dataset = dataset.batch(32)
</code></pre><p>将不重复应用<code>Dataset.repeat()</code>转换 输入无限期。 <code>Dataset.repeat()</code>转换将其连接起来<br>而不是一个时代的结束和下一个开始的信号 时代。</p>
<p>如果你想在每个纪元结束时收到一个信号，你可以写一个 训练循环捕捉到<code>tf.errors.OutOfRangeError</code>的末尾<br>数据集。在这一点上，你可能会收集一些统计数据（例如验证 错误）的时代。</p>
<pre><code>filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(...)
dataset = dataset.batch(32)
iterator = dataset.make_initializable_iterator()
next_element = iterator.get_next()

# Compute for 100 epochs.
for _ in range(100):
  sess.run(iterator.initializer)
  while True:
    try:
      sess.run(next_element)
    except tf.errors.OutOfRangeError:
      break

  # [Perform end-of-epoch calculations here.]
</code></pre><h3><span id="随机洗牌输入数据">随机洗牌输入数据</span></h3><p><code>Dataset.shuffle()</code>变换随机混洗输入数据集 使用与<code>tf.RandomShuffleQueue</code>类似的算法：它保持固定大小<br>缓冲区并从该缓冲区中随机选择下一个元素。</p>
<pre><code>filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(...)
dataset = dataset.shuffle(buffer_size=10000)
dataset = dataset.batch(32)
dataset = dataset.repeat()
</code></pre><h3><span id="使用高级api">使用高级API</span></h3><p><code>tf.train.MonitoredTrainingSession</code> API简化了运行的许多方面 TensorFlow在分布式设置中。<br><code>MonitoredTrainingSession</code>使用的 <code>tf.errors.OutOfRangeError</code>表示训练已经完成，所以使用它<br>使用<code>Dataset</code> API，我们推荐使用 <code>Dataset.make_one_shot_iterator()</code>。例如：</p>
<pre><code>filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(...)
dataset = dataset.shuffle(buffer_size=10000)
dataset = dataset.batch(32)
dataset = dataset.repeat(num_epochs)
iterator = dataset.make_one_shot_iterator()

next_example, next_label = iterator.get_next()
loss = model_function(next_example, next_label)

training_op = tf.train.AdagradOptimizer(...).minimize(loss)

with tf.train.MonitoredTrainingSession(...) as sess:
  while not sess.should_stop():
    sess.run(training_op)
</code></pre><p>要在<code>Dataset</code>的<code>input_fn</code>中使用<code>tf.estimator.Estimator</code>，我们也<br>推荐使用<code>Dataset.make_one_shot_iterator()</code>。例如：</p>
<pre><code>def dataset_input_fn():
  filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
  dataset = tf.data.TFRecordDataset(filenames)

  # Use `tf.parse_single_example()` to extract data from a `tf.Example`
  # protocol buffer, and perform any additional per-record preprocessing.
  def parser(record):
    keys_to_features = {
        &quot;image_data&quot;: tf.FixedLenFeature((), tf.string, default_value=&quot;&quot;),
        &quot;date_time&quot;: tf.FixedLenFeature((), tf.int64, default_value=&quot;&quot;),
        &quot;label&quot;: tf.FixedLenFeature((), tf.int64,
                                    default_value=tf.zeros([], dtype=tf.int64)),
    }
    parsed = tf.parse_single_example(record, keys_to_features)

    # Perform additional preprocessing on the parsed data.
    image = tf.decode_jpeg(parsed[&quot;image_data&quot;])
    image = tf.reshape(image, [299, 299, 1])
    label = tf.cast(parsed[&quot;label&quot;], tf.int32)

    return {&quot;image_data&quot;: image, &quot;date_time&quot;: parsed[&quot;date_time&quot;]}, label

  # Use `Dataset.map()` to build a pair of a feature dictionary and a label
  # tensor for each example.
  dataset = dataset.map(parser)
  dataset = dataset.shuffle(buffer_size=10000)
  dataset = dataset.batch(32)
  dataset = dataset.repeat(num_epochs)
  iterator = dataset.make_one_shot_iterator()

  # `features` is a dictionary in which each value is a batch of values for
  # that feature; `labels` is a batch of labels.
  features, labels = iterator.get_next()
  return features, labels
</code></pre>
        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/linking_libs/" title="集成TensorFlow库" itemprop="url">集成TensorFlow库</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="集成tensorflow库">集成TensorFlow库</span></h1><p>一旦你在模型上取得了一些进展，解决你的问题 试图解决，重要的是在你的应用程序内部进行测试 立即。您的训练数据通常有意想不到的差异<br>以及用户在真实世界中遇到的情况，并获得清晰的图像 的差距，尽快提高产品体验。</p>
<p>本页面讨论如何将TensorFlow库集成到您自己的 移动应用程序，一旦你已经成功地建立和部署了 TensorFlow移动演示应用程序。</p>
<h2><span id="链接库">链接库</span></h2><p>在设法构建示例之后，您可能需要打电话 来自您现有应用程序的TensorFlow。最简单的方法 这是使用描述的Pod安装步骤<br>这里，但如果你想建立TensorFlow 从源代码（例如，自定义哪些运算符包含在内），您将需要 打破TensorFlow框架，包括正确的头文件和链接<br>针对构建的库和依赖项。</p>
<h3><span id="android的">Android的</span></h3><p>对于Android，您只需链接JAR文件中包含的Java库<br>称为<code>libandroid_tensorflow_inference_java.jar</code>。有三种方法 在你的程序中包含这个功能：</p>
<p>包含包含它的jcenter AAR，就像这样  示例应用程序 从下载每晚预编译的版本 ci.tensorflow.org。 使用我们的Android<br>Github回购中的说明自行构建JAR文件</p>
<h3><span id="ios版">iOS版</span></h3><p>在iOS上调用TensorFlow库会稍微复杂一些。这是 一个清单，你需要做什么到你的iOS应用程序：</p>
<p>与tensorflow / contrib / makefile / gen / lib / libtensorflow-core.a链接，通常<br>通过加入<code>-L/your/path/tensorflow/contrib/makefile/gen/lib/</code>和   <code>-ltensorflow-
core</code>添加到您的链接器标志。 通过添加链接与生成的protobuf库<br><code>-L/your/path/tensorflow/contrib/makefile/gen/protobuf_ios/lib</code>和<br><code>-lprotobuf</code>和<code>-lprotobuf-lite</code>到您的命令行。 对于包含路径，您需要TensorFlow源文件夹的根目录   第一个入口，之后<br><code>tensorflow/contrib/makefile/downloads/protobuf/src</code>，<br><code>tensorflow/contrib/makefile/downloads</code>，<br><code>tensorflow/contrib/makefile/downloads/eigen</code>，和<br><code>tensorflow/contrib/makefile/gen/proto</code>。 确保你的二进制文件是用<code>-force_load</code>（或者你的<br>平台），针对TensorFlow库确保链接   正确。关于为什么这是必要的更多细节可以在下面找到   部分，全球构造魔术。在Linux上<br>平台，你需要不同的标志，更像   <code>-Wl,--allow-multiple-definition -Wl,--whole-archive</code>。</p>
<p>您还需要链接加速器框架，因为这是用来 加快了一些操作。</p>
<h2><span id="全球构造魔术">全球构造魔术</span></h2><p>你可能遇到的最微妙的问题之一是“没有会话工厂 在尝试调用TensorFlow时出错 从你自己的应用程序。了解为什么会发生这种情况，以及如何解决<br>它，你需要了解一下TensorFlow的架构。</p>
<p>框架被设计成非常模块化的，有一个薄的核心和一个大的 独立的特定对象的数量，可以混合匹配 需要。为了实现这一点，C ++中的编码模式不得不让模块容易<br>通知框架有关他们提供的服务，而不需要中央 列表必须与每个实现分开更新。它也必须 允许单独的库添加自己的实现，而不需要一个 重新编译核心。</p>
<p>为了实现这个功能，TensorFlow使用了很多的注册模式 地方。在代码中，它看起来像这样：</p>
<pre><code>class MulKernel : OpKernel {
  Status Compute(OpKernelContext* context) { … }
};
REGISTER_KERNEL(MulKernel, &quot;Mul&quot;);
</code></pre><p>这将在独立的<code>.cc</code>文件中链接到您的应用程序中 作为主要内核集的一部分或作为单独的自定义库。魔术<br>部分是<code>REGISTER_KERNEL()</code>宏能通知核心的 它有一个执行Mul操作的TensorFlow，所以它可以 在需要它的任何图表中调用。</p>
<p>从编程的角度来看，这个设置非常方便。该 实现和注册码在同一个文件中，并添加新的 实现就像编译和链接它一样简单。困难的部分<br>来自<code>REGISTER_KERNEL()</code>宏的实现方式。 C ++ 没有提供这样的注册的好机制，所以我们有 诉诸一些棘手的代码。在引擎盖下，宏是这样实现的<br>它产生这样的东西：</p>
<pre><code>class RegisterMul {
 public:
  RegisterMul() {
    global_kernel_registry()-&gt;Register(&quot;Mul&quot;, [](){
      return new MulKernel()
    });
  }
};
RegisterMul g_register_mul;
</code></pre><p>这建立了一个类<code>RegisterMul</code>与一个构造函数，告诉全球 内核注册表有什么功能，当有人问如何创建一个<br>“Mul”核心。那么这个类就有一个全局对象，所以就是构造函数 应该在任何程序开始时被调用。</p>
<p>虽然这听起来很合理，但不幸的是，这个全球性的对象 这是定义不被任何其他代码使用，所以链接器不是用这个设计的 记住会决定可以删除。结果，构造函数是<br>从来没有打过电话，而且这个班从来没有注册各种各样的模块使用这个 模式在TensorFlow中，而<code>Session</code>的实现就是这样的<br>首先要查找代码运行的时间，这就是为什么它显示为 发生此问题时的特征错误。</p>
<p>解决的办法是强制链接器不去掉库中的任何代码，甚至 如果它认为它没有被使用。在iOS上，这一步可以用<br><code>-force_load</code>标志，指定一个库路径，在你需要的Linux上 <code>--whole-archive</code>。这些说服连接器不要那么咄咄逼人<br>剥离，应保留全局。</p>
<p>各种<code>REGISTER_*</code>宏的实际执行情况稍多一些 在实践中很复杂，但都遭受同样的根本问题。如果 你感兴趣的是它们如何工作，op_kernel.h<br>是开始调查的好地方。</p>
<h2><span id="protobuf问题">Protobuf问题</span></h2><p>TensorFlow依靠 协议缓冲区库， 俗称protobuf。这个库需要数据结构的定义 并为它们生成各种序列化和访问代码<br>语言。棘手的部分是这个生成的代码需要被链接 针对共享库的完全相同版本的框架 用于发电机。 <code>protoc</code>，这个工具可以用来解决这个问题<br>生成的代码，是从不同版本的protobuf比库中 标准链接和包含路径。例如，您可能正在使用副本<br>在<code>protoc</code>本地制造的<code>~/projects/protobuf-3.0.1.a</code>，但你有<br>安装在<code>/usr/local/lib</code>和<code>/usr/local/include</code>上的库 3.0.0。</p>
<p>此问题的症状在编译或链接阶段出现错误 与protobufs。通常，构建工具会照顾到这一点，但是如果你正在使用<br>makefile，确保你在本地构建protobuf库并使用 它，如这个Makefile所示。</p>
<p>另一种可能导致问题的情况是protobuf头文件和源文件 文件需要作为构建过程的一部分生成。这个过程使得 建设更复杂，因为第一阶段必须是通过protobuf<br>定义来创建所有需要的代码文件，只有在这之后，你可以去 提前做一个库代码的构建。</p>
<h3><span id="在同一个应用程序中的多个版本的protobufs">在同一个应用程序中的多个版本的protobufs</span></h3><p>Protobufs生成头文件，这是C ++接口的一部分 整体TensorFlow库。这使图书馆作为独立使用变得复杂 框架。</p>
<p>如果您的应用程序已经在使用协议缓冲区库的版本1， 您可能无法集成TensorFlow，因为它需要版本2<br>你只是尝试将两个版本链接到相同的二进制文件，你会看到链接 错误，因为一些符号冲突。为了解决这个特殊的问题，我们<br>在rename_protobuf.sh上有一个实验脚本。</p>
<p>在下载全部文件之后，您需要将其作为makefile版本的一部分来运行 依赖关系：</p>
<pre><code>tensorflow/contrib/makefile/download_dependencies.sh
tensorflow/contrib/makefile/rename_protobuf.sh
</code></pre><h2><span id="调用tensorflow-api">调用TensorFlow API</span></h2><p>一旦你有框架可用，你需要调用它。通常 模式是，你首先加载你的模型，它代表一个预设的集合 数字计算，然后通过该模型运行输入（例如，<br>来自相机的图像）和接收输出（例如，预测的标签）。</p>
<p>在Android上，我们提供了专注于此的Java推理库 用例，而在iOS和Raspberry Pi上，您可以直接调用C ++ API。</p>
<h3><span id="android的">Android的</span></h3><p>以下是典型的推理库序列在Android上的样子：</p>
<pre><code>// Load the model from disk.
TensorFlowInferenceInterface inferenceInterface =
new TensorFlowInferenceInterface(assetManager, modelFilename);

// Copy the input data into TensorFlow.
inferenceInterface.feed(inputName, floatValues, 1, inputSize, inputSize, 3);

// Run the inference call.
inferenceInterface.run(outputNames, logStats);

// Copy the output Tensor back into the output array.
inferenceInterface.fetch(outputName, outputs);
</code></pre><p>您可以在Android示例中找到此代码的来源。</p>
<h3><span id="ios和树莓派">iOS和树莓派</span></h3><p>以下是iOS和Raspberry Pi的等效代码：</p>
<pre><code>// Load the model.
PortableReadFileToProto(file_path, &amp;tensorflow_graph);

// Create a session from the model.
tensorflow::Status s = session-&gt;Create(tensorflow_graph);
if (!s.ok()) {
  LOG(FATAL) &lt;&lt; &quot;Could not create TensorFlow Graph: &quot; &lt;&lt; s;
}

// Run the model.
std::string input_layer = &quot;input&quot;;
std::string output_layer = &quot;output&quot;;
std::vector&lt;tensorflow::Tensor&gt; outputs;
tensorflow::Status run_status = session-&gt;Run({ {input_layer, image_tensor}},
                           {output_layer}, {}, &amp;outputs);
if (!run_status.ok()) {
  LOG(FATAL) &lt;&lt; &quot;Running model failed: &quot; &lt;&lt; run_status;
}

// Access the output data.
tensorflow::Tensor* output = &amp;outputs[0];
</code></pre><p>这一切都基于 iOS示例代码， 但没有什么特定的iOS;相同的代码应该可以在任何平台上使用 支持C ++。</p>
<p>你也可以找到树莓派的具体例子 这里。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/word2vec/" title="词的矢量表示" itemprop="url">词的矢量表示</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="词的矢量表示">词的矢量表示</span></h1><p>在本教程中，我们看一下word2vec模型 Mikolov等人 这个模型用于学习单词的向量表示，称为“单词” 的嵌入”。</p>
<h2><span id="强调">强调</span></h2><p>本教程旨在突出有趣的，实质性的部分 在TensorFlow中建立一个word2vec模型。</p>
<p>我们首先给出为什么我们想要的动机 将单词表示为向量。 我们看看模型背后的直觉以及如何训练 （用数学的飞溅为好措施）。<br>我们还在TensorFlow中展示了一个简单的模型实现。 最后，我们看看如何让天真版本更好地扩展。</p>
<p>稍后在教程中我们会遍历代码，但是如果您愿意潜水 直接进来，随意看看简约的执行情况 tensorflow /示例/教程/ word2vec /<br>word2vec_basic.py 这个基本的例子包含了下载一些数据所需的代码，在其上进行训练 并可视化结果。一旦你阅读和运行舒适 基本版本，你可以毕业<br>车型/教程/嵌入/ word2vec.py 这是一个更严重的实施，展示了一些更先进的 有关如何有效地使用线程将数据移入数据库的TensorFlow原则<br>文本模型，训练期间如何检查点等</p>
<p>但首先，我们来看看为什么我们想在第一个字中学习单词嵌入 地点。如果你是一个嵌入式专家，你可以随意跳过这一节 喜欢把你的手弄脏的细节。</p>
<h2><span id="动机为什么学习word嵌入">动机：为什么学习Word嵌入？</span></h2><p>图像和音频处理系统可以处理丰富的高维数据集 编码为图像数据的各个原始像素强度的向量，或者 例如音频数据的功率谱密度系数。对象的任务<br>或者语音识别我们知道所有成功所需的信息 执行任务在数据中被编码（因为人类可以执行这些任务 来自原始数据）。但是，传统上自然语言处理系统<br>将单词视为离散的原子符号，因此可以表示“猫” 如<code>Id537</code>和“狗”，如<code>Id143</code>。这些编码是任意的，并提供<br>对于系统中可能存在的关系没有任何有用的信息 在各个符号之间。这意味着该模型可以利用 当它处理有关数据时，它所学到的关于“猫”的知识很少<br>‘狗’（例如，它们都是动物，四条腿，宠物等）。代表 字作为独特的，离散的ID进一步导致数据稀疏，通常 意味着我们可能需要更多的数据才能成功地训练统计数据<br>楷模。使用矢量表示可以克服这些障碍中的一些。</p>
<p><img src="https://www.tensorflow.org/images/audio-image-text.png" alt=""></p>
<p>向量空间模型（VSM） 在语义上表示（嵌入）连续向量空间中的单词 相似的词映射到附近的点（’嵌入在彼此附近’）。<br>VSM在NLP中有着悠久丰富的历史，但是所有的方法都依赖于某种方式 另一个 分布假说， 其中指出，出现在相同的情况下的话分享<br>语义意义。利用这个原理的不同方法可以 分为两类：基于计数的方法（例如， 潜在语义分析）， 和预测方法（例如 神经概率语言模型）。</p>
<p>这个区别是由更详细的阐述 Baroni等人， 但简而言之：基于计数的方法计算的统计 在一个大的文本语料库中，某个词与其相邻词汇共同出现的频率，<br>然后将这些计数统计映射到每个单词的小密集矢量。 预测模型直接试图从其邻居预测一个字 学习小，密集的嵌入向量（考虑的参数 模型）。</p>
<p>Word2vec是一个特别有效的计算预测模型 学习从原始文本中的单词嵌入。它有两个口味，连续 Bag-of-Words模型（CBOW）和Skip-<br>Gram模型（Mikolov等人的第3.1节和第3.2节）。算法上，这些 模型是相似的，除了CBOW预测目标词（例如“mat”）<br>源语境词语（’猫坐在’上），而跳跃词就是这样 反转并预测来自目标词语的源语境词语。这个倒置 可能看起来像一个任意的选择，但从统计上来看，它有这样的效果<br>CBOW平滑了许多分布信息（通过对待一个 整个上下文作为一个观察）。在大多数情况下，这原来是一个 小数据集有用的东西。但是，skip-<br>gram会处理每个上下文目标 对作为一个新的观察，这往往会做的更好，当我们有更大的 数据集。我们将在本教程的其余部分重点介绍skip-gram模型。</p>
<h2><span id="加大噪声对比培训力度">加大噪声对比培训力度</span></h2><p>神经概率语言模型传统上使用的训练 最大似然（ML） 原则来最大化下一个单词\（w_t \）的概率（对于“目标”） 给出前面的单词\（h<br>\）（对于“历史”）而言 softmax功能，</p>
<p>$$ \begin{align} P(w_t | h) &amp;= \text{softmax} (\text{score} (w_t, h)) \\ &amp;=<br>\frac{\exp \{ \text{score} (w<em>t, h) \} } {\sum</em>\text{Word w’ in Vocab} \exp<br>\{ \text{score} (w’, h) \} } \end{align} $$</p>
<p>其中\（\ text {score}（w_t，h）\）计算word \（w_t \）的兼容性 与上下文\（h \）（点积通常使用）。我们训练这个模型<br>通过最大化其对数似然性 在训练集上，即通过最大化</p>
<p>$$ \begin{align} J_\text{ML} &amp;= \log P(w_t | h) \\ &amp;= \text{score} (w<em>t, h) -<br>\log \left( \sum</em>\text{Word w’ in Vocab} \exp \{ \text{score} (w’, h) \}<br>\right). \end{align} $$</p>
<p>这产生了一个适当的规范化的语言建模概率模型。 然而，这是非常昂贵的，因为我们需要计算和归一化每个 概率使用当前所有其他\（V \）单词\（W’\）的得分<br>上下文\（h \），在每个训练步骤。</p>
<p><img src="https://www.tensorflow.org/images/softmax-nplm.png" alt=""></p>
<p>另一方面，对于word2vec中的特征学习，我们不需要一个完整的 概率模型。 CBOW和skip-gram模型是用a来训练的 二元分类目标（逻辑回归）<br>从（k \）虚数（噪声）字\（\波浪w \）中区分真实目标字\（w_t \）， 相同的背景。我们在下面对CBOW模型进行说明。对于skip-gram来说<br>方向是简单的倒置。</p>
<p><img src="https://www.tensorflow.org/images/nce-nplm.png" alt=""></p>
<p>在数学上，目标（对于每个示例）是最大化的</p>
<p>$$J<em>\text{NEG} = \log Q</em>\theta(D=1 |w<em>t, h) + k \mathop{\mathbb{E}}</em>{\tilde w<br>\sim P<em>\text{noise}} \left[ \log Q</em>\theta(D = 0 |\tilde w, h) \right]$$</p>
<p>其中\（Q_ \ theta（D = 1 | w，h）\）是二元逻辑回归概率 在数据集的上下文\（h \）中查看单词\（w \）的模型下 \（D<br>\），根据学习的嵌入向量\（\ theta \）计算。在 实践中，我们通过画（\）对比词来逼近期望 从噪声分布（即我们计算a 蒙特卡洛平均）。</p>
<p>当模型分配高概率时，这个目标是最大化的 真实的话，低概率的噪音词。从技术上讲，这是 叫 负面抽样， 使用这种损失函数有很好的数学动机：<br>它提出的更新近似于softmax函数的更新 限制。但是从计算角度来看，这是特别有吸引力的，因为计算 现在损失函数只能随着我们的噪声词的数量而缩放<br>选择（\（k \）），而不是词汇表中的所有单词（\（V \））。这使得它 训练要快得多。实际上我们会利用非常相似的 噪声对比估计（NCE）<br>为此TensorFlow有一个方便的帮手功能<code>tf.nn.nce_loss()</code>。</p>
<p>让我们直观地感受一下，在实践中这将如何工作！</p>
<h2><span id="跳跃模型">跳跃模型</span></h2><p>作为一个例子，我们来考虑一下数据集</p>
<p><code>the quick brown fox jumped over the lazy dog</code></p>
<p>我们首先形成单词的数据集和它们出现的上下文。我们 可以用任何有意义的方式来界定“背景”，事实上人们也可以 看着语法上下文（即当前的语法依赖者）<br>目标单词，请参阅 Levy等人）， 目标的左边，目标的右边，等等。现在， 让我们坚持香草的定义，并定义“上下文”作为窗口 的目标词的左侧和右侧的词。使用窗口<br>大小为1，那么我们有数据集</p>
<p><code>([the, brown], quick), ([quick, fox], brown), ([brown, jumped], fox), ...</code></p>
<p>的<code>(context, target)</code>对。回想一下，skip-gram会颠倒上下文 目标，并试图从其目标词预测每个环境词，所以<br>任务变成从“快”，“快”和“狐狸”预测’the’和’brown’ “棕色”等，因此我们的数据集成为</p>
<p><code>(quick, the), (quick, brown), (brown, quick), (brown, fox), ...</code></p>
<p>的<code>(input, output)</code>对。目标函数定义在整个 数据集，但我们通常使用优化 随机梯度下降<br>（SGD）一次只使用一个例子（或<code>batch_size</code>示例的“小批次” 典型的是<code>16 &lt;= batch_size &lt;= 512</code>）。所以我们来看一下<br>这个流程。</p>
<p>让我们想象在训练步骤\（t \）我们观察上面的第一个训练案例， 目标是从<code>the</code>预测<code>quick</code>。我们选择<code>num_noise</code>编号<br>嘈杂（对比）的例子，从一些噪音分布， 通常是一元分布，\（P（w）\）。为了简单，让我们说<br><code>num_noise=1</code>和我们选择<code>sheep</code>作为一个嘈杂的例子。接下来我们计算 这一对观察到的和有噪音的例子，即在时间上的目标的损失 步骤\（t<br>\）变成</p>
<p>$$J^{(t)}<em>\text{NEG} = \log Q</em>\theta(D=1 | \text{the, quick}) +<br>\log(Q_\theta(D=0 | \text{sheep, quick}))$$</p>
<p>目标是对嵌入参数\（\ theta \）进行更新以改善 （在这种情况下，最大化）这个目标函数。我们通过派生来做到这一点 相对于嵌入参数的损失梯度，即 \（\<br>frac {\ partial} {\ partial \ theta} J_ \ text {NEG} \）（幸运的是TensorFlow提供<br>简单的辅助功能来做到这一点！）。然后，我们执行更新 通过向梯度方向迈出一小步来嵌入。当这个 过程在整个训练集上重复进行，这就产生了效果<br>为每个单词“移动”嵌入向量，直到模型为止 成功地区分真实的单词和噪音单词。</p>
<p>我们可以通过将它们向下投影到2维来可视化所学习的向量 使用例如类似的东西 t-SNE降维技术。 当我们检查这些可视化时，变得明显的向量<br>捕捉一些一般的，实际上相当有用的语义信息 单词和他们之间的关系。当我们这是非常有趣的 首先发现了诱导向量空间中的某些方向是专门化的<br>朝着某些语义关系，例如男女，动词时态和 甚至包括国与国之间的文字之间的关系，如图所示 下面（参见例如 Mikolov等，2013）。</p>
<p><img src="https://www.tensorflow.org/images/linear-relationships.png" alt=""></p>
<p>这就解释了为什么这些矢量也可以用作许多规范的特征 NLP预测任务，如词性标注或命名实体识别 （见例如原来的工作 Collobert等人，2011<br>（pdf）或后续工作 Turian等，2010）。</p>
<p>但现在，让我们用它们来画美丽的图画！</p>
<h2><span id="建立图表">建立图表</span></h2><p>这是关于嵌入，所以我们来定义我们的嵌入矩阵。 这只是一个很大的随机矩阵开始。我们将初始化值 在单位立方体统一。</p>
<pre><code>embeddings = tf.Variable(
    tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))
</code></pre><p>噪声对比估计损失是根据逻辑回归定义的 模型。为此，我们需要为每个单词定义权重和偏差 词汇（也被称为<code>output weights</code>而不是输入<br>嵌入物）。所以我们来定义一下。</p>
<pre><code>nce_weights = tf.Variable(
  tf.truncated_normal([vocabulary_size, embedding_size],
                      stddev=1.0 / math.sqrt(embedding_size)))
nce_biases = tf.Variable(tf.zeros([vocabulary_size]))
</code></pre><p>现在我们已经有了参数，我们可以定义我们的skip-gram模型 图形。为了简单起见，假设我们已经整合了我们的文本语料库<br>与一个词汇，使每个单词被表示为一个整数（见 tensorflow /示例/教程/ word2vec / word2vec_basic.py<br>的细节）。跳跃模型需要两个输入。一个是满满的一批 代表源语境词的整数，另一个代表目标 话。让我们为这些输入创建占位符节点，以便我们可以输入 数据稍后。</p>
<pre><code># Placeholders for inputs
train_inputs = tf.placeholder(tf.int32, shape=[batch_size])
train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])
</code></pre><p>现在我们需要做的是查找每个源词的向量 该批次。 TensorFlow有方便的帮手，使这个简单。</p>
<pre><code>embed = tf.nn.embedding_lookup(embeddings, train_inputs)
</code></pre><p>好的，现在我们有每个单词的嵌入，我们想尝试预测 目标词使用噪声对比训练目标。</p>
<pre><code># Compute the NCE loss, using a sample of the negative labels each time.
loss = tf.reduce_mean(
  tf.nn.nce_loss(weights=nce_weights,
                 biases=nce_biases,
                 labels=train_labels,
                 inputs=embed,
                 num_sampled=num_sampled,
                 num_classes=vocabulary_size))
</code></pre><p>现在我们有一个损失节点，我们需要添加计算所需的节点 渐变和更新参数等。为此，我们将使用随机<br>梯度下降，而且TensorFlow也有方便的帮手来使这一切变得简单。</p>
<pre><code># We use the SGD optimizer.
optimizer = tf.train.GradientDescentOptimizer(learning_rate=1.0).minimize(loss)
</code></pre><h2><span id="培训模型">培训模型</span></h2><p>然后使用<code>feed_dict</code>将数据推送到模型中，然后训练模型 占位符和呼叫 <code>tf.Session.run</code>与这个新的数据 在一个循环中。</p>
<pre><code>for inputs, labels in generate_batch(...):
  feed_dict = {train_inputs: inputs, train_labels: labels}
  _, cur_loss = session.run([optimizer, loss], feed_dict=feed_dict)
</code></pre><p>请参阅完整的示例代码 tensorflow /例子/教程/ word2vec / word2vec_basic.py。</p>
<h2><span id="可视化的嵌入">可视化的嵌入</span></h2><p>训练完成后，我们可以使用可视化的学习嵌入 T-SNE。</p>
<p><img src="https://www.tensorflow.org/images/tsne.png" alt=""></p>
<p>Et瞧！如预期的那样，类似的词汇最终在每个附近聚集 其他。对于更重量级的word2vec实现，展示更多的 TensorFlow的高级功能，请参阅实现<br>车型/教程/嵌入/ word2vec.py。</p>
<h2><span id="评估嵌入类比推理">评估嵌入：类比推理</span></h2><p>嵌入对于NLP中的各种预测任务是有用的。缺乏 训练一个完整的词性模型或命名实体模型，一个简单的方法 评估嵌入是直接使用它们来预测句法和语义 像<code>king
is to queen as father is to ?</code>的关系。这就是所谓的 类比推理和任务被介绍了 Mikolov和同事 。<br>从该任务下载该任务的数据集 download.tensorflow.org。</p>
<p>看看我们如何做这个评估，看看<code>build_eval_graph()</code>和 <code>eval()</code>的功能 车型/教程/嵌入/ word2vec.py。</p>
<p>超参数的选择可以强烈影响此任务的准确性。 为了在这个任务上达到最高水平的表现，需要训练一个 非常大的数据集，仔细调整超参数和使用<br>这些技巧就像对数据进行二次采样，这超出了本教程的范围。</p>
<h2><span id="优化实施">优化实施</span></h2><p>我们的香草实施展示了TensorFlow的灵活性。对于 例如，改变培训目标就像换掉电话一样简单 以<code>tf.nn.nce_loss()</code>为代表的现成替代品<br><code>tf.nn.sampled_softmax_loss()</code>。如果你有一个新的损失函数的想法，你 可以在TensorFlow中手动为新目标写一个表达式并让<br>优化器计算它的导数。这种灵活性是无价的 机器学习模式开发的探索阶段，我们正在尝试 出几个不同的想法，并迅速迭代。</p>
<p>一旦你有一个模型结构你满意，这可能是值得的 优化您的实现以更高效地运行（并覆盖更多的数据 更短的时间）。例如，我们在本教程中使用的朴素代码会受到影响<br>由于我们使用Python来读取和提供数据项， 每个TensorFlow后端都需要很少的工作。如果你发现 你的模型是严重瓶颈输入数据，你可能想要实现一个<br>自定义数据读取器为您的问题，如所述 新的数据格式。对于Skip-Gram的情况 建模，我们实际上已经为你做了这个例子 车型/教程/嵌入/<br>word2vec.py。</p>
<p>如果你的模型不再是I / O绑定的，但是你还需要更多的性能，你 可以通过编写自己的TensorFlow Ops来进一步处理，如下所述<br>添加一个新的操作我们再次提供了一个 这个例子就是Skip-Gram的例子 车型/教程/嵌入/ word2vec_o​​ptimized.py。<br>随意基准这些对方来衡量表现 每个阶段的改进。</p>
<h2><span id="结论">结论</span></h2><p>在本教程中，我们介绍了word2vec模型，这是一个计算效率高的模型 学习单词嵌入的模型。我们激励为什么嵌入是有用的，<br>讨论了高效的培训技术，并展示了如何实施所有这些 在TensorFlow中。总的来说，我们希望这已经证明TensorFlow是如何提供的<br>你的灵活性，你需要早期的实验，并控制你 以后需要定制优化实施。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/dev/" title="发展" itemprop="url">发展</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="发展">发展</span></h1><p>有关TensorFlow编程基础的简要概述，请参阅以下内容 指南：</p>
<p>TensorFlow入门</p>
<p>MNIST已经成为尝试新机器学习的标准数据集 工具包。我们提供了三个指南，每个指南都有不同的方法 在TensorFlow上培训MNIST模型：</p>
<p>MN初学者MNIST，介绍MNIST     高级API。 专家深度MNIST，比深度更深     “MN初学者MNIST”，并假定对机器有一定的了解<br>学习的概念。 通过引入MNIST的TensorFlow Mechanics 101     低级的API。</p>
<p>对于新开发TensorFlow的开发者来说，高级API是一个很好的开始。 要了解高级API，请阅读以下指南：</p>
<p>tf.estimator快速入门，介绍了这一点     API。 建立输入功能​​，     这会让你进入这个API的更复杂的使用。</p>
<p>TensorBoard是可视化机器学习的不同方面的实用程序。 以下指南介绍如何使用TensorBoard：</p>
<p>TensorBoard：可视化学习，     这让你开始。 TensorBoard：图形可视化，解释     如何可视化计算图。图形可视化通常是<br>对使用低级API的程序员更有用。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/recurrent/" title="复发神经网络" itemprop="url">复发神经网络</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="复发神经网络">复发神经网络</span></h1><h2><span id="介绍">介绍</span></h2><p>看看这个伟大的文章 对于递归神经网络和LSTM的介绍尤其如此。</p>
<h2><span id="语言建模">语言建模</span></h2><p>在本教程中，我们将展示如何训练一个循环神经网络 语言模型的挑战性任务。这个问题的目标是适合一个 将概率赋予句子的概率模型。它通过<br>预测文本中的下一个单词，给出以前单词的历史。为了这 我们将使用宾州树银行 （PTB）数据集，这是衡量这些数据质量的流行基准 模型，虽然小，相对较快的训练。</p>
<p>语言建模是语音等许多有趣问题的关键 识别，机器翻译或图像字幕。这也很有趣 - 看看这里。</p>
<p>为了本教程的目的，我们将重现结果 Zaremba等，2014 （pdf），达到非常好的质量 在PTB数据集上。</p>
<h2><span id="教程文件">教程文件</span></h2><p>本教程在TensorFlow模型库中引用<code>models/tutorials/rnn/ptb</code>中的以下文件：</p>
<table>
<thead>
<tr>
<th>File</th>
<th>Purpose  </th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ptb_word_lm.py</code></td>
<td>The code to train a language model on the PTB dataset.  </td>
</tr>
<tr>
<td><code>reader.py</code></td>
<td>The code to read the dataset.  </td>
</tr>
</tbody>
</table>
<h2><span id="下载并准备数据">下载并准备数据</span></h2><p>本教程所需的数据位于<code>data/</code>目录中 PTM数据集来自Tomas Mikolov的网页。</p>
<p>数据集已经过预处理，包含10000个不同的单词， 包括稀有的结束句子标记和特殊符号（\ ）<br>话。在<code>reader.py</code>中，我们将每个字转换为唯一的整数标识符， 以便使神经网络容易处理数据。</p>
<h2><span id="该模型">该模型</span></h2><h3><span id="lstm">LSTM</span></h3><p>模型的核心由一个LSTM单元组成，它处理一个单词 并计算下一个单词可能值的概率 句子。网络的存储器状态用零矢量初始化<br>并在阅读每个单词后得到更新。出于计算的原因，我们会 处理大小为<code>batch_size</code>的小批量数据。在这个例子中，它是<br>重要的是要注意<code>current_batch_of_words</code>不对应一个 “句子”的话。批次中的每一个字都应该对应一个时间t。<br>TensorFlow会自动将您每批次的梯度加起来。</p>
<p>例如：</p>
<pre><code> t=0  t=1    t=2  t=3     t=4
[The, brown, fox, is,     quick]
[The, red,   fox, jumped, high]

words_in_dataset[0] = [The, The]
words_in_dataset[1] = [brown, red]
words_in_dataset[2] = [fox, fox]
words_in_dataset[3] = [is, jumped]
words_in_dataset[4] = [quick, high]
batch_size = 2, time_steps = 5
</code></pre><p>基本的伪代码如下：</p>
<pre><code>words_in_dataset = tf.placeholder(tf.float32, [time_steps, batch_size, num_features])
lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)
# Initial state of the LSTM memory.
hidden_state = tf.zeros([batch_size, lstm.state_size])
current_state = tf.zeros([batch_size, lstm.state_size])
state = hidden_state, current_state
probabilities = []
loss = 0.0
for current_batch_of_words in words_in_dataset:
    # The value of state is updated after processing each batch of words.
    output, state = lstm(current_batch_of_words, state)

    # The LSTM output can be used to make next word predictions
    logits = tf.matmul(output, softmax_w) + softmax_b
    probabilities.append(tf.nn.softmax(logits))
    loss += loss_function(probabilities, target_words)
</code></pre><h3><span id="截断后向传播">截断后向传播</span></h3><p>通过设计，递归神经网络（RNN）的输出取决于任意 遥远的投入。不幸的是，这使得后向计算困难。 为了使学习过程易于处理，创建是常见的做法<br>网络的“展开”版本，其中包含一个固定的号码 （<code>num_steps</code>）的LSTM输入和输出。然后，这个模型被训练 RNN的有限近似。这可以通过馈送输入来实现<br>长度为<code>num_steps</code>，每次之后执行反向传球 这样的输入块。</p>
<p>这是一个简化的代码块来创建一个图表执行 截断反向传播：</p>
<pre><code># Placeholder for the inputs in a given iteration.
words = tf.placeholder(tf.int32, [batch_size, num_steps])

lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)
# Initial state of the LSTM memory.
initial_state = state = tf.zeros([batch_size, lstm.state_size])

for i in range(num_steps):
    # The value of state is updated after processing each batch of words.
    output, state = lstm(words[:, i], state)

    # The rest of the code.
    # ...

final_state = state
</code></pre><p>这就是如何实现对整个数据集的迭代：</p>
<pre><code># A numpy array holding the state of LSTM after each batch of words.
numpy_state = initial_state.eval()
total_loss = 0.0
for current_batch_of_words in words_in_dataset:
    numpy_state, current_loss = session.run([final_state, loss],
        # Initialize the LSTM state from the previous iteration.
        feed_dict={initial_state: numpy_state, words: current_batch_of_words})
    total_loss += current_loss
</code></pre><h3><span id="输入">输入</span></h3><p>单词ID将被嵌入到一个密集的表示形式中 矢量表示教程） LSTM。这使模型能够有效地表示有关的知识 特别的话。这也很容易写：</p>
<pre><code># embedding_matrix is a tensor of shape [vocabulary_size, embedding size]
word_embeddings = tf.nn.embedding_lookup(embedding_matrix, word_ids)
</code></pre><p>嵌入矩阵将被随机初始化，模型将学习到 通过查看数据来区分单词的含义。</p>
<h3><span id="损失函数">损失函数</span></h3><p>我们希望最小化目标词的平均负对数概率：</p>
<p>$$ \text{loss} = -\frac{1}{N}\sum<em>{i=1}^{N} \ln p</em>{\text{target}_i} $$</p>
<p>这个功能不是很难实现， <code>sequence_loss_by_example</code>已经上市，所以我们可以在这里使用它。</p>
<p>文件中报告的典型测量是平均每个词的困惑（经常 只是被称为困惑），这相当于</p>
<p>$$e^{-\frac{1}{N}\sum<em>{i=1}^{N} \ln p</em>{\text{target}_i}} = e^{\text{loss}} $$</p>
<p>我们将在整个培训过程中监控其价值。</p>
<h3><span id="堆叠多个lstm">堆叠多个LSTM</span></h3><p>为了给模型更多的表现力，我们可以添加多层LSTM 处理数据。第一层的输出将成为输入 第二个等等。</p>
<p>我们有一个称为<code>MultiRNNCell</code>的类，使得实现无缝：</p>
<pre><code>def lstm_cell():
  return tf.contrib.rnn.BasicLSTMCell(lstm_size)
stacked_lstm = tf.contrib.rnn.MultiRNNCell(
    [lstm_cell() for _ in range(number_of_layers)])

initial_state = state = stacked_lstm.zero_state(batch_size, tf.float32)
for i in range(num_steps):
    # The value of state is updated after processing each batch of words.
    output, state = stacked_lstm(words[:, i], state)

    # The rest of the code.
    # ...

final_state = state
</code></pre><h2><span id="运行代码">运行代码</span></h2><p>在运行代码之前，下载PTB数据集，正如开头讨论的那样 本教程。然后，提取主目录下的PTB数据集 如下：</p>
<pre><code>tar xvfz simple-examples.tgz -C $HOME
</code></pre><p>（注意：在Windows上，您可能需要使用 其他工具。）</p>
<p>现在，克隆TensorFlow模型回购 从GitHub。运行以下命令：</p>
<pre><code>cd models/tutorials/rnn/ptb
python ptb_word_lm.py --data_path=$HOME/simple-examples/data/ --model=small
</code></pre><p>教程代码中有3种支持的模型配置：“小”， “中”和“大”。它们之间的区别在于LSTMs和 用于训练的一组超参数。</p>
<p>模型越大，应该得到的结果就越好。 <code>small</code>型号应该 在测试装置和下面的<code>large</code>上可以达到120以下的困惑度 80，虽然可能需要几个小时的训练。</p>
<h2><span id="接下来是什么">接下来是什么？</span></h2><p>有几个技巧，我们没有提到，使模型更好， 包含：</p>
<p>降低学习速度时间表， LSTM层之间的压差。</p>
<p>研究代码并对其进行修改以进一步改进模型。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/ios_build/" title="在iOS上构建TensorFlow" itemprop="url">在iOS上构建TensorFlow</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="在ios上构建tensorflow">在iOS上构建TensorFlow</span></h1><h2><span id="使用cocoapods">使用CocoaPods</span></h2><p>在iOS上开始使用TensorFlow最简单的方法是使用CocoaPods 包管理系统。您可以将<code>TensorFlow-
experimental</code>吊舱添加到您的 Podfile，它安装一个通用的二进制框架。这使得它很容易得到 开始，但有难以定制的缺点，这是重要的<br>如果你想缩小你的二进制大小。如果你确实需要的能力 自定义您的库，请参阅后面的部分关于如何做到这一点。</p>
<h2><span id="创建自己的应用程序">创建自己的应用程序</span></h2><p>如果您想将TensorFlow功能添加到您自己的应用程序中，请执行以下操作：</p>
<p>创建自己的应用程序或在XCode中加载已经创建的应用程序。 在项目根目录下添加一个名为Podfile的文件，内容如下：<br>目标’YourProjectName’ pod’TensorFlow-experimental’ 运行<code>pod install</code>下载并安装<br><code>TensorFlow-experimental</code>吊舱。 打开<code>YourProjectName.xcworkspace</code>并添加您的代码。<br>在您的应用程序的生成设置中，请确保将<code>$(inherited)</code>添加到   其他链接器标志和标题搜索路径部分。</p>
<h2><span id="运行示例">运行示例</span></h2><p>您需要Xcode 7.3或更高版本来运行我们的iOS示例。</p>
<p>目前有三个例子：简单，基准和相机。现在，你 可以通过克隆主张量库（我们是。）下载示例代码 计划稍后将样品作为单独的存储库提供）。</p>
<p>从tensorflow文件夹的根目录下载Inception V1， 并将标签和图形文件提取到两个数据文件夹中 简单和相机的例子使用这些步骤：</p>
<pre><code>mkdir -p ~/graphs
curl -o ~/graphs/inception5h.zip \
 https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip \
 &amp;&amp; unzip ~/graphs/inception5h.zip -d ~/graphs/inception5h
cp ~/graphs/inception5h/* tensorflow/examples/ios/benchmark/data/
cp ~/graphs/inception5h/* tensorflow/examples/ios/camera/data/
cp ~/graphs/inception5h/* tensorflow/examples/ios/simple/data/
</code></pre><p>切换到一个示例目录，下载 Tensorflow实验性 荚，并打开Xcode工作区。请注意，安装吊舱可能需要很长时间<br>因为它很大（〜450MB）。如果你想运行这个简单的例子，那么：</p>
<pre><code>cd tensorflow/examples/ios/simple
pod install
open tf_simple_example.xcworkspace   # note .xcworkspace, not .xcodeproj
                                     # this is created by pod install
</code></pre><p>在XCode模拟器中运行简单的应用程序。你应该看到一个单屏幕的应用程序 与运行模型按钮。点击，你应该看到一些调试输出 出现在下面，指出示例Grace<br>Hopper图像在目录数据中 已经被分析，用军装认可。</p>
<p>使用相同的过程运行其他样品。相机的例子需要一个真实的 设备已连接。一旦你建立和运行，你应该得到一个实时相机视图 你可以指向对象获得实时识别结果。</p>
<h3><span id="ios示例细节">iOS示例细节</span></h3><p>iOS有三个演示应用程序，全部在Xcode项目中定义 tensorflow /示例/ IOS。</p>
<p>简单：这是一个简单的例子，展示了如何加载和运行一个TensorFlow   在尽可能少的线条模型。它只是一个单一的视图与一个<br>按钮，当按下它时执行模型加载和推理。 相机：这是非常类似于Android的TF分类演示。它加载   Inception<br>v3并输出其最佳标签估计值，以查看实况相机中的内容   视图。与Android版本一样，您可以使用训练您自己的自定义模型<br>用于诗人的TensorFlow并将其放入此示例中，只需最少的代码更改。 基准：与Simple很接近，但它反复运行图形<br>向Android上的基准测试工具输出类似的统计数据。</p>
<h3><span id="故障排除">故障排除</span></h3><p>确保你使用了TensorFlow-experimental pod（而不是TensorFlow）。 TensorFlow-experimental<br>pod目前约为450MB。原因是这样的   大的是因为我们捆绑了多个平台，而且这个吊舱包括了所有的平台<br>TensorFlow功能（例如操作）。构建后的最终应用程序大小是   （〜25MB）大大减小。使用完整的吊舱是<br>在开发过程中很方便，但请参阅下面关于如何构建您的   自己定制的TensorFlow库来减小尺寸。</p>
<h2><span id="从源码构建tensorflow-ios库">从源码构建TensorFlow iOS库</span></h2><p>虽然Cocapods是最快，最简单的入门方式，但有时候也是如此 需要更多的灵活性来确定你的应用应该是TensorFlow的哪个部分<br>随附。对于这种情况下，你可以从 源。这个 指南 包含如何做到这一点的详细说明。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/pdes/" title="偏微分方程" itemprop="url">偏微分方程</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="偏微分方程">偏微分方程</span></h1><p>TensorFlow不仅仅是机器学习。这里我们给出一个（有点 行人）使用TensorFlow模拟行为的例子 偏微分方程。<br>我们将模拟几个雨滴落在它上面的方形池塘表面。</p>
<h2><span id="基本设置">基本设置</span></h2><p>我们需要一些进口产品。</p>
<pre><code>#Import libraries for simulation
import tensorflow as tf
import numpy as np

#Imports for visualization
import PIL.Image
from io import BytesIO
from IPython.display import clear_output, Image, display
</code></pre><p>用于将池塘表面的状态显示为图像的功能。</p>
<pre><code>def DisplayArray(a, fmt=&apos;jpeg&apos;, rng=[0,1]):
  &quot;&quot;&quot;Display an array as a picture.&quot;&quot;&quot;
  a = (a - rng[0])/float(rng[1] - rng[0])*255
  a = np.uint8(np.clip(a, 0, 255))
  f = BytesIO()
  PIL.Image.fromarray(a).save(f, fmt)
  clear_output(wait = True)
  display(Image(data=f.getvalue()))
</code></pre><p>在这里，我们开始一个交互式的TensorFlow会话，以方便玩游戏 周围。如果我们这样做的话，一个常规会议也可以工作 可执行的.py文件。</p>
<pre><code>sess = tf.InteractiveSession()
</code></pre><h2><span id="计算便利功能">计算便利功能</span></h2><pre><code>def make_kernel(a):
  &quot;&quot;&quot;Transform a 2D array into a convolution kernel&quot;&quot;&quot;
  a = np.asarray(a)
  a = a.reshape(list(a.shape) + [1,1])
  return tf.constant(a, dtype=1)

def simple_conv(x, k):
  &quot;&quot;&quot;A simplified 2D convolution operation&quot;&quot;&quot;
  x = tf.expand_dims(tf.expand_dims(x, 0), -1)
  y = tf.nn.depthwise_conv2d(x, k, [1, 1, 1, 1], padding=&apos;SAME&apos;)
  return y[0, :, :, 0]

def laplace(x):
  &quot;&quot;&quot;Compute the 2D laplacian of an array&quot;&quot;&quot;
  laplace_k = make_kernel([[0.5, 1.0, 0.5],
                           [1.0, -6., 1.0],
                           [0.5, 1.0, 0.5]])
  return simple_conv(x, laplace_k)
</code></pre><h2><span id="定义pde">定义PDE</span></h2><p>我们的池塘是一个完美的500×500平方米，大多数池塘发现的情况 性质。</p>
<pre><code>N = 500
</code></pre><p>在这里，我们创造了我们的池塘，并与一些雨滴打。</p>
<pre><code># Initial Conditions -- some rain drops hit a pond

# Set everything to zero
u_init = np.zeros([N, N], dtype=np.float32)
ut_init = np.zeros([N, N], dtype=np.float32)

# Some rain drops hit a pond at random points
for n in range(40):
  a,b = np.random.randint(0, N, 2)
  u_init[a,b] = np.random.uniform()

DisplayArray(u_init, rng=[-0.1, 0.1])
</code></pre><p><img src="https://www.tensorflow.org/images/pde_output_1.jpg" alt="jpeg"></p>
<p>现在我们来指定微分方程的细节。</p>
<pre><code># Parameters:
# eps -- time resolution
# damping -- wave damping
eps = tf.placeholder(tf.float32, shape=())
damping = tf.placeholder(tf.float32, shape=())

# Create variables for simulation state
U  = tf.Variable(u_init)
Ut = tf.Variable(ut_init)

# Discretized PDE update rules
U_ = U + eps * Ut
Ut_ = Ut + eps * (laplace(U) - damping * Ut)

# Operation to update the state
step = tf.group(
  U.assign(U_),
  Ut.assign(Ut_))
</code></pre><h2><span id="运行模拟">运行模拟</span></h2><p>这是它获得乐趣的地方 - 用简单的for循环运行时间。</p>
<pre><code># Initialize state to initial conditions
tf.global_variables_initializer().run()

# Run 1000 steps of PDE
for i in range(1000):
  # Step simulation
  step.run({eps: 0.03, damping: 0.04})
  DisplayArray(U.eval(), rng=[-0.1, 0.1])
</code></pre><p><img src="https://www.tensorflow.org/images/pde_output_2.jpg" alt="jpeg"></p>
<p>看！涟漪！</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/input_fn/" title="用tf.estimator构建输入函数" itemprop="url">用tf.estimator构建输入函数</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="用tfestimator构建输入函数">用tf.estimator构建输入函数</span></h1><p>本教程将向您介绍如何在tf.estimator中创建输入函数。 您将了解如何构建<code>input_fn</code>以进行预处理和馈送<br>数据进入你的模型。然后，你将实施一个<code>input_fn</code>， 评估和预测数据组合成神经网络回归器进行预测 中间房屋价值。</p>
<h2><span id="用input_fn自定义输入管道">用input_fn自定义输入管道</span></h2><p><code>input_fn</code>用于将特征和目标数据传送到<code>train</code>， <code>evaluate</code>，以及<code>predict</code>的<code>Estimator</code>方法。<br>用户可以在<code>input_fn</code>内进行特征设计或预处理。 以下是从tf.estimator快速入门教程中获取的示例：</p>
<pre><code>import numpy as np

training_set = tf.contrib.learn.datasets.base.load_csv_with_header(
    filename=IRIS_TRAINING, target_dtype=np.int, features_dtype=np.float32)

train_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={&quot;x&quot;: np.array(training_set.data)},
    y=np.array(training_set.target),
    num_epochs=None,
    shuffle=True)

classifier.train(input_fn=train_input_fn, steps=2000)
</code></pre><h3><span id="解剖一个input_fn">解剖一个input_fn</span></h3><p>以下代码说明了输入函数的基本框架：</p>
<pre><code>def my_input_fn():

    # Preprocess your data here...

    # ...then return 1) a mapping of feature columns to Tensors with
    # the corresponding feature data, and 2) a Tensor containing labels
    return feature_cols, labels
</code></pre><p>输入函数的主体包含预处理的特定逻辑 你的输入数据，如清理不好的例子或 功能缩放。</p>
<p>输入函数必须返回以下两个包含最终值的值 功能和标签数据输入到您的模型中（如上面的代码所示） 骨架）：</p>
<p><code>feature_cols</code></p>
<pre><code>A dict containing key/value pairs that map feature column names to `Tensor`s (or `SparseTensor`s) containing the corresponding feature data.
</code></pre><p><code>labels</code></p>
<pre><code>A `Tensor` containing your label (target) values: the values your model aims to predict.
</code></pre><h3><span id="将要素数据转换为张量">将要素数据转换为张量</span></h3><p>如果你的特征/标签数据是一个Python数组或存储在 熊猫数据框或 numpy数组，你可以使用下面的方法来 构建体<code>input_fn</code>：</p>
<pre><code>import numpy as np
# numpy input_fn.
my_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={&quot;x&quot;: np.array(x_data)},
    y=np.array(y_data),
    ...)



import pandas as pd
# pandas input_fn.
my_input_fn = tf.estimator.inputs.pandas_input_fn(
    x=pd.DataFrame({&quot;x&quot;: x_data}),
    y=pd.Series(y_data),
    ...)
</code></pre><p>对于稀疏的分类数据 （数据的大部分值是0），你会改为填充一个 <code>SparseTensor</code>，它有三个参数实例化：</p>
<p><code>dense_shape</code></p>
<pre><code>The shape of the tensor. Takes a list indicating the number of elements in each dimension. For example, `dense_shape=[3,6]` specifies a two-dimensional 3x6 tensor, `dense_shape=[2,3,4]` specifies a three-dimensional 2x3x4 tensor, and `dense_shape=[9]` specifies a one-dimensional tensor with 9 elements.
</code></pre><p><code>indices</code></p>
<pre><code>The indices of the elements in your tensor that contain nonzero values. Takes a list of terms, where each term is itself a list containing the index of a nonzero element. (Elements are zero-indexed--i.e., [0,0] is the index value for the element in the first column of the first row in a two-dimensional tensor.) For example, `indices=[[1,3], [2,4]]` specifies that the elements with indexes of [1,3] and [2,4] have nonzero values.
</code></pre><p><code>values</code></p>
<pre><code>A one-dimensional tensor of values. Term `i` in `values` corresponds to term `i` in `indices` and specifies its value. For example, given `indices=[[1,3], [2,4]]`, the parameter `values=[18, 3.6]` specifies that element [1,3] of the tensor has a value of 18, and element [2,4] of the tensor has a value of 3.6.
</code></pre><p>下面的代码定义了一个三维和五维的二维<code>SparseTensor</code> 列。索引[0,1]的元素的值为6，元素的值为<br>索引[2,4]的值为0.5（所有其他值为0）：</p>
<pre><code>sparse_tensor = tf.SparseTensor(indices=[[0,1], [2,4]],
                                values=[6, 0.5],
                                dense_shape=[3, 5])
</code></pre><p>这对应于下面的稠密张量：</p>
<pre><code>[[0, 6, 0, 0, 0]
 [0, 0, 0, 0, 0]
 [0, 0, 0, 0, 0.5]]
</code></pre><p>有关<code>SparseTensor</code>的更多信息，请参阅<code>tf.SparseTensor</code>。</p>
<h3><span id="将input_fn数据传递给您的模型">将input_fn数据传递给您的模型</span></h3><p>要将数据提供给您的模型进行培训，只需传递输入函数即可 您创建的<code>train</code>的操作值为<code>input_fn</code> 参数，例如：</p>
<pre><code>classifier.train(input_fn=my_input_fn, steps=2000)
</code></pre><p>请注意，<code>input_fn</code>参数必须接收一个功能对象（即， <code>input_fn=my_input_fn</code>），而不是函数调用的返回值<br>（<code>input_fn=my_input_fn()</code>）。这意味着如果你尝试传递参数给 在<code>input_fn</code>调用中使用<code>train</code>，如以下代码所示，将导致<br><code>TypeError</code>：</p>
<pre><code>classifier.train(input_fn=my_input_fn(training_set), steps=2000)
</code></pre><p>但是，如果你想能够参数化你的输入功能，那么有 其他方法这样做。你可以使用不包含的包装函数 作为<code>input_fn</code>的参数，并用它来调用你的输入功能<br>与所需的参数。例如：</p>
<pre><code>def my_input_fn(data_set):
  ...

def my_input_fn_training_set():
  return my_input_fn(training_set)

classifier.train(input_fn=my_input_fn_training_set, steps=2000)
</code></pre><p>或者，您可以使用Python的<code>functools.partial</code> 函数来构建一个固定了所有参数值的新函数对象：</p>
<pre><code>classifier.train(
    input_fn=functools.partial(my_input_fn, data_set=training_set),
    steps=2000)
</code></pre><p>第三个选项是将<code>input_fn</code>调用包装在一个 <code>lambda</code> 并传递给<code>input_fn</code>参数：</p>
<pre><code>classifier.train(input_fn=lambda: my_input_fn(training_set), steps=2000)
</code></pre><p>设计输入流水线的一大优势就是如上所示 - 接受一个 参数数据集 - 是你可以通过相同的<code>input_fn</code>到<code>evaluate</code><br>和<code>predict</code>操作，只需更改数据集参数，例如：</p>
<pre><code>classifier.evaluate(input_fn=lambda: my_input_fn(test_set), steps=2000)
</code></pre><p>这种方法增强了代码的可维护性：不需要定义多个<br><code>input_fn</code>（例如<code>input_fn_train</code>，<code>input_fn_test</code>，<code>input_fn_predict</code>） 操作类型。</p>
<p>最后，您可以使用<code>tf.estimator.inputs</code>中的方法创建<code>input_fn</code> 从numpy或pandas数据集。额外的好处是你可以使用<br>更多的参数，如<code>num_epochs</code>和<code>shuffle</code>来控制<code>input_fn</code> 迭代数据：</p>
<pre><code>import pandas as pd

def get_input_fn_from_pandas(data_set, num_epochs=None, shuffle=True):
  return tf.estimator.inputs.pandas_input_fn(
      x=pdDataFrame(...),
      y=pd.Series(...),
      num_epochs=num_epochs,
      shuffle=shuffle)



import numpy as np

def get_input_fn_from_numpy(data_set, num_epochs=None, shuffle=True):
  return tf.estimator.inputs.numpy_input_fn(
      x={...},
      y=np.array(...),
      num_epochs=num_epochs,
      shuffle=shuffle)
</code></pre><h3><span id="波士顿房屋价值的神经网络模型">波士顿房屋价值的神经网络模型</span></h3><p>在本教程的其余部分中，您将为其编写一个输入函数 预处理从UCI住房数据中提取的一部分波士顿房屋数据 设置并使用它来提供数据<br>用于预测房屋中值的神经网络回归器。</p>
<p>您将使用波士顿CSV数据集来训练您的神经网络 包含以下内容 特征数据 对于波士顿郊区：</p>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Description  </th>
</tr>
</thead>
<tbody>
<tr>
<td>CRIM</td>
<td>Crime rate per capita  </td>
</tr>
<tr>
<td>ZN</td>
<td>Fraction of residential land zoned to permit 25,000+ sq ft lots  </td>
</tr>
<tr>
<td>INDUS</td>
<td>Fraction of land that is non-retail business  </td>
</tr>
<tr>
<td>NOX</td>
<td>Concentration of nitric oxides in parts per 10 million  </td>
</tr>
<tr>
<td>RM</td>
<td>Average Rooms per dwelling  </td>
</tr>
<tr>
<td>AGE</td>
<td>Fraction of owner-occupied residences built before 1940  </td>
</tr>
<tr>
<td>DIS</td>
<td>Distance to Boston-area employment centers  </td>
</tr>
<tr>
<td>TAX</td>
<td>Property tax rate per $10,000  </td>
</tr>
<tr>
<td>PTRATIO</td>
<td>Student-teacher ratio  </td>
</tr>
</tbody>
</table>
<p>而你的模型预测的标签是MEDV，中值 自住住房以千美元计。</p>
<h2><span id="建立">建立</span></h2><p>下载以下数据集： boston_train.csv， boston_test.csv和 boston_predict.csv。</p>
<p>以下各节将逐步介绍如何创建一个 输入功能，将这些数据集输入到神经网络回归器，训练器 评估模型，并做房屋价值预测。完整的，最终的代码是可用的 这里。</p>
<h3><span id="导入住房数据">导入住房数据</span></h3><p>首先，设置您的导入（包括<code>pandas</code>和<code>tensorflow</code>），并设置日志记录的详细程度 <code>INFO</code>更详细的日志输出：</p>
<pre><code>from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import itertools

import pandas as pd
import tensorflow as tf

tf.logging.set_verbosity(tf.logging.INFO)
</code></pre><p>定义<code>COLUMNS</code>中数据集的列名。区分特征 从标签上也定义了<code>FEATURES</code>和<code>LABEL</code>。然后阅读三个CSV （<code>tf.train</code>，<br><code>tf.test</code>，和 预测）熊猫 <code>DataFrame</code>s：</p>
<pre><code>COLUMNS = [&quot;crim&quot;, &quot;zn&quot;, &quot;indus&quot;, &quot;nox&quot;, &quot;rm&quot;, &quot;age&quot;,
           &quot;dis&quot;, &quot;tax&quot;, &quot;ptratio&quot;, &quot;medv&quot;]
FEATURES = [&quot;crim&quot;, &quot;zn&quot;, &quot;indus&quot;, &quot;nox&quot;, &quot;rm&quot;,
            &quot;age&quot;, &quot;dis&quot;, &quot;tax&quot;, &quot;ptratio&quot;]
LABEL = &quot;medv&quot;

training_set = pd.read_csv(&quot;boston_train.csv&quot;, skipinitialspace=True,
                           skiprows=1, names=COLUMNS)
test_set = pd.read_csv(&quot;boston_test.csv&quot;, skipinitialspace=True,
                       skiprows=1, names=COLUMNS)
prediction_set = pd.read_csv(&quot;boston_predict.csv&quot;, skipinitialspace=True,
                             skiprows=1, names=COLUMNS)
</code></pre><h3><span id="定义featurecolumns并创建回归器">定义FeatureColumns并创建回归器</span></h3><p>接下来，正式为输入数据创建一个<code>FeatureColumn</code>的列表 指定用于训练的一组功能。因为所有的功能 住房数据集包含连续值，您可以创建自己的<br><code>FeatureColumn</code>使用<code>tf.contrib.layers.real_valued_column()</code>功能：</p>
<pre><code>feature_cols = [tf.feature_column.numeric_column(k) for k in FEATURES]
</code></pre><p>注：有关功能列的更深入的概述，请参阅 这个介绍， 并举例说明如何定义<code>FeatureColumns</code> 分类数据，请参阅线性模型教程。</p>
<p>现在，将<code>DNNRegressor</code>实例化为神经网络回归模型。 您需要在这里提供两个参数：<code>hidden_units</code>，一个超参数<br>指定每个隐藏层（这里是两个隐藏层）中的节点数量 每个节点有10个节点）和<code>feature_columns</code>（包含该节点的列表）<br>您刚刚定义的<code>FeatureColumns</code>：</p>
<pre><code>regressor = tf.estimator.DNNRegressor(feature_columns=feature_cols,
                                      hidden_units=[10, 10],
                                      model_dir=&quot;/tmp/boston_model&quot;)
</code></pre><h3><span id="建立input_fn">建立input_fn</span></h3><p>要将输入数据传递到<code>regressor</code>，请编写一个工厂方法，接受一个 大熊猫<code>Dataframe</code>，并返回<code>input_fn</code>：</p>
<pre><code>def get_input_fn(data_set, num_epochs=None, shuffle=True):
  return tf.estimator.inputs.pandas_input_fn(
      x=pd.DataFrame({k: data_set[k].values for k in FEATURES}),
      y = pd.Series(data_set[LABEL].values),
      num_epochs=num_epochs,
      shuffle=shuffle)
</code></pre><p>请注意，输入数据在<code>input_fn</code>参数中传递给<code>data_set</code>， 这意味着该功能可以处理您导入的任何<code>DataFrame</code>：<br><code>training_set</code>，<code>test_set</code>和<code>prediction_set</code>。</p>
<p>提供了另外两个参数：  <code>num_epochs</code>：控制的数量   时代迭代数据。对于培训，请将此设置为<code>None</code>，这样的话<br><code>input_fn</code>不断返回数据，直到所需的列车步数为止   到达。为了评估和预测，设置为1，所以<code>input_fn</code>将会<br>重复数据一次，然后提出<code>OutOfRangeError</code>。那个错误会的   指示<code>Estimator</code>停止评估或预测。<br><code>shuffle</code>：是否洗牌数据。为了评估和预测，将其设置为   <code>False</code>，所以<code>input_fn</code>依次迭代数据。对于火车，   设置为<code>True</code>。</p>
<h3><span id="培训减压阀">培训减压阀</span></h3><p>使用<code>train</code>运行<code>training_set</code>，训练神经网络回归器 按如下方式传给<code>input_fn</code>：</p>
<pre><code>regressor.train(input_fn=get_input_fn(training_set), steps=5000)
</code></pre><p>您应该看到类似于以下内容的日志输出，这会报告培训损失 每100步：</p>
<pre><code>INFO:tensorflow:Step 1: loss = 483.179
INFO:tensorflow:Step 101: loss = 81.2072
INFO:tensorflow:Step 201: loss = 72.4354
...
INFO:tensorflow:Step 1801: loss = 33.4454
INFO:tensorflow:Step 1901: loss = 32.3397
INFO:tensorflow:Step 2001: loss = 32.0053
INFO:tensorflow:Step 4801: loss = 27.2791
INFO:tensorflow:Step 4901: loss = 27.2251
INFO:tensorflow:Saving checkpoints for 5000 into /tmp/boston_model/model.ckpt.
INFO:tensorflow:Loss for final step: 27.1674.
</code></pre><h3><span id="评估模型">评估模型</span></h3><p>接下来，看看训练的模型如何针对测试数据集执行。跑 <code>evaluate</code>，这次将<code>test_set</code>传递给<code>input_fn</code>：</p>
<pre><code>ev = regressor.evaluate(
    input_fn=get_input_fn(test_set, num_epochs=1, shuffle=False))
</code></pre><p>从<code>ev</code>结果中检索损失并打印输出：</p>
<pre><code>loss_score = ev[&quot;loss&quot;]
print(&quot;Loss: {0:f}&quot;.format(loss_score))
</code></pre><p>您应该看到类似于以下的结果：</p>
<pre><code>INFO:tensorflow:Eval steps [0,1) for training step 5000.
INFO:tensorflow:Saving evaluation summary for 5000 step: loss = 11.9221
Loss: 11.922098
</code></pre><h3><span id="做预测">做预测</span></h3><p>最后，您可以使用该模型来预测房屋的中位数值 <code>prediction_set</code>，其中包含功能数据，但没有标签的六个例子：</p>
<pre><code>y = regressor.predict(
    input_fn=get_input_fn(prediction_set, num_epochs=1, shuffle=False))
# .predict() returns an iterator of dicts; convert to a list and print
# predictions
predictions = list(p[&quot;predictions&quot;] for p in itertools.islice(y, 6))
print(&quot;Predictions: {}&quot;.format(str(predictions)))
</code></pre><p>你的结果应该包含六千美元的房屋价值预测， 例如：</p>
<pre><code>Predictions: [ 33.30348587  17.04452896  22.56370163  34.74345398  14.55953979
  19.58005714]
</code></pre><h2><span id="其他资源">其他资源</span></h2><p>本教程着重于为神经网络回归器创建<code>input_fn</code>。 要了解有关将<code>input_fn</code>用于其他类型型号的更多信息，请查看 以下资源：</p>
<p>具有张量流的大型线性模型：这个     在TensorFlow中引入线性模型提供了一个高层次的概述     用于转换输入数据的特征列和技术。<br>TensorFlow线性模型教程：本教程涵盖     创建<code>FeatureColumn</code>和<code>input_fn</code>进行线性分类<br>根据人口普查数据预测收入范围的模型。 TensorFlow广泛和深度学习教程：建立在     线性模型教程，本教程涵盖<br><code>FeatureColumn</code>和<code>input_fn</code>创造了一个“宽而深”的模型     结合了线性模型和神经网络的使用<br><code>DNNLinearCombinedClassifier</code>。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/fling-gesture-detection-on-grid-layout/" title="在网格布局上进行手势检测" itemprop="url">在网格布局上进行手势检测</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>我想要得到<code>fling</code>手势检测工作在我的Android应用程序。</p>
<p>我有一个<code>GridLayout</code>，其中包含9个<code>ImageView</code>s。来源可以在这里找到：罗曼人的网格布局。</p>
<p>我拿的文件是从罗曼盖伊的Photostream应用程序，只有轻微的适应。</p>
<p>对于简单的点击情况，我只需要为每个<code>onClickListener</code>设置<code>ImageView</code>，我将其添加为实现<code>activity</code>的主要<code>View.OnClickListener</code>。实现能识别<code>fling</code>的东西似乎是无限复杂的。我想这是因为它可能跨越<code>views</code>？</p>
<p>如果我的活动实施 <code>OnGestureListener</code>我不知道如何 设置为手势监听器 <code>Grid</code>或<code>Image</code>的意见，我 加。<br>公共类SelectFilterActivity扩展了Activity实现    View.OnClickListener，OnGestureListener<br>{… 如果我的活动实施 <code>OnTouchListener</code>然后我没有 <code>onFling</code>方法到<code>override</code>（它有 两个事件作为允许我的参数<br>以确定是否是一扔 值得注意的）。 公共类SelectFilterActivity扩展了Activity实现<br>View.OnClickListener，OnTouchListener {…<br>如果我做一个自定义<code>View</code>，就像<code>GestureImageView</code>扩展<code>ImageView</code>我不知道如何告诉活动，从视图<code>fling</code>已经发生。无论如何，我试过这个，当我触摸屏幕的时候，方法并没有被调用。</p>
<p>我真的只是需要一个具体的例子，跨视图工作。什么，何时以及如何附加这个<code>listener</code>？我需要能够检测到单击也。</p>
<pre><code>// Gesture detection
mGestureDetector = new GestureDetector(this, new GestureDetector.SimpleOnGestureListener() {

    public boolean onFling(MotionEvent e1, MotionEvent e2, float velocityX, float velocityY) {
        int dx = (int) (e2.getX() - e1.getX());
        // don&apos;t accept the fling if it&apos;s too short
        // as it may conflict with a button push
        if (Math.abs(dx) &gt; MAJOR_MOVE &amp;&amp; Math.abs(velocityX) &gt; Math.absvelocityY)) {
            if (velocityX &gt; 0) {
                moveRight();
            } else {
                moveLeft();
            }
            return true;
        } else {
            return false;
        }
    }
});
</code></pre><p>是否可以在屏幕上方放置一个透明视图来捕捉掠过？</p>
<p>如果我选择不从<code>inflate</code>我的孩子图像视图从XML我可以传递<code>GestureDetector</code>作为构造函数参数创建<code>ImageView</code>新的子类？</p>
<p>这是我试图让<code>fling</code>检测工作的非常简单的活动：SelectFilterActivity（从照片流改编）。</p>
<p>我一直在看这些来源：</p>
<p>检测手势 - 教程 SDK文档 计算器代码</p>
<p>到目前为止，没有任何工作为我工作，我希望得到一些指示。</p>
        
        
        <p class="article-more-link">
          
            <a href="/2018/01/01/fling-gesture-detection-on-grid-layout/#more">Read More</a>
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  


  <nav id="page-nav" class="clearfix">
    <a class="extend prev" rel="prev" href="/page/121/"><span></span>Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/120/">120</a><a class="page-number" href="/page/121/">121</a><span class="page-number current">122</span><a class="page-number" href="/page/123/">123</a><a class="page-number" href="/page/124/">124</a><span class="space">&hellip;</span><a class="page-number" href="/page/157/">157</a><a class="extend next" rel="next" href="/page/123/">Next<span></span></a>
  </nav>

</div>

      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- side-bar-ad -->
<ins class="adsbygoogle"
     style="display:block; overflow:hidden;"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="2232545787"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


  


  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/javascript/" title="javascript">javascript<sup>207</sup></a></li>
			
		
			
				<li><a href="/tags/java/" title="java">java<sup>205</sup></a></li>
			
		
			
				<li><a href="/tags/html/" title="html">html<sup>203</sup></a></li>
			
		
			
				<li><a href="/tags/python/" title="python">python<sup>199</sup></a></li>
			
		
			
				<li><a href="/tags/bash/" title="bash">bash<sup>198</sup></a></li>
			
		
			
				<li><a href="/tags/php/" title="php">php<sup>197</sup></a></li>
			
		
			
				<li><a href="/tags/css/" title="css">css<sup>88</sup></a></li>
			
		
			
				<li><a href="/tags/shell/" title="shell">shell<sup>78</sup></a></li>
			
		
			
				<li><a href="/tags/jquery/" title="jquery">jquery<sup>61</sup></a></li>
			
		
			
				<li><a href="/tags/linux/" title="linux">linux<sup>57</sup></a></li>
			
		
			
				<li><a href="/tags/机器学习/" title="机器学习">机器学习<sup>41</sup></a></li>
			
		
			
				<li><a href="/tags/unix/" title="unix">unix<sup>30</sup></a></li>
			
		
			
				<li><a href="/tags/mysql/" title="mysql">mysql<sup>17</sup></a></li>
			
		
			
				<li><a href="/tags/html5/" title="html5">html5<sup>16</sup></a></li>
			
		
			
				<li><a href="/tags/xml/" title="xml">xml<sup>13</sup></a></li>
			
		
			
				<li><a href="/tags/http/" title="http">http<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/区块链/" title="区块链">区块链<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://tracholar.github.io" target="_blank" title="个人博客">个人博客</a>
            
          </li>
        
    </ul>
</div>

  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

</aside>
</div>

    </div>
    <footer><div id="footer" >
	
	
	<section class="info">
		<p> To be or not to be, that is a question. <br/>
			This is my blog,believe it or not.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		版权所有 © 2018 本站文章未经同意，禁止转载！作者：
		
		<a href="/about" target="_blank" title="zhizi">zhizi</a>
		


		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>












<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->





<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
