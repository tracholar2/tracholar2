
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>智子</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="zhizi">
    

    
    <meta name="description" content="IT技术、编程、web开发以及新兴的技术翻译与总结">
<meta property="og:type" content="website">
<meta property="og:title" content="智子">
<meta property="og:url" content="https://www.tracholar.top/page/122/index.html">
<meta property="og:site_name" content="智子">
<meta property="og:description" content="IT技术、编程、web开发以及新兴的技术翻译与总结">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="智子">
<meta name="twitter:description" content="IT技术、编程、web开发以及新兴的技术翻译与总结">

    
    <link rel="alternative" href="/atom.xml" title="智子" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">

    <!-- ad start -->
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-6300557868920774",
    enable_page_level_ads: true
  });
</script>

    <!-- ad end -->

    <!--  stat -->
    <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?4036f580b1119e720db871571faa68cc";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-78529611-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-78529611-1');
</script>

    <!-- end stat -->
</head>

  <body>
    <header>
      
<div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="智子">智子</a></h1>
				<h2 class="blog-motto">智子之家</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:www.tracholar.top">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main">


   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/dev/" title="发展" itemprop="url">发展</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="发展">发展</span></h1><p>有关TensorFlow编程基础的简要概述，请参阅以下内容 指南：</p>
<p>TensorFlow入门</p>
<p>MNIST已经成为尝试新机器学习的标准数据集 工具包。我们提供了三个指南，每个指南都有不同的方法 在TensorFlow上培训MNIST模型：</p>
<p>MN初学者MNIST，介绍MNIST     高级API。 专家深度MNIST，比深度更深     “MN初学者MNIST”，并假定对机器有一定的了解<br>学习的概念。 通过引入MNIST的TensorFlow Mechanics 101     低级的API。</p>
<p>对于新开发TensorFlow的开发者来说，高级API是一个很好的开始。 要了解高级API，请阅读以下指南：</p>
<p>tf.estimator快速入门，介绍了这一点     API。 建立输入功能​​，     这会让你进入这个API的更复杂的使用。</p>
<p>TensorBoard是可视化机器学习的不同方面的实用程序。 以下指南介绍如何使用TensorBoard：</p>
<p>TensorBoard：可视化学习，     这让你开始。 TensorBoard：图形可视化，解释     如何可视化计算图。图形可视化通常是<br>对使用低级API的程序员更有用。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  
      <ins class="adsbygoogle"
     style="display:block;  overflow:hidden;"
     data-ad-format="fluid"
     data-ad-layout-key="-ej+6f-q-c7+ou"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="5206371097"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/datasets/" title="导入数据" itemprop="url">导入数据</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="导入数据">导入数据</span></h1><p><code>Dataset</code> API使您能够构建复杂的输入管道 简单，可重复使用的作品。例如，图像模型的管道可能会 从分布式文件系统中的文件汇总数据，随机应用<br>扰动每个图像，并将随机选择的图像合并为一批 为了训练。文本模型的管道可能涉及提取符号 从原始文本数据，将其转换为查找嵌入标识符<br>表，并将不同长度的序列分配在一起。 <code>Dataset</code> API 可以轻松处理大量的数据，不同的数据格式 复杂的转变。</p>
<p><code>Dataset</code> API为TensorFlow引入了两个新的抽象：</p>
<p><code>tf.data.Dataset</code>代表一系列元素，其中   每个元素包含一个或多个<code>Tensor</code>对象。例如，在一个图像<br>管道，一个元素可能是一个训练的例子，有一对   张量表示图像数据和标签。有两个截然不同的   创建数据集的方法：<br>创建一个源（例如<code>Dataset.from_tensor_slices()</code>）构建一个     数据集     一个或多个<code>tf.Tensor</code>对象。<br>应用转换（例如<code>Dataset.batch()</code>）构建数据集     来自一个或多个<code>tf.data.Dataset</code>对象。<br>一个<code>tf.data.Iterator</code>提供了从一个提取元素的主要方法   数据集。由<code>Iterator.get_next()</code>返回的操作产生下一个<br><code>Dataset</code>的元件在执行时通常用作接口   输入管道代码和你的模型之间。最简单的迭代器是a   “一次迭代器”，它与一个特定的<code>Dataset</code>和<br>迭代一次。对于更复杂的用途，   <code>Iterator.initializer</code>操作使您能够重新初始化和参数化   一个具有不同数据集的迭代器，以便您可以迭代<br>在同一个程序中多次训练和验证数据。</p>
<h2><span id="基本力学">基本力学</span></h2><p>本指南的这一部分描述了创建不同种类的基础知识 <code>Dataset</code>和<code>Iterator</code>的对象，以及如何从中提取数据。</p>
<p>要启动输入管道，您必须定义一个源。例如， 从记忆中的一些张量构建一个<code>Dataset</code>，就可以使用<br><code>tf.data.Dataset.from_tensors()</code>或<br><code>tf.data.Dataset.from_tensor_slices()</code>。或者，如果你的输入 数据在推荐的TFRecord格式磁盘上，你可以构造一个<br><code>tf.data.TFRecordDataset</code>。</p>
<p>一旦你有一个<code>Dataset</code>的对象，你可以转换成一个新的<code>Dataset</code> 链接方法调用<code>tf.data.Dataset</code>对象。例如，你<br>可以应用每元素转换，如<code>Dataset.map()</code>（申请一个 函数到每个元素）和多元素转换，如<br><code>Dataset.batch()</code>。请参阅<code>tf.data.Dataset</code>的文档 为完整的转换列表。</p>
<p>从<code>Dataset</code>中消费数值的最常用方法是制作一个 迭代器对象，一次提供对数据集的一个元素的访问<br>（例如，通过调用<code>Dataset.make_one_shot_iterator()</code>）。一个<br><code>tf.data.Iterator</code>提供两种操作：<code>Iterator.initializer</code>， 它使您能够（重新）初始化迭代器的状态;和<br><code>Iterator.get_next()</code>，它返回对应的<code>tf.Tensor</code>对象 象征性的下一个元素。根据你的用例，你可能会选择一个不同的<br>迭代器类型，下面列出了选项。</p>
<h3><span id="数据集结构">数据集结构</span></h3><p>数据集包含各自具有相同结构的元素。一个元素 包含一个或多个称为组件的<code>tf.Tensor</code>对象。每个组件 <code>tf.DType</code>代表张量中元素的类型，a<br><code>tf.TensorShape</code>代表（可能部分指定）的静态形状 每个元素。<br><code>Dataset.output_types</code>和<code>Dataset.output_shapes</code>属性 允许您检查a的每个组件的推断类型和形状<br>数据集元素。这些属性的嵌套结构映射到结构 一个元素，它可能是单张量，张量元组或嵌套 张量元组。例如：</p>
<pre><code>dataset1 = tf.data.Dataset.from_tensor_slices(tf.random_uniform([4, 10]))
print(dataset1.output_types)  # ==&gt; &quot;tf.float32&quot;
print(dataset1.output_shapes)  # ==&gt; &quot;(10,)&quot;

dataset2 = tf.data.Dataset.from_tensor_slices(
   (tf.random_uniform([4]),
    tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)))
print(dataset2.output_types)  # ==&gt; &quot;(tf.float32, tf.int32)&quot;
print(dataset2.output_shapes)  # ==&gt; &quot;((), (100,))&quot;

dataset3 = tf.data.Dataset.zip((dataset1, dataset2))
print(dataset3.output_types)  # ==&gt; (tf.float32, (tf.float32, tf.int32))
print(dataset3.output_shapes)  # ==&gt; &quot;(10, ((), (100,)))&quot;
</code></pre><p>为一个元素的每个元素命名通常很方便 例如，如果它们表示训练示例的不同特征。此外<br>到元组，可以使用<code>collections.namedtuple</code>或字典映射字符串 张量来代表<code>Dataset</code>的单个元素。</p>
<pre><code>dataset = tf.data.Dataset.from_tensor_slices(
   {&quot;a&quot;: tf.random_uniform([4]),
    &quot;b&quot;: tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)})
print(dataset.output_types)  # ==&gt; &quot;{&apos;a&apos;: tf.float32, &apos;b&apos;: tf.int32}&quot;
print(dataset.output_shapes)  # ==&gt; &quot;{&apos;a&apos;: (), &apos;b&apos;: (100,)}&quot;
</code></pre><p><code>Dataset</code>转换支持任何结构的数据集。使用时<br><code>Dataset.map()</code>，<code>Dataset.flat_map()</code>和<code>Dataset.filter()</code>转化，<br>它将一个函数应用到每个元素，元素的结构决定了 函数的参数：</p>
<pre><code>dataset1 = dataset1.map(lambda x: ...)

dataset2 = dataset2.flat_map(lambda x, y: ...)

# Note: Argument destructuring is not available in Python 3.
dataset3 = dataset3.filter(lambda x, (y, z): ...)
</code></pre><h3><span id="创建一个迭代器">创建一个迭代器</span></h3><p>一旦你建立了一个<code>Dataset</code>来表示你的输入数据，下一步就是 创建一个<code>Iterator</code>来访问该数据集中的元素。 <code>Dataset</code> API<br>目前支持以下迭代器，在增加级别 成熟：</p>
<p>一次性的， initializable， 可重新初始化和 可补给。</p>
<p>一次迭代器是仅支持的最简单的迭代器形式 迭代一次数据集，而不需要显式的初始化。 一次迭代器处理几乎所有现有的基于队列的情况<br>输入管道支持，但不支持参数化。使用 <code>Dataset.range()</code>的示例：</p>
<pre><code>dataset = tf.data.Dataset.range(100)
iterator = dataset.make_one_shot_iterator()
next_element = iterator.get_next()

for i in range(100):
  value = sess.run(next_element)
  assert i == value
</code></pre><p>注意：目前，一次迭代器是唯一可以轻松使用的类型 与<code>Estimator</code>。</p>
<p>一个可初始化的迭代器需要你运行一个显式的 <code>iterator.initializer</code>的使用方法。作为交换 不方便，它使您能够参数化数据集的定义，<br>使用一个或多个可在您喂食的<code>tf.placeholder()</code>张量 初始化迭代器。继续<code>Dataset.range()</code>示例：</p>
<pre><code>max_value = tf.placeholder(tf.int64, shape=[])
dataset = tf.data.Dataset.range(max_value)
iterator = dataset.make_initializable_iterator()
next_element = iterator.get_next()

# Initialize an iterator over a dataset with 10 elements.
sess.run(iterator.initializer, feed_dict={max_value: 10})
for i in range(10):
  value = sess.run(next_element)
  assert i == value

# Initialize the same iterator over a dataset with 100 elements.
sess.run(iterator.initializer, feed_dict={max_value: 100})
for i in range(100):
  value = sess.run(next_element)
  assert i == value
</code></pre><p>可重新初始化的迭代器可以从多个不同的初始化 <code>Dataset</code>物体。例如，您可能有一个培训输入管道 对输入图像使用随机扰动来改善泛化，<br>验证输入管道，用于评估未修改数据的预测。这些 管道通常会使用具有相同的不同<code>Dataset</code>对象 结构（即，每个部件的相同类型和相容的形状）。</p>
<pre><code># Define training and validation datasets with the same structure.
training_dataset = tf.data.Dataset.range(100).map(
    lambda x: x + tf.random_uniform([], -10, 10, tf.int64))
validation_dataset = tf.data.Dataset.range(50)

# A reinitializable iterator is defined by its structure. We could use the
# `output_types` and `output_shapes` properties of either `training_dataset`
# or `validation_dataset` here, because they are compatible.
iterator = Iterator.from_structure(training_dataset.output_types,
                                   training_dataset.output_shapes)
next_element = iterator.get_next()

training_init_op = iterator.make_initializer(training_dataset)
validation_init_op = iterator.make_initializer(validation_dataset)

# Run 20 epochs in which the training dataset is traversed, followed by the
# validation dataset.
for _ in range(20):
  # Initialize an iterator over the training dataset.
  sess.run(training_init_op)
  for _ in range(100):
    sess.run(next_element)

  # Initialize an iterator over the validation dataset.
  sess.run(validation_init_op)
  for _ in range(50):
    sess.run(next_element)
</code></pre><p>可馈入迭代器可与<code>tf.placeholder</code>一起使用进行选择 <code>Iterator</code>在每次<code>tf.Session.run</code>呼叫中使用什么<br><code>feed_dict</code>机制。它提供了与可重新初始化相同的功能 迭代器，但它不要求你从头开始初始化迭代器 在迭代器之间切换时，数据集的数据集。例如，使用相同的<br>从上面的培训和验证的例子，你可以使用 <code>tf.data.Iterator.from_string_handle</code>定义一个可馈送的迭代器<br>这使您可以在两个数据集之间切换：</p>
<pre><code># Define training and validation datasets with the same structure.
training_dataset = tf.data.Dataset.range(100).map(
    lambda x: x + tf.random_uniform([], -10, 10, tf.int64)).repeat()
validation_dataset = tf.data.Dataset.range(50)

# A feedable iterator is defined by a handle placeholder and its structure. We
# could use the `output_types` and `output_shapes` properties of either
# `training_dataset` or `validation_dataset` here, because they have
# identical structure.
handle = tf.placeholder(tf.string, shape=[])
iterator = tf.data.Iterator.from_string_handle(
    handle, training_dataset.output_types, training_dataset.output_shapes)
next_element = iterator.get_next()

# You can use feedable iterators with a variety of different kinds of iterator
# (such as one-shot and initializable iterators).
training_iterator = training_dataset.make_one_shot_iterator()
validation_iterator = validation_dataset.make_initializable_iterator()

# The `Iterator.string_handle()` method returns a tensor that can be evaluated
# and used to feed the `handle` placeholder.
training_handle = sess.run(training_iterator.string_handle())
validation_handle = sess.run(validation_iterator.string_handle())

# Loop forever, alternating between training and validation.
while True:
  # Run 200 steps using the training dataset. Note that the training dataset is
  # infinite, and we resume from where we left off in the previous `while` loop
  # iteration.
  for _ in range(200):
    sess.run(next_element, feed_dict={handle: training_handle})

  # Run one pass over the validation dataset.
  sess.run(validation_iterator.initializer)
  for _ in range(50):
    sess.run(next_element, feed_dict={handle: validation_handle})
</code></pre><h3><span id="从迭代器中消费值">从迭代器中消费值</span></h3><p><code>Iterator.get_next()</code>方法返回一个或多个<code>tf.Tensor</code>对象 对应于迭代器的符号下一个元素。每次这些张量<br>被评估，他们采取底层的下一个元素的值 数据集。 （请注意，像TensorFlow中的其他有状态对象一样，调用<br><code>Iterator.get_next()</code>不会立即推进迭代器。相反，你 必须在TensorFlow表达式中使用返回的<code>tf.Tensor</code>对象，并通过<br><code>tf.Session.run()</code>的表达结果得到下一个元素和 推进迭代器。）</p>
<p>如果迭代器到达数据集的末尾，则执行 <code>Iterator.get_next()</code>将提升<code>tf.errors.OutOfRangeError</code>。<br>在这一点之后，迭代器将处于不可用状态，并且您必须 如果你想进一步使用它，再次初始化它。</p>
<pre><code>dataset = tf.data.Dataset.range(5)
iterator = dataset.make_initializable_iterator()
next_element = iterator.get_next()

# Typically `result` will be the output of a model, or an optimizer&apos;s
# training operation.
result = tf.add(next_element, next_element)

sess.run(iterator.initializer)
print(sess.run(result))  # ==&gt; &quot;0&quot;
print(sess.run(result))  # ==&gt; &quot;2&quot;
print(sess.run(result))  # ==&gt; &quot;4&quot;
print(sess.run(result))  # ==&gt; &quot;6&quot;
print(sess.run(result))  # ==&gt; &quot;8&quot;
try:
  sess.run(result)
except tf.errors.OutOfRangeError:
  print(&quot;End of dataset&quot;)  # ==&gt; &quot;End of dataset&quot;
</code></pre><p><code>try</code>-<code>except</code>程序段中包含“训练循环”的常用模式：</p>
<pre><code>sess.run(iterator.initializer)
while True:
  try:
    sess.run(result)
  except tf.errors.OutOfRangeError:
    break
</code></pre><p>如果数据集的每个元素都有嵌套结构，则返回值为 <code>Iterator.get_next()</code>将是同一个或多个<code>tf.Tensor</code>物件 嵌套结构：</p>
<pre><code>dataset1 = tf.data.Dataset.from_tensor_slices(tf.random_uniform([4, 10]))
dataset2 = tf.data.Dataset.from_tensor_slices((tf.random_uniform([4]), tf.random_uniform([4, 100])))
dataset3 = tf.data.Dataset.zip((dataset1, dataset2))

iterator = dataset3.make_initializable_iterator()

sess.run(iterator.initializer)
next1, (next2, next3) = iterator.get_next()
</code></pre><p>请注意，对<code>next1</code>，<code>next2</code>或<code>next3</code>进行评估将推动 所有组件的迭代器。一个迭代器的典型消费者将包括所有 组件在一个单一的表达。</p>
<h2><span id="读取输入数据">读取输入数据</span></h2><h3><span id="使用numpy数组">使用NumPy数组</span></h3><p>如果所有的输入数据都适合内存，那么创建一个<code>Dataset</code>的最简单的方法就是使用它 从他们是把它们转换成<code>tf.Tensor</code>对象并使用<br><code>Dataset.from_tensor_slices()</code>。</p>
<pre><code># Load the training data into two NumPy arrays, for example using `np.load()`.
with np.load(&quot;/var/data/training_data.npy&quot;) as data:
  features = data[&quot;features&quot;]
  labels = data[&quot;labels&quot;]

# Assume that each row of `features` corresponds to the same row as `labels`.
assert features.shape[0] == labels.shape[0]

dataset = tf.data.Dataset.from_tensor_slices((features, labels))
</code></pre><p>请注意，上面的代码片段将嵌入<code>features</code>和<code>labels</code>阵列 在您的TensorFlow图中作为<code>tf.constant()</code>的操作。这适用于一个<br>小数据集，但浪费内存—因为数组的内容将是 复制多次—可以达到<code>tf.GraphDef</code>的2GB限制 协议缓冲区。</p>
<p>作为替代，您可以根据<code>Dataset</code>定义<code>tf.placeholder()</code> 张量，并在您初始化<code>Iterator</code>时提供NumPy阵列 数据集。</p>
<pre><code># Load the training data into two NumPy arrays, for example using `np.load()`.
with np.load(&quot;/var/data/training_data.npy&quot;) as data:
  features = data[&quot;features&quot;]
  labels = data[&quot;labels&quot;]

# Assume that each row of `features` corresponds to the same row as `labels`.
assert features.shape[0] == labels.shape[0]

features_placeholder = tf.placeholder(features.dtype, features.shape)
labels_placeholder = tf.placeholder(labels.dtype, labels.shape)

dataset = tf.data.Dataset.from_tensor_slices((features_placeholder, labels_placeholder))
# [Other transformations on `dataset`...]
dataset = ...
iterator = dataset.make_initializable_iterator()

sess.run(iterator.initializer, feed_dict={features_placeholder: features,
                                          labels_placeholder: labels})
</code></pre><h3><span id="消费tfrecord数据">消费TFRecord数据</span></h3><p><code>Dataset</code> API支持多种文件格式，以便进行处理 大数据集不适合内存。例如，TFRecord文件格式<br>是许多TensorFlow应用程序使用的简单的面向记录的二进制格式 用于训练数据。 <code>tf.data.TFRecordDataset</code>级可以让您<br>将一个或多个TFRecord文件的内容作为输入的一部分进行流式传输 管道。</p>
<pre><code># Creates a dataset that reads all of the examples from two files.
filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
</code></pre><p><code>filenames</code>初始化程序的<code>TFRecordDataset</code>参数可以是 字符串，字符串列表或<code>tf.Tensor</code>字符串。因此，如果你有<br>两套文件供培训和验证之用，可以使用一个 <code>tf.placeholder(tf.string)</code>来表示文件名，并初始化一个 迭代器从适当的文件名：</p>
<pre><code>filenames = tf.placeholder(tf.string, shape=[None])
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(...)  # Parse the record into tensors.
dataset = dataset.repeat()  # Repeat the input indefinitely.
dataset = dataset.batch(32)
iterator = dataset.make_initializable_iterator()

# You can feed the initializer with the appropriate filenames for the current
# phase of execution, e.g. training vs. validation.

# Initialize `iterator` with training data.
training_filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
sess.run(iterator.initializer, feed_dict={filenames: training_filenames})

# Initialize `iterator` with validation data.
validation_filenames = [&quot;/var/data/validation1.tfrecord&quot;, ...]
sess.run(iterator.initializer, feed_dict={filenames: validation_filenames})
</code></pre><h3><span id="消费文本数据">消费文本数据</span></h3><p>许多数据集分布为一个或多个文本文件。该 <code>tf.data.TextLineDataset</code>提供了一个简单的方法来提取线路<br>一个或多个文本文件。给定一个或多个文件名，<code>TextLineDataset</code>将 产生这些文件的每行一个字符串值的元素。像一个<br><code>TFRecordDataset</code>，<code>TextLineDataset</code>可接受<code>filenames</code>作为<code>tf.Tensor</code><br>您可以通过传递<code>tf.placeholder(tf.string)</code>来进行参数化。</p>
<pre><code>filenames = [&quot;/var/data/file1.txt&quot;, &quot;/var/data/file2.txt&quot;]
dataset = tf.data.TextLineDataset(filenames)
</code></pre><p>默认情况下，<code>TextLineDataset</code>会产生每个文件的每一行，这可能是 不是所希望的，例如，如果文件以标题行或包含开始<br>注释。这些线可以使用<code>Dataset.skip()</code>和 <code>Dataset.filter()</code>转换。将这些转换应用于每个转换<br>我们使用<code>Dataset.flat_map()</code>创建一个嵌套的<code>Dataset</code> 每个文件。</p>
<pre><code>filenames = [&quot;/var/data/file1.txt&quot;, &quot;/var/data/file2.txt&quot;]

dataset = tf.data.Dataset.from_tensor_slices(filenames)

# Use `Dataset.flat_map()` to transform each file as a separate nested dataset,
# and then concatenate their contents sequentially into a single &quot;flat&quot; dataset.
# * Skip the first line (header row).
# * Filter out lines beginning with &quot;#&quot; (comments).
dataset = dataset.flat_map(
    lambda filename: (
        tf.data.TextLineDataset(filename)
        .skip(1)
        .filter(lambda line: tf.not_equal(tf.substr(line, 0, 1), &quot;#&quot;))))
</code></pre><p>有关使用数据集解析CSV文件的完整示例，请参阅<code>imports85.py</code> 在回归的例子。</p>
<h2><span id="用datasetmap预处理数据">用<code>Dataset.map()</code>预处理数据</span></h2><p><code>Dataset.map(f)</code>转换通过应用给定的方法产生一个新的数据集 功能<code>f</code>到输入数据集的每个元素。它基于 该 <code>map()</code>功能<br>这是通常适用于功能列表（和其他结构） 编程语言。功能<code>f</code>使用<code>tf.Tensor</code>对象 表示输入中的单个元素，并返回<code>tf.Tensor</code>对象<br>这将代表新数据集中的单个元素。它的实现使用 标准的TensorFlow操作将一个元素转换成另一个元素。</p>
<p>本节介绍如何使用<code>Dataset.map()</code>的常用示例。</p>
<h3><span id="解析tfexample协议缓冲区信息">解析<code>tf.Example</code>协议缓冲区信息</span></h3><p>许多输入流水线从a中提取<code>tf.train.Example</code>协议缓冲区消息 TFRecord格式的文件（例如，使用<br><code>tf.python_io.TFRecordWriter</code>）。每个<code>tf.train.Example</code>记录包含一个或者一个<br>更多的“功能”，输入管道通常将这些功能转换成 张量。</p>
<pre><code># Transforms a scalar string `example_proto` into a pair of a scalar string and
# a scalar integer, representing an image and its label, respectively.
def _parse_function(example_proto):
  features = {&quot;image&quot;: tf.FixedLenFeature((), tf.string, default_value=&quot;&quot;),
              &quot;label&quot;: tf.FixedLenFeature((), tf.int32, default_value=0)}
  parsed_features = tf.parse_single_example(example_proto, features)
  return parsed_features[&quot;image&quot;], parsed_features[&quot;label&quot;]

# Creates a dataset that reads all of the examples from two files, and extracts
# the image and label features.
filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(_parse_function)
</code></pre><h3><span id="解码图像数据并调整大小">解码图像数据并调整大小</span></h3><p>当在真实世界的图像数据上训练神经网络时，通常是必要的 把不同大小的图像转换成一个通用的大小，以便它们可以 分批成一个固定的大小。</p>
<pre><code># Reads an image from a file, decodes it into a dense tensor, and resizes it
# to a fixed shape.
def _parse_function(filename, label):
  image_string = tf.read_file(filename)
  image_decoded = tf.image.decode_image(image_string)
  image_resized = tf.image.resize_images(image_decoded, [28, 28])
  return image_resized, label

# A vector of filenames.
filenames = tf.constant([&quot;/var/data/image1.jpg&quot;, &quot;/var/data/image2.jpg&quot;, ...])

# `labels[i]` is the label for the image in `filenames[i].
labels = tf.constant([0, 37, ...])

dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))
dataset = dataset.map(_parse_function)
</code></pre><h3><span id="应用tfpy_func的任意python逻辑">应用<code>tf.py_func()</code>的任意Python逻辑</span></h3><p>出于性能原因，我们鼓励您使用TensorFlow操作 尽可能预处理您的数据。但是，它有时是有用的 解析输入数据时调用外部Python库。为此，<br>调用<code>tf.py_func()</code>转换中的<code>Dataset.map()</code>操作。</p>
<pre><code>import cv2

# Use a custom OpenCV function to read the image, instead of the standard
# TensorFlow `tf.read_file()` operation.
def _read_py_function(filename, label):
  image_decoded = cv2.imread(image_string, cv2.IMREAD_GRAYSCALE)
  return image_decoded, label

# Use standard TensorFlow operations to resize the image to a fixed shape.
def _resize_function(image_decoded, label):
  image_decoded.set_shape([None, None, None])
  image_resized = tf.image.resize_images(image_decoded, [28, 28])
  return image_resized, label

filenames = [&quot;/var/data/image1.jpg&quot;, &quot;/var/data/image2.jpg&quot;, ...]
labels = [0, 37, 29, 1, ...]

dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))
dataset = dataset.map(
    lambda filename, label: tuple(tf.py_func(
        _read_py_function, [filename, label], [tf.uint8, label.dtype])))
dataset = dataset.map(_resize_function)
</code></pre><h2><span id="批处理数据集元素">批处理数据集元素</span></h2><h3><span id="简单的配料">简单的配料</span></h3><p><code>n</code>连续数据集元素的最简单的批处理形式 一个单一的元素。 <code>Dataset.batch()</code>转换就是这样做的<br>与<code>tf.stack()</code>操作员相同的约束适用于每个组件 的元素：即对于每个元素i，所有元素必须具有张量 完全相同的形状。</p>
<pre><code>inc_dataset = tf.data.Dataset.range(100)
dec_dataset = tf.data.Dataset.range(0, -100, -1)
dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))
batched_dataset = dataset.batch(4)

iterator = batched_dataset.make_one_shot_iterator()
next_element = iterator.get_next()

print(sess.run(next_element))  # ==&gt; ([0, 1, 2,   3],   [ 0, -1,  -2,  -3])
print(sess.run(next_element))  # ==&gt; ([4, 5, 6,   7],   [-4, -5,  -6,  -7])
print(sess.run(next_element))  # ==&gt; ([8, 9, 10, 11],   [-8, -9, -10, -11])
</code></pre><h3><span id="用填料分批张量">用填料分批张量</span></h3><p>上面的配方适用于所有尺寸相同的张量。但是，很多 模型（例如序列模型）与可能具有不同大小的输入数据一起工作 （例如不同长度的序列）。为了处理这种情况，<br><code>Dataset.padded_batch()</code>转换使您能够批量张量 通过指定一个或多个维度来指定不同的形状 填充。</p>
<pre><code>dataset = tf.data.Dataset.range(100)
dataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))
dataset = dataset.padded_batch(4, padded_shapes=[None])

iterator = dataset.make_one_shot_iterator()
next_element = iterator.get_next()

print(sess.run(next_element))  # ==&gt; [[0, 0, 0], [1, 0, 0], [2, 2, 0], [3, 3, 3]]
print(sess.run(next_element))  # ==&gt; [[4, 4, 4, 4, 0, 0, 0],
                               #      [5, 5, 5, 5, 5, 0, 0],
                               #      [6, 6, 6, 6, 6, 6, 0],
                               #      [7, 7, 7, 7, 7, 7, 7]]
</code></pre><p><code>Dataset.padded_batch()</code>转换允许您设置不同的填充 为每个组件的每个维度，它可能是可变长度（表示<br>在上面的例子中由<code>None</code>）或恒定长度。也有可能 重写填充值，默认为0。</p>
<h2><span id="培训工作流程">培训工作流程</span></h2><h3><span id="处理多个时代">处理多个时代</span></h3><p><code>Dataset</code> API提供了两种主要的方法来处理多个相同的历元 数据。</p>
<p>在多个时期迭代数据集的最简单方法是使用 <code>Dataset.repeat()</code>转换。例如，创建重复的数据集 它的输入为10个时期：</p>
<pre><code>filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(...)
dataset = dataset.repeat(10)
dataset = dataset.batch(32)
</code></pre><p>将不重复应用<code>Dataset.repeat()</code>转换 输入无限期。 <code>Dataset.repeat()</code>转换将其连接起来<br>而不是一个时代的结束和下一个开始的信号 时代。</p>
<p>如果你想在每个纪元结束时收到一个信号，你可以写一个 训练循环捕捉到<code>tf.errors.OutOfRangeError</code>的末尾<br>数据集。在这一点上，你可能会收集一些统计数据（例如验证 错误）的时代。</p>
<pre><code>filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(...)
dataset = dataset.batch(32)
iterator = dataset.make_initializable_iterator()
next_element = iterator.get_next()

# Compute for 100 epochs.
for _ in range(100):
  sess.run(iterator.initializer)
  while True:
    try:
      sess.run(next_element)
    except tf.errors.OutOfRangeError:
      break

  # [Perform end-of-epoch calculations here.]
</code></pre><h3><span id="随机洗牌输入数据">随机洗牌输入数据</span></h3><p><code>Dataset.shuffle()</code>变换随机混洗输入数据集 使用与<code>tf.RandomShuffleQueue</code>类似的算法：它保持固定大小<br>缓冲区并从该缓冲区中随机选择下一个元素。</p>
<pre><code>filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(...)
dataset = dataset.shuffle(buffer_size=10000)
dataset = dataset.batch(32)
dataset = dataset.repeat()
</code></pre><h3><span id="使用高级api">使用高级API</span></h3><p><code>tf.train.MonitoredTrainingSession</code> API简化了运行的许多方面 TensorFlow在分布式设置中。<br><code>MonitoredTrainingSession</code>使用的 <code>tf.errors.OutOfRangeError</code>表示训练已经完成，所以使用它<br>使用<code>Dataset</code> API，我们推荐使用 <code>Dataset.make_one_shot_iterator()</code>。例如：</p>
<pre><code>filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(...)
dataset = dataset.shuffle(buffer_size=10000)
dataset = dataset.batch(32)
dataset = dataset.repeat(num_epochs)
iterator = dataset.make_one_shot_iterator()

next_example, next_label = iterator.get_next()
loss = model_function(next_example, next_label)

training_op = tf.train.AdagradOptimizer(...).minimize(loss)

with tf.train.MonitoredTrainingSession(...) as sess:
  while not sess.should_stop():
    sess.run(training_op)
</code></pre><p>要在<code>Dataset</code>的<code>input_fn</code>中使用<code>tf.estimator.Estimator</code>，我们也<br>推荐使用<code>Dataset.make_one_shot_iterator()</code>。例如：</p>
<pre><code>def dataset_input_fn():
  filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
  dataset = tf.data.TFRecordDataset(filenames)

  # Use `tf.parse_single_example()` to extract data from a `tf.Example`
  # protocol buffer, and perform any additional per-record preprocessing.
  def parser(record):
    keys_to_features = {
        &quot;image_data&quot;: tf.FixedLenFeature((), tf.string, default_value=&quot;&quot;),
        &quot;date_time&quot;: tf.FixedLenFeature((), tf.int64, default_value=&quot;&quot;),
        &quot;label&quot;: tf.FixedLenFeature((), tf.int64,
                                    default_value=tf.zeros([], dtype=tf.int64)),
    }
    parsed = tf.parse_single_example(record, keys_to_features)

    # Perform additional preprocessing on the parsed data.
    image = tf.decode_jpeg(parsed[&quot;image_data&quot;])
    image = tf.reshape(image, [299, 299, 1])
    label = tf.cast(parsed[&quot;label&quot;], tf.int32)

    return {&quot;image_data&quot;: image, &quot;date_time&quot;: parsed[&quot;date_time&quot;]}, label

  # Use `Dataset.map()` to build a pair of a feature dictionary and a label
  # tensor for each example.
  dataset = dataset.map(parser)
  dataset = dataset.shuffle(buffer_size=10000)
  dataset = dataset.batch(32)
  dataset = dataset.repeat(num_epochs)
  iterator = dataset.make_one_shot_iterator()

  # `features` is a dictionary in which each value is a batch of values for
  # that feature; `labels` is a batch of labels.
  features, labels = iterator.get_next()
  return features, labels
</code></pre>
        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/tensors/" title="张量" itemprop="url">张量</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="张量">张量</span></h1><p>如名称所示，TensorFlow是定义和运行计算的框架 涉及张量。张量是向量和矩阵的推广 可能更高的尺寸。在内部，TensorFlow表示张量<br>基本数据类型的n维数组。</p>
<p>编写一个TensorFlow程序时，您操作并传递的主要对象 周围是<code>tf.Tensor</code>。 <code>tf.Tensor</code>对象表示一个部分定义的对象<br>计算，最终会产生一个价值。 TensorFlow程序工作 首先建立<code>tf.Tensor</code>物体的图形，详细说明每个张量是如何的<br>根据其他可用的张量计算，然后运行其中的一部分 图表来达到预期的效果。</p>
<p><code>tf.Tensor</code>具有以下特性：</p>
<p>数据类型（例如，<code>float32</code>，<code>int32</code>或<code>string</code>） 一个形状</p>
<p>张量中的每个元素具有相同的数据类型，并且数据类型始终为 众所周知。形状（也就是它的尺寸数量和尺寸 维度）可能只是部分已知的。大多数操作产生的张量<br>如果它们的输入形状也是完全已知的，但是是完全已知的形状 有些情况下只能在图执行时找到张量的形状 时间。</p>
<p>有些类型的张量是特殊的，这些将被其他的覆盖 程序员指南的单位。主要的是：</p>
<p><code>tf.Variable</code> <code>tf.Constant</code> <code>tf.Placeholder</code> <code>tf.SparseTensor</code></p>
<p>除了<code>tf.Variable</code>之外，张量的值是不变的 意味着在单个执行张量的情况下只有一个 值。然而，两次评估相同的张量可以返回不同的值;<br>例如张量可以是从磁盘读取数据的结果，或者 生成一个随机数。</p>
<h2><span id="秩">秩</span></h2><p><code>tf.Tensor</code>对象的等级是它的维数。同义词 排名包括顺序或程度或n维。 请注意，TensorFlow中的排名与数学中的矩阵排名并不相同。<br>如下表所示，TensorFlow中的每个等级对应于a 不同的数学实体：</p>
<table>
<thead>
<tr>
<th>Rank</th>
<th>Math entity  </th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Scalar (magnitude only)  </td>
</tr>
<tr>
<td>1</td>
<td>Vector (magnitude and direction)  </td>
</tr>
<tr>
<td>2</td>
<td>Matrix (table of numbers)  </td>
</tr>
<tr>
<td>3</td>
<td>3-Tensor (cube of numbers)  </td>
</tr>
<tr>
<td>n</td>
<td>n-Tensor (you get the idea)  </td>
</tr>
</tbody>
</table>
<h3><span id="等级0">等级0</span></h3><p>以下片段演示了创建几个0级变量：</p>
<pre><code>mammal = tf.Variable(&quot;Elephant&quot;, tf.string)
ignition = tf.Variable(451, tf.int16)
floating = tf.Variable(3.14159265359, tf.float64)
its_complicated = tf.Variable((12.3, -4.85), tf.complex64)
</code></pre><p>注意：一个字符串在TensorFlow中被视为单个项目，而不是作为一个序列 字符。标量字符串，字符串向量等是可能的</p>
<h3><span id="等级1">等级1</span></h3><p>要创建1级<code>tf.Tensor</code>对象，可以传递一个项目列表作为 初始值。例如：</p>
<pre><code>mystr = tf.Variable([&quot;Hello&quot;], tf.string)
cool_numbers  = tf.Variable([3.14159, 2.71828], tf.float32)
first_primes = tf.Variable([2, 3, 5, 7, 11], tf.int32)
its_very_complicated = tf.Variable([(12.3, -4.85), (7.5, -6.23)], tf.complex64)
</code></pre><h3><span id="排名较高">排名较高</span></h3><p>排名第2的<code>tf.Tensor</code>对象至少由一行组成，至少包含一行 一列：</p>
<pre><code>mymat = tf.Variable([[7],[11]], tf.int16)
myxor = tf.Variable([[False, True],[True, False]], tf.bool)
linear_squares = tf.Variable([[4], [9], [16], [25]], tf.int32)
squarish_squares = tf.Variable([ [4, 9], [16, 25] ], tf.int32)
rank_of_squares = tf.rank(squarish_squares)
mymatC = tf.Variable([[7],[11]], tf.int32)
</code></pre><p>较高等级的张量同样由一个n维数组组成。例如， 在图像处理过程中，使用了许多等级为4的张量 对应于批量示例，图像宽度，图像高度和颜色通道。</p>
<pre><code>my_image = tf.zeros([10, 299, 299, 3])  # batch x height x width x color
</code></pre><h3><span id="获取tftensor对象的等级">获取<code>tf.Tensor</code>对象的等级</span></h3><p>要确定<code>tf.Tensor</code>对象的等级，请调用<code>tf.rank</code>方法。 例如，以下方法以编程方式确定排名 上一节中定义的<code>tf.Tensor</code>：</p>
<pre><code>r = tf.rank(my3d)
# After the graph runs, r will hold the value 3.
</code></pre><h3><span id="参考tftensor切片">参考<code>tf.Tensor</code>切片</span></h3><p>由于<code>tf.Tensor</code>是一个n维的单元阵列，可以访问单个单元 在<code>tf.Tensor</code>中，您需要指定n个索引。</p>
<p>对于0级张量（标量），没有指数是必要的，因为它已经是一个 单号。</p>
<p>对于秩1张量（矢量），传递单个索引允许您访问一个 数：</p>
<pre><code>my_scalar = my_vector[2]
</code></pre><p>请注意，在<code>[]</code>内部传递的索引本身可以是标量<code>tf.Tensor</code>，如果 你想动态地从矢量中选择一个元素。</p>
<p>对于等级2或更高的张量，情况更有趣。为一个 等级2的<code>tf.Tensor</code>，按预期传递两个数字返回一个标量：</p>
<pre><code>my_scalar = my_matrix[1, 2]
</code></pre><p>但是，传递一个数字将返回一个矩阵的子向量，如下所示：</p>
<pre><code>my_row_vector = my_matrix[2]
my_column_vector = my_matrix[:, 3]
</code></pre><p><code>:</code>符号是“单独保留这个维度”的python切片语法。这个 在较高等级的张量中是有用的，因为它允许你访问它的子矢量， 子矩阵，甚至其他的副手。</p>
<h2><span id="形状">形状</span></h2><p>张量的形状是每个维度中元素的数量。 图形构建期间，TensorFlow自动推断形状。这些推断 形状可能已知或未知的级别。如果排名是已知的，每个的大小<br>维度可能是已知的或未知的。</p>
<p>TensorFlow文档使用三个符号约定来描述 张量维数：等级，形状和维数。下表 显示了这些如何相互关联：</p>
<table>
<thead>
<tr>
<th>Rank</th>
<th>Shape</th>
<th>Dimension number</th>
<th>Example  </th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>[]</td>
<td>0-D</td>
<td>A 0-D tensor. A scalar.  </td>
</tr>
<tr>
<td>1</td>
<td>[D0]</td>
<td>1-D</td>
<td>A 1-D tensor with shape [5].  </td>
</tr>
<tr>
<td>2</td>
<td>[D0, D1]</td>
<td>2-D</td>
<td>A 2-D tensor with shape [3, 4].  </td>
</tr>
<tr>
<td>3</td>
<td>[D0, D1, D2]</td>
<td>3-D</td>
<td>A 3-D tensor with shape [1, 4, 3].  </td>
</tr>
<tr>
<td>n</td>
<td>[D0, D1, … Dn-1]</td>
<td>n-D</td>
<td>A tensor with shape [D0, D1, … Dn-1].  </td>
</tr>
</tbody>
</table>
<p>形状可以通过Python列表/元组的int或者 <code>tf.TensorShape</code>。</p>
<h3><span id="获取tftensor物体的形状">获取<code>tf.Tensor</code>物体的形状</span></h3><p>有两种方法可以访问<code>tf.Tensor</code>的形状。在建设中 图，问什么是已知的张量常常是有用的<br>形状。这可以通过阅读<code>shape</code>对象的<code>tf.Tensor</code>属性来完成。 这个方法返回一个<code>TensorShape</code>对象，这是一个方便的方法<br>表示部分指定的形状（因为在构建图形时不是全部 形状将被完全知道）。</p>
<p><code>tf.Tensor</code>也可以代表完全定义 另一台<code>tf.Tensor</code>在运行时的形状。这是通过调用<code>tf.shape</code>完成的<br>操作。这样，你可以建立一个图形来处理形状 张量通过建立其他张量依赖于输入的动态形状 <code>tf.Tensor</code>。</p>
<p>例如，这里是如何做一个与零相同大小的零向量 给定矩阵中的列数：</p>
<pre><code>zeros = tf.zeros(tf.shape(my_matrix)[1])
</code></pre><h3><span id="改变tftensor的形状">改变<code>tf.Tensor</code>的形状</span></h3><p>张量元素的数量是其所有尺寸的乘积 形状。标量元素的数量总是<code>1</code>。因为经常有 许多不同的形状有相同数量的元素，通常是这样<br>方便可以改变<code>tf.Tensor</code>的形状，保持其元素 固定。这可以通过<code>tf.reshape</code>完成。</p>
<p>以下示例演示如何重构张量：</p>
<pre><code>rank_three_tensor = tf.ones([3, 4, 5])
matrix = tf.reshape(rank_three_tensor, [6, 10])  # Reshape existing content into
                                                 # a 6x10 matrix
matrixB = tf.reshape(matrix, [3, -1])  #  Reshape existing content into a 3x20
                                       # matrix. -1 tells reshape to calculate
                                       # the size of this dimension.
matrixAlt = tf.reshape(matrixB, [4, 3, -1])  # Reshape existing content into a
                                             #4x3x5 tensor

# Note that the number of elements of the reshaped Tensors has to match the
# original number of elements. Therefore, the following example generates an
# error because no possible value for the last dimension will match the number
# of elements.
yet_another = tf.reshape(matrixAlt, [13, 2, -1])  # ERROR!
</code></pre><h2><span id="数据类型">数据类型</span></h2><p>除了维度，张量有一个数据类型。参考 程序员指南中的<code>tf.DataType</code>页面提供了数据类型的完整列表。</p>
<p>具有多种数据类型的<code>tf.Tensor</code>是不可能的。它是 但是，也可以将任意数据结构序列化为<code>string</code>并存储 那些在<code>tf.Tensor</code>s。</p>
<p>可以使用<code>tf.Tensor</code>从一种数据类型转换为另一种数据类型 <code>tf.cast</code>：</p>
<pre><code># Cast a constant integer tensor into floating point.
float_tensor = tf.cast(tf.constant([1, 2, 3]), dtype=tf.float32)
</code></pre><p>要检查<code>tf.Tensor</code>的数据类型，请使用<code>Tensor.dtype</code>属性。</p>
<p>从python对象创建<code>tf.Tensor</code>时，可以选择指定 数据类型。如果你不这样做，TensorFlow会选择一个可以代表你的数据类型 数据。<br>TensorFlow将Python整数转换为<code>tf.int32</code>和python浮动<br>点号到<code>tf.float32</code>。否则，TensorFlow使用相同的规则numpy 转换为数组时使用。</p>
<h2><span id="评估张量">评估张量</span></h2><p>一旦计算图已经建立，你可以运行计算 生成一个特定的<code>tf.Tensor</code>并获取分配给它的值。这是 通常用于调试以及TensorFlow的许多要求 工作。</p>
<p>评估张量的最简单方法是使用<code>Tensor.eval</code>方法。对于 例：</p>
<pre><code>constant = tf.constant([1, 2, 3])
tensor = constant * constant
print tensor.eval()
</code></pre><p><code>eval</code>方法仅适用于默认<code>tf.Session</code>有效时（请参阅 图表和会话了解更多信息）。</p>
<p><code>Tensor.eval</code>返回与张量相同内容的numpy数组。</p>
<p>有时无法评估没有上下文的<code>tf.Tensor</code>，因为 其价值可能取决于不可用的动态信息。对于 例如，依赖于<code>Placeholder</code>s的张量不能被评估<br>为<code>Placeholder</code>提供了一个价值。</p>
<pre><code>p = tf.placeholder(tf.float32)
t = p + 1.0
t.eval()  # This will fail, since the placeholder did not get a value.
t.eval(feed_dict={p:2.0})  # This will succeed because we&apos;re feeding a value
                           # to the placeholder.
</code></pre><p>请注意，<code>tf.Tensor</code>是可能的，而不仅仅是占位符。</p>
<p>其他模型构造可能会使<code>tf.Tensor</code>评估 复杂。 TensorFlow无法直接评估内部定义的<code>tf.Tensor</code><br>功能或内部控制流程结构。如果一个<code>tf.Tensor</code>取决于一个值 从一个队列中，评估<code>tf.Tensor</code>只会有一些工作<br>排队;否则，评估会挂起。在处理队列时，请记住 在评估任何<code>tf.train.start_queue_runners</code>之前请拨打<code>tf.Tensor</code>。</p>
<h2><span id="打印张力">打印张力</span></h2><p>出于调试目的，您可能需要打印<code>tf.Tensor</code>的值。而  tfdbg提供了高级的调试支持，TensorFlow也有<br>操作直接打印<code>tf.Tensor</code>的值。</p>
<p>请注意，打印时很少使用以下模式 <code>tf.Tensor</code>：</p>
<pre><code>t = &lt;&lt;some tensorflow operation&gt;&gt;
print t  # This will print the symbolic tensor when the graph is being built.
         # This tensor does not have a value in this context.
</code></pre><p>此代码打印<code>tf.Tensor</code>对象（表示延迟计算） 而不是它的价值。相反，TensorFlow提供了<code>tf.Print</code>操作<br>返回它的第一个张量参数，同时打印该集合 <code>tf.Tensor</code>s作为第二个参数传递。</p>
<p>要正确使用<code>tf.Print</code>，必须使用其返回值。看下面的例子</p>
<pre><code>t = &lt;&lt;some tensorflow operation&gt;&gt;
tf.Print(t, [t])  # This does nothing
t = tf.Print(t, [t])  # Here we are using the value returned by tf.Print
result = t + 1  # Now when result is evaluated the value of `t` will be printed.
</code></pre><p>当您评估<code>result</code>时，您将评估<code>result</code>所依赖的一切 根据。由于<code>result</code>取决于<code>t</code>，而评估<code>t</code>有副作用<br>打印输入（<code>t</code>的旧值），<code>t</code>打印。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/beginners/" title="MN初学者MNIST" itemprop="url">MN初学者MNIST</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="mn初学者mnist">MN初学者MNIST</span></h1><p>本教程适用于对机器学习和机器学习都陌生的读者 TensorFlow。如果你已经知道MNIST是什么，以及什么softmax（multinomial<br>逻辑）回归是，你可能更喜欢这个 节奏更快的教程。务必 在启动之前安装TensorFlow 教程。</p>
<p>当学习如何编程时，首先要做的就是传统 打印“Hello World”。就像编程有Hello World，机器学习一样 有MNIST。</p>
<p>MNIST是一个简单的计算机视觉数据集。它由手写的图像组成 这样的数字：</p>
<p><img src="https://www.tensorflow.org/images/MNIST.png" alt=""></p>
<p>它还包括每个图像的标签，告诉我们它是哪个数字。对于 例如，上述图片的标签是5,0,4和1。</p>
<p>在本教程中，我们将训练一个模型来查看图像并进行预测 他们是什么数字。我们的目标不是训练一个真正精细的模型 达到了最先进的性能 - 尽管我们会给你这样的代码<br>后来！ - 而是倾向于使用TensorFlow的脚趾。就这样，我们走了 开始一个非常简单的模型，称为Softmax回归。</p>
<p>本教程的实际代码非常短，而且都很有趣 东西发生在三行。但是，这是非常 重要的是要理解它背后的想法：TensorFlow如何工作和<br>核心机器学习概念。因此，我们要非常小心 通过代码工作。</p>
<h2><span id="关于本教程">关于本教程</span></h2><p>这个教程是一行一行的解释 mnist_softmax.py代码。</p>
<p>您可以通过几种不同的方式使用本教程，其中包括：</p>
<p>将每个代码片段逐行复制并粘贴到Python环境中   你读通过每一行的解释。 在读取之前或之后运行整个<code>mnist_softmax.py</code> Python文件<br>通过解释，并使用本教程了解的行   代码不清楚给你。</p>
<p>我们将在本教程中完成的任务：</p>
<p>了解MNIST数据和softmax回归 创建一个函数，这个函数是一个基于数据来识别数字的模型   图像中的每个像素<br>使用TensorFlow训练模型，通过“看”来识别数字   成千上万的例子（并运行我们的第一个TensorFlow会话来这样做）<br>用我们的测试数据检查模型的准确性</p>
<h2><span id="mnist数据">MNIST数据</span></h2><p>MNIST数据托管在 Yann LeCun的网站。如果你正在复制和 从本教程的代码粘贴，从这里开始这两行代码 它将自动下载并读取数据：</p>
<pre><code>from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot=True)
</code></pre><p>MNIST数据分为三部分：55,000个训练数据点 数据（<code>mnist.train</code>），10,000点测试数据（<code>mnist.test</code>）和5,000<br>验证数据点（<code>mnist.validation</code>）。这个分裂是非常重要的： 在机器学习中，我们有独立的数据是不可或缺的<br>从中学习，以便我们确保我们所学到的东西 概括！</p>
<p>如前所述，每个MNIST数据点都有两部分：a 手写数字和相应的标签。我们将调用图像“x” 和标签“y”。训练集和测试集都包含图像及其图像<br>相应的标签;例如训练图像是<code>mnist.train.images</code> 培训标签为<code>mnist.train.labels</code>。</p>
<p>每个图像是28像素×28像素。我们可以把它解释为一大堆 数字：</p>
<p><img src="https://www.tensorflow.org/images/MNIST-Matrix.png" alt=""></p>
<p>我们可以把这个数组变成一个28x28 = 784的数字。它不 只要我们在图像之间保持一致，那么我们如何平铺阵列。 从这个角度来看，MNIST图像只是一堆点<br>784维矢量空间，用a 结构非常丰富 （警告：计算密集的可视化）。</p>
<p>展平数据会丢弃有关图像二维结构的信息。 那不好吗？那么，最好的计算机视觉方法是利用这一点 结构，我们将在以后的教程。但是，我们将是简单的方法<br>在这里使用softmax回归（下面定义）不会。</p>
<p>结果是<code>mnist.train.images</code>是一个张量（一个n维阵列） 形状为<code>[55000, 784]</code>。第一个维度是列表中的一个索引<br>第二维是每个图像中每个像素的索引。 张量中的每个条目都是0到1之间的像素强度，对于特定的 像素在特定的图像。</p>
<p><img src="https://www.tensorflow.org/images/mnist-train-xs.png" alt=""></p>
<p>MNIST中的每个图像都有一个相应的标签，一个介于0和9之间的数字 代表在图像中绘制的数字。</p>
<p>对于本教程的目的，我们将要我们的标签为“一热” 矢量“，单向矢量是大多数情况下为0，向量为1的矢量 单一维度。在这种情况下，\（n \）的数字将被表示为a<br>向量在\（n \）维上是1。例如，3将是 \（[0,0,0,1,0,0,0,0,0,0] \）。因此，<code>mnist.train.labels</code>是一款<br><code>[55000, 10]</code>浮标阵列。</p>
<p><img src="https://www.tensorflow.org/images/mnist-train-ys.png" alt=""></p>
<p>我们现在准备好实际制作我们的模型！</p>
<h2><span id="softmax回归">Softmax回归</span></h2><p>我们知道MNIST中的每个图像都是一个0到0之间的手写数字 九。所以一个给定的图像可能只有十个可能的东西。我们想要 能够看图像，并给出它们的概率<br>数字。例如，我们的模型可能会看到一个九的图片，并有80％的把握 这是一个九，但有一个5％的机会，作为一个八（因为顶级循环）<br>对所有其他人都有一定的概率，因为这不是100％确定的。</p>
<p>这是softmax回归是一个自然，简单模型的经典案例。 如果你想给一个对象分配几个不同的概率<br>事情，softmax是要做的事情，因为softmax给了我们一个价值清单 在0和1之间加起来就是1.甚至在以后，当我们训练更复杂时<br>型号，最后一步将是softmax的一层。</p>
<p>softmax回归有两个步骤：首先我们加上我们输入的证据 在某些类别中，然后我们将这些证据转化为概率。</p>
<p>为了统计一个给定的图像是在一个特定的类别的证据，我们做一个 像素强度的加权和。如果该像素的重量是负的 具有高强度的证据是反对该类图像的证据<br>积极的，如果它是有利的证据。</p>
<p>下图显示了一个模型为每个模型学习的权重 类。红色代表负重，蓝色代表正值 权重。</p>
<p><img src="https://www.tensorflow.org/images/softmax-weights.png" alt=""></p>
<p>我们还添加了一些额外的证据，称为偏见。基本上，我们希望能够 说有些东西更可能独立于输入。结果是 证明给定输入\（x \）的类\（i \）的证据是：</p>
<p>$$\text{evidence}_i = \sum<em>j W</em>{i,~ j} x_j + b_i$$</p>
<p>其中\（W_i \）是权重，\（b_i \）是类别\（i \）的偏差， \（j \）是对我们输入图像\（x \）中的像素求和的索引。<br>然后，我们将证据变成我们预测的概率 \（y \）使用“softmax”功能：</p>
<p>$$y = \text{softmax}(\text{evidence})$$</p>
<p>这里softmax是作为一个“激活”或“链接”功能，塑造 我们的线性函数输出成我们想要的形式 - 在这种情况下，a 概率分布10例。 你可以把它当作转换符号<br>将证据转化为我们在每个阶层投入的概率。 它被定义为：</p>
<p>$$\text{softmax}(evidence) = \text{normalize}(\exp(evidence))$$</p>
<p>如果将这个等式展开，你会得到：</p>
<p>$$\text{softmax}(evidence)_i = \frac{\exp(evidence_i)}{\sum_j<br>\exp(evidence_j)}$$</p>
<p>但是，首先想到softmax是指数式的，这通常会更有帮助 其输入，然后正常化他们。指数意味着多一个 证据单位乘以增加给予任何假设的权重。<br>相反，少一个单位的证据意味着一个假设得到一个 早期重量的一小部分。没有假设曾经有零或负面的 重量。 Softmax然后归一化这些权重，以便它们合计为一，<br>形成有效的概率分布。 （为了获得更多的直觉 softmax功能，检查出来 在它的部分 迈克尔·尼尔森（Michael<br>Nielsen）的书，完成一个交互式的可视化。</p>
<p>您可以将我们的softmax回归看成如下所示， 尽管有更多\（x \）s。对于每个输出，我们计算一个加权和 \（x<br>\）s，添加一个偏差，然后应用softmax。</p>
<p><img src="https://www.tensorflow.org/images/softmax-regression-scalargraph.png" alt=""></p>
<p>如果我们把它写成等式，我们得到：</p>
<p><img src="https://www.tensorflow.org/images/softmax-regression-scalarequation.png" alt="\[y1, y2, y3\] = softmax\(W11*x1 + W12*x2 + W13*x3 + b1,  W21*x1 + W22*x2 +
W23*x3 + b2,  W31*x1 + W32*x2 + W33*x3 +
b3\)"></p>
<p>我们可以将这个过程“矢量化”，将其转化为矩阵乘法 和矢量添加。这对于计算效率是有帮助的。 （这也是 一个有用的思考方式。）</p>
<p><img src="https://www.tensorflow.org/images/softmax-regression-
vectorequation.png" alt="\[y1, y2, y3\] = softmax\(\[\[W11, W12, W13\], \[W21, W22, W23\], \[W31,
W32, W33\]\]*\[x1, x2, x3\] + \[b1, b2,
b3\]\)"></p>
<p>更简洁，我们可以写：</p>
<p>$$y = \text{softmax}(Wx + b)$$</p>
<p>现在让我们把它转换成TensorFlow可以使用的东西。</p>
<h2><span id="实施回归">实施回归</span></h2><p>为了在Python中进行高效的数值计算，我们通常使用像 NumPy做矩阵等昂贵的操作 在Python之外进行乘法，使用在其中实现的高效代码<br>另一种语言。不幸的是，还是会有很多开销 切换回Python的每一个操作。如果你这个开销特别糟糕 想要在GPU上运行计算或以分布式方式运行，在哪里可以<br>传输数据的成本很高。</p>
<p>TensorFlow也在Python之外做了繁重的工作，但是它需要一些东西 进一步避免这种开销。而不是运行一个昂贵的<br>独立于Python的操作，TensorFlow让我们描述一个图 完全在Python之外运行的交互操作。 （像这样的方法 可以在几个机器学习库中看到）。</p>
<p>要使用TensorFlow，首先我们需要导入它。</p>
<pre><code>import tensorflow as tf
</code></pre><p>我们通过操纵符号变量来描述这些交互操作。 我们来创建一个：</p>
<pre><code>x = tf.placeholder(tf.float32, [None, 784])
</code></pre><p><code>x</code>不是一个具体的值。这是一个<code>placeholder</code>，我们将在什么时候输入 我们要求TensorFlow进行计算。我们希望能够输入任何数字<br>的MNIST图像，每个平面化成784维向量。我们代表 这是一个浮点数的二维张量，形状为<code>[None, 784]</code>。<br>（这里<code>None</code>是指尺寸可以是任意长度。）</p>
<p>我们也需要我们的模型的权重和偏见。我们可以想象治疗 这些额外的输入，但TensorFlow有一个更好的方式来处理 它：<code>Variable</code>。<br><code>Variable</code>是生活在TensorFlow中的可修改张量 互动操作图。它可以被使用甚至被修改 计算。对于机器学习应用程序，通常有一个模型<br>参数为<code>Variable</code>。</p>
<pre><code>W = tf.Variable(tf.zeros([784, 10]))
b = tf.Variable(tf.zeros([10]))
</code></pre><p>我们通过给<code>Variable</code>创建这些<code>tf.Variable</code>的初始值 <code>Variable</code>：在这种情况下，我们将<code>W</code>和<code>b</code>初始化为张量充满<br>零。由于我们要学习<code>W</code>和<code>b</code>，所以没关系 他们最初是什么。</p>
<p>请注意，<code>W</code>的形状为[784，10]，因为我们想要乘以 784维图像矢量由它产生的10维矢量 证据的差异类。 <code>b</code>具有[10]的形状，所以我们可以添加它<br>到输出。</p>
<p>我们现在可以实现我们的模型。只需要一行来定义它！</p>
<pre><code>y = tf.nn.softmax(tf.matmul(x, W) + b)
</code></pre><p>首先，用<code>x</code>将<code>W</code>乘以<code>tf.matmul(x, W)</code>。这是 从我们在我们的方程中乘以它们的时候翻转过来，在那里我们有\（Wx \），如<br>处理<code>x</code>是一个具有多个输入的2D张量的小技巧。然后我们 加<code>b</code>，最后用<code>tf.nn.softmax</code>。</p>
<p>而已。在短短几句之后，我们只用了一条线来定义我们的模型 设置线。那并不是因为TensorFlow被设计成softmax<br>回归特别容易：这只是一个非常灵活的方式来描述很多 从机器学习模型到物理学的各种数值计算 模拟。一旦定义，我们的模型可以在不同的设备上运行：<br>你的电脑的CPU，GPU甚至手机！</p>
<h2><span id="训练">训练</span></h2><p>为了训练我们的模型，我们需要定义模型的含义 好。实际上，在机器学习中，我们通常定义它的意义 一个模型是坏的。我们称之为成本或损失，代表了多远<br>关闭我们的模型是从我们期望的结果。我们尽量减少这个错误，并且 误差越小，我们的模型越好。</p>
<p>调用一个非常常见的非常好的函数来确定模型的损失 “交叉熵”。交叉熵来源于思考信息 压缩信息论中的代码，但它是一个重要的想法<br>在从赌博到机器学习的很多领域。它被定义为：</p>
<p>$$H_{y’}(y) = -\sum_i y’_i \log(y_i)$$</p>
<p>其中\（y \）是我们预测的概率分布，而\（y’\）是真实的 分配（带有数字标签的一个热点向量）。在一些粗略的意义上，<br>交叉熵是衡量我们的预测是如何低效的描述 真相。关于交叉熵的更多细节超出了范围 本教程，但它是非常值得的 理解。</p>
<p>为了实现交叉熵，我们需要先添加一个新的占位符来输入 正确答案：</p>
<pre><code>y_ = tf.placeholder(tf.float32, [None, 10])
</code></pre><p>然后我们可以实现交叉熵函数\（ - \ sum y’\ log（y）\）：</p>
<pre><code>cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))
</code></pre><p>首先，<code>tf.log</code>计算<code>y</code>各个元素的对数。接下来，我们乘以 <code>y_</code>的每个元件与<code>tf.log(y)</code>的相应元件。然后<br><code>tf.reduce_sum</code>增加了y的第二维中的元素，由于<br><code>reduction_indices=[1]</code>参数。最后，<code>tf.reduce_mean</code>计算平均值 在批处理中的所有例子。</p>
<p>请注意，在源代码中，我们不使用这个公式，因为它是 数字不稳定。相反，我们申请<br><code>tf.nn.softmax_cross_entropy_with_logits</code>在非规范化的logits（例如，我们<br>请拨打<code>softmax_cross_entropy_with_logits</code>上的<code>tf.matmul(x, W) + b</code>），因为这样<br>在数值上更稳定的函数在内部计算softmax激活。在 你的代码，考虑使用<code>tf.nn.softmax_cross_entropy_with_logits</code><br>代替。</p>
<p>现在我们知道我们的模型要做什么了，那么就很容易有TensorFlow 训练它这样做。因为TensorFlow知道你的整个图表 计算，它可以自动使用的<br>反向传播算法 有效地确定你的变量如何影响你所要求的损失 最小化。然后它可以应用你选择的优化算法来修改 变量并减少损失。</p>
<pre><code>train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)
</code></pre><p>在这种情况下，我们要求TensorFlow使<code>cross_entropy</code>最小化 梯度下降算法 学习率为0.5。渐变下降是一个简单的程序，在哪里<br>TensorFlow简单地将每个变量稍微向一个方向移动 降低成本。但是TensorFlow也提供了 许多其他优化算法： 使用一个就像调整一行一样简单。</p>
<p>什么TensorFlow实际上在这里，在幕后，是添加新的操作 实现向后传播和梯度下降的图形。然后呢 给你一个单一的操作，当运行时，做一个梯度的步骤<br>下降训练，稍微调整你的变量以减少损失。</p>
<p>我们现在可以在<code>InteractiveSession</code>中启动该模型：</p>
<pre><code>sess = tf.InteractiveSession()
</code></pre><p>我们首先必须创建一个操作来初始化我们创建的变量：</p>
<pre><code>tf.global_variables_initializer().run()
</code></pre><p>让我们训练 - 我们将运行1000次的训练步骤！</p>
<pre><code>for _ in range(1000):
  batch_xs, batch_ys = mnist.train.next_batch(100)
  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})
</code></pre><p>循环的每一步，我们从中获得一百个随机数据点的“批” 我们的训练集。我们运行<code>train_step</code>送料批量数据更换 <code>placeholder</code>s。</p>
<p>使用小批量的随机数据称为随机训练 情况下，随机梯度下降。理想情况下，我们想使用我们所有的数据 每一步的训练，因为这将使我们更好地了解我们的<br>应该在做，但是这很贵。所以，我们使用不同的子集 每次。这样做很便宜，而且有很多相同的好处。</p>
<h2><span id="评估我们的模型">评估我们的模型</span></h2><p>我们的模型有多好？</p>
<p>那么，首先让我们弄清楚我们预测了正确的标签。 <code>tf.argmax</code> 是一个非常有用的功能，它给你最高的条目索引<br>沿着一些轴张量。例如，<code>tf.argmax(y,1)</code>是我们的标签 型号认为是最有可能的每一个输入，而<code>tf.argmax(y_,1)</code>是<br>正确的标签。我们可以使用<code>tf.equal</code>来检查我们的预测是否符合 真相。</p>
<pre><code>correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
</code></pre><p>这给了我们一个布尔的列表。为了确定什么部分是正确的，我们 投到浮点数，然后取平均值。例如， <code>[True, False, True,
True]</code>将成为<code>[1,0,1,1]</code>，成为<code>0.75</code>。</p>
<pre><code>accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
</code></pre><p>最后，我们要求您的测试数据的准确性。</p>
<pre><code>print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
</code></pre><p>这应该是大约92％。</p>
<p>那好吗？那么，不是真的。事实上，这很糟糕。这是因为我们 使用一个非常简单的模型。有一些小的变化，我们可以达到97％。最好的<br>模型可以达到超过99.7％的准确性！ （有关更多信息，请参阅 这个 结果列表）</p>
<p>重要的是我们从这个模型中学到了东西。不过，如果你有点感觉 关于这些结果，退房 下一个教程，我们做了很多<br>更好地学习如何使用TensorFlow构建更复杂的模型！</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/fling-gesture-detection-on-grid-layout/" title="在网格布局上进行手势检测" itemprop="url">在网格布局上进行手势检测</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>我想要得到<code>fling</code>手势检测工作在我的Android应用程序。</p>
<p>我有一个<code>GridLayout</code>，其中包含9个<code>ImageView</code>s。来源可以在这里找到：罗曼人的网格布局。</p>
<p>我拿的文件是从罗曼盖伊的Photostream应用程序，只有轻微的适应。</p>
<p>对于简单的点击情况，我只需要为每个<code>onClickListener</code>设置<code>ImageView</code>，我将其添加为实现<code>activity</code>的主要<code>View.OnClickListener</code>。实现能识别<code>fling</code>的东西似乎是无限复杂的。我想这是因为它可能跨越<code>views</code>？</p>
<p>如果我的活动实施 <code>OnGestureListener</code>我不知道如何 设置为手势监听器 <code>Grid</code>或<code>Image</code>的意见，我 加。<br>公共类SelectFilterActivity扩展了Activity实现    View.OnClickListener，OnGestureListener<br>{… 如果我的活动实施 <code>OnTouchListener</code>然后我没有 <code>onFling</code>方法到<code>override</code>（它有 两个事件作为允许我的参数<br>以确定是否是一扔 值得注意的）。 公共类SelectFilterActivity扩展了Activity实现<br>View.OnClickListener，OnTouchListener {…<br>如果我做一个自定义<code>View</code>，就像<code>GestureImageView</code>扩展<code>ImageView</code>我不知道如何告诉活动，从视图<code>fling</code>已经发生。无论如何，我试过这个，当我触摸屏幕的时候，方法并没有被调用。</p>
<p>我真的只是需要一个具体的例子，跨视图工作。什么，何时以及如何附加这个<code>listener</code>？我需要能够检测到单击也。</p>
<pre><code>// Gesture detection
mGestureDetector = new GestureDetector(this, new GestureDetector.SimpleOnGestureListener() {

    public boolean onFling(MotionEvent e1, MotionEvent e2, float velocityX, float velocityY) {
        int dx = (int) (e2.getX() - e1.getX());
        // don&apos;t accept the fling if it&apos;s too short
        // as it may conflict with a button push
        if (Math.abs(dx) &gt; MAJOR_MOVE &amp;&amp; Math.abs(velocityX) &gt; Math.absvelocityY)) {
            if (velocityX &gt; 0) {
                moveRight();
            } else {
                moveLeft();
            }
            return true;
        } else {
            return false;
        }
    }
});
</code></pre><p>是否可以在屏幕上方放置一个透明视图来捕捉掠过？</p>
<p>如果我选择不从<code>inflate</code>我的孩子图像视图从XML我可以传递<code>GestureDetector</code>作为构造函数参数创建<code>ImageView</code>新的子类？</p>
<p>这是我试图让<code>fling</code>检测工作的非常简单的活动：SelectFilterActivity（从照片流改编）。</p>
<p>我一直在看这些来源：</p>
<p>检测手势 - 教程 SDK文档 计算器代码</p>
<p>到目前为止，没有任何工作为我工作，我希望得到一些指示。</p>
        
        
        <p class="article-more-link">
          
            <a href="/2018/01/01/fling-gesture-detection-on-grid-layout/#more">Read More</a>
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/android_build/" title="在Android上构建TensorFlow" itemprop="url">在Android上构建TensorFlow</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="在android上构建tensorflow">在Android上构建TensorFlow</span></h1><p>为了让您开始在Android上使用TensorFlow，我们将介绍两个 如何构建我们的TensorFlow移动演示并在Android上进行部署<br>设备。首先是Android Studio，它可以让你在一个 IDE。第二个是与Bazel合作，并与ADB一起部署 线。</p>
<p>为什么要选择这些方法之一？</p>
<p>在Android上使用TensorFlow最简单的方法就是使用Android Studio。如果你<br>不打算自定义您的TensorFlow构建，或者如果你想使用 Android Studio的编辑器和其他功能来构建一个应用程序，只是想添加<br>TensorFlow，我们推荐使用Android Studio。</p>
<p>如果您正在使用自定义操作，或有其他原因来构建TensorFlow 从头开始，向下滚动并查看我们的说明 用于与Bazel一起构建演示。</p>
<h2><span id="使用android-studio构建演示">使用Android Studio构建演示</span></h2><p>先决条件</p>
<p>如果还没有，请做以下两件事：</p>
<p>安装Android Studio，   遵循其网站上的指示。 从Github克隆TensorFlow存储库： git clone<br><a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow</a></p>
<p>建造</p>
<p>打开Android Studio，然后从欢迎屏幕中选择打开一个现有的    Android Studio项目。<br>在出现的打开文件或项目窗​​口中，导航至并选择     从克隆的<code>tensorflow/examples/android</code>目录     TensorFlow<br>Github回购。点击OK。 如果它要求您执行Gradle同步，请单击确定。 您可能还需要安装各种平台和工具<br>像“无法找到与哈希字符串’android-23’目标和类似的错误。 打开<code>build.gradle</code>文件（可以在侧面板中进入1：Project<br>并在Android下的Gradle Scripts zippy下找到它）。寻找<br><code>nativeBuildSystem</code>变量，如果它尚未设置为<code>none</code>： //设置为“bazel”，“cmake”，“makefile”，“none”<br>def nativeBuildSystem =’none’ 点击运行按钮（绿色箭头）或使用运行 - &gt;运行’android’从顶部菜单。<br>如果要求您使用“即时运行”，请单击“不进行即时运行”。 此外，你需要有一个Android设备插入开发人员选项 在此启用 点。看到这里<br>有关设置开发人员设备的更多细节。</p>
<p>这会在您的手机上安装三个全部属于TensorFlow的应用程序 演示。有关更多信息，请参阅Android示例应用程序 他们。</p>
<h2><span id="使用android-studio将tensorflow添加到您的应用程序">使用Android Studio将TensorFlow添加到您的应用程序</span></h2><p>要在您的Android上添加TensorFlow到您自己的应用程序，最简单的方法是添加 跟随你的Gradle构建文件的行：</p>
<pre><code>allprojects {
    repositories {
        jcenter()
    }
}

dependencies {
    compile &apos;org.tensorflow:tensorflow-android:+&apos;
}
</code></pre><p>这会自动下载TensorFlow的最新稳定版本作为AAR 并将其安装到您的项目中。</p>
<h2><span id="使用bazel构建演示">使用Bazel构建演示</span></h2><p>在Android上使用TensorFlow的另一种方法是构建一个APK 使用Bazel并将其加载到您的设备上 使用亚行。这个<br>需要一些构建系统和Android开发人员工具的知识，但我们会 引导你通过这里的基础知识。</p>
<p>首先，按照我们的说明进行安装   源。这也将引导你通过安装Bazel和克隆   TensorFlow代码。 下载Android SDK<br>和NDK，如果你这样做   还没有他们。你至少需要版本12b的NDK，和23的   SDK。 在您的TensorFlow源的副本中，更新   工作区<br>文件与您的SDK和NDK的位置，它表示   和。 运行Bazel构建演示APK： bazel build -c opt // tensorflow /<br>examples / android：tensorflow_demo 用亚行来   将APK安装到您的设备上： adb install -r bazel-<br>bin / tensorflow / examples / android / tensorflow_demo.apk</p>
<p>注意：一般来说，当您需要使用Bazel编译Android时 Bazel命令行上的<code>--config=android</code>，尽管在这种情况下是这样的<br>特别的例子是Android，所以你不需要它。</p>
<p>这会在您的手机上安装三个全部属于TensorFlow的应用程序 演示。有关更多信息，请参阅Android示例应用程序 他们。</p>
<h2><span id="android示例应用程序">Android示例应用程序</span></h2><p>该 Android示例代码是 一个项目，建立和安装三个示例应用程序，都使用 相同的底层代码。示例应用程序都从电话的视频输入 相机：</p>
<p>TF Classify使用Inception v3模型来标记指向的对象   来自Imagenet的课程。 Imagenet只有1000个类别，<br>它错过了大多数的日常物品，包括很多你不太可能的东西   经常在现实生活中遇到，所以结果往往会相当有趣。对于<br>例如没有“人物”类别，相反，它会经常猜测它的事情   知道经常与人的照片，如安全带相关联   或氧气面罩。如果你想要自定义这个例子来识别<br>你关心的对象，你可以使用   该   TensorFlow for Poets codelab as   一个如何根据自己的数据来训练模型的例子。 TF<br>Detect使用一个多盒子模型试图绘制周围的边界框   人在摄像机的位置。这些框用注释   对每个检测结果都有信心。结果将不会完美，因为这一点<br>对象检测仍然是一个活跃的研究课题。演示也   包括光学追踪物体在帧之间移动的时间   比TensorFlow推断更频繁。这改善了用户<br>经验以来，表观帧率更快，但它也给了   能够估计哪些方框指的是帧之间的同一个对象，   对于随着时间的推移计数对象是重要 TF<br>Stylize在相机上实现实时样式的传输算法   饲料。您可以选择使用哪种样式，并使用它们在它们之间进行混合   在屏幕底部的调色板，也切换出的分辨率<br>处理去更高或更低雷斯。</p>
<p>当您构建并安装演示程序时，您会在手机上看到三个应用程序图标， 每个演示一个。点击他们应该打开应用程序，让你<br>探索他们做什么。您可以通过点击在屏幕上启用分析统计 音量提高按钮，而他们正在运行。</p>
<h3><span id="android推理库">Android推理库</span></h3><p>由于Android应用程序需要用Java编写，核心TensorFlow用C ++编写， TensorFlow有一个JNI库来连接两者。它的接口是针对的<br>只有在推理，所以它提供了加载图形，设置输入， 并运行模型来计算特定的输出。你可以看到满的 文档中的最小的一套方法<br>TensorFlowInferenceInterface.java</p>
<p>演示应用程序使用这个接口，所以他们是一个好地方寻找 示例用法。您可以下载预先构建的二进制罐 在 ci.tensorflow.org。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/word2vec/" title="词的矢量表示" itemprop="url">词的矢量表示</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="词的矢量表示">词的矢量表示</span></h1><p>在本教程中，我们看一下word2vec模型 Mikolov等人 这个模型用于学习单词的向量表示，称为“单词” 的嵌入”。</p>
<h2><span id="强调">强调</span></h2><p>本教程旨在突出有趣的，实质性的部分 在TensorFlow中建立一个word2vec模型。</p>
<p>我们首先给出为什么我们想要的动机 将单词表示为向量。 我们看看模型背后的直觉以及如何训练 （用数学的飞溅为好措施）。<br>我们还在TensorFlow中展示了一个简单的模型实现。 最后，我们看看如何让天真版本更好地扩展。</p>
<p>稍后在教程中我们会遍历代码，但是如果您愿意潜水 直接进来，随意看看简约的执行情况 tensorflow /示例/教程/ word2vec /<br>word2vec_basic.py 这个基本的例子包含了下载一些数据所需的代码，在其上进行训练 并可视化结果。一旦你阅读和运行舒适 基本版本，你可以毕业<br>车型/教程/嵌入/ word2vec.py 这是一个更严重的实施，展示了一些更先进的 有关如何有效地使用线程将数据移入数据库的TensorFlow原则<br>文本模型，训练期间如何检查点等</p>
<p>但首先，我们来看看为什么我们想在第一个字中学习单词嵌入 地点。如果你是一个嵌入式专家，你可以随意跳过这一节 喜欢把你的手弄脏的细节。</p>
<h2><span id="动机为什么学习word嵌入">动机：为什么学习Word嵌入？</span></h2><p>图像和音频处理系统可以处理丰富的高维数据集 编码为图像数据的各个原始像素强度的向量，或者 例如音频数据的功率谱密度系数。对象的任务<br>或者语音识别我们知道所有成功所需的信息 执行任务在数据中被编码（因为人类可以执行这些任务 来自原始数据）。但是，传统上自然语言处理系统<br>将单词视为离散的原子符号，因此可以表示“猫” 如<code>Id537</code>和“狗”，如<code>Id143</code>。这些编码是任意的，并提供<br>对于系统中可能存在的关系没有任何有用的信息 在各个符号之间。这意味着该模型可以利用 当它处理有关数据时，它所学到的关于“猫”的知识很少<br>‘狗’（例如，它们都是动物，四条腿，宠物等）。代表 字作为独特的，离散的ID进一步导致数据稀疏，通常 意味着我们可能需要更多的数据才能成功地训练统计数据<br>楷模。使用矢量表示可以克服这些障碍中的一些。</p>
<p><img src="https://www.tensorflow.org/images/audio-image-text.png" alt=""></p>
<p>向量空间模型（VSM） 在语义上表示（嵌入）连续向量空间中的单词 相似的词映射到附近的点（’嵌入在彼此附近’）。<br>VSM在NLP中有着悠久丰富的历史，但是所有的方法都依赖于某种方式 另一个 分布假说， 其中指出，出现在相同的情况下的话分享<br>语义意义。利用这个原理的不同方法可以 分为两类：基于计数的方法（例如， 潜在语义分析）， 和预测方法（例如 神经概率语言模型）。</p>
<p>这个区别是由更详细的阐述 Baroni等人， 但简而言之：基于计数的方法计算的统计 在一个大的文本语料库中，某个词与其相邻词汇共同出现的频率，<br>然后将这些计数统计映射到每个单词的小密集矢量。 预测模型直接试图从其邻居预测一个字 学习小，密集的嵌入向量（考虑的参数 模型）。</p>
<p>Word2vec是一个特别有效的计算预测模型 学习从原始文本中的单词嵌入。它有两个口味，连续 Bag-of-Words模型（CBOW）和Skip-<br>Gram模型（Mikolov等人的第3.1节和第3.2节）。算法上，这些 模型是相似的，除了CBOW预测目标词（例如“mat”）<br>源语境词语（’猫坐在’上），而跳跃词就是这样 反转并预测来自目标词语的源语境词语。这个倒置 可能看起来像一个任意的选择，但从统计上来看，它有这样的效果<br>CBOW平滑了许多分布信息（通过对待一个 整个上下文作为一个观察）。在大多数情况下，这原来是一个 小数据集有用的东西。但是，skip-<br>gram会处理每个上下文目标 对作为一个新的观察，这往往会做的更好，当我们有更大的 数据集。我们将在本教程的其余部分重点介绍skip-gram模型。</p>
<h2><span id="加大噪声对比培训力度">加大噪声对比培训力度</span></h2><p>神经概率语言模型传统上使用的训练 最大似然（ML） 原则来最大化下一个单词\（w_t \）的概率（对于“目标”） 给出前面的单词\（h<br>\）（对于“历史”）而言 softmax功能，</p>
<p>$$ \begin{align} P(w_t | h) &amp;= \text{softmax} (\text{score} (w_t, h)) \\ &amp;=<br>\frac{\exp \{ \text{score} (w<em>t, h) \} } {\sum</em>\text{Word w’ in Vocab} \exp<br>\{ \text{score} (w’, h) \} } \end{align} $$</p>
<p>其中\（\ text {score}（w_t，h）\）计算word \（w_t \）的兼容性 与上下文\（h \）（点积通常使用）。我们训练这个模型<br>通过最大化其对数似然性 在训练集上，即通过最大化</p>
<p>$$ \begin{align} J_\text{ML} &amp;= \log P(w_t | h) \\ &amp;= \text{score} (w<em>t, h) -<br>\log \left( \sum</em>\text{Word w’ in Vocab} \exp \{ \text{score} (w’, h) \}<br>\right). \end{align} $$</p>
<p>这产生了一个适当的规范化的语言建模概率模型。 然而，这是非常昂贵的，因为我们需要计算和归一化每个 概率使用当前所有其他\（V \）单词\（W’\）的得分<br>上下文\（h \），在每个训练步骤。</p>
<p><img src="https://www.tensorflow.org/images/softmax-nplm.png" alt=""></p>
<p>另一方面，对于word2vec中的特征学习，我们不需要一个完整的 概率模型。 CBOW和skip-gram模型是用a来训练的 二元分类目标（逻辑回归）<br>从（k \）虚数（噪声）字\（\波浪w \）中区分真实目标字\（w_t \）， 相同的背景。我们在下面对CBOW模型进行说明。对于skip-gram来说<br>方向是简单的倒置。</p>
<p><img src="https://www.tensorflow.org/images/nce-nplm.png" alt=""></p>
<p>在数学上，目标（对于每个示例）是最大化的</p>
<p>$$J<em>\text{NEG} = \log Q</em>\theta(D=1 |w<em>t, h) + k \mathop{\mathbb{E}}</em>{\tilde w<br>\sim P<em>\text{noise}} \left[ \log Q</em>\theta(D = 0 |\tilde w, h) \right]$$</p>
<p>其中\（Q_ \ theta（D = 1 | w，h）\）是二元逻辑回归概率 在数据集的上下文\（h \）中查看单词\（w \）的模型下 \（D<br>\），根据学习的嵌入向量\（\ theta \）计算。在 实践中，我们通过画（\）对比词来逼近期望 从噪声分布（即我们计算a 蒙特卡洛平均）。</p>
<p>当模型分配高概率时，这个目标是最大化的 真实的话，低概率的噪音词。从技术上讲，这是 叫 负面抽样， 使用这种损失函数有很好的数学动机：<br>它提出的更新近似于softmax函数的更新 限制。但是从计算角度来看，这是特别有吸引力的，因为计算 现在损失函数只能随着我们的噪声词的数量而缩放<br>选择（\（k \）），而不是词汇表中的所有单词（\（V \））。这使得它 训练要快得多。实际上我们会利用非常相似的 噪声对比估计（NCE）<br>为此TensorFlow有一个方便的帮手功能<code>tf.nn.nce_loss()</code>。</p>
<p>让我们直观地感受一下，在实践中这将如何工作！</p>
<h2><span id="跳跃模型">跳跃模型</span></h2><p>作为一个例子，我们来考虑一下数据集</p>
<p><code>the quick brown fox jumped over the lazy dog</code></p>
<p>我们首先形成单词的数据集和它们出现的上下文。我们 可以用任何有意义的方式来界定“背景”，事实上人们也可以 看着语法上下文（即当前的语法依赖者）<br>目标单词，请参阅 Levy等人）， 目标的左边，目标的右边，等等。现在， 让我们坚持香草的定义，并定义“上下文”作为窗口 的目标词的左侧和右侧的词。使用窗口<br>大小为1，那么我们有数据集</p>
<p><code>([the, brown], quick), ([quick, fox], brown), ([brown, jumped], fox), ...</code></p>
<p>的<code>(context, target)</code>对。回想一下，skip-gram会颠倒上下文 目标，并试图从其目标词预测每个环境词，所以<br>任务变成从“快”，“快”和“狐狸”预测’the’和’brown’ “棕色”等，因此我们的数据集成为</p>
<p><code>(quick, the), (quick, brown), (brown, quick), (brown, fox), ...</code></p>
<p>的<code>(input, output)</code>对。目标函数定义在整个 数据集，但我们通常使用优化 随机梯度下降<br>（SGD）一次只使用一个例子（或<code>batch_size</code>示例的“小批次” 典型的是<code>16 &lt;= batch_size &lt;= 512</code>）。所以我们来看一下<br>这个流程。</p>
<p>让我们想象在训练步骤\（t \）我们观察上面的第一个训练案例， 目标是从<code>the</code>预测<code>quick</code>。我们选择<code>num_noise</code>编号<br>嘈杂（对比）的例子，从一些噪音分布， 通常是一元分布，\（P（w）\）。为了简单，让我们说<br><code>num_noise=1</code>和我们选择<code>sheep</code>作为一个嘈杂的例子。接下来我们计算 这一对观察到的和有噪音的例子，即在时间上的目标的损失 步骤\（t<br>\）变成</p>
<p>$$J^{(t)}<em>\text{NEG} = \log Q</em>\theta(D=1 | \text{the, quick}) +<br>\log(Q_\theta(D=0 | \text{sheep, quick}))$$</p>
<p>目标是对嵌入参数\（\ theta \）进行更新以改善 （在这种情况下，最大化）这个目标函数。我们通过派生来做到这一点 相对于嵌入参数的损失梯度，即 \（\<br>frac {\ partial} {\ partial \ theta} J_ \ text {NEG} \）（幸运的是TensorFlow提供<br>简单的辅助功能来做到这一点！）。然后，我们执行更新 通过向梯度方向迈出一小步来嵌入。当这个 过程在整个训练集上重复进行，这就产生了效果<br>为每个单词“移动”嵌入向量，直到模型为止 成功地区分真实的单词和噪音单词。</p>
<p>我们可以通过将它们向下投影到2维来可视化所学习的向量 使用例如类似的东西 t-SNE降维技术。 当我们检查这些可视化时，变得明显的向量<br>捕捉一些一般的，实际上相当有用的语义信息 单词和他们之间的关系。当我们这是非常有趣的 首先发现了诱导向量空间中的某些方向是专门化的<br>朝着某些语义关系，例如男女，动词时态和 甚至包括国与国之间的文字之间的关系，如图所示 下面（参见例如 Mikolov等，2013）。</p>
<p><img src="https://www.tensorflow.org/images/linear-relationships.png" alt=""></p>
<p>这就解释了为什么这些矢量也可以用作许多规范的特征 NLP预测任务，如词性标注或命名实体识别 （见例如原来的工作 Collobert等人，2011<br>（pdf）或后续工作 Turian等，2010）。</p>
<p>但现在，让我们用它们来画美丽的图画！</p>
<h2><span id="建立图表">建立图表</span></h2><p>这是关于嵌入，所以我们来定义我们的嵌入矩阵。 这只是一个很大的随机矩阵开始。我们将初始化值 在单位立方体统一。</p>
<pre><code>embeddings = tf.Variable(
    tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))
</code></pre><p>噪声对比估计损失是根据逻辑回归定义的 模型。为此，我们需要为每个单词定义权重和偏差 词汇（也被称为<code>output weights</code>而不是输入<br>嵌入物）。所以我们来定义一下。</p>
<pre><code>nce_weights = tf.Variable(
  tf.truncated_normal([vocabulary_size, embedding_size],
                      stddev=1.0 / math.sqrt(embedding_size)))
nce_biases = tf.Variable(tf.zeros([vocabulary_size]))
</code></pre><p>现在我们已经有了参数，我们可以定义我们的skip-gram模型 图形。为了简单起见，假设我们已经整合了我们的文本语料库<br>与一个词汇，使每个单词被表示为一个整数（见 tensorflow /示例/教程/ word2vec / word2vec_basic.py<br>的细节）。跳跃模型需要两个输入。一个是满满的一批 代表源语境词的整数，另一个代表目标 话。让我们为这些输入创建占位符节点，以便我们可以输入 数据稍后。</p>
<pre><code># Placeholders for inputs
train_inputs = tf.placeholder(tf.int32, shape=[batch_size])
train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])
</code></pre><p>现在我们需要做的是查找每个源词的向量 该批次。 TensorFlow有方便的帮手，使这个简单。</p>
<pre><code>embed = tf.nn.embedding_lookup(embeddings, train_inputs)
</code></pre><p>好的，现在我们有每个单词的嵌入，我们想尝试预测 目标词使用噪声对比训练目标。</p>
<pre><code># Compute the NCE loss, using a sample of the negative labels each time.
loss = tf.reduce_mean(
  tf.nn.nce_loss(weights=nce_weights,
                 biases=nce_biases,
                 labels=train_labels,
                 inputs=embed,
                 num_sampled=num_sampled,
                 num_classes=vocabulary_size))
</code></pre><p>现在我们有一个损失节点，我们需要添加计算所需的节点 渐变和更新参数等。为此，我们将使用随机<br>梯度下降，而且TensorFlow也有方便的帮手来使这一切变得简单。</p>
<pre><code># We use the SGD optimizer.
optimizer = tf.train.GradientDescentOptimizer(learning_rate=1.0).minimize(loss)
</code></pre><h2><span id="培训模型">培训模型</span></h2><p>然后使用<code>feed_dict</code>将数据推送到模型中，然后训练模型 占位符和呼叫 <code>tf.Session.run</code>与这个新的数据 在一个循环中。</p>
<pre><code>for inputs, labels in generate_batch(...):
  feed_dict = {train_inputs: inputs, train_labels: labels}
  _, cur_loss = session.run([optimizer, loss], feed_dict=feed_dict)
</code></pre><p>请参阅完整的示例代码 tensorflow /例子/教程/ word2vec / word2vec_basic.py。</p>
<h2><span id="可视化的嵌入">可视化的嵌入</span></h2><p>训练完成后，我们可以使用可视化的学习嵌入 T-SNE。</p>
<p><img src="https://www.tensorflow.org/images/tsne.png" alt=""></p>
<p>Et瞧！如预期的那样，类似的词汇最终在每个附近聚集 其他。对于更重量级的word2vec实现，展示更多的 TensorFlow的高级功能，请参阅实现<br>车型/教程/嵌入/ word2vec.py。</p>
<h2><span id="评估嵌入类比推理">评估嵌入：类比推理</span></h2><p>嵌入对于NLP中的各种预测任务是有用的。缺乏 训练一个完整的词性模型或命名实体模型，一个简单的方法 评估嵌入是直接使用它们来预测句法和语义 像<code>king
is to queen as father is to ?</code>的关系。这就是所谓的 类比推理和任务被介绍了 Mikolov和同事 。<br>从该任务下载该任务的数据集 download.tensorflow.org。</p>
<p>看看我们如何做这个评估，看看<code>build_eval_graph()</code>和 <code>eval()</code>的功能 车型/教程/嵌入/ word2vec.py。</p>
<p>超参数的选择可以强烈影响此任务的准确性。 为了在这个任务上达到最高水平的表现，需要训练一个 非常大的数据集，仔细调整超参数和使用<br>这些技巧就像对数据进行二次采样，这超出了本教程的范围。</p>
<h2><span id="优化实施">优化实施</span></h2><p>我们的香草实施展示了TensorFlow的灵活性。对于 例如，改变培训目标就像换掉电话一样简单 以<code>tf.nn.nce_loss()</code>为代表的现成替代品<br><code>tf.nn.sampled_softmax_loss()</code>。如果你有一个新的损失函数的想法，你 可以在TensorFlow中手动为新目标写一个表达式并让<br>优化器计算它的导数。这种灵活性是无价的 机器学习模式开发的探索阶段，我们正在尝试 出几个不同的想法，并迅速迭代。</p>
<p>一旦你有一个模型结构你满意，这可能是值得的 优化您的实现以更高效地运行（并覆盖更多的数据 更短的时间）。例如，我们在本教程中使用的朴素代码会受到影响<br>由于我们使用Python来读取和提供数据项， 每个TensorFlow后端都需要很少的工作。如果你发现 你的模型是严重瓶颈输入数据，你可能想要实现一个<br>自定义数据读取器为您的问题，如所述 新的数据格式。对于Skip-Gram的情况 建模，我们实际上已经为你做了这个例子 车型/教程/嵌入/<br>word2vec.py。</p>
<p>如果你的模型不再是I / O绑定的，但是你还需要更多的性能，你 可以通过编写自己的TensorFlow Ops来进一步处理，如下所述<br>添加一个新的操作我们再次提供了一个 这个例子就是Skip-Gram的例子 车型/教程/嵌入/ word2vec_o​​ptimized.py。<br>随意基准这些对方来衡量表现 每个阶段的改进。</p>
<h2><span id="结论">结论</span></h2><p>在本教程中，我们介绍了word2vec模型，这是一个计算效率高的模型 学习单词嵌入的模型。我们激励为什么嵌入是有用的，<br>讨论了高效的培训技术，并展示了如何实施所有这些 在TensorFlow中。总的来说，我们希望这已经证明TensorFlow是如何提供的<br>你的灵活性，你需要早期的实验，并控制你 以后需要定制优化实施。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/wide/" title="TensorFlow线性模型教程" itemprop="url">TensorFlow线性模型教程</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="tensorflow线性模型教程">TensorFlow线性模型教程</span></h1><p>在本教程中，我们将使用TensorFlow中的tf.estimator API来解决这个问题 二元分类问题：给定一个人的普查数据，如年龄，<br>教育程度，婚姻状况和职业（特征），我们将尝试预测 无论这个人一年挣多5万美元（目标） 标签）。我们将训练逻辑回归模型，并给予个人的<br>我们的模型的信息将输出一个介于0和1之间的数字，这可以是 解释为个人年收入超过的概率 5万美元</p>
<h2><span id="建立">建立</span></h2><p>要尝试本教程的代码：</p>
<p>如果你还没有安装TensorFlow， 下载教程代码。 执行我们提供给您的数据下载脚本： $ python data_download.py<br>使用以下命令执行教程代码以训练线性 模型在本教程中描述： $ python wide_deep.py –model_type = wide</p>
<p>继续阅读以了解此代码如何构建其线性模型。</p>
<h2><span id="读取人口普查数据">读取人口普查数据</span></h2><p>我们将使用的数据集是 人口普查收入数据集。 我们提供了 data_download.py 下载代码并执行一些额外的清理。</p>
<p>由于任务是一个二元分类问题，我们将构造一个标签 列名为“标签”，如果收入超过5万，则为1 除此以外。有关参考，请参阅<code>input_fn</code><br>wide_deep.py。</p>
<p>接下来，我们来看看数据框，看看我们可以使用哪些列 预测目标标签。这些列可以分为两类 - 分类 和连续的列：</p>
<p>如果一个列的值只能是其中的一个，则该列被称为分类     有限集合中的类别。例如，一个人的关系状态     （妻子，丈夫，未婚等）或教育水平（高中，<br>大学等）是分类专栏。 如果某列的值可以是任何数值，则称该列为连续的     一个连续的范围。例如，一个人的资本收益（例如$ 14,084）<br>是一个连续的列。</p>
<p>以下是人口普查收入数据集中可用列的列表：</p>
<table>
<thead>
<tr>
<th>Column Name</th>
<th>Type</th>
<th>Description  </th>
</tr>
</thead>
<tbody>
<tr>
<td>age</td>
<td>Continuous</td>
<td>The age of the individual  </td>
</tr>
<tr>
<td>workclass</td>
<td>Categorical</td>
<td>The type of employer the individual has (government,</td>
</tr>
</tbody>
</table>
<p>military, private, etc.).<br>fnlwgt | Continuous | The number of people the census takers believe that<br>observation represents (sample weight). Final weight will not be used.<br>education | Categorical | The highest level of education achieved for that<br>individual.<br>education_num | Continuous | The highest level of education in numerical form.<br>marital_status | Categorical | Marital status of the individual.<br>occupation | Categorical | The occupation of the individual.<br>relationship | Categorical | Wife, Own-child, Husband, Not-in-family, Other-<br>relative, Unmarried.<br>race | Categorical | White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other,<br>Black.<br>gender | Categorical | Female, Male.<br>capital_gain | Continuous | Capital gains recorded.<br>capital_loss | Continuous | Capital Losses recorded.<br>hours_per_week | Continuous | Hours worked per week.<br>native_country | Categorical | Country of origin of the individual.<br>income | Categorical | “&gt;50K” or “&lt;=50K”, meaning whether the person makes<br>more than $50,000 annually.  </p>
<h2><span id="将数据转换为张量">将数据转换为张量</span></h2><p>在建立一个tf.estimator模型时，输入数据是通过一个 输入生成器功能。这个构建函数直到它才会被调用<br>后来传递给tf.estimator.Estimator方法，如<code>train</code>和<code>evaluate</code>。 这个功能的目的是构建输入数据，这是<br>以<code>tf.Tensor</code>或<code>tf.SparseTensor</code>的形式表示。 更详细地说，输入生成器函数将成对返回以下内容：</p>
<p><code>features</code>：从特征列名到<code>Tensors</code>的字典或     <code>SparseTensors</code>。 <code>labels</code>：含有标签柱的<code>Tensor</code>。</p>
<p><code>features</code>的键将用于构建下一个列 部分。因为我们想用<code>train</code>和<code>evaluate</code>方法来调用<br>不同的数据，我们定义一个方法返回一个输入函数的基础上 给出的数据。请注意，返回的输入函数将被调用 构建TensorFlow图，而不是在运行图时。这是什么<br>返回是输入数据表示的基本单位 TensorFlow计算，<code>Tensor</code>（或<code>SparseTensor</code>）。</p>
<p>列车中的每个连续列或测试数据将被转换成一个 <code>Tensor</code>，它通常是一种很好的格式来表示密集的数据。对于<br>分类数据，我们必须将数据表示为<code>SparseTensor</code>。这个数据 格式适合表示稀疏数据。我们的<code>input_fn</code>使用<code>tf.data</code><br>API，可以很容易地将转换应用于我们的数据集：</p>
<pre><code>def input_fn(data_file, num_epochs, shuffle, batch_size):
  &quot;&quot;&quot;Generate an input function for the Estimator.&quot;&quot;&quot;
  assert tf.gfile.Exists(data_file), (
      &apos;%s not found. Please make sure you have either run data_download.py or &apos;
      &apos;set both arguments --train_data and --test_data.&apos; % data_file)

  def parse_csv(value):
    print(&apos;Parsing&apos;, data_file)
    columns = tf.decode_csv(value, record_defaults=_CSV_COLUMN_DEFAULTS)
    features = dict(zip(_CSV_COLUMNS, columns))
    labels = features.pop(&apos;income_bracket&apos;)
    return features, tf.equal(labels, &apos;&gt;50K&apos;)

  # Extract lines from input files using the Dataset API.
  dataset = tf.data.TextLineDataset(data_file)

  if shuffle:
    dataset = dataset.shuffle(buffer_size=_SHUFFLE_BUFFER)

  dataset = dataset.map(parse_csv, num_parallel_calls=5)

  # We call repeat after shuffling, rather than before, to prevent separate
  # epochs from blending together.
  dataset = dataset.repeat(num_epochs)
  dataset = dataset.batch(batch_size)

  iterator = dataset.make_one_shot_iterator()
  features, labels = iterator.get_next()
  return features, labels
</code></pre><h2><span id="模型的选择和工程特性">模型的选择和工程特性</span></h2><p>选择和制作正确的特征列是学习的关键 有效的模式。一个特征列可以是其中的一个原始列 原始数据框（我们称之为基本特征列）或任何新的<br>基于在一个或多个基础上定义的一些转换创建的列 列（我们称之为派生特征列）。基本上“功能 列“是任何可以使用的原始或衍生变量的抽象概念 预测目标标签。</p>
<h3><span id="基本分类特征列">基本分类特征列</span></h3><p>要为分类特征定义特征列，我们可以创建一个 <code>CategoricalColumn</code>使用tf.feature_column API。如果你知道所有的集合<br>一个列的可能的特征值，只有其中的几个，你可以 使用<code>categorical_column_with_vocabulary_list</code>。列表中的每个键都会得到<br>分配从0开始的自动增量ID。例如，对于 <code>relationship</code>栏可以将特征字符串“丈夫”分配给一个整数 ID为0，“不在家”为1等，做法是：</p>
<pre><code>relationship = tf.feature_column.categorical_column_with_vocabulary_list(
    &apos;relationship&apos;, [
        &apos;Husband&apos;, &apos;Not-in-family&apos;, &apos;Wife&apos;, &apos;Own-child&apos;, &apos;Unmarried&apos;,
        &apos;Other-relative&apos;])
</code></pre><p>如果我们事先不知道可能的价值观呢？不是问题。我们 可以用<code>categorical_column_with_hash_bucket</code>代替：</p>
<pre><code>occupation = tf.feature_column.categorical_column_with_hash_bucket(
    &apos;occupation&apos;, hash_bucket_size=1000)
</code></pre><p><code>occupation</code>功能列中的每个可能的值将会发生什么 当我们在训练中遇到它们时将被散列为整数ID。看一个例子 插图如下：</p>
<table>
<thead>
<tr>
<th>ID</th>
<th>Feature  </th>
</tr>
</thead>
<tbody>
<tr>
<td>…</td>
<td></td>
</tr>
<tr>
<td>9</td>
<td><code>&quot;Machine-op-inspct&quot;</code>  </td>
</tr>
<tr>
<td>…</td>
<td></td>
</tr>
<tr>
<td>103</td>
<td><code>&quot;Farming-fishing&quot;</code>  </td>
</tr>
<tr>
<td>…</td>
<td></td>
</tr>
<tr>
<td>375</td>
<td><code>&quot;Protective-serv&quot;</code>  </td>
</tr>
<tr>
<td>…</td>
<td></td>
</tr>
</tbody>
</table>
<p>无论我们选择哪一种方式来定义<code>SparseColumn</code>，每个功能字符串 将通过查找一个固定的映射或散列来映射到一个整数ID。<br>请注意，散列冲突是可能的，但可能不会显着影响 模型质量。 <code>LinearModel</code>课程负责人 管理映射并创建<code>tf.Variable</code>来存储模型参数<br>（也称为模型权重）为每个功能ID。模型参数将是 通过模型培训过程了解到，我们稍后会经历。</p>
<p>我们将做类似的技巧来定义其他的分类特征：</p>
<pre><code>education = tf.feature_column.categorical_column_with_vocabulary_list(
    &apos;education&apos;, [
        &apos;Bachelors&apos;, &apos;HS-grad&apos;, &apos;11th&apos;, &apos;Masters&apos;, &apos;9th&apos;, &apos;Some-college&apos;,
        &apos;Assoc-acdm&apos;, &apos;Assoc-voc&apos;, &apos;7th-8th&apos;, &apos;Doctorate&apos;, &apos;Prof-school&apos;,
        &apos;5th-6th&apos;, &apos;10th&apos;, &apos;1st-4th&apos;, &apos;Preschool&apos;, &apos;12th&apos;])

marital_status = tf.feature_column.categorical_column_with_vocabulary_list(
    &apos;marital_status&apos;, [
        &apos;Married-civ-spouse&apos;, &apos;Divorced&apos;, &apos;Married-spouse-absent&apos;,
        &apos;Never-married&apos;, &apos;Separated&apos;, &apos;Married-AF-spouse&apos;, &apos;Widowed&apos;])

relationship = tf.feature_column.categorical_column_with_vocabulary_list(
    &apos;relationship&apos;, [
        &apos;Husband&apos;, &apos;Not-in-family&apos;, &apos;Wife&apos;, &apos;Own-child&apos;, &apos;Unmarried&apos;,
        &apos;Other-relative&apos;])

workclass = tf.feature_column.categorical_column_with_vocabulary_list(
    &apos;workclass&apos;, [
        &apos;Self-emp-not-inc&apos;, &apos;Private&apos;, &apos;State-gov&apos;, &apos;Federal-gov&apos;,
        &apos;Local-gov&apos;, &apos;?&apos;, &apos;Self-emp-inc&apos;, &apos;Without-pay&apos;, &apos;Never-worked&apos;])

# To show an example of hashing:
occupation = tf.feature_column.categorical_column_with_hash_bucket(
    &apos;occupation&apos;, hash_bucket_size=1000)
</code></pre><h3><span id="基本连续功能列">基本连续功能列</span></h3><p>同样，我们可以为每个连续特征列定义一个<code>NumericColumn</code> 我们想在模型中使用：</p>
<pre><code>age = tf.feature_column.numeric_column(&apos;age&apos;)
education_num = tf.feature_column.numeric_column(&apos;education_num&apos;)
capital_gain = tf.feature_column.numeric_column(&apos;capital_gain&apos;)
capital_loss = tf.feature_column.numeric_column(&apos;capital_loss&apos;)
hours_per_week = tf.feature_column.numeric_column(&apos;hours_per_week&apos;)
</code></pre><h3><span id="通过分解实现连续性特征的分类">通过分解实现连续性特征的分类</span></h3><p>有时连续特征和标签之间的关系不是 线性的。作为一个假设的例子，一个人的收入可能随着年龄的增长而增长 事业的早期阶段，那么增长速度可能会放慢，最后<br>退休后收入减少。在这种情况下，使用原始的<code>age</code>作为 一个实值特征列可能不是一个好的选择，因为该模型可以 只学习三种情况之一：</p>
<p>收入总是随着年龄增长而增长（正相关）， 收入总是随着年龄的增长而减少（负相关），或者 不论年龄多少，收入都保持不变（不相关）</p>
<p>如果我们想要学习收入与各个年龄之间的细微关联， 分组分组，可以利用分期付款。巴克化是一个过程 将连续特征的整个范围划分为一组连续的特征<br>箱/桶，然后将原始数字特征转换成桶 ID（作为分类特征），取决于该值落入哪个桶。<br>因此，我们可以通过<code>bucketized_column</code>定义<code>age</code>，如下所示：</p>
<pre><code>age_buckets = tf.feature_column.bucketized_column(
    age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])
</code></pre><p>其中<code>boundaries</code>是一个桶边界列表。在这种情况下，有 10个界限，导致11个年龄段桶（从17岁以下，18-24岁，<br>25-29，…，65以上）。</p>
<h3><span id="用crossedcolumn交叉多列">用CrossedColumn交叉多列</span></h3><p>单独使用每个基本特征列可能不足以解释数据。 例如，教育与标签之间的相关性（收入&gt; 50,000美元）<br>美元）可能会因不同的职业而有所不同。因此，如果我们只学习<br><code>education=&quot;Bachelors&quot;</code>和<code>education=&quot;Masters&quot;</code>的单一型号重量，我们 将无法捕获每一个教育职业组合（例如，<br>区分<code>education=&quot;Bachelors&quot; AND occupation=&quot;Exec-managerial&quot;</code><br>和<code>education=&quot;Bachelors&quot; AND occupation=&quot;Craft-repair&quot;</code>）。要学习<br>不同的功能组合之间的差异，我们可以添加交叉功能 模型列。</p>
<pre><code>education_x_occupation = tf.feature_column.crossed_column(
    [&apos;education&apos;, &apos;occupation&apos;], hash_bucket_size=1000)
</code></pre><p>我们也可以创建一个超过两列的<code>CrossedColumn</code>。每 组成列可以是分类的基础特征列<br>（<code>SparseColumn</code>），一个bucketized实值特征列（<code>BucketizedColumn</code>），<br>甚至另一台<code>CrossColumn</code>。这是一个例子：</p>
<pre><code>age_buckets_x_education_x_occupation = tf.feature_column.crossed_column(
    [age_buckets, &apos;education&apos;, &apos;occupation&apos;], hash_bucket_size=1000)
</code></pre><h2><span id="定义logistic回归模型">定义Logistic回归模型</span></h2><p>处理完输入数据并定义所有的特征列后，我们现在就完成了 准备把它们放在一起，建立一个Logistic回归模型。在里面<br>在上一节中，我们已经看到几种类型的基础和派生特征列， 包含：</p>
<p><code>CategoricalColumn</code> <code>NumericColumn</code> <code>BucketizedColumn</code> <code>CrossedColumn</code></p>
<p>所有这些都是抽象的<code>FeatureColumn</code>类的子类，可以是 添加到模型的<code>feature_columns</code>领域：</p>
<pre><code>base_columns = [
    education, marital_status, relationship, workclass, occupation,
    age_buckets,
]
crossed_columns = [
    tf.feature_column.crossed_column(
        [&apos;education&apos;, &apos;occupation&apos;], hash_bucket_size=1000),
    tf.feature_column.crossed_column(
        [age_buckets, &apos;education&apos;, &apos;occupation&apos;], hash_bucket_size=1000),
]

model_dir = tempfile.mkdtemp()
model = tf.estimator.LinearClassifier(
    model_dir=model_dir, feature_columns=base_columns + crossed_columns)
</code></pre><p>该模型还自动学习控制预测的偏差项 人们可以在不观察任何特征的情况下（参见“如何物流” 回归工程“以获得更多解释），学习的模型文件将被存储<br>在<code>model_dir</code>中。</p>
<h2><span id="培训和评估我们的模型">培训和评估我们的模型</span></h2><p>将所有的功能添加到模型后，现在让我们看看如何实际 训练模型。训练一个模型只是一个单一的命令使用 tf.estimator API：</p>
<pre><code>model.train(input_fn=lambda: input_fn(train_data, num_epochs, True, batch_size))
</code></pre><p>在模型被训练之后，我们可以评估我们的模型在预测方面有多好 坚持数据的标签：</p>
<pre><code>results = model.evaluate(input_fn=lambda: input_fn(
    test_data, 1, False, batch_size))
for key in sorted(results):
  print(&apos;%s: %s&apos; % (key, results[key]))
</code></pre><p>最终输出的第一行应该是这样的 <code>accuracy: 0.83557522</code>，表示准确率为83.6％。随意尝试更多 功能和转换，看看你能做得更好！</p>
<p>如果你想看到一个工作的端到端的例子，你可以下载我们的 示例代码 并将<code>model_type</code>标志设置为<code>wide</code>。</p>
<h2><span id="加入正则化来防止过度拟合">加入正则化来防止过度拟合</span></h2><p>正规化是一种避免过度拟合的技术。过度配合发生 当你的模型在训练的数据上表现良好，但在测试数据上更糟糕 这个模型以前没有见过，比如现场交通。过度配合一般<br>当模型过于复杂，如参数太多时会发生 相对于观察到的训练数据的数量。正规化允许你 控制你的模型的复杂性，使模型更一般化 看不见的数据。</p>
<p>在线性模型库中，可以将L1和L2正则化添加到模型中 如：</p>
<pre><code>model = tf.estimator.LinearClassifier(
    model_dir=model_dir, feature_columns=base_columns + crossed_columns,
    optimizer=tf.train.FtrlOptimizer(
        learning_rate=0.1,
        l1_regularization_strength=1.0,
        l2_regularization_strength=1.0))
</code></pre><p>L1和L2正则化之间的一个重要区别是L1 正则化倾向于使模型权重保持为零，创造更稀疏 模型，而L2正则化也试图使模型权重更接近<br>零但不一定是零。所以，如果你增加L1的实力 正规化，因为许多模型，你将有一个更小的模型大小 权重将为零。当特征空间非常大时，这通常是可取的<br>大但稀疏，当有资源限制，阻止你 为一个太大的模型提供服务。</p>
<p>在实践中，你应该尝试L1，L2正则化的各种组合 优势，并找到最好的控制过度和给予的最佳参数 你一个理想的模型大小。</p>
<h2><span id="逻辑回归如何工作">逻辑回归如何工作</span></h2><p>最后，让我们花一点时间来谈谈什么是Logistic回归模型 实际上看起来像你不熟悉它。我们会表示 标签为\（Y \），观察特征集为特征向量 \（\<br>mathbf {x} = [x_1，x_2，…，x_d] \）。我们定义\（Y = 1 \）如果一个人 赚取了5万美元以及\（Y = 0<br>\）。在Logistic回归中， 给定特征的标签为正（\（Y = 1 \））的概率 \（\ mathbf {x} \）给出如下：</p>
<p>$$ P(Y=1|\mathbf{x}) = \frac{1}{1+\exp(-(\mathbf{w}^T\mathbf{x}+b))}$$</p>
<p>其中\（\ mathbf {w} = [w_1，w_2，…，w_d] \）是 features \（\ mathbf {x} =<br>[x_1，x_2，…，x_d] \）。 \（b \）是一个常数 通常被称为模型的偏见。等式由两部分组成 线性模型和逻辑函数：</p>
<p>线性模型：首先，我们可以看到\（\ mathbf {w} ^ T \ mathbf {x} + b = b +     w_1x_1 + … +<br>w_dx_d \）是输出为线性的线性模型     输入要素的函数\（\ mathbf {x} \）。偏见\（b \）是<br>人们可以预测，而不会观察任何特征。模型重量     \（w_i \）反映特征\（x_i \）如何与正相关     标签。如果\（x_i<br>\）与正向标签正相关，那么     重量\（w_i \）增加，概率\（P（Y = 1 | \ mathbf {x}）\）将<br>接近1.另一方面，如果\（x_i \）是负相关的     与正面的标签，那么体重\（w_i \）减少和     概率\（P（Y = 1 | \ mathbf<br>{x}）\）将接近于0。 逻辑函数：其次，我们可以看到有一个逻辑函数     （也称为S形函数）\（S（t）= 1 /（1+ \ exp（-t））\）是<br>应用于线性模型。逻辑功能是用来转换的     从任何实数的线性模型输出（\ mathbf {w} ^ T \ mathbf {x} + b \）<br>数字放到\（[0，1] \）的范围内，可以解释为a     可能性。</p>
<p>模型训练是一个优化问题：目标是找到一组模型 权重（即模型参数）最小化定义的损失函数 训练数据，如逻辑回归模型的逻辑损失。亏损<br>函数测量地面实况标签和模型之间的差异 预测。如果预测非常接近地面实况标签，那就是损失 价值会很低;如果预测离标签很远，那么就是亏损 价值会很高。</p>
<h2><span id="深入学习">深入学习</span></h2><p>如果你有兴趣了解更多，请查看我们的 广泛和深度学习教程，我们将告诉你如何 联合线性模型和深度神经网络的优势 使用tf.estimator API来训练它们。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/wide_and_deep/" title="TensorFlow广泛深度学习教程" itemprop="url">TensorFlow广泛深度学习教程</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="tensorflow广泛深度学习教程">TensorFlow广泛深度学习教程</span></h1><p>在之前的TensorFlow线性模型教程中，我们训练了一个逻辑 回归模型来预测个体每年的概率 超过5万美元的收入使用 人口普查收入数据集。<br>TensorFlow也非常适合训练深度神经网络，而且你也许是 思考你应该选择哪一个 - 好吧，为什么不呢？会有可能吗？ 在一个模型中结合两者的优点？</p>
<p>在本教程中，我们将介绍如何共同使用tf.estimator API 训练宽线性模型和深度前馈神经网络。这种方法 结合记忆和泛化的优势。这是有用的<br>通用的大规模回归和稀疏输入的分类问题 特征（例如，具有大量可能特征的分类特征 值）。如果您有兴趣了解更多关于如何广泛和深度学习 作品，请查看我们的研究论文。</p>
<p><img src="https://www.tensorflow.org/images/wide_n_deep.svg" alt="Wide &amp; Deep Spectrum of
Models"></p>
<p>上图显示了一个广泛的模型（logistic回归与 稀疏特征和变换），深层模型（前馈神经网络） 有一个嵌入层和几个隐藏层）和一个Wide＆Deep模型<br>（两者的联合训练）。在较高的层面上，配置a只需要3个步骤 使用tf.estimator API的宽，深或Wide＆Deep模型：</p>
<p>选择广泛部分的功能：选择稀疏基础列和     想要使用的交叉列。 选择深部的特征：选择连续的列，     为每个分类列嵌入维度，以及隐藏层大小。<br>把他们放在一个宽和深的模型     （<code>DNNLinearCombinedClassifier</code>）。</p>
<p>而就是这样！我们来看一个简单的例子。</p>
<h2><span id="建立">建立</span></h2><p>要尝试本教程的代码：</p>
<p>如果你还没有安装TensorFlow， 下载教程代码。 执行我们提供给您的数据下载脚本： $ python data_download.py<br>使用以下命令执行教程代码以训练宽度和 本教程中描述的深层模型： $ python wide_deep.py</p>
<p>继续阅读以了解此代码如何构建其模型。</p>
<h2><span id="定义基本特征列">定义基本特征列</span></h2><p>首先，我们来定义基本分类和连续的特征列 我们将使用。这些基础列将是广泛使用的构建块 部分和模型的深层部分。</p>
<pre><code>import tensorflow as tf

# Continuous columns
age = tf.feature_column.numeric_column(&apos;age&apos;)
education_num = tf.feature_column.numeric_column(&apos;education_num&apos;)
capital_gain = tf.feature_column.numeric_column(&apos;capital_gain&apos;)
capital_loss = tf.feature_column.numeric_column(&apos;capital_loss&apos;)
hours_per_week = tf.feature_column.numeric_column(&apos;hours_per_week&apos;)

education = tf.feature_column.categorical_column_with_vocabulary_list(
    &apos;education&apos;, [
        &apos;Bachelors&apos;, &apos;HS-grad&apos;, &apos;11th&apos;, &apos;Masters&apos;, &apos;9th&apos;, &apos;Some-college&apos;,
        &apos;Assoc-acdm&apos;, &apos;Assoc-voc&apos;, &apos;7th-8th&apos;, &apos;Doctorate&apos;, &apos;Prof-school&apos;,
        &apos;5th-6th&apos;, &apos;10th&apos;, &apos;1st-4th&apos;, &apos;Preschool&apos;, &apos;12th&apos;])

marital_status = tf.feature_column.categorical_column_with_vocabulary_list(
    &apos;marital_status&apos;, [
        &apos;Married-civ-spouse&apos;, &apos;Divorced&apos;, &apos;Married-spouse-absent&apos;,
        &apos;Never-married&apos;, &apos;Separated&apos;, &apos;Married-AF-spouse&apos;, &apos;Widowed&apos;])

relationship = tf.feature_column.categorical_column_with_vocabulary_list(
    &apos;relationship&apos;, [
        &apos;Husband&apos;, &apos;Not-in-family&apos;, &apos;Wife&apos;, &apos;Own-child&apos;, &apos;Unmarried&apos;,
        &apos;Other-relative&apos;])

workclass = tf.feature_column.categorical_column_with_vocabulary_list(
    &apos;workclass&apos;, [
        &apos;Self-emp-not-inc&apos;, &apos;Private&apos;, &apos;State-gov&apos;, &apos;Federal-gov&apos;,
        &apos;Local-gov&apos;, &apos;?&apos;, &apos;Self-emp-inc&apos;, &apos;Without-pay&apos;, &apos;Never-worked&apos;])

# To show an example of hashing:
occupation = tf.feature_column.categorical_column_with_hash_bucket(
    &apos;occupation&apos;, hash_bucket_size=1000)

# Transformations.
age_buckets = tf.feature_column.bucketized_column(
    age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])
</code></pre><h2><span id="宽模型具有交叉特征列的线性模型">宽模型：具有交叉特征列的线性模型</span></h2><p>宽模型是具有多种稀疏交叉特征的线性模型 列：</p>
<pre><code>base_columns = [
    education, marital_status, relationship, workclass, occupation,
    age_buckets,
]

crossed_columns = [
    tf.feature_column.crossed_column(
        [&apos;education&apos;, &apos;occupation&apos;], hash_bucket_size=1000),
    tf.feature_column.crossed_column(
        [age_buckets, &apos;education&apos;, &apos;occupation&apos;], hash_bucket_size=1000),
]
</code></pre><p>您也可以看到TensorFlow线性模型教程的更多细节。</p>
<p>具有交叉特征列的宽模型可以记忆稀疏交互 之间的功能有效。这就是说，交叉特征的一个局限性 列是他们不推广到没有特征的组合<br>出现在训练数据中。让我们添加一个嵌入式的深层模型来解决 那。</p>
<h2><span id="深层模型带嵌入的神经网络">深层模型：带嵌入的神经网络</span></h2><p>如前所述，深层模型是一个前馈神经网络 数字。每个稀疏的高维分类特征都是第一个 转换成低维和密集的实值矢量，通常被称为 作为嵌入向量。这些低维稠密嵌入向量是<br>与连续的特征串联，然后馈送到隐藏层 神经网络的正向传递。嵌入值被初始化 随机地，并与所有其他模型参数一起训练以最小化<br>训练损失。如果您有兴趣了解有关嵌入的更多信息，请查看 单词或单词向量表示的TensorFlow教程 在维基百科上嵌入的词。</p>
<p>另一种方法来表示分类列喂养神经网络是 通过单热或多热表示。这通常适合于 只有几个可能值的分类列。作为一个热门的例子 <code>&quot;Husband&quot;</code>可以表示为关系栏<br>[1,0,0,0,0,0]和<code>&quot;Not-in-family&quot;</code>为[0,1,0,0,0,0]等。这是一个 固定表示，而嵌入更灵活，并计算在 训练时间。</p>
<p>我们将使用配置分类列的嵌入 <code>embedding_column</code>，并将它们与连续色谱柱连接。 我们还使用<code>indicator_column</code>创建一些多热表示<br>分类列。</p>
<pre><code>deep_columns = [
    age,
    education_num,
    capital_gain,
    capital_loss,
    hours_per_week,
    tf.feature_column.indicator_column(workclass),
    tf.feature_column.indicator_column(education),
    tf.feature_column.indicator_column(marital_status),
    tf.feature_column.indicator_column(relationship),
    # To show an example of embedding
    tf.feature_column.embedding_column(occupation, dimension=8),
]
</code></pre><p>嵌入的<code>dimension</code>越高，自由度越高 模型将不得不学习这些特征的表示。为了简单，我们 在此处将所有要素列的维度设置为8。经验上，更多<br>明智的决定维度的数量是从一个值开始的 \（\ log_2（n）\）或\（k \ sqrt [4] n \）的顺序，其中\（n \）是<br>特征列中的独特功能和\（k \）是一个小常量（通常是 小于10）。</p>
<p>通过密集的嵌入，深层模型可以更好地推广和预测 在训练数据中以前看不到的特征对。不过呢 很难学习有效的低维表征 当两个特征列之间的基础交互矩阵是<br>稀疏和高级。在这种情况下，大多数特征对之间的相互作用 除少数外应为零，但密集的嵌入将导致非零 所有特征对的预测，因此可以过度概括。在另一<br>手，具有交叉特征的线性模型可以记住这些“例外规则” 使用更少的模型参数。</p>
<p>现在，让我们看看如何联合训练广泛和深刻的模型，并允许他们 相辅相成的优点和缺点。</p>
<h2><span id="将宽和深的模型组合成一个">将宽和深的模型组合成一个</span></h2><p>宽模型和深模型通过总结其最终输出进行组合 将对数作为预测，然后将预测结果提供给逻辑损失 功能。所有的图形定义和变量分配已经完成<br>在引擎盖下处理，所以你只需要创建一个 <code>DNNLinearCombinedClassifier</code>：</p>
<pre><code>model = tf.estimator.DNNLinearCombinedClassifier(
    model_dir=&apos;/tmp/census_model&apos;,
    linear_feature_columns=base_columns + crossed_columns,
    dnn_feature_columns=deep_columns,
    dnn_hidden_units=[100, 50])
</code></pre><h2><span id="培训和评估模型">培训和评估模型</span></h2><p>在我们训练模型之前，让我们先看看人口普查数据集 TensorFlow线性模型教程。参见<code>data_download.py</code>以及 <code>input_fn</code>之内<br><code>wide_deep.py</code>。</p>
<p>读完数据后，您可以训练和评估模型：</p>
<pre><code># Train and evaluate the model every `FLAGS.epochs_per_eval` epochs.
for n in range(FLAGS.train_epochs // FLAGS.epochs_per_eval):
  model.train(input_fn=lambda: input_fn(
      FLAGS.train_data, FLAGS.epochs_per_eval, True, FLAGS.batch_size))

  results = model.evaluate(input_fn=lambda: input_fn(
      FLAGS.test_data, 1, False, FLAGS.batch_size))

  # Display evaluation metrics
  print(&apos;Results at epoch&apos;, (n + 1) * FLAGS.epochs_per_eval)
  print(&apos;-&apos; * 30)

  for key in sorted(results):
    print(&apos;%s: %s&apos; % (key, results[key]))
</code></pre><p>最终的输出精度应该在85.5％左右。如果你想 看到一个工作端到端的例子，你可以下载我们的 示例代码。</p>
<p>请注意，本教程只是一个小数据集的简单例子 熟悉API。如果你有广泛和深度的学习将更加强大 尝试使用具有大量稀疏特征列的大型数据集<br>可能的特征值的数量。再次，请随时看看我们的 研究论文如何更多的想法 在现实世界的大型机器学习问题中应用广泛和深度学习。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/seq2seq/" title="神经机器翻译（seq2seq）教程" itemprop="url">神经机器翻译（seq2seq）教程</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="神经机器翻译seq2seq教程">神经机器翻译（seq2seq）教程</span></h1><p>作者：Thang Luong，Eugene Brevdo，赵锐</p>
<p>本教程的这个版本需要TensorFlow版本1.4+。 警告：Beam Search的错误修复不在TensorFlow 1.4中。</p>
<h1><span id="介绍">介绍</span></h1><p>序列 - 序列（seq2seq）模型 （Sutskever等，2014， Cho等，2014） 在机器翻译，演讲等各种工作中取得了巨大的成功<br>识别和文本摘要。本教程给读者一个完整的 了解seq2seq模型，并展示如何建立一个有竞争力的seq2seq<br>模型从头开始。我们专注于神经机器翻译（NMT）的任务， 这是seq2seq模型的第一个测试平台 野生 成功。该 包括代码是轻量级，高质量，生产就绪，并入<br>有最新的研究思路。我们通过以下方式达到这个</p>
<p>使用最近的解码器/注意力    包装纸    API，    TensorFlow 1.2数据迭代器 结合我们强大的专业知识，建立经常性和seq2seq模型<br>提供建立最好的NMT模型和复制的技巧和窍门    Google的NMT（GNMT）系统。</p>
<p>我们相信提供人们可以轻松掌握的基准是非常重要的 复制。因此，我们提供了全面的实验结果 在以下公开可用的数据集上对模型进行预训练：</p>
<p>小规模：英语 - 越南语TED会话平行语料库（133K句子    双）由提供    该    IWSLT评估活动。<br>大规模：提供德英平行语料库（4.5M句子对）    由WMT评估运动。</p>
<p>我们首先建立一些关于NMT seq2seq模型的基本知识，解释 如何建立和训练一个香草NMT模型。第二部分将详细介绍<br>建立具有注意机制的竞争性NMT模型。我们然后讨论 提示和技巧，以建立最好的NMT模型（速度和速度）<br>翻译质量），如TensorFlow最佳实践（配料，桶装）， 双向RNN，波束搜索以及使用GNMT注意力扩展到多个GPU。</p>
<h1><span id="基本">基本</span></h1><h2><span id="神经机器翻译的背景">神经机器翻译的背景</span></h2><p>早在过去，传统的基于短语的翻译系统就被执行了 他们的任务是把源语句分解成多个块然后 把它们翻译成短语。这导致翻译不流利<br>产出，并不像我们人类的翻译。我们阅读整个 源句，理解它的意思，然后产生一个翻译。神经 机器翻译（NMT）模仿！</p>
<p><img src="https://www.tensorflow.org/images/seq2seq/encdec.jpg" alt=""> 图1.编码器 - 解码器架构 -<br>一个通用方法的例子 NMT。编码器将源语句转换为“含义”向量 通过解码器产生翻译。</p>
<p>具体而言，NMT系统首先使用编码器读取源句子 建立 一个 “思想”载体， 代表句子意思的数字序列;一个解码器，那么， 处理句子向量发出翻译，如图所示<br>图1.这通常被称为编码器 - 解码器架构。在 这种方式，NMT解决了传统的本地翻译问题 基于短语的方法：它可以捕捉语言的远程依赖关系，<br>例如性别协议;语法结构;等等，而且生产得更流畅 翻译如展示 通过 谷歌神经机器翻译系统。</p>
<p>NMT模型根据其确切的体系结构而有所不同。自然的选择 时序数据是大多数NMT模型使用的递归神经网络（RNN）。 编码器和解码器通常使用RNN。 RNN模型，<br>然而，不同的方面：（一）方向性 - 单向或 双向的; （b）深度 - 单层或多层;和（三）类型 - 往往 香草RNN，长期短期记忆（LSTM）或门控复发单位<br>（GRU）。有兴趣的读者可以在上找到关于RNN和LSTM的更多信息 这篇博文。</p>
<p>在本教程中，我们将深入多层RNN作为示例 单向，并使用LSTM作为经常性单位。我们展示一个这样的例子<br>模型如图2所示。在这个例子中，我们建立了一个模型来翻译源代码 把“我是学生”这句话变成目标句子“Je suisétudiant”。在一个很高的<br>NMT模型由两个递归神经网络组成：编码器 RNN仅仅消耗输入的源词而不作任何预测;该 另一方面，解码器在预测目标语句的同时对其进行处理 接下来的话。</p>
<p>有关更多信息，请参阅读者 到本教程的Luong（2016） 基于。</p>
<p><img src="https://www.tensorflow.org/images/seq2seq/seq2seq.jpg" alt=""> 图2.神经机器翻译 -<br>一个经常性的例子 由“我是学生”这个源语句翻译成的建筑 目标句子“Jesuisétudiant”。在这里，“＆lts＆gt”标志着 解码过程，而“＆lt;<br>s＆gt;”告诉解码器停止。</p>
<h2><span id="安装教程">安装教程</span></h2><p>要安装本教程，您需要在系统上安装TensorFlow。 本教程需要TensorFlow Nightly。要安装TensorFlow，请按照 安装说明在这里。</p>
<p>一旦安装了TensorFlow，您可以下载本教程的源代码 通过运行：</p>
<pre><code>git clone https://github.com/tensorflow/nmt/
</code></pre><h2><span id="培训-如何建立我们的第一个nmt系统">培训 - 如何建立我们的第一个NMT系统</span></h2><p>我们先来看看用具体代码构建NMT模型的核心 通过我们将更详细地解释图2的片段。我们推迟了数据 准备和后面的完整代码。这部分是指 文件 model.py。</p>
<p>在底层，编码器和解码器RNNs接收作为输入 如下：首先，源句子，然后是一个边界标记“\ ~~”其中 指示从编码到解码模式的过渡以及目标<br>句子。为了训练，我们将给系统提供以下张量， 它们在时间上是主要的格式，并包含单词索引：</p>
<p>encoder_inputs [max_encoder_time，batch_size]：源输入字。 decoder_inputs<br>[max_decoder_time，batch_size]：目标输入字。 decoder_outputs<br>[max_decoder_time，batch_size]：目标输出字，    这些是decode_inputs向左移一个时间步与一个<br>在右侧附加句末标签。</p>
<p>这里为了提高效率，我们用多个句子（batch_size）进行训练 一旦。测试稍有不同，所以我们稍后再讨论。</p>
<h3><span id="嵌入">嵌入</span></h3><p>鉴于单词的分类性质，该模型必须先查找来源 和目标嵌入来检索相应的词表示。对于 这个嵌入层的工作，首先为每种语言选择一个词汇。<br>通常，选择一个词汇量V，只有最常见的V个词是 视为独特。所有其他单词都转换为“未知”令牌和所有 得到相同的嵌入。嵌入权重，每种语言一组 通常在训练中学习。</p>
<pre><code># Embedding
embedding_encoder = variable_scope.get_variable(
    &quot;embedding_encoder&quot;, [src_vocab_size, embedding_size], ...)
# Look up embedding:
#   encoder_inputs: [max_time, batch_size]
#   encoder_emb_inp: [max_time, batch_size, embedding_size]
encoder_emb_inp = embedding_ops.embedding_lookup(
    embedding_encoder, encoder_inputs)
</code></pre><p>同样，我们可以构建embedding_decoder和decoder_emb_inp。注意一个 可以选择用预训练词表示来初始化嵌入权重<br>如word2vec或Glove矢量。一般来说，给予大量的培训 数据我们可以从头学习这些嵌入。</p>
<h3><span id="编码器">编码器</span></h3><p>一旦检索到，嵌入字就作为输入被馈送到主网络中， 它由两个多层RNN组成 - 一个用于源语言的编码器 目标语言的解码器。这两个RNN原则上可以共享<br>相同的重量;然而，在实践中，我们经常使用两个不同的RNN参数 （当拟合大量的训练数据集时，这样的模型做得更好）。该<br>编码器RNN使用零矢量作为其起始状态，并且构建如下：</p>
<pre><code># Build RNN cell
encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)

# Run Dynamic RNN
#   encoder_outpus: [max_time, batch_size, num_units]
#   encoder_state: [batch_size, num_units]
encoder_outputs, encoder_state = tf.nn.dynamic_rnn(
    encoder_cell, encoder_emb_inp,
    sequence_length=source_sequence_length, time_major=True)
</code></pre><p>请注意，句子有不同的长度，以避免浪费计算，我们告诉 dynamic_rnn确切的源句子的长度<br>source_sequence_length。由于我们的投入是主要的时间，我们设置 time_major<br>=真。在这里，我们只建立一个单层的LSTM，encoder_cell。我们 将描述如何构建多层LSTM，添加丢失，并引起注意 稍后的部分。</p>
<h3><span id="解码器">解码器</span></h3><p>解码器还需要访问源信息，还有一个 简单的方法来实现，就是用最后一个隐藏状态来初始化它<br>编码器，encoder_state。在图2中，我们从源代码中传递隐藏状态 单词“学生”到解码器端。</p>
<pre><code># Build RNN cell
decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)



# Helper
helper = tf.contrib.seq2seq.TrainingHelper(
    decoder_emb_inp, decoder_lengths, time_major=True)
# Decoder
decoder = tf.contrib.seq2seq.BasicDecoder(
    decoder_cell, helper, encoder_state,
    output_layer=projection_layer)
# Dynamic decoding
outputs, _ = tf.contrib.seq2seq.dynamic_decode(decoder, ...)
logits = outputs.rnn_output
</code></pre><p>在这里，这个代码的核心部分是BasicDecoder对象，解码器，这个<br>接收decoder_cell（类似于encoder_cell），helper和previous<br>encoder_state作为输入。通过分离解码器和帮助器，我们可以重用 不同的代码库，例如，TrainingHelper可以被替换<br>GreedyEmbeddingHelper做贪心解码。查看更多 在 helper.py。</p>
<p>最后，我们还没有提到projection_layer这是一个密集的矩阵转向 我们说明了这一点 过程在图2的顶部。</p>
<pre><code>projection_layer = layers_core.Dense(
    tgt_vocab_size, use_bias=False)
</code></pre><h3><span id="失利">失利</span></h3><p>鉴于上面的逻辑，我们现在准备计算我们的训练损失：</p>
<pre><code>crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(
    labels=decoder_outputs, logits=logits)
train_loss = (tf.reduce_sum(crossent * target_weights) /
    batch_size)
</code></pre><p>这里，target_weights是一个大小与之相同的零一个矩阵 decoder_outputs。它掩盖了目标序列之外的填充位置 长度值为0。</p>
<p>重要提示：值得指出的是，我们将损失除以 batch_size，所以我们的超参数对batch_size是“不变的”。有些人 用（batch_size *<br>num_time_steps）来划分损失，这就淡化了 短句错误。更微妙的是，我们的超参数（应用于 以前的方式）不能用于后一种方式。例如，如果两者都接近<br>使用SGD学习1.0，后一种方法有效地使用了很多 1 / num_time_steps较小的学习率。</p>
<h3><span id="梯度计算和优化">梯度计算和优化</span></h3><p>现在我们已经定义了NMT模型的正向通过。计算 反向传播只是几行代码的问题：</p>
<pre><code># Calculate and clip gradients
params = tf.trainable_variables()
gradients = tf.gradients(train_loss, params)
clipped_gradients, _ = tf.clip_by_global_norm(
    gradients, max_gradient_norm)
</code></pre><p>训练RNNs的重要步骤之一是渐变裁剪。在这里，我们剪辑 由全球规范。最大值max_gradient_norm通常设置为一个值<br>像5或1.最后一步是选择优化器。 Adam优化器是一个 共同的选择。我们也选择一个学习率。 learning_rate的值<br>通常可以在0.0001至0.001的范围内;并可以设置为减少 培训进展。</p>
<pre><code># Optimization
optimizer = tf.train.AdamOptimizer(learning_rate)
update_step = optimizer.apply_gradients(
    zip(clipped_gradients, params))
</code></pre><p>在我们自己的实验中，我们使用标准的SGD（tf.train.GradientDescentOptimizer） 随着学习速度的降低，这会产生更好的表现。看到<br>基准。</p>
<h2><span id="动手-让我们训练一个nmt模型">动手 - 让我们训练一个NMT模型</span></h2><p>让我们训练我们第一个NMT模型，从越南翻译成英文！ 我们的代码的入口点 是 nmt.py.</p>
<p>我们将使用一个小规模的TED演讲语料库（133K培训 例子）这个练习。我们在这里使用的所有数据都可以找到 在：<br><a href="https://nlp.stanford.edu/projects/nmt/。我们" target="_blank" rel="noopener">https://nlp.stanford.edu/projects/nmt/。我们</a><br>将使用tst2012作为我们的开发数据集，tst2013作为我们的测试数据集。</p>
<p>运行以下命令下载用于训练NMT模型的数据：\     <code>nmt/scripts/download_iwslt15.sh /tmp/nmt_data</code></p>
<p>运行以下命令开始训练：</p>
<pre><code>mkdir /tmp/nmt_model
python -m nmt.nmt \
    --src=vi --tgt=en \
    --vocab_prefix=/tmp/nmt_data/vocab  \
    --train_prefix=/tmp/nmt_data/train \
    --dev_prefix=/tmp/nmt_data/tst2012  \
    --test_prefix=/tmp/nmt_data/tst2013 \
    --out_dir=/tmp/nmt_model \
    --num_train_steps=12000 \
    --steps_per_stats=100 \
    --num_layers=2 \
    --num_units=128 \
    --dropout=0.2 \
    --metrics=bleu
</code></pre><p>以上命令训练一个128层隐藏单元的2层LSTM seq2seq模型 并嵌入12个时期。我们使用0.2的退出值（保持概率<br>0.8）。如果没有错误，我们应该看到类似于下面的日志递减 我们训练时的困惑价值。</p>
<pre><code># First evaluation, global step 0
  eval dev: perplexity 17193.66
  eval test: perplexity 17193.27
# Start epoch 0, step 0, lr 1, Tue Apr 25 23:17:41 2017
  sample train data:
    src_reverse: &lt;/s&gt; &lt;/s&gt; Điều đo , dĩ nhien , la cau chuyện trich ra từ học thuyết của Karl Marx .
    ref: That , of course , was the &lt;unk&gt; distilled from the theories of Karl Marx . &lt;/s&gt; &lt;/s&gt; &lt;/s&gt;
  epoch 0 step 100 lr 1 step-time 0.89s wps 5.78K ppl 1568.62 bleu 0.00
  epoch 0 step 200 lr 1 step-time 0.94s wps 5.91K ppl 524.11 bleu 0.00
  epoch 0 step 300 lr 1 step-time 0.96s wps 5.80K ppl 340.05 bleu 0.00
  epoch 0 step 400 lr 1 step-time 1.02s wps 6.06K ppl 277.61 bleu 0.00
  epoch 0 step 500 lr 1 step-time 0.95s wps 5.89K ppl 205.85 bleu 0.00
</code></pre><p>有关更多详细信息，请参阅train.py。</p>
<p>我们可以启动Tensorboard来查看训练过程中的模型摘要：</p>
<pre><code>tensorboard --port 22222 --logdir /tmp/nmt_model/
</code></pre><p>从英语和越南语的相反方向训练可以简单地通过改变：\     <code>--src=en --tgt=vi</code></p>
<h2><span id="推论-如何生成翻译">推论 - 如何生成翻译</span></h2><p>你正在训练你的NMT模型（一旦你有训练有素的模型），你 可以获得以前看不见的源句子的翻译。这个流程 被称为推理。训练和推理之间有明确的区别<br>（测试）：在推理的时候，我们只能访问源句子， 即encoder_inputs。有很多方法来执行解码。解码 方法包括贪婪，采样和波束搜索解码。在这里，我们会的<br>讨论贪婪的解码策略。</p>
<p>这个想法很简单，我们在图3中进行说明：</p>
<p>我们仍然按照与训练期间相同的方式对源句进行编码    获得一个encoder_state，并且这个encoder_state被用来初始化    解码器。<br>一旦解码器接收到解码（翻译）过程即开始    一个起始符号“\ <del>”（在我们的代码中称为tgt_sos_id）;<br>对于解码器端的每个时间步，我们将RNN的输出视为一组    logits。我们选择最可能的单词，与最大的相关联的ID<br>逻辑值，作为发出的词（这是“贪婪的”行为）。对于    在图3中的例子中，词“moi”具有最高的翻译概率<br>在第一个解码步骤中。然后，我们把这个单词作为下一个的输入    时间步长。 这个过程一直持续到产生结束标记“\</del> ”为止<br>一个输出符号（在我们的代码中称为tgt_eos_id）。</p>
<p><img src="https://www.tensorflow.org/images/seq2seq/greedy_dec.jpg" alt=""> 图3.贪婪解码 -<br>一个训练NMT模型如何产生一个例子 翻译源句子“Je suisétudiant”使用贪婪的搜索。</p>
<p>第三步是使得推论与训练不同。而不是总是 喂养正确的目标词作为输入，推理使用预测的词 该模型。这是实现贪婪解码的代码。这是非常相似的 训练解码器。</p>
<pre><code># Helper
helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(
    embedding_decoder,
    tf.fill([batch_size], tgt_sos_id), tgt_eos_id)

# Decoder
decoder = tf.contrib.seq2seq.BasicDecoder(
    decoder_cell, helper, encoder_state,
    output_layer=projection_layer)
# Dynamic decoding
outputs, _ = tf.contrib.seq2seq.dynamic_decode(
    decoder, maximum_iterations=maximum_iterations)
translations = outputs.sample_id
</code></pre><p>在这里，我们使用GreedyEmbeddingHelper而不是TrainingHelper。因为我们这样做<br>事先不知道目标序列长度，我们使用maximum_iterations来 限制翻译长度。一个启发式就是解码两倍的 源句子长度。</p>
<pre><code>maximum_iterations = tf.round(tf.reduce_max(source_sequence_length) * 2)
</code></pre><p>在训练完模型后，我们现在可以创建一个推理文件并翻译一些 句子：</p>
<pre><code>cat &gt; /tmp/my_infer_file.vi
# (copy and paste some sentences from /tmp/nmt_data/tst2013.vi)

python -m nmt.nmt \
    --out_dir=/tmp/nmt_model \
    --inference_input_file=/tmp/my_infer_file.vi \
    --inference_output_file=/tmp/nmt_model/output_infer

cat /tmp/nmt_model/output_infer # To view the inference as output
</code></pre><p>请注意，上述命令也可以在模型仍在训练时运行 只要有一个培训 检查点。有关更多详细信息，请参阅inference.py。</p>
<h1><span id="中间">中间</span></h1><p>经历了最基本的seq2seq模型，让我们更先进！至 建立最先进的神经机器翻译系统，我们将需要更多 “秘诀”：首先介绍的注意机制<br>由Bahdanau等人，2015年，然后再提炼 由Luong等人，2015等人提供。钥匙 关注机制的构想是建立直接的快捷连接<br>通过对相关来源的“关注”，在目标和来源之间 我们翻译的内容。关注机制的一个很好的副产品是一个 易于可视化源句子和目标句子之间的对齐矩阵（如 如图4所示）。</p>
<p><img src="https://www.tensorflow.org/images/seq2seq/attention_vis.jpg" alt=""> 图4.注意可视化 -<br>来源之间对齐的示例 和目标句子。图片取自（Bahdanau等，2015）。</p>
<p>请记住，在香草seq2seq模型中，我们传递最后的源状态 当开始解码过程时编码器到解码器。这很好 中短句子;然而，对于长句，单身<br>固定大小的隐藏状态成为信息瓶颈。而不是丢弃 在源RNN中计算的所有隐藏状态，关注机制 提供了一个方法，使解码器偷看他们（把他们当作一个<br>动态存储源信息）。通过这样做，注意机制 改善了较长句子的翻译。目前，关注机制是 事实上的标准，并已成功应用于许多其他任务 （包括图像标题生成，语音识别和文本<br>摘要）。</p>
<h2><span id="注意机制的背景">注意机制的背景</span></h2><p>我们现在描述（Luong et al 2015年），已被用于几个最先进的系统，包括 开放源代码工具包，如OpenNMT和TF 本教程中的seq2seq<br>API。我们还将提供到其他变体的连接 的关注机制。</p>
<p><img src="https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg" alt=""> 图5.注意机制</p>
<ul>
<li>基于注意的NMT系统的例子 如（Luong等，2015）中所述。我们详细地强调了第一步 关注计算。为了清楚起见，我们不显示嵌入和 图（2）中的投影层。</li>
</ul>
<p>如图5所示，关注计算发生在每个解码器 时间步。它由以下几个阶段组成：</p>
<p>将当前目标隐藏状态与所有源状态进行比较以导出    注意力权重（可以如图4所示）。 基于注意力权重，我们计算一个上下文向量作为加权    平均来源国。<br>将上下文向量与当前目标隐藏状态相结合以产生    最后关注矢量 注意向量作为下一个时间步的输入（输入    馈送）。前三个步骤可以用下面的等式来总结：</p>
<p><img src="https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg" alt=""></p>
<p>在这里，功能<code>score</code>用来比较目标隐藏状态\（h_t \） 与每个源隐藏状态\（\ overline {h} _s \），并将结果标准化为<br>产生注意力权重（一个分配源头位置）。有 评分功能的各种选择;流行的得分功能包括 乘法和加法形式在方程（4）。一旦计算，注意 矢量\（a_t<br>\）被用来导出softmax logit和损失。这与之类似 目标隐藏状态在香草seq2seq模型的顶层。功能 <code>f</code>也可以采取其他形式。</p>
<p><img src="https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg" alt=""></p>
<p>关注机制的各种实现可以找到 在 attention_wrapper.py。</p>
<p>关注机制中有什么关系？</p>
<p>正如上面的方程式所暗示的，有很多不同的注意变量。 这些变体取决于得分功能的形式和注意力 函数，以及是否使用之前的状态\（h_ {t-1} \）<br>（Bahdanau et al。， 2015年）。经验上，我们发现只有某些选择很重要。首先，基本 注意的形式，即目标与源之间的直接联系<br>出席。其次，将注意力向量输入下一个是很重要的 时间步骤通知网络关于过去的关注决定如在展示 （Luong等，2015）。最后，评分功能的选择常常会导致<br>在不同的表现。在基准测试结果中看到更多 部分。</p>
<h2><span id="注意包装api">注意包装API</span></h2><p>在我们的执行 该 AttentionWrapper， 我们借用一些术语 来自（Weston等人，2015）的工作 内存网络。而不是有可读可写的记忆，注意力<br>本教程中介绍的机制是只读内存。具体来说， 源隐藏状态集合（或它们的转换版本，例如， \（W \ overline {h} _s<br>\）在Luong的得分风格或\（W_2 \ overline {h} _s \）中 Bahdanau的得分风格）被称为“记忆”。在每个时间步骤，<br>我们使用当前目标隐藏状态作为“查询”来决定哪些部分 的内存来读取。通常，查询需要与键进行比较 对应于单独的内存插槽。在上面的介绍中<br>注意机制，我们碰巧使用了一组源隐藏状态（或它们的隐藏状态） 例如Bahdanau得分风格的\（W_1h_t \））<br>“键”。人们可以从这个记忆网络术语中得到启发 注意的形式！</p>
<p>感谢关注包装，扩展我们的香草seq2seq代码 注意力是微不足道的。这部分是指 文件attention_model.py</p>
<p>首先，我们需要定义一个注意机制，例如（Luong et al。， 2015年）：</p>
<pre><code># attention_states: [batch_size, max_time, num_units]
attention_states = tf.transpose(encoder_outputs, [1, 0, 2])

# Create an attention mechanism
attention_mechanism = tf.contrib.seq2seq.LuongAttention(
    num_units, attention_states,
    memory_sequence_length=source_sequence_length)
</code></pre><p>在之前的编码器部分，encoder_outputs是全部的集合 源顶层隐藏状态，形状为[max_time，<br>batch_size，num_units]（因为我们用time_major设置为dynamic_rnn 真正的效率）。对于注意机制，我们需要确保<br>传入的“内存”是批量专业，所以我们需要转置 attention_states。我们将source_sequence_length传递给关注机制<br>以确保注意力权重得到正确的标准化（非填充 职位）。</p>
<p>定义了关注机制后，我们使用AttentionWrapper来包装 解码单元格：</p>
<pre><code>decoder_cell = tf.contrib.seq2seq.AttentionWrapper(
    decoder_cell, attention_mechanism,
    attention_layer_size=num_units)
</code></pre><p>其余的代码和Section Decoder几乎一样！</p>
<h2><span id="动手-建立一个基于注意力的nmt模型">动手 - 建立一个基于注意力的NMT模型</span></h2><p>为了引起注意，我们需要使用<code>luong</code>，<code>scaled_luong</code>，<code>bahdanau</code><br>或<code>normed_bahdanau</code>作为训练期间<code>attention</code>标志的值。该 标志指定我们将使用哪种注意机制。另外，我们<br>需要为注意模型创建一个新的目录，所以我们不重用 以前训练过的基本NMT模型。</p>
<p>运行以下命令开始训练：</p>
<pre><code>mkdir /tmp/nmt_attention_model

python -m nmt.nmt \
    --attention=scaled_luong \
    --src=vi --tgt=en \
    --vocab_prefix=/tmp/nmt_data/vocab  \
    --train_prefix=/tmp/nmt_data/train \
    --dev_prefix=/tmp/nmt_data/tst2012  \
    --test_prefix=/tmp/nmt_data/tst2013 \
    --out_dir=/tmp/nmt_attention_model \
    --num_train_steps=12000 \
    --steps_per_stats=100 \
    --num_layers=2 \
    --num_units=128 \
    --dropout=0.2 \
    --metrics=bleu
</code></pre><p>训练结束后，我们可以使用与新的out_dir相同的推理命令 推理：</p>
<pre><code>python -m nmt.nmt \
    --out_dir=/tmp/nmt_attention_model \
    --inference_input_file=/tmp/my_infer_file.vi \
    --inference_output_file=/tmp/nmt_attention_model/output_infer
</code></pre><h1><span id="提示与技巧">提示与技巧</span></h1><h2><span id="构建训练评估和推理图">构建训练，评估和推理图</span></h2><p>在TensorFlow中构建机器学习模型时，通常最好进行构建 三个单独的图表：</p>
<p>培训图表，其中： 批次，桶和可能的子样本从一组输入数据    文件/外部输入。 包括forward和backprop操作。 构造优化器，并添加训练操作。<br>评估图，其中： 批处理和桶从一组文件/外部输入中输入数据。 包括培训前沿操作，以及额外的评估操作    不用于训练。 推理图，其中： 可能不批量输入数据。<br>不抽取或抽取输入数据。 从占位符中读取输入数据（数据可以直接输入到图形中    通过feed_dict或C ++ TensorFlow服务二进制文件）。<br>包括模型转发操作的一个子集，可能还有其他的    用于在session.run调用之间存储状态的特殊输入/输出。</p>
<p>构建独立的图有几个好处：</p>
<p>推理图通常与其他两个非常不同，所以它是成立的    感觉分开建造它。 评估图变得更简单，因为它不再有所有的附加    反向操作。<br>数据馈送可以针对每个图分别实施。 变量重用要简单得多。例如，在评估图中没有    需要重新打开变量范围重用= True只是因为培训<br>模型已经创建了这些变量。所以相同的代码可以重用    而不是随处可见地重复使用参数。 在分布式培训中，单独的员工表现是司空见惯的<br>训练，评估和推理。无论如何，这些都需要建立自己的图形。    所以通过这种方式构建系统可以为分布式培训做好准备。</p>
<p>复杂性的主要来源是如何在三者之间共享变量 图表在一台机器设置。这是通过使用单独的会话来解决的 为每个图。培训会定期保存检查点，<br>eval会话和推断会话从检查点恢复参数。该 下面的例子显示了两种方法的主要区别。</p>
<p>之前：三个模型在一个图中共享一个Session</p>
<pre><code>with tf.variable_scope(&apos;root&apos;):
  train_inputs = tf.placeholder()
  train_op, loss = BuildTrainModel(train_inputs)
  initializer = tf.global_variables_initializer()

with tf.variable_scope(&apos;root&apos;, reuse=True):
  eval_inputs = tf.placeholder()
  eval_loss = BuildEvalModel(eval_inputs)

with tf.variable_scope(&apos;root&apos;, reuse=True):
  infer_inputs = tf.placeholder()
  inference_output = BuildInferenceModel(infer_inputs)

sess = tf.Session()

sess.run(initializer)

for i in itertools.count():
  train_input_data = ...
  sess.run([loss, train_op], feed_dict={train_inputs: train_input_data})

  if i % EVAL_STEPS == 0:
    while data_to_eval:
      eval_input_data = ...
      sess.run([eval_loss], feed_dict={eval_inputs: eval_input_data})

  if i % INFER_STEPS == 0:
    sess.run(inference_output, feed_dict={infer_inputs: infer_input_data})
</code></pre><p>之后：三个图中的三个模型，三个会话共享相同的变量</p>
<pre><code>train_graph = tf.Graph()
eval_graph = tf.Graph()
infer_graph = tf.Graph()

with train_graph.as_default():
  train_iterator = ...
  train_model = BuildTrainModel(train_iterator)
  initializer = tf.global_variables_initializer()

with eval_graph.as_default():
  eval_iterator = ...
  eval_model = BuildEvalModel(eval_iterator)

with infer_graph.as_default():
  infer_iterator, infer_inputs = ...
  infer_model = BuildInferenceModel(infer_iterator)

checkpoints_path = &quot;/tmp/model/checkpoints&quot;

train_sess = tf.Session(graph=train_graph)
eval_sess = tf.Session(graph=eval_graph)
infer_sess = tf.Session(graph=infer_graph)

train_sess.run(initializer)
train_sess.run(train_iterator.initializer)

for i in itertools.count():

  train_model.train(train_sess)

  if i % EVAL_STEPS == 0:
    checkpoint_path = train_model.saver.save(train_sess, checkpoints_path, global_step=i)
    eval_model.saver.restore(eval_sess, checkpoint_path)
    eval_sess.run(eval_iterator.initializer)
    while data_to_eval:
      eval_model.eval(eval_sess)

  if i % INFER_STEPS == 0:
    checkpoint_path = train_model.saver.save(train_sess, checkpoints_path, global_step=i)
    infer_model.saver.restore(infer_sess, checkpoint_path)
    infer_sess.run(infer_iterator.initializer, feed_dict={infer_inputs: infer_input_data})
    while data_to_infer:
      infer_model.infer(infer_sess)
</code></pre><p>注意后一种方法是如何“准备好”转换为分布式的 版。</p>
<p>新方法的另一个区别是不使用feed_dicts 在每个session.run调用提供数据（从而执行我们自己的 批处理，数据处理和操作），我们使用有状态迭代器<br>对象。这些迭代器使输入流水线在两者中都变得更容易 单机和分布式设置。我们将覆盖新的输入数据 流水线（在TensorFlow 1.2中介绍）。</p>
<h2><span id="数据输入管道">数据输入管道</span></h2><p>在TensorFlow 1.2之前，用户有两种选择向数据提供数据 TensorFlow培训和评估管道：</p>
<p>在每个培训session.run调用直接通过feed_dict提供数据。 使用tf.train中的排队机制（例如tf.train.batch）和<br>tf.contrib.train。 使用更高级别的框架，如tf.contrib.learn或    tf.contrib.slim（有效地使用＃2）。</p>
<p>第一种方法对于不熟悉TensorFlow或者 需要做异国情调的输入修改（即他们自己的小批量排队） 只能在Python中完成。第二种和第三种方法更为标准<br>但有点不灵活;他们还需要启动多个python线程 （排队跑步者）。而且，如果使用不正确的队列会导致死锁 或不透明的错误信息。尽管如此，排队更有效率<br>比使用feed_dict和单机和标准 分布式培训。</p>
<p>从TensorFlow 1.2开始，有一个新的系统可以读取数据 进入TensorFlow模型：数据集迭代器，在tf.contrib.data中找到<br>模块。数据迭代器是灵活的，易于推理和操作，并且 通过利用TensorFlow C ++运行时提供效率和多线程。</p>
<p>数据集可以从批量数据张量，文件名或张量创建 包含多个文件名。一些例子：</p>
<pre><code># Training dataset consists of multiple files.
train_dataset = tf.contrib.data.TextLineDataset(train_files)

# Evaluation dataset uses a single file, but we may
# point to a different file for each evaluation round.
eval_file = tf.placeholder(tf.string, shape=())
eval_dataset = tf.contrib.data.TextLineDataset(eval_file)

# For inference, feed input data to the dataset directly via feed_dict.
infer_batch = tf.placeholder(tf.string, shape=(num_infer_examples,))
infer_dataset = tf.contrib.data.Dataset.from_tensor_slices(infer_batch)
</code></pre><p>所有的数据集可以通过输入处理类似的处理。这包括 阅读和清理数据，分类（在训练和评估的情况下） 过滤和配料。</p>
<p>为了将每个句子转换成单词串的向量，例如，我们使用 数据集图转换：</p>
<pre><code>dataset = dataset.map(lambda string: tf.string_split([string]).values)
</code></pre><p>然后，我们可以将每个句子向量切换成包含两个向量的元组 和它的动态长度：</p>
<pre><code>dataset = dataset.map(lambda words: (words, tf.size(words))
</code></pre><p>最后，我们可以对每个句子进行词汇查询。给一个查询 表格对象表，这个映射将从一个向量中转换出第一个元组元素 字符串到整数的向量。</p>
<pre><code>dataset = dataset.map(lambda words, size: (table.lookup(words), size))
</code></pre><p>加入两个数据集也很容易。如果两个文件包含一行一行 互相翻译，每一个都被读入自己的数据集，然后一个新的 包含压缩行的元组的数据集可以通过以下方式创建：</p>
<pre><code>source_target_dataset = tf.contrib.data.Dataset.zip((source_dataset, target_dataset))
</code></pre><p>可变长度句子的分组很简单。下列 转换批量从source_target_dataset批处理batch_size元素，和<br>分别将源向量和目标向量填充到最长的长度 源和目标载体在每批。</p>
<pre><code>batched_dataset = source_target_dataset.padded_batch(
        batch_size,
        padded_shapes=((tf.TensorShape([None]),  # source vectors of unknown size
                        tf.TensorShape([])),     # size(source)
                       (tf.TensorShape([None]),  # target vectors of unknown size
                        tf.TensorShape([]))),    # size(target)
        padding_values=((src_eos_id,  # source vectors padded on the right with src_eos_id
                         0),          # size(source) -- unused
                        (tgt_eos_id,  # target vectors padded on the right with tgt_eos_id
                         0)))         # size(target) -- unused
</code></pre><p>从这个数据集发出的值将是张量有张量的嵌套元组 大小为batch_size的最左边的维度。结构将是：</p>
<p>迭代器[0] [0]具有批处理和填充的源句子矩阵。 迭代器[0] [1]具有成批的源大小向量。 迭代器[1] [0]具有批处理和填充的目标语句矩阵。<br>迭代器[1] [1]具有成批的目标大小向量。</p>
<p>最后，将批量相似大小的源语句一起分组 也有可能。请看 文件 utils / iterator_utils.py for 更多细节和全面实施。</p>
<p>从数据集中读取数据需要三行代码：创建迭代器， 获取它的值，并初始化它。</p>
<pre><code>batched_iterator = batched_dataset.make_initializable_iterator()

((source, source_lengths), (target, target_lenghts)) = batched_iterator.get_next()

# At initialization time.
session.run(batched_iterator.initializer, feed_dict={...})
</code></pre><p>一旦迭代器被初始化，每个访问源的session.run调用 或目标张量将要求来自底层数据集的下一个小批次。</p>
<h2><span id="更好的nmt模型的其他细节">更好的NMT模型的其他细节</span></h2><h3><span id="双向rnn">双向RNN</span></h3><p>编码器方面的双向性通常会带来更好的性能（使用 速度随着更多层的使用而降低）。在这里，我们给一个简化 如何建立一个单一的双向层编码器的例子：</p>
<pre><code># Construct forward and backward cells
forward_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)
backward_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)

bi_outputs, encoder_state = tf.nn.bidirectional_dynamic_rnn(
    forward_cell, backward_cell, encoder_emb_inp,
    sequence_length=source_sequence_length, time_major=True)
encoder_outputs = tf.concat(bi_outputs, -1)
</code></pre><p>可以以相同的方式使用变量encoder_outputs和encoder_state 如在部分编码器中。请注意，对于多个双向层，我们需要<br>操纵一下encoder_state，看model.py，方法 _build_bidirectional_rnn（）获取更多细节。</p>
<h3><span id="梁搜索">梁搜索</span></h3><p>而贪婪的解码可以给我们相当合理的翻译质量，一个梁 搜索解码器可进一步提升性能。梁搜索的想法是 更好地探索所有可能的翻译搜索空间，保持周围<br>我们翻译的一小组顶级候选人。梁的大小被称为 光束宽度;例如尺寸10的最小光束宽度通常就足够了。对于 更多的信息，请参阅第7.2.3节<br>Neubig，（2017）。这是一个例子 光束搜索可以做到：</p>
<pre><code># Replicate encoder infos beam_width times
decoder_initial_state = tf.contrib.seq2seq.tile_batch(
    encoder_state, multiplier=hparams.beam_width)

# Define a beam-search decoder
decoder = tf.contrib.seq2seq.BeamSearchDecoder(
        cell=decoder_cell,
        embedding=embedding_decoder,
        start_tokens=start_tokens,
        end_token=end_token,
        initial_state=decoder_initial_state,
        beam_width=beam_width,
        output_layer=projection_layer,
        length_penalty_weight=0.0)

# Dynamic decoding
outputs, _ = tf.contrib.seq2seq.dynamic_decode(decoder, ...)
</code></pre><p>请注意，使用相同的dynamic_decode（）API调用，类似于 部分解码器。一旦解码，我们可以访问翻译为 如下：</p>
<pre><code>translations = outputs.predicted_ids
# Make sure translations shape is [batch_size, beam_width, time]
if self.time_major:
   translations = tf.transpose(translations, perm=[1, 2, 0])
</code></pre><p>有关更多详细信息，请参阅model.py，_build_decoder（）方法。</p>
<h3><span id="超参数">超参数</span></h3><p>有几个超参数可以导致额外的 表演。在这里，我们根据自己的经验列出一些[免责声明： 别人可能不同意我们写的东西！ ]。</p>
<p>优化：亚当可以导致“陌生”的合理结果， 体系结构，带调度的SGD通常会导致更好的性能 你可以用SGD来训练。</p>
<p>注意：Bahdanau式的注意往往需要双向的 编码器端工作正常;而Luong式的注意力往往适用于 不同的设置。对于本教程的代码，我们建议使用这两个改进<br>Luong＆Bahdanau式的注意变体：scaled_luong＆normed bahdanau。</p>
<h3><span id="多gpu训练">多GPU训练</span></h3><p>培训一个NMT模型可能需要几天的时间。放置不同的RNN图层 不同的GPU可以提高训练速度。这是一个创建的例子 RNN层在多个GPU上。</p>
<pre><code>cells = []
for i in range(num_layers):
  cells.append(tf.contrib.rnn.DeviceWrapper(
      tf.contrib.rnn.LSTMCell(num_units),
      &quot;/gpu:%d&quot; % (num_layers % num_gpus)))
cell = tf.contrib.rnn.MultiRNNCell(cells)
</code></pre><p>另外，我们需要启用<code>colocate_gradients_with_ops</code>选项 <code>tf.gradients</code>并行化梯度计算。</p>
<p>您可能会注意到基于注意力的NMT模型的速度提高非常快 随着GPU数量的增加而变小。标准的一个主要缺点 注意体系结构正在使用顶层（最终）层的输出来查询<br>注意在每个时间步骤。这意味着每个解码步骤都必须等待 上一步完全完成;因此，我们不能并行解码 通过简单地在多个GPU上放置RNN层进行处理。</p>
<p>GNMT关注架构 通过使用底层（第一层）来并行解码器的计算 输出查询关注。因此，每个解码步骤可以尽快开始 其前一步的第一层和关注计算完成。我们<br>在中实现了架构 GNMTAttentionMultiCell， tf.contrib.rnn.MultiRNNCell的子类。这里是一个如何创建的例子<br>具有GNMTAttentionMultiCell的解码器单元。</p>
<pre><code>cells = []
for i in range(num_layers):
  cells.append(tf.contrib.rnn.DeviceWrapper(
      tf.contrib.rnn.LSTMCell(num_units),
      &quot;/gpu:%d&quot; % (num_layers % num_gpus)))
attention_cell = cells.pop(0)
attention_cell = tf.contrib.seq2seq.AttentionWrapper(
    attention_cell,
    attention_mechanism,
    attention_layer_size=None,  # don&apos;t add an additional dense layer.
    output_attention=False,)
cell = GNMTAttentionMultiCell(attention_cell, cells)
</code></pre><h1><span id="基准">基准</span></h1><h2><span id="iwslt英语-越南语">IWSLT英语 - 越南语</span></h2><p>训练：133K例子，vocab = vocab。（vi | en），train = train。（vi | en） 开发= tst2012（六| EN）。，<br>test = tst2013。（vi | en），下载脚本。</p>
<p>培训细节。我们训练双向512个单元的2层LSTM 编码器（即，用于编码器的1个双向层），嵌入暗淡 是512. LuongAttention（scale =<br>True）和drop_out_prob一起使用 0.8。所有的参数是统一的。学习率1.0的SGD使用如下： 列车12K步（约12个时代）;<br>8K步后，我们开始减半学习 每步1K。</p>
<p>结果。 TODO（rzhao）：添加英语 - 越南语训练模型的URL。</p>
<p>以下是2个模型的平均结果 （型号1， 模型2）。\ 我们用BLEU得分来衡量翻译质量（Papineni et al。，2002）。</p>
<table>
<thead>
<tr>
<th>Systems</th>
<th>tst2012 (dev)</th>
<th>test2013 (test)  </th>
</tr>
</thead>
<tbody>
<tr>
<td>NMT (greedy)</td>
<td>23.2</td>
<td>25.5  </td>
</tr>
<tr>
<td>NMT (beam=10)</td>
<td>23.8</td>
<td><strong>26.1</strong>  </td>
</tr>
</tbody>
</table>
<p><a href="https://nlp.stanford.edu/pubs/luong-manning-
iwslt15.pdf" target="_blank" rel="noopener">(Luong &amp; Manning, 2015)</a> |  - | 23.3  </p>
<p>训练速度：在TitanX上的K40m和（0.17s步进时间，32.2K wps）上（0.37s步进时间，15.3K wps）<br>在这里，步进时间是指运行一个小批量（128号）的时间。对于wps，我们计算来源和目标上的字数。</p>
<h2><span id="wmt德语-英语">WMT德语 - 英语</span></h2><p>训练：4.5M例子，vocab = vocab.bpe.32000。（de | en）， train =<br>train.tok.clean.bpe.32000。（de | en），dev = newstest2013.tok.bpe.32000。（de |<br>en）， 测试= newstest2015.tok.bpe.32000。（DE | EN） 下载脚本</p>
<p>培训细节。我们的训练超参数类似于 英语 - 越南语的实验除了以下细节。数据是 使用BPE拆分为子字单位<br>（32K操作）。我们训练双向1024个单元的4层LSTMs 编码器（即，用于编码器的2个双向层），嵌入暗淡<br>是1024.我们训练了350K步（〜10个纪元）。经过170K步，我们开始 每17K步减半学习率。</p>
<p>结果。 TODO（rzhao）：为德英培训模型添加网址。</p>
<p>前两行是2个模型的平均结果 （型号1， 模型2）。 第三行的结果是GNMT的关注 （模型） ;使用4个GPU进行训练。</p>
<table>
<thead>
<tr>
<th>Systems</th>
<th>newstest2013 (dev)</th>
<th>newstest2015  </th>
</tr>
</thead>
<tbody>
<tr>
<td>NMT (greedy)</td>
<td>27.1</td>
<td>27.6  </td>
</tr>
<tr>
<td>NMT (beam=10)</td>
<td>28.0</td>
<td>28.9  </td>
</tr>
<tr>
<td>NMT + GNMT attention (beam=10)</td>
<td>29.0</td>
<td><strong>29.9</strong>  </td>
</tr>
<tr>
<td><a href="http://matrix.statmt.org/" target="_blank" rel="noopener">WMT SOTA</a></td>
<td>-</td>
<td>29.3  </td>
</tr>
</tbody>
</table>
<p>这些结果表明我们的代码为NMT构建了强大的基线系统。 （请注意，WMT系统通常使用大量的单语数据，而目前我们没有。</p>
<p>Nvidia K40m和（0.7s step-time，8.7K wps）在Nvidia TitanX上的训练速度（2.1s step-time，3.4K<br>wps） 为了看到GNMT关注的加速，我们仅以K40m为基准：</p>
<table>
<thead>
<tr>
<th>Systems</th>
<th>1 gpu</th>
<th>4 gpus</th>
<th>8 gpus  </th>
</tr>
</thead>
<tbody>
<tr>
<td>NMT (4 layers)</td>
<td>2.2s, 3.4K</td>
<td>1.9s, 3.9K</td>
<td>-  </td>
</tr>
<tr>
<td>NMT (8 layers)</td>
<td>3.5s, 2.0K</td>
<td>-</td>
<td>2.9s, 2.4K  </td>
</tr>
<tr>
<td>NMT + GNMT attention (4 layers)</td>
<td>2.6s, 2.8K</td>
<td>1.7s, 4.3K</td>
<td>-  </td>
</tr>
<tr>
<td>NMT + GNMT attention (8 layers)</td>
<td>4.2s, 1.7K</td>
<td>-</td>
<td>1.9s, 3.8K  </td>
</tr>
</tbody>
</table>
<p>这些结果表明，没有GNMT的关注，使用多个gpus的收益是最小的。 在GNMT的关注下，我们从多个gpus中获得了50％-100％的加速。</p>
<h2><span id="wmt英语-德语-全面比较">WMT英语 - 德语 - 全面比较</span></h2><p>前两行是我们的GNMT模型 注意： 模型1（4层）， 模型2（8层）。</p>
<table>
<thead>
<tr>
<th>Systems</th>
<th>newstest2014</th>
<th>newstest2015  </th>
</tr>
</thead>
<tbody>
<tr>
<td><em>Ours</em> – NMT + GNMT attention (4 layers)</td>
<td>23.7</td>
<td>26.5  </td>
</tr>
<tr>
<td><em>Ours</em> – NMT + GNMT attention (8 layers)</td>
<td>24.4</td>
<td><strong>27.6</strong>  </td>
</tr>
<tr>
<td><a href="http://matrix.statmt.org/" target="_blank" rel="noopener">WMT SOTA</a></td>
<td>20.6</td>
<td>24.9  </td>
</tr>
<tr>
<td>OpenNMT <a href="https://arxiv.org/abs/1701.02810" target="_blank" rel="noopener">(Klein et al., 2017)</a></td>
<td>19.3</td>
<td>-  </td>
</tr>
<tr>
<td>tf-seq2seq <a href="https://arxiv.org/abs/1703.03906" target="_blank" rel="noopener">(Britz et al., 2017)</a></td>
<td>22.2</td>
<td></td>
</tr>
</tbody>
</table>
<p>25.2<br>GNMT <a href="https://research.google.com/pubs/pub45610.html" target="_blank" rel="noopener">(Wu et al., 2016)</a> |<br><strong>24.6</strong> |  -  </p>
<p>上述结果表明，我们的模型在类似架构的模型中是非常有竞争力的。<br>[请注意，OpenNMT使用较小的模型，目前最好的结果（截至撰写本文时）是由Transformer网络（Vaswani et<br>al。，2017）获得的28.4，具有明显不同的架构。</p>
<h2><span id="标准hparams">标准HParams</span></h2><p>我们提供了 一套标准的hparams 使用预先训练的检查点推断或训练NMT架构 在基准中使用。</p>
<p>我们将使用WMT16的德英数据，您可以通过下载数据 以下命令。</p>
<pre><code>nmt/scripts/wmt16_en_de.sh /tmp/wmt16
</code></pre><p>以下是加载预先训练的GNMT WMT德语 - 英语的示例命令 检查点推断。</p>
<pre><code>python -m nmt.nmt \
    --src=de --tgt=en \
    --ckpt=/path/to/checkpoint/translate.ckpt \
    --hparams_path=nmt/standard_hparams/wmt16_gnmt_4_layer.json \
    --out_dir=/tmp/deen_gnmt \
    --vocab_prefix=/tmp/wmt16/vocab.bpe.32000 \
    --inference_input_file=/tmp/wmt16/newstest2014.tok.bpe.32000.de \
    --inference_output_file=/tmp/deen_gnmt/output_infer \
    --inference_ref_file=/tmp/wmt16/newstest2014.tok.bpe.32000.en
</code></pre><p>这里是GNMT WMT德 - 英模型的示例命令。</p>
<pre><code>python -m nmt.nmt \
    --src=de --tgt=en \
    --hparams_path=nmt/standard_hparams/wmt16_gnmt_4_layer.json \
    --out_dir=/tmp/deen_gnmt \
    --vocab_prefix=/tmp/wmt16/vocab.bpe.32000 \
    --train_prefix=/tmp/wmt16/train.tok.clean.bpe.32000 \
    --dev_prefix=/tmp/wmt16/newstest2013.tok.bpe.32000 \
    --test_prefix=/tmp/wmt16/newstest2015.tok.bpe.32000
</code></pre><h1><span id="其他资源">其他资源</span></h1><p>深入阅读“神经机器翻译”和“序列到序列” 型号，我们强烈推荐以下材料 通过 Luong，Cho，Manning，（2016）; Luong，（2016）;<br>和Neubig（2017）。</p>
<p>建立seq2seq模型有各种各样的工具，所以我们选择一个 语言：\ 斯坦福大学NMT<br><a href="https://nlp.stanford.edu/projects/nmt/" target="_blank" rel="noopener">https://nlp.stanford.edu/projects/nmt/</a> [Matlab] \ TF-seq2seq<br><a href="https://github.com/google/seq2seq" target="_blank" rel="noopener">https://github.com/google/seq2seq</a> [TensorFlow] \ Nemantus<br><a href="https://github.com/rsennrich/nematus" target="_blank" rel="noopener">https://github.com/rsennrich/nematus</a> [Theano] \ OpenNMT <a href="http://opennmt.net/" target="_blank" rel="noopener">http://opennmt.net/</a><br>[火炬] \ OpenNMT-py <a href="https://github.com/OpenNMT/OpenNMT-py" target="_blank" rel="noopener">https://github.com/OpenNMT/OpenNMT-py</a> [PyTorch]</p>
<h1><span id="承认">承认</span></h1><p>我们要感谢Denny Britz，Anna Goldie，Derek Murray和Cinjon<br>Resnick为TensorFlow和seq2seq库带来的新功能。另外感谢Lukasz Kaiser在seq2seq代码库上的初步帮助。 Quoc<br>Le提出复制GNMT的建议;关于GNMT系统的细节，吴永辉和陈志峰;以及Google Brain团队的支持和反馈！</p>
<h1><span id="参考">参考</span></h1><p>Dzmitry Bahdanau，Kyunghyun Cho和Yoshua    Bengio。神经机器翻译通过共同学习来对齐和翻译。 ICLR。<br>Minh-Thang Luong，Hieu Pham和Christopher D.    曼宁。有效的基于注意力的神经机器翻译方法。 EMNLP。 Ilya<br>Sutskever，Oriol Vinyals和Quoc    V. Le。 2014年。序列学习与神经网络。 NIPS。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  


  <nav id="page-nav" class="clearfix">
    <a class="extend prev" rel="prev" href="/page/121/"><span></span>Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/120/">120</a><a class="page-number" href="/page/121/">121</a><span class="page-number current">122</span><a class="page-number" href="/page/123/">123</a><a class="page-number" href="/page/124/">124</a><span class="space">&hellip;</span><a class="page-number" href="/page/157/">157</a><a class="extend next" rel="next" href="/page/123/">Next<span></span></a>
  </nav>

</div>

      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- side-bar-ad -->
<ins class="adsbygoogle"
     style="display:block; overflow:hidden;"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="2232545787"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


  


  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/javascript/" title="javascript">javascript<sup>207</sup></a></li>
			
		
			
				<li><a href="/tags/java/" title="java">java<sup>205</sup></a></li>
			
		
			
				<li><a href="/tags/html/" title="html">html<sup>203</sup></a></li>
			
		
			
				<li><a href="/tags/python/" title="python">python<sup>199</sup></a></li>
			
		
			
				<li><a href="/tags/bash/" title="bash">bash<sup>198</sup></a></li>
			
		
			
				<li><a href="/tags/php/" title="php">php<sup>197</sup></a></li>
			
		
			
				<li><a href="/tags/css/" title="css">css<sup>88</sup></a></li>
			
		
			
				<li><a href="/tags/shell/" title="shell">shell<sup>78</sup></a></li>
			
		
			
				<li><a href="/tags/jquery/" title="jquery">jquery<sup>61</sup></a></li>
			
		
			
				<li><a href="/tags/linux/" title="linux">linux<sup>57</sup></a></li>
			
		
			
				<li><a href="/tags/机器学习/" title="机器学习">机器学习<sup>41</sup></a></li>
			
		
			
				<li><a href="/tags/unix/" title="unix">unix<sup>30</sup></a></li>
			
		
			
				<li><a href="/tags/mysql/" title="mysql">mysql<sup>17</sup></a></li>
			
		
			
				<li><a href="/tags/html5/" title="html5">html5<sup>16</sup></a></li>
			
		
			
				<li><a href="/tags/xml/" title="xml">xml<sup>13</sup></a></li>
			
		
			
				<li><a href="/tags/http/" title="http">http<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/区块链/" title="区块链">区块链<sup>1</sup></a></li>
			
		
			
		
			
		
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
        
          <li>
            
            	<a href="https://tracholar.github.io" target="_blank" title="个人博客">个人博客</a>
            
          </li>
        
    </ul>
</div>

  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS</a>
</div>

</aside>
</div>

    </div>
    <footer><div id="footer" >
	
	
	<section class="info">
		<p> To be or not to be, that is a question. <br/>
			This is my blog,believe it or not.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		版权所有 © 2018 本站文章未经同意，禁止转载！作者：
		
		<a href="/about" target="_blank" title="zhizi">zhizi</a>
		


		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>












<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->





<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="Back to Top"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
