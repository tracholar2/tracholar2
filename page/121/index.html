
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>智子</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="zhizi">
    

    
    <meta name="description" content="IT技术、编程、web开发以及新兴的技术翻译与总结">
<meta property="og:type" content="website">
<meta property="og:title" content="智子">
<meta property="og:url" content="https://www.tracholar.top/page/121/index.html">
<meta property="og:site_name" content="智子">
<meta property="og:description" content="IT技术、编程、web开发以及新兴的技术翻译与总结">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="智子">
<meta name="twitter:description" content="IT技术、编程、web开发以及新兴的技术翻译与总结">

    
    <link rel="alternative" href="/atom.xml" title="智子" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">

    <!-- ad start -->
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-6300557868920774",
    enable_page_level_ads: true
  });
</script>

    <!-- ad end -->

    <!--  stat -->
    <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?4036f580b1119e720db871571faa68cc";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-78529611-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-78529611-1');
</script>

    <!-- end stat -->
</head>

  <body>
    <header>
      
<div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="智子">智子</a></h1>
				<h2 class="blog-motto">智子之家</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:www.tracholar.top">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main">


   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/02/auto-scale-textview-text-to-fit-within-bounds/" title="自动缩放TextView文本以适合边界" itemprop="url">自动缩放TextView文本以适合边界</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-02T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-02</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>我正在寻找一个最佳方式来调整<code>TextView</code>中的包装文本的大小，以便它适合在其getHeight和getWidth范围内。我不是简单地寻找一种方式来包装文本</p>
<ul>
<li>我想确保它包装和足够小，完全适合在屏幕上。</li>
</ul>
<p>我在StackOverflow上看到了一些需要自动调整大小的例子，但是它们或者是非常特殊的黑客解决方案，没有解决方案，或者是递归地重新绘制<code>TextView</code>，直到它足够小（这是内存激烈的，用户每次递归观看文本缩小步骤）。</p>
<p>但是我确定有人在那里找到了一个不涉及我所做事情的好方法：编写几个沉重的例程来分析和测量文本，调整文本的大小，并重复，直到找到适当的小尺寸。</p>
<p><code>TextView</code>使用哪些例程来包装文本？难道不能以某种方式来预测文字是否足够小？</p>
<p>tl; dr：是否有一种最佳实践方式来自动调整<code>TextView</code>的大小，使其适合包装在其getHeight和getWidth范围内？</p>
        
        
        <p class="article-more-link">
          
            <a href="/2018/01/02/auto-scale-textview-text-to-fit-within-bounds/#more">Read More</a>
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  
      <ins class="adsbygoogle"
     style="display:block;  overflow:hidden;"
     data-ad-format="fluid"
     data-ad-layout-key="-ej+6f-q-c7+ou"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="5206371097"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/02/how-to-check-whether-a-checkbox-is-checked-in-jquery/" title="如何检查复选框是否在jQuery中检查？" itemprop="url">如何检查复选框是否在jQuery中检查？</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-02T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-02</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>我需要检查复选框的<code>checked</code>属性，并使用jQuery根据选中的属性执行操作。</p>
<p>例如，如果年龄复选框被选中，那么我需要显示一个文本框输入年龄，否则隐藏文本框。</p>
<p>但是下面的代码默认返回<code>false</code>：</p>
<pre><code>if($(&apos;#isAgeSelected&apos;).attr(&apos;checked&apos;)) {
    $(&quot;#txtAge&quot;).show();
} else {
    $(&quot;#txtAge&quot;).hide();
}
</code></pre><p>如何成功查询<code>checked</code>属性？</p>
        
        
        <p class="article-more-link">
          
            <a href="/2018/01/02/how-to-check-whether-a-checkbox-is-checked-in-jquery/#more">Read More</a>
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/javascript/">javascript</a><a href="/tags/jquery/">jquery</a><a href="/tags/html/">html</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/get_started/" title="TensorFlow入门" itemprop="url">TensorFlow入门</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="tensorflow入门">TensorFlow入门</span></h1><p>本指南让您开始在TensorFlow中编程。在使用本指南之前， 安装TensorFlow。为了充分利用 本指南中，您应该了解以下内容：</p>
<p>如何用Python编程。 至少有一点关于数组。 理想的是，关于机器学习的东西。但是，如果你知道的很少或     没有关于机器学习，那么这仍然是你的第一个指导<br>应该读。</p>
<p>TensorFlow提供了多个API。最低级别的API - TensorFlow Core– 为您提供完整的编程控制。我们推荐TensorFlow<br>Core 机器学习研究人员和其他需要精细控制的人员 他们的模型。更高层次的API建立在TensorFlow核心之上。这些 比TensorFlow<br>Core更高级别的API通常更容易学习和使用。在 此外，更高级别的API使重复性任务更容易和更一致<br>在不同的用户之间像tf.estimator这样的高级API可以帮助您管理 数据集，估计器，训练和推断。</p>
<p>本指南从TensorFlow核心教程开始。后来我们 演示如何在tf.estimator中实现相同的模型。会心<br>TensorFlow核心原则会给你一个很好的思维模式 当您使用更紧凑的更高级别的API时在内部工作。</p>
<h1><span id="张量">张量</span></h1><p>TensorFlow中的数据中心单位是张量。张量由一个 将原始值集合整形成任意数量维度的数组。一个 张量的等级是它的维数。这里有一些例子 张量：</p>
<pre><code>3 # a rank 0 tensor; a scalar with shape []
[1., 2., 3.] # a rank 1 tensor; a vector with shape [3]
[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3]
[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]
</code></pre><h2><span id="tensorflow核心教程">TensorFlow核心教程</span></h2><h3><span id="导入张量流">导入张量流</span></h3><p>TensorFlow程序的规范导入语句如下所示：</p>
<pre><code>import tensorflow as tf
</code></pre><p>这使得Python可以访问所有TensorFlow的类，方法和符号。 大多数文档假定您已经完成了这个工作。</p>
<h3><span id="计算图">计算图</span></h3><p>你可能会想到TensorFlow核心程序由两个离散的组成 部分：</p>
<p>构建计算图。 运行计算图。</p>
<p>计算图是一系列排列成a的TensorFlow操作 节点图。 我们来构建一个简单的计算图。每个节点都是零 或更多的张量作为输入，并产生张量作为输出。一种节点<br>是一个常数。像所有的TensorFlow常量一样，它不需要输入，而是输出 它存储在内部的值。我们可以创建两个浮点张量<code>node1</code> 和<code>node2</code>如下：</p>
<pre><code>node1 = tf.constant(3.0, dtype=tf.float32)
node2 = tf.constant(4.0) # also tf.float32 implicitly
print(node1, node2)
</code></pre><p>最后的打印声明产生</p>
<pre><code>Tensor(&quot;Const:0&quot;, shape=(), dtype=float32) Tensor(&quot;Const_1:0&quot;, shape=(), dtype=float32)
</code></pre><p>请注意，打印节点时不会输出<code>3.0</code>和<code>4.0</code>的值 可能期望。相反，它们是在评估时会产生3.0的节点 和4.0，分别。为了实际评估节点，我们必须运行<br>会话内的计算图。会话封装了控件和 TensorFlow运行时的状态。</p>
<p>以下代码创建一个<code>Session</code>对象，然后调用其<code>run</code>方法 运行足够的计算图来评估<code>node1</code>和<code>node2</code>。通过 在会话中运行计算图如下：</p>
<pre><code>sess = tf.Session()
print(sess.run([node1, node2]))
</code></pre><p>我们看到了3.0和4.0的预期值：</p>
<pre><code>[3.0, 4.0]
</code></pre><p>通过将<code>Tensor</code>节点组合起来，可以构建更复杂的计算 操作（操作也是节点）。例如，我们可以添加我们的两个 常量节点，并产生一个新的图形如下：</p>
<pre><code>from __future__ import print_function
node3 = tf.add(node1, node2)
print(&quot;node3:&quot;, node3)
print(&quot;sess.run(node3):&quot;, sess.run(node3))
</code></pre><p>最后两个打印语句产生</p>
<pre><code>node3: Tensor(&quot;Add:0&quot;, shape=(), dtype=float32)
sess.run(node3): 7.0
</code></pre><p>TensorFlow提供了一个名为TensorBoard的实用程序，可以显示图片 计算图。这里是一个截图显示如何TensorBoard 可视化图形：</p>
<p><img src="https://www.tensorflow.org/images/getting_started_add.png" alt="TensorBoard
screenshot"></p>
<p>就目前而言，这张图并不特别有趣，因为它总是如此 产生一个不变的结果。图形可以被参数化来接受外部的 输入，称为占位符。占位符是提供一个的承诺 稍后的价值。</p>
<pre><code>a = tf.placeholder(tf.float32)
b = tf.placeholder(tf.float32)
adder_node = a + b  # + provides a shortcut for tf.add(a, b)
</code></pre><p>前面的三行有点像我们的函数或者lambda 定义两个输入参数（a和b），然后对它们进行操作。我们可以 使用feed_dict参数来评估具有多个输入的图形<br>运行方法 将具体值提供给占位符：</p>
<pre><code>print(sess.run(adder_node, {a: 3, b: 4.5}))
print(sess.run(adder_node, {a: [1, 3], b: [2, 4]}))
</code></pre><p>导致输出</p>
<pre><code>7.5
[ 3.  7.]
</code></pre><p>在TensorBoard中，图形如下所示：</p>
<p><img src="https://www.tensorflow.org/images/getting_started_adder.png" alt="TensorBoard
screenshot"></p>
<p>我们可以通过添加另一个操作来使计算图更加复杂。 例如，</p>
<pre><code>add_and_triple = adder_node * 3.
print(sess.run(add_and_triple, {a: 3, b: 4.5}))
</code></pre><p>产生输出</p>
<pre><code>22.5
</code></pre><p>在TensorBoard中，上面的计算图如下所示：</p>
<p><img src="https://www.tensorflow.org/images/getting_started_triple.png" alt="TensorBoard
screenshot"></p>
<p>在机器学习中，我们通常需要一个可以任意使用的模型 输入，比如上面的那个。为了使模型可训练，我们需要能够 修改图形以获得具有相同输入的新输出。变量允许<br>我们将可训练参数添加到图形中。他们是用一种类型和 初始值：</p>
<pre><code>W = tf.Variable([.3], dtype=tf.float32)
b = tf.Variable([-.3], dtype=tf.float32)
x = tf.placeholder(tf.float32)
linear_model = W*x + b
</code></pre><p>当您调用<code>tf.constant</code>时，常量被初始化，并且它们的值永远不会被初始化 更改。相比之下，当您调用<code>tf.Variable</code>时，变量不会被初始化。<br>要初始化TensorFlow程序中的所有变量，必须明确 调用一个特殊的操作如下：</p>
<pre><code>init = tf.global_variables_initializer()
sess.run(init)
</code></pre><p>实现<code>init</code>是TensorFlow子图的一个句柄 初始化所有的全局变量。直到我们称之为<code>sess.run</code>，变量 未初始化。</p>
<p>由于<code>x</code>是一个占位符，我们可以评估<code>linear_model</code>的几个值 <code>x</code>同时如下：</p>
<pre><code>print(sess.run(linear_model, {x: [1, 2, 3, 4]}))
</code></pre><p>产生输出</p>
<pre><code>[ 0.          0.30000001  0.60000002  0.90000004]
</code></pre><p>我们已经创建了一个模型，但我们不知道它有多好。评估 模型训练数据，我们需要一个<code>y</code>占位符来提供所需的值， 我们需要写一个损失函数。</p>
<p>亏损功能衡量的是多远 目前的模型是从提供的数据。我们将使用一个标准的损失模型 线性回归，它将电流之间的三角形的平方相加 模型和提供的数据。<br><code>linear_model - y</code>创建一个向量 元素是相应示例的错误增量。我们称之为<code>tf.square</code><br>平方那个错误。然后，我们总结所有的平方误差来创建一个标量 使用<code>tf.reduce_sum</code>提取所有示例的错误：</p>
<pre><code>y = tf.placeholder(tf.float32)
squared_deltas = tf.square(linear_model - y)
loss = tf.reduce_sum(squared_deltas)
print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))
</code></pre><p>产生损失价值</p>
<pre><code>23.66
</code></pre><p>我们可以通过将<code>W</code>和<code>b</code>的值重新分配给 -1和1的完美值。一个变量被初始化为提供的值<br><code>tf.Variable</code>，但可以使用<code>tf.assign</code>等操作进行更改。例如， <code>W=-1</code>和<code>b=1</code>是我们模型的最佳参数。我们可以改变<code>W</code>和<br><code>b</code>相应的：</p>
<pre><code>fixW = tf.assign(W, [-1.])
fixb = tf.assign(b, [1.])
sess.run([fixW, fixb])
print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))
</code></pre><p>最后的印刷品显示现在的损失是零。</p>
<pre><code>0.0
</code></pre><p>我们猜测<code>W</code>和<code>b</code>的“完美”价值，但是机器的全部重点 学习是自动找到正确的模型参数。我们将展示 如何在下一节中做到这一点。</p>
<h2><span id="tftrain-api">tf.train API</span></h2><p>机器学习的完整讨论超出了本教程的范围。 但是，TensorFlow提供的优化器可以缓慢地改变每个变量 为了尽量减少损失的功能。最简单的优化器是渐变的<br>血统。它根据的大小修改每个变量 与该变量有关的损失的导数。一般来说，计算符号 衍生品手工是乏味和容易出错。因此，TensorFlow可以<br>自动产生的衍生物只给出了使用模型的描述 功能<code>tf.gradients</code>。为了简单起见，优化器通常会这样做 为你。例如，</p>
<pre><code>optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss)



sess.run(init) # reset values to incorrect defaults.
for i in range(1000):
  sess.run(train, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})

print(sess.run([W, b]))
</code></pre><p>导致最终的模型参数：</p>
<pre><code>[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]
</code></pre><p>现在我们已经完成了机器学习！虽然这个简单的线性 回归模型不需要太多的TensorFlow核心代码，比较复杂<br>将数据提供给模型的模型和方法需要更多的代码。从而， TensorFlow为常见的模式，结构， 和功能。我们将学习如何使用这些抽象中的一些 下一节。</p>
<h3><span id="完整的程序">完整的程序</span></h3><p>完成的可训练线性回归模型如下所示：</p>
<pre><code>import tensorflow as tf

# Model parameters
W = tf.Variable([.3], dtype=tf.float32)
b = tf.Variable([-.3], dtype=tf.float32)
# Model input and output
x = tf.placeholder(tf.float32)
linear_model = W*x + b
y = tf.placeholder(tf.float32)

# loss
loss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares
# optimizer
optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss)

# training data
x_train = [1, 2, 3, 4]
y_train = [0, -1, -2, -3]
# training loop
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init) # reset values to wrong
for i in range(1000):
  sess.run(train, {x: x_train, y: y_train})

# evaluate training accuracy
curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})
print(&quot;W: %s b: %s loss: %s&quot;%(curr_W, curr_b, curr_loss))
</code></pre><p>运行时产生</p>
<pre><code>W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11
</code></pre><p>请注意，损失是非常小的数字（非常接近零）。如果你跑步 这个程序，你的损失可能与上述损失不完全一样 因为模型是用伪随机值初始化的。</p>
<p>这个更复杂的程序仍然可以在TensorBoard中可视化 <img src="https://www.tensorflow.org/images/getting_started_final.png" alt="TensorBoard final model
visualization"></p>
<h2><span id="tfestimator"><code>tf.estimator</code></span></h2><p><code>tf.estimator</code>是一个高级的TensorFlow库，可以简化 机器学习机制包括以下内容：</p>
<p>运行训练循环 运行评估循环 管理数据集</p>
<p>tf.estimator定义了许多常见的模型。</p>
<h3><span id="基本用法">基本用法</span></h3><p>注意线性回归程序变得简单多了 <code>tf.estimator</code>：</p>
<pre><code># NumPy is often used to load, manipulate and preprocess data.
import numpy as np
import tensorflow as tf

# Declare list of features. We only have one numeric feature. There are many
# other types of columns that are more complicated and useful.
feature_columns = [tf.feature_column.numeric_column(&quot;x&quot;, shape=[1])]

# An estimator is the front end to invoke training (fitting) and evaluation
# (inference). There are many predefined types like linear regression,
# linear classification, and many neural network classifiers and regressors.
# The following code provides an estimator that does linear regression.
estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)

# TensorFlow provides many helper methods to read and set up data sets.
# Here we use two data sets: one for training and one for evaluation
# We have to tell the function how many batches
# of data (num_epochs) we want and how big each batch should be.
x_train = np.array([1., 2., 3., 4.])
y_train = np.array([0., -1., -2., -3.])
x_eval = np.array([2., 5., 8., 1.])
y_eval = np.array([-1.01, -4.1, -7, 0.])
input_fn = tf.estimator.inputs.numpy_input_fn(
    {&quot;x&quot;: x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)
train_input_fn = tf.estimator.inputs.numpy_input_fn(
    {&quot;x&quot;: x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)
eval_input_fn = tf.estimator.inputs.numpy_input_fn(
    {&quot;x&quot;: x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)

# We can invoke 1000 training steps by invoking the  method and passing the
# training data set.
estimator.train(input_fn=input_fn, steps=1000)

# Here we evaluate how well our model did.
train_metrics = estimator.evaluate(input_fn=train_input_fn)
eval_metrics = estimator.evaluate(input_fn=eval_input_fn)
print(&quot;train metrics: %r&quot;% train_metrics)
print(&quot;eval metrics: %r&quot;% eval_metrics)
</code></pre><p>运行时，会产生类似的东西</p>
<pre><code>train metrics: {&apos;average_loss&apos;: 1.4833182e-08, &apos;global_step&apos;: 1000, &apos;loss&apos;: 5.9332727e-08}
eval metrics: {&apos;average_loss&apos;: 0.0025353201, &apos;global_step&apos;: 1000, &apos;loss&apos;: 0.01014128}
</code></pre><p>请注意我们的评估数据是如何有更高的损失，但仍然接近于零。 这意味着我们正在正确地学习。</p>
<h3><span id="自定义模型">自定义模型</span></h3><p><code>tf.estimator</code>不会将您锁定在预定义的型号中。假设我们 想要创建一个自定义模型，而不是内置到TensorFlow中。我们仍然可以<br>保留数据集，喂养，培训等的高层次抽象 <code>tf.estimator</code>。为了说明，我们将展示如何实现我们自己的<br>等同于<code>LinearRegressor</code>的模型使用我们的较低水平的知识 TensorFlow API。</p>
<p>要定义一个适用于<code>tf.estimator</code>的自定义模型，我们需要使用 <code>tf.estimator.Estimator</code>。<br><code>tf.estimator.LinearRegressor</code>其实是 <code>tf.estimator.Estimator</code>的一个子类。而不是分类<br><code>Estimator</code>，我们只是简单地提供<code>Estimator</code>功能<code>model_fn</code>，告诉 <code>tf.estimator</code>如何评估预测，训练步骤和<br>失利。代码如下：</p>
<pre><code>import numpy as np
import tensorflow as tf

# Declare list of features, we only have one real-valued feature
def model_fn(features, labels, mode):
  # Build a linear model and predict values
  W = tf.get_variable(&quot;W&quot;, [1], dtype=tf.float64)
  b = tf.get_variable(&quot;b&quot;, [1], dtype=tf.float64)
  y = W*features[&apos;x&apos;] + b
  # Loss sub-graph
  loss = tf.reduce_sum(tf.square(y - labels))
  # Training sub-graph
  global_step = tf.train.get_global_step()
  optimizer = tf.train.GradientDescentOptimizer(0.01)
  train = tf.group(optimizer.minimize(loss),
                   tf.assign_add(global_step, 1))
  # EstimatorSpec connects subgraphs we built to the
  # appropriate functionality.
  return tf.estimator.EstimatorSpec(
      mode=mode,
      predictions=y,
      loss=loss,
      train_op=train)

estimator = tf.estimator.Estimator(model_fn=model_fn)
# define our data sets
x_train = np.array([1., 2., 3., 4.])
y_train = np.array([0., -1., -2., -3.])
x_eval = np.array([2., 5., 8., 1.])
y_eval = np.array([-1.01, -4.1, -7., 0.])
input_fn = tf.estimator.inputs.numpy_input_fn(
    {&quot;x&quot;: x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)
train_input_fn = tf.estimator.inputs.numpy_input_fn(
    {&quot;x&quot;: x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)
eval_input_fn = tf.estimator.inputs.numpy_input_fn(
    {&quot;x&quot;: x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)

# train
estimator.train(input_fn=input_fn, steps=1000)
# Here we evaluate how well our model did.
train_metrics = estimator.evaluate(input_fn=train_input_fn)
eval_metrics = estimator.evaluate(input_fn=eval_input_fn)
print(&quot;train metrics: %r&quot;% train_metrics)
print(&quot;eval metrics: %r&quot;% eval_metrics)
</code></pre><p>运行时产生</p>
<pre><code>train metrics: {&apos;loss&apos;: 1.227995e-11, &apos;global_step&apos;: 1000}
eval metrics: {&apos;loss&apos;: 0.01010036, &apos;global_step&apos;: 1000}
</code></pre><p>注意习惯<code>model_fn()</code>功能的内容是如何非常相似的 到我们的低级API的手动模型训练循环。</p>
<h2><span id="下一步">下一步</span></h2><p>现在您已经掌握了TensorFlow的基础知识。我们有几个 更多的教程，你可以看看了解更多。如果你是一个初学者 机器学习参见MNIST初学者，<br>否则请参阅Deep MNIST专家。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/faq/" title="经常问的问题" itemprop="url">经常问的问题</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="经常问的问题">经常问的问题</span></h1><p>本文档提供了有关某些常见问题的答案 TensorFlow。如果你有一个这里没有涉及的问题，你可能会找到一个 回答一个TensorFlow社区资源。</p>
<h2><span id="功能和兼容性">功能和兼容性</span></h2><h4><span id="我可以在多台电脑上运行分布式培训吗">我可以在多台电脑上运行分布式培训吗？</span></h4><p>是! TensorFlow获得了 支持分布式计算 版本0.8。 TensorFlow现在支持一个或多个设备（CPU和GPU） 更多的电脑。</p>
<h4><span id="tensorflow与python-3一起工作吗">TensorFlow与Python 3一起工作吗？</span></h4><p>从0.6.0发布时间（2015年12月初）开始，我们支持Python 3.3+。</p>
<h2><span id="建立张量流图">建立张量流图</span></h2><p>另见 关于建筑图的API文档。</p>
<h4><span id="为什么c-tfmatmula-b不立即执行矩阵乘法">为什么<code>c = tf.matmul(a, b)</code>不立即执行矩阵乘法？</span></h4><p>在TensorFlow Python API中，<code>a</code>，<code>b</code>和<code>c</code>分别是 <code>tf.Tensor</code>物体。一个<code>Tensor</code>的对象是<br>一个操作结果的符号句柄，但实际上并不包含该句柄 操作输出的值。相反，TensorFlow鼓励用户构建 把复杂的表达式（比如整个神经网络和它的梯度）表示为<br>一个数据流图。然后卸载整个数据流图的计算 （或其子图）添加到TensorFlow中 <code>tf.Session</code>，它能够执行 整个计算比执行操作更有效率<br>一个接一个。</p>
<h4><span id="如何命名设备">如何命名设备？</span></h4><p>支持的设备名称为CPU的<code>&quot;/device:CPU:0&quot;</code>（或<code>&quot;/cpu:0&quot;</code>）<br>设备以及用于第i个GPU设备的<code>&quot;/device:GPU:i&quot;</code>（或<code>&quot;/gpu:i&quot;</code>）。</p>
<h4><span id="如何在特定设备上进行操作">如何在特定设备上进行操作？</span></h4><p>要在设备上放置一组操作，请在一个设备中创建它们 <code>with tf.device(name):</code>上下文。看到 如何在文件上<br>使用GPU与TensorFlow的细节如何 TensorFlow将操作分配给设备， CIFAR-10教程中的示例模型 使用多个GPU。</p>
<h2><span id="运行一个tensorflow计算">运行一个TensorFlow计算</span></h2><p>另见 关于运行图形的API文档。</p>
<h4><span id="什么是喂养和占位符交易">什么是喂养和占位符交易？</span></h4><p>Feeding是TensorFlow Session API中的一种机制，可以让您 在运行时替换一个或多个张量的不同值。 <code>feed_dict</code><br>对<code>tf.Session.run</code>的说法是一个 将<code>tf.Tensor</code>对象映射到的字典 numpy数组（和一些其他类型），将被用作这些值<br>张量在执行一个步骤。</p>
<p>通常情况下，你有一定的张量，如投入，总是会被喂食。该 <code>tf.placeholder</code> op允许你 定义必须被馈送的张量，并且可选地允许你约束<br>他们的形状也是如此。看到了 初学者的MNIST教程 举例说明如何使用占位符和喂食来提供训练数据 为神经网络。</p>
<h4><span id="sessionrun和tensoreval有何区别"><code>Session.run()</code>和<code>Tensor.eval()</code>有何区别？</span></h4><p>如果<code>t</code>是<code>tf.Tensor</code>的对象， <code>tf.Tensor.eval</code>是速记 <code>tf.Session.run</code>（其中<code>sess</code>是<br>目前<code>tf.get_default_session</code>。该 以下两段代码片段是等价的：</p>
<pre><code># Using `Session.run()`.
sess = tf.Session()
c = tf.constant(5.0)
print(sess.run(c))

# Using `Tensor.eval()`.
c = tf.constant(5.0)
with tf.Session():
  print(c.eval())
</code></pre><p>在第二个例子中，会话充当一个 上下文经理， 它具有将其安装为默认会话的效果 <code>with</code>模块。上下文管理器的方法可以导致更简洁的代码<br>简单用例（如单元测试）;如果你的代码处理多个图表和 会话，明确的呼叫可能更直接 <code>Session.run()</code>。</p>
<h4><span id="会议有一生吗中间张量怎么样">会议有一生吗？中间张量怎么样？</span></h4><p>会话可以拥有自己的资源，比如 <code>tf.Variable</code>， <code>tf.QueueBase</code>，和 <code>tf.ReaderBase</code>;而这些资源可以使用<br>大量的记忆。这些资源（和相关的内存）是 会议结束后通过电话发布 <code>tf.Session.close</code>。</p>
<p>作为呼叫的一部分创建的中间张量 <code>Session.run()</code>将在或之前被释放 通话结束。</p>
<h4><span id="运行时并行化图的执行部分">运行时并行化图的执行部分？</span></h4><p>TensorFlow运行时间跨多种不同的并行图表执行 尺寸：</p>
<p>单独的操作具有并行的实现，使用a中的多个核心   CPU或GPU中的多个线程。 TensorFlow图中的独立节点可以并行运行多个<br>设备，这使得加快成为可能   CIFAR-10使用多个GPU进行培训。 会话API允许多个并发步骤（即呼叫   <code>tf.Session.run</code>并联。这个<br>如果单个步骤不使用，则可以使运行时获得更高的吞吐量   计算机中的所有资源。</p>
<h4><span id="tensorflow支持哪些客户端语言">TensorFlow支持哪些客户端语言？</span></h4><p>TensorFlow旨在支持多种客户端语言。 目前，支持最好的客户端语言是Python。的实验接口 执行和构建图也可用于 C ++，Java和Go。</p>
<p>TensorFlow也有一个 基于C的客户端API 帮助构建对更多客户端语言的支持。我们邀请新的贡献 语言绑定。</p>
<p>由TensorFlow维护人员支持的C API之上的开源社区创建和支持的各种其他语言（如C＃，Julia，Ruby和Scala）的绑定。</p>
<h4><span id="tensorflow是否使用我的机器上可用的所有设备gpu和cpu">TensorFlow是否使用我的机器上可用的所有设备（GPU和CPU）？</span></h4><p>TensorFlow支持多个GPU和CPU。请参阅关于如何使用的文档 使用GPU与TensorFlow的细节如何 TensorFlow将操作分配给设备，<br>CIFAR-10教程中的示例模型 使用多个GPU。</p>
<p>请注意，TensorFlow只使用计算能力更强的GPU设备 比3.5。</p>
<h4><span id="为什么sessionrun在使用阅读器或队列时会挂起">为什么<code>Session.run()</code>在使用阅读器或队列时会挂起？</span></h4><p><code>tf.ReaderBase</code>和 <code>tf.QueueBase</code>类提供了特殊的操作 可以阻塞，直到输入（或有界队列中的空闲空间）变成为止<br>可用。这些操作允许您构建复杂的 输入管道，在做的成本 TensorFlow计算有点复杂。请参阅how-to文档 对于 运用<br><code>QueueRunner</code>对象驱动队列和阅读器 有关如何使用它们的更多信息。</p>
<h2><span id="变量">变量</span></h2><p>另请参阅有关变量和方法的how-to文档 变量的API文档。</p>
<h4><span id="什么是一个变量的生命周期">什么是一个变量的生命周期？</span></h4><p>首次运行时会创建一个变量 <code>tf.Variable.initializer</code> 在会话中为该变量操作。那个时候被破坏了 <code>tf.Session.close</code>。</p>
<h4><span id="变量如何被同时访问">变量如何被同时访问？</span></h4><p>变量允许并发的读写操作。从a中读取的值 变量可能会改变，如果它同时更新。默认情况下，并发 对变量的赋值操作允许运行而不互斥。<br>将<code>use_locking=True</code>分配给变量时要获取锁定 <code>tf.Variable.assign</code>。</p>
<h2><span id="张量形状">张量形状</span></h2><p>另见 <code>tf.TensorShape</code>。</p>
<h4><span id="我如何确定python中张量的形状">我如何确定Python中张量的形状？</span></h4><p>在TensorFlow中，张量具有静态（推断）形状和动态（真实） 形状。静态形状可以使用 <code>tf.Tensor.get_shape</code><br>方法：这个形状是从用来创建的操作中推断出来的 张量，可能是 部分完成。如果是静态的 <code>Tensor</code> <code>t</code>的动态形状可以是<br>通过评估<code>tf.shape(t)</code>来确定。</p>
<h4><span id="xset_shape和x-tfreshapex有何区别"><code>x.set_shape()</code>和<code>x = tf.reshape(x)</code>有何区别？</span></h4><p><code>tf.Tensor.set_shape</code>方法更新 <code>Tensor</code>物体的静态形状，通常用于提供 当不能直接推断出附加的形状信息。它不是<br>改变张量的动态形状。</p>
<p><code>tf.reshape</code>操作创建 一个具有不同动态形状的新张量。</p>
<h4><span id="我如何构建一个可用于批量变量的图形">我如何构建一个可用于批量变量的图形？</span></h4><p>建立一个可变批处理大小的图形常常是有用的 例如，以便相同的代码可以用于（小型）批量训练 单实例推断。结果图可以 保存为协议缓冲区 和 导入另一个程序。</p>
<p>在构建可变大小的图时，最重要的是记住不是 将批量大小编码为Python常量，而是使用符号 <code>Tensor</code>来代表它。以下提示可能会有用：</p>
<p>使用<code>batch_size = tf.shape(input)[0]</code>   从称为<code>Tensor</code>的<code>input</code>中提取批量维度，并将其存储<br>称为<code>Tensor</code>的<code>batch_size</code>。 改用<code>tf.reduce_mean</code>   <code>tf.reduce_sum(...) /
batch_size</code>。</p>
<h2><span id="tensorboard">TensorBoard</span></h2><h4><span id="我如何可视化张量流图">我如何可视化张量流图？</span></h4><p>看图可视化教程。</p>
<h4><span id="向tensorboard发送数据最简单的方法是什么">向TensorBoard发送数据最简单的方法是什么？</span></h4><p>将总结操作添加到您的TensorFlow图表中，然后编写 这些摘要到一个日志目录。然后，启动TensorBoard使用</p>
<pre><code>python tensorflow/tensorboard/tensorboard.py --logdir=path/to/log-directory
</code></pre><p>有关更多详细信息，请参阅 摘要和TensorBoard教程。</p>
<h4><span id="每次启动tensorboard我都会得到一个网络安全弹出窗口">每次启动TensorBoard，我都会得到一个网络安全弹出窗口！</span></h4><p>您可以将TensorBoard更改为本地主机而不是“0.0.0.0” 标志–host = localhost。这应该消除任何安全警告。</p>
<h2><span id="扩展tensorflow">扩展TensorFlow</span></h2><p>请参阅如何使用文档 添加一个新的操作到TensorFlow。</p>
<h4><span id="我的数据是自定义格式-我如何使用tensorflow读取它">我的数据是自定义格式。我如何使用TensorFlow读取它？</span></h4><p>以自定义格式处理数据有三个主要选项。</p>
<p>最简单的选择是编写用Python转换数据的解析代码 成一个numpy数组。然后用<code>tf.data.Dataset.from_tensor_slices</code>来<br>从内存数据创建输入管道。</p>
<p>如果您的数据不适合内存，请尝试在数据集中进行解析 管道。从适当的文件阅读器开始，像<br><code>tf.data.TextLineDataset</code>。然后通过映射转换数据集 映射适当的操作。<br>优先使用预定义的TensorFlow操作，如<code>tf.decode_raw</code>，<br><code>tf.decode_csv</code>，<code>tf.parse_example</code>或<code>tf.image.decode_png</code>。</p>
<p>如果您的数据不能通过内置的TensorFlow操作轻松解析， 考虑将其脱机转换为易于解析的格式 作为$<br>{tf.python_io.TFRecordWriter $ <code>TFRecord</code>}格式。</p>
<p>定制解析行为的更有效的方法是 添加一个用C ++编写的解析你的 数据格式。处理新数据格式的指南已经 有关执行此操作的步骤的更多信息。</p>
<h2><span id="杂">杂</span></h2><h4><span id="什么是tensorflow的编码风格约定">什么是TensorFlow的编码风格约定？</span></h4><p>TensorFlow Python API遵循 PEP8约定 特别是，我们使用<code>CamelCase</code>名称作为类别，<code>snake_case</code>名称<br>功能，方法和属性。我们也坚持了 Google Python风格指南。</p>
<p>TensorFlow C ++代码库遵守 Google C ++风格指南</p>
<p>（*有一个例外：我们使用2空格缩进而不是4空格 缩进。）</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/estimators/" title="估计" itemprop="url">估计</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="估计">估计</span></h1><p>本文介绍了Estimators - 高级TensorFlow API大大简化了机器学习编程。估算器封装 采取以下行动：</p>
<p>训练 评测 预测 出口服务</p>
<p>您可以使用我们提供的预先制作的估算器或者编写您的 自己的定制估算器。所有估算器 - 无论是预制还是定制 - 都是<br>基于<code>tf.estimator.Estimator</code>等级的课程。</p>
<p>注意：TensorFlow还包括一个已弃用的<code>Estimator</code>类 <code>tf.contrib.learn.Estimator</code>，你不应该使用。</p>
<h2><span id="估算的优点">估算的优点</span></h2><p>估算人员提供以下好处：</p>
<p>您可以在本地主机上运行基于估算器的模型     分布式多服务器环境而不改变你的模型。     此外，您可以在CPU，GPU和GPU上运行基于估算器的模型，<br>或TPU而无需重新编码模型。 估算器简化了模型开发人员之间的共享实现。 您可以使用高级直观的代码开发最先进的模型，<br>简而言之，用Estimators创建模型通常要容易得多     比使用低级别的TensorFlow API。 估算器本身是建立在tf.layers上的，<br>简化了定制。 估计者为你建立图表。换句话说，你不需要     建立图表。 估算人员提供一个安全的分布式培训循环，控制如何和     何时： 建立图表<br>初始化变量 开始排队 处理异常 创建检查点文件并从失败中恢复 保存TensorBoard的摘要</p>
<p>用Estimators编写应用程序时，必须分开数据输入 从模型的管道。这种分离简化了实验 不同的数据集。</p>
<h2><span id="预先估算的">预先估算的</span></h2><p>预制估算器使您能够在更高的概念层面上工作 比基本的TensorFlow APIs。你不必再担心创建 由Estimators处理所有的计算图或会话<br>“水暖”给你。也就是说，预先制定的估算人员可以创建和管理 <code>Graph</code>和<code>Session</code>物件。此外， 预先制作的估算器可以让你通过不同的模型架构进行实验<br>只做最小的代码更改。 <code>DNNClassifier</code>， 例如，是预先制作的Estimator类，其训练分类模型 通过密集的前馈神经网络。</p>
<h3><span id="预先制定的估算人员计划的结构">预先制定的估算人员计划的结构</span></h3><p>一个依靠预先制定的估算器的TensorFlow程序通常包括 以下四个步骤：</p>
<p>编写一个或多个数据集导入功能。例如，你可能会     创建一个功能导入训练集和另一个功能     导入测试集。每个数据集导入功能必须返回两个     对象：<br>一个字典，其中的键是功能名称和     值是包含相应的Tensors（或SparseTensors）     特征数据 包含一个或多个标签的张量<br>例如，以下代码说明了基本框架 一个输入功能： def input_fn（dataset）：    …＃操作数据集，提取功能名称和标签<br>返回feature_dict，标签 （有关完整的详细信息，请参阅导入数据。） 定义特征列。每个<code>tf.feature_column</code><br>标识功能名称，类型和任何输入预处理。     例如，以下片段创建三个功能     保存整数或浮点数据的列。前两个     特征列只是标识特征的名称和类型。该<br>第三个特性列还指定了程序将调用的lambda     调整原始数据： ＃定义三个数字特征列。 人口=<br>tf.feature_column.numeric_column（’人口’） crime_rate =<br>tf.feature_column.numeric_column（’crime_rate’） median_education =<br>tf.feature_column.numeric_column（’median_education’，<br>normalizer_fn =’lambda x：x - global_education_mean’） 实例化相关的预制估算器。例如，在这里<br>预先制作的估算器<code>LinearClassifier</code>的样品实例： ＃实例化一个估计器，传递特征列。 estimator =<br>tf.estimator.Estimator.LinearClassifier（     feature_columns =<br>[population，crime_rate，median_education]，     ） 调用培训，评估或推理方法。<br>例如，所有估算器都提供<code>train</code>方法，用于训练模型。 ＃my_training_set是在步骤1中创建的函数<br>estimator.train（input_fn = my_training_set，steps = 2000）</p>
<h3><span id="预先估算的好处">预先估算的好处</span></h3><p>预制估算器编码最佳实践，提供以下好处：</p>
<p>确定计算的不同部分的最佳实践     图应该运行，在一台机器上或者一台机器上实施策略     簇。 事件（摘要）写作的最佳实践和普遍有用的     摘要。</p>
<p>如果您不使用预先制定的估算器，则必须执行上述操作 特点你自己。</p>
<h2><span id="自定义估算器">自定义估算器</span></h2><p>每个估算器的核心 - 无论是预制还是定制 - 都是它的核心 模型函数，这是一种为训练建立图形的方法， 评估和预测。当您使用预先制作的估算器时，<br>其他人已经实现了模型功能。依靠时 在自定义的估算器上，您必须自己编写模型函数。一个 伴侣文件 解释如何编写模型函数。</p>
<h2><span id="推荐工作流程">推荐工作流程</span></h2><p>我们推荐以下工作流程：</p>
<p>假设存在合适的预制估算器，请使用它来构建您的估算器     第一个模型，并使用其结果来建立基线。 建立和测试你的整个管道，包括完整性和<br>用这个预先制作的估算器，您的数据的可靠性。 如果合适的替代预制估算器可用，则运行     实验来确定哪个预先制作的Estimator产生的<br>最好的结果。 可能通过构建您自己的自定义估算器来进一步改进您的模型。</p>
<h2><span id="从keras模型创建估计量">从Keras模型创建估计量</span></h2><p>您可以将现有的Keras模型转换为Estimators。这样做可以使您的Keras 模型来访问Estimator的优势，如分布式培训。呼叫<br>如在<code>tf.keras.estimator.model_to_estimator</code>中 以下示例：</p>
<pre><code># Instantiate a Keras inception v3 model.
keras_inception_v3 = tf.keras.applications.inception_v3.InceptionV3(weights=None)
# Compile model with the optimizer, loss, and metrics you&apos;d like to train with.
keras_inception_v3.compile(optimizer=tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9),
                          loss=&apos;categorical_crossentropy&apos;,
                          metric=&apos;accuracy&apos;)
# Create an Estimator from the compiled Keras model.
est_inception_v3 = tf.keras.estimator.model_to_estimator(keras_model=keras_inception_v3)
# Treat the derived Estimator as you would any other Estimator. For example,
# the following derived Estimator calls the train method:
est_inception_v3.train(input_fn=my_training_set, steps=2000)
</code></pre><p>有关更多详细信息，请参阅文档 <code>tf.keras.estimator.model_to_estimator</code>。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/estimator/" title="tf.estimator快速入门" itemprop="url">tf.estimator快速入门</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="tfestimator快速入门">tf.estimator快速入门</span></h1><p>TensorFlow的高级机器学习API（tf.estimator）使其变得容易 配置，训练和评估各种机器学习模型。在这<br>教程，你将使用tf.estimator构造一个 神经网络 分类器并在其上进行训练 虹膜数据集 根据萼片/花瓣几何学预测花种。你会写代码 执行以下五个步骤：</p>
<p>将包含虹膜训练/测试数据的CSV加载到TensorFlow <code>Dataset</code>中 构建一个神经网络分类器 使用训练数据训练模型 评估模型的准确性 分类新样品</p>
<p>注意：请记住在您的机器上安装TensorFlow 在开始本教程之前。</p>
<h2><span id="完整的神经网络源代码">完整的神经网络源代码</span></h2><p>以下是神经网络分类器的完整代码：</p>
<pre><code>from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
from six.moves.urllib.request import urlopen

import numpy as np
import tensorflow as tf

# Data sets
IRIS_TRAINING = &quot;iris_training.csv&quot;
IRIS_TRAINING_URL = &quot;http://download.tensorflow.org/data/iris_training.csv&quot;

IRIS_TEST = &quot;iris_test.csv&quot;
IRIS_TEST_URL = &quot;http://download.tensorflow.org/data/iris_test.csv&quot;

def main():
  # If the training and test sets aren&apos;t stored locally, download them.
  if not os.path.exists(IRIS_TRAINING):
    raw = urlopen(IRIS_TRAINING_URL).read()
    with open(IRIS_TRAINING, &quot;wb&quot;) as f:
      f.write(raw)

  if not os.path.exists(IRIS_TEST):
    raw = urlopen(IRIS_TEST_URL).read()
    with open(IRIS_TEST, &quot;wb&quot;) as f:
      f.write(raw)

  # Load datasets.
  training_set = tf.contrib.learn.datasets.base.load_csv_with_header(
      filename=IRIS_TRAINING,
      target_dtype=np.int,
      features_dtype=np.float32)
  test_set = tf.contrib.learn.datasets.base.load_csv_with_header(
      filename=IRIS_TEST,
      target_dtype=np.int,
      features_dtype=np.float32)

  # Specify that all features have real-value data
  feature_columns = [tf.feature_column.numeric_column(&quot;x&quot;, shape=[4])]

  # Build 3 layer DNN with 10, 20, 10 units respectively.
  classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,
                                          hidden_units=[10, 20, 10],
                                          n_classes=3,
                                          model_dir=&quot;/tmp/iris_model&quot;)
  # Define the training inputs
  train_input_fn = tf.estimator.inputs.numpy_input_fn(
      x={&quot;x&quot;: np.array(training_set.data)},
      y=np.array(training_set.target),
      num_epochs=None,
      shuffle=True)

  # Train model.
  classifier.train(input_fn=train_input_fn, steps=2000)

  # Define the test inputs
  test_input_fn = tf.estimator.inputs.numpy_input_fn(
      x={&quot;x&quot;: np.array(test_set.data)},
      y=np.array(test_set.target),
      num_epochs=1,
      shuffle=False)

  # Evaluate accuracy.
  accuracy_score = classifier.evaluate(input_fn=test_input_fn)[&quot;accuracy&quot;]

  print(&quot;\nTest Accuracy: {0:f}\n&quot;.format(accuracy_score))

  # Classify two new flower samples.
  new_samples = np.array(
      [[6.4, 3.2, 4.5, 1.5],
       [5.8, 3.1, 5.0, 1.7]], dtype=np.float32)
  predict_input_fn = tf.estimator.inputs.numpy_input_fn(
      x={&quot;x&quot;: new_samples},
      num_epochs=1,
      shuffle=False)

  predictions = list(classifier.predict(input_fn=predict_input_fn))
  predicted_classes = [p[&quot;classes&quot;] for p in predictions]

  print(
      &quot;New Samples, Class Predictions:    {}\n&quot;
      .format(predicted_classes))

if __name__ == &quot;__main__&quot;:
    main()
</code></pre><p>以下部分详细介绍了代码。</p>
<h2><span id="将iris-csv数据加载到tensorflow">将Iris CSV数据加载到TensorFlow</span></h2><p>虹膜数据集包含 150行数据，包括来自三个相关虹膜种类的每一个的50个样本： Iris setosa，Iris virginica，以及杂色鸢尾花。</p>
<p><img src="https://www.tensorflow.org/images/iris_three_species.jpg" alt="Petal geometry compared for three iris species: Iris setosa, Iris virginica,
and Iris
versicolor">从左到右，<br>Iris setosa（by Radomil，CC BY-SA 3.0）， 鸢尾花（by Dlanglois，CC BY-SA 3.0），<br>和虹膜virginica （由CC BY-SA的Frank Mayfield提供 2.0）。</p>
<p>每行包含每个花样的以下数据： 萼片长度，萼片宽度， 花瓣长度，花瓣宽度和花 种类。花种以整数表示，0表示虹膜<br>（setosa），1代表鸢尾花，2代表鸢尾花（irris virginica）。</p>
<table>
<thead>
<tr>
<th>Sepal Length</th>
<th>Sepal Width</th>
<th>Petal Length</th>
<th>Petal Width</th>
<th>Species  </th>
</tr>
</thead>
<tbody>
<tr>
<td>5.1</td>
<td>3.5</td>
<td>1.4</td>
<td>0.2</td>
<td>0  </td>
</tr>
<tr>
<td>4.9</td>
<td>3.0</td>
<td>1.4</td>
<td>0.2</td>
<td>0  </td>
</tr>
<tr>
<td>4.7</td>
<td>3.2</td>
<td>1.3</td>
<td>0.2</td>
<td>0  </td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…  </td>
</tr>
<tr>
<td>7.0</td>
<td>3.2</td>
<td>4.7</td>
<td>1.4</td>
<td>1  </td>
</tr>
<tr>
<td>6.4</td>
<td>3.2</td>
<td>4.5</td>
<td>1.5</td>
<td>1  </td>
</tr>
<tr>
<td>6.9</td>
<td>3.1</td>
<td>4.9</td>
<td>1.5</td>
<td>1  </td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…  </td>
</tr>
<tr>
<td>6.5</td>
<td>3.0</td>
<td>5.2</td>
<td>2.0</td>
<td>2  </td>
</tr>
<tr>
<td>6.2</td>
<td>3.4</td>
<td>5.4</td>
<td>2.3</td>
<td>2  </td>
</tr>
<tr>
<td>5.9</td>
<td>3.0</td>
<td>5.1</td>
<td>1.8</td>
<td>2  </td>
</tr>
</tbody>
</table>
<p>在本教程中，虹膜数据已经被随机分成两个独立的部分 CSV的：</p>
<p>120个样本的训练集     （iris_training.csv） 30个样本的测试集     （iris_test.csv）。</p>
<p>要开始，首先导入所有必要的模块，并定义在哪里 下载并存储数据集：</p>
<pre><code>from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
from six.moves.urllib.request import urlopen

import tensorflow as tf
import numpy as np

IRIS_TRAINING = &quot;iris_training.csv&quot;
IRIS_TRAINING_URL = &quot;http://download.tensorflow.org/data/iris_training.csv&quot;

IRIS_TEST = &quot;iris_test.csv&quot;
IRIS_TEST_URL = &quot;http://download.tensorflow.org/data/iris_test.csv&quot;
</code></pre><p>然后，如果训练和测试集尚未存储在本地，请下载 他们。</p>
<pre><code>if not os.path.exists(IRIS_TRAINING):
  raw = urlopen(IRIS_TRAINING_URL).read()
  with open(IRIS_TRAINING,&apos;wb&apos;) as f:
    f.write(raw)

if not os.path.exists(IRIS_TEST):
  raw = urlopen(IRIS_TEST_URL).read()
  with open(IRIS_TEST,&apos;wb&apos;) as f:
    f.write(raw)
</code></pre><p>接下来，用<code>Dataset</code>s将训练和测试集加载到<code>load_csv_with_header()</code>s中 <code>learn.datasets.base</code><br>方法在<code>load_csv_with_header()</code>中。 <code>filename</code>方法需要三个 需要的参数：</p>
<p><code>target_dtype</code>，将文件路径转换为CSV文件 <code>numpy</code>，它采取了     <code>features_dtype</code>数据类型<br>的数据集的目标值。 <code>numpy</code>，它采取了     <code>numpy</code>数据类型     数据集的特征值。</p>
<p>在这里，目标（你正在训练模型来预测的价值）是花朵 物种，这是一个从0-2的整数，所以适当的<code>np.int</code>数据类型 是<code>Dataset</code>：</p>
<pre><code># Load datasets.
training_set = tf.contrib.learn.datasets.base.load_csv_with_header(
    filename=IRIS_TRAINING,
    target_dtype=np.int,
    features_dtype=np.float32)
test_set = tf.contrib.learn.datasets.base.load_csv_with_header(
    filename=IRIS_TEST,
    target_dtype=np.int,
    features_dtype=np.float32)
</code></pre><p>在tf.contrib.learn的<code>data</code>s是 命名元组; 您可以通过<code>target</code>和<code>training_set.data</code>访问功能数据和目标值<br>领域。在这里，<code>training_set.target</code>和<code>test_set.data</code>包含此功能<br>数据和训练集的目标值分别和<code>test_set.target</code> 和<code>training_set.data</code>包含测试装置的特征数据和目标值。</p>
<p>后来，在 “将DNNClassifier安装到虹膜培训数据” 您将使用<code>training_set.target</code>和<br><code>test_set.data</code>训练你的模型，并在 “评估模型精度”，您将使用<code>test_set.target</code>和<br><code>Estimator</code>。但首先，您将在下一节中构建您的模型。</p>
<h2><span id="构建深度神经网络分类器">构建深度神经网络分类器</span></h2><p>tf.estimator提供了各种预定义的模型，称为<code>tf.estimator.DNNClassifier</code>s<br>您可以使用“开箱即用”的方式来运行培训和评估操作 数据。 在这里，你将配置一个深度神经网络分类器模型来适应虹膜<br>数据。使用tf.estimator，你可以实例化你的 <code>tf.feature_column.numeric_column</code>只需几行代码：</p>
<pre><code># Specify that all features have real-value data
feature_columns = [tf.feature_column.numeric_column(&quot;x&quot;, shape=[4])]

# Build 3 layer DNN with 10, 20, 10 units respectively.
classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,
                                        hidden_units=[10, 20, 10],
                                        n_classes=3,
                                        model_dir=&quot;/tmp/iris_model&quot;)
</code></pre><p>上面的代码首先定义了指定数据的模型的特征列 键入数据集中的要素。所有的功能数据是连续的，所以 <code>shape</code>是适用的功能<br>构建特征列。数据集中有四个特征（sepal 宽度，萼片高度，花瓣宽度和花瓣高度），因此<code>[4]</code> 必须设置为<code>DNNClassifier</code>才能保存所有数据。</p>
<p>然后，代码使用以下参数创建一个<code>feature_columns=feature_columns</code>模型：</p>
<p><code>hidden_units=[10, 20, 10]</code>。上面定义的一组特征列。 <code>n_classes=3</code>。三     隐藏的图层，<br>含有10,20和10个神经元。 <code>model_dir=/tmp/iris_model</code>。三个目标类，代表三个鸢尾属。 <code>tf.estimator</code>。<br>TensorFlow将保存的目录     检查点数据和TensorBoard摘要在模型训练期间。</p>
<h2><span id="描述训练输入流水线">描述训练输入流水线</span></h2><p><code>tf.estimator.inputs.numpy_input_fn</code> API使用输入功能，创建TensorFlow 为模型生成数据的操作。<br>我们可以使用<code>classifier</code>生成输入流水线：</p>
<pre><code># Define the training inputs
train_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={&quot;x&quot;: np.array(training_set.data)},
    y=np.array(training_set.target),
    num_epochs=None,
    shuffle=True)
</code></pre><h2><span id="将dnnclassifier安装到虹膜培训数据">将DNNClassifier安装到虹膜培训数据</span></h2><p>现在您已经配置好了DNN <code>train</code>型号，您可以将其安装到 虹膜训练数据使用<code>train_input_fn</code>方法。<br>通过<code>input_fn</code>作为<code>classifier</code>，以及要训练的步数 （这里2000）：</p>
<pre><code># Train model.
classifier.train(input_fn=train_input_fn, steps=2000)
</code></pre><p><code>SessionRunHook</code>中保存了模型的状态，这意味着您可以 如果你喜欢，反复训练。比如上面的就相当于了 以下：</p>
<pre><code>classifier.train(input_fn=train_input_fn, steps=1000)
classifier.train(input_fn=train_input_fn, steps=1000)
</code></pre><p>但是，如果您想在训练时跟踪模型，则可能会有这种情况 想改用TensorFlow <code>DNNClassifier</code> 执行日志记录操作。</p>
<h2><span id="评估模型的准确性">评估模型的准确性</span></h2><p>您已经在虹膜训练数据上训练了您的<code>evaluate</code>模型;轮到你了 可以用Iris检查Iris测试数据的准确性<br><code>train</code>方法。像<code>evaluate</code>一样， <code>evaluate</code>具有构建输入流水线的输入功能。 <code>dict</code><br>返回<code>test_set.data</code>s的评估结果。下面的代码通过了 虹膜测试数据-XCJ743-HDK-<br>53L和<code>test_set.target</code>-到<code>evaluate</code> 并从结果中打印<code>accuracy</code>：</p>
<pre><code># Define the test inputs
test_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={&quot;x&quot;: np.array(test_set.data)},
    y=np.array(test_set.target),
    num_epochs=1,
    shuffle=False)

# Evaluate accuracy.
accuracy_score = classifier.evaluate(input_fn=test_input_fn)[&quot;accuracy&quot;]

print(&quot;\nTest Accuracy: {0:f}\n&quot;.format(accuracy_score))
</code></pre><p>注意：这里<code>num_epochs=1</code>的<code>numpy_input_fn</code>参数非常重要。 <code>test_input_fn</code>将迭代一次数据，然后升高<br><code>OutOfRangeError</code>。这个错误指示分类器停止评估，所以它 将对输入进行一次评估。</p>
<p>当你运行完整的脚本时，它会打印出一些接近的内容：</p>
<pre><code>Test Accuracy: 0.966667
</code></pre><p>您的准确性结果可能会有所不同，但应该高于90％。不坏 一个相对较小的数据集！</p>
<h2><span id="分类新样品">分类新样品</span></h2><p>使用估算器的<code>predict()</code>方法对新样品进行分类。比如说 你有这两个新的花样：</p>
<table>
<thead>
<tr>
<th>Sepal Length</th>
<th>Sepal Width</th>
<th>Petal Length</th>
<th>Petal Width  </th>
</tr>
</thead>
<tbody>
<tr>
<td>6.4</td>
<td>3.2</td>
<td>4.5</td>
<td>1.5  </td>
</tr>
<tr>
<td>5.8</td>
<td>3.1</td>
<td>5.0</td>
<td>1.7  </td>
</tr>
</tbody>
</table>
<p>您可以使用<code>predict()</code>方法预测它们的种类。 <code>predict</code>返回一个 可以很容易地将其转换成列表。下面的代码 检索并打印类别预测：</p>
<pre><code># Classify two new flower samples.
new_samples = np.array(
    [[6.4, 3.2, 4.5, 1.5],
     [5.8, 3.1, 5.0, 1.7]], dtype=np.float32)
predict_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={&quot;x&quot;: new_samples},
    num_epochs=1,
    shuffle=False)

predictions = list(classifier.predict(input_fn=predict_input_fn))
predicted_classes = [p[&quot;classes&quot;] for p in predictions]

print(
    &quot;New Samples, Class Predictions:    {}\n&quot;
    .format(predicted_classes))
</code></pre><p>你的结果应该如下所示：</p>
<pre><code>New Samples, Class Predictions:    [1 2]
</code></pre><p>因此，该模型预测，第一个样本是鸢尾花，并且 第二个样品是虹膜virginica。</p>
<h2><span id="其他资源">其他资源</span></h2><p>要了解更多关于使用tf.estimator创建线性模型的信息，请参阅     具有张量流的大规模线性模型。 要使用tf.estimator<br>API构建您自己的Estimator，请查看     在tf.estimator中创建估计器 为了在浏览器中实现神经网络建模和可视化，<br>看看深度游乐场。 有关神经网络的更高级教程，请参阅     卷积神经网络与递归神经网络     网络。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/embedding/" title="的嵌入" itemprop="url">的嵌入</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="的嵌入">的嵌入</span></h1><p>本文档介绍了嵌入的概念，给出了一个简单的例子 如何在TensorFlow中训练嵌入，并解释如何查看嵌入<br>与TensorBoard嵌入式投影仪。前两部分针对新人 机器学习或TensorFlow，和嵌入式投影机的方法是 各级用户。</p>
<p>嵌入是从离散对象（例如单词）到矢量的映射 的实数。例如，一个300维嵌入英文单词 可能包括：</p>
<pre><code>blue:  (0.01359, 0.00075997, 0.24608, ..., -0.2524, 1.0048, 0.06259)
blues:  (0.01396, 0.11887, -0.48963, ..., 0.033483, -0.10007, 0.1158)
orange:  (-0.24776, -0.12359, 0.20986, ..., 0.079717, 0.23865, -0.014213)
oranges:  (-0.35609, 0.21854, 0.080944, ..., -0.35413, 0.38511, -0.070976)
</code></pre><p>这些向量中的各个维度通常没有固有的意义。 相反，它是矢量之间的位置和距离的整体模式 机器学习利用。</p>
<p>嵌入对于机器学习的输入非常重要。分类器和神经 更普遍的网络，工作向量的实数。他们训练得最好 密集的向量，其中所有的值都有助于定义一个对象。但是，很多<br>机器学习的重要投入，如文字的话，没有一个 自然向量表示。嵌入功能是标准和 有效的方法将这些离散的输入对象转化为有用的 连续矢量。</p>
<p>嵌入作为机器学习的输出也是有价值的。因为嵌入 将对象映射到向量，应用程序可以使用向量空间中的相似性（for 欧几里德距离或矢量之间的夹角）作为一个鲁棒的和<br>对象相似度的灵活度量。一个常见的用途是找到最近的 邻居。例如，使用与上面相同的词嵌入，这里是 每个单词的三个最近的邻居和相应的角度：</p>
<pre><code>blue:  (red, 47.6°), (yellow, 51.9°), (purple, 52.4°)
blues:  (jazz, 53.3°), (folk, 59.1°), (bluegrass, 60.6°)
orange:  (yellow, 53.5°), (colored, 58.0°), (bright, 59.9°)
oranges:  (apples, 45.3°), (lemons, 48.3°), (mangoes, 50.4°)
</code></pre><p>这将告诉一个应用程序，苹果和橙子在某种程度上更多 与柠檬和桔子（间隔48.3°）相似（相距45.3°）。</p>
<h2><span id="在tensorflow中嵌入">在TensorFlow中嵌入</span></h2><p>为了在TensorFlow中创建词嵌入，我们首先将文本分成单词 然后为词汇表中的每个单词分配一个整数。让我们假设<br>这已经完成了，<code>word_ids</code>是这些整数的向量。 例如，“我有一只猫”这个句子可以被分成两部分 <code>[&quot;I&quot;, &quot;have&quot;, &quot;a&quot;, &quot;cat&quot;,
&quot;.&quot;]</code>和相应的<code>word_ids</code>张量 将形成<code>[5]</code>并由5个整数组成。映射这些单词ID 对于向量，我们需要创建嵌入变量并使用<br><code>tf.nn.embedding_lookup</code>的功能如下：</p>
<pre><code>word_embeddings = tf.get_variable(&quot;word_embeddings&quot;,
    [vocabulary_size, embedding_size])
embedded_word_ids = tf.nn.embedding_lookup(word_embeddings, word_ids)
</code></pre><p>在此之后，张量器<code>embedded_word_ids</code>将具有形状<code>[5, embedding_size]</code> 在我们的例子中，并包含每个5的嵌入（密集向量）<br>话。在训练结束时，<code>word_embeddings</code>将包含嵌入 为词汇中的所有单词。</p>
<p>嵌入可以训练许多网络类型，并有各种损失 功能和数据集。例如，可以使用循环神经网络 来预测下一个词从前一个给定的大语料库<br>句子，或者可以训练两个网络进行多语言翻译。 这些方法在“矢量表示”中有描述 教程。</p>
<h2><span id="可视化嵌入">可视化嵌入</span></h2><p>TensorBoard包括嵌入式投影仪，这个工具可以让你 交互式地显示嵌入。这个工具可以读取你的嵌入 模型并在二维或三维中渲染它们。</p>
<p>嵌入式投影机有三个面板：</p>
<p>在左上方的数据面板中，您可以选择运行，嵌入   可变数据列和数据列来为点添加颜色和标签。 在左下角的投影面板，您可以在其中选择类型   投影。<br>在右侧的检查面板，在那里你可以搜索特定的   点，看看最近的邻居列表。</p>
<h3><span id="预测">预测</span></h3><p>嵌入式投影机提供三种方法来降低a 数据集。</p>
<p>T-SNE：   非线性非确定性算法（T-分布随机邻居）   嵌入），试图在数据中保存当地的社区，通常在   扭曲全球结构的代价。你可以选择是否计算<br>二维或三维投影。 PCA：   线性确定性算法（主成分分析）试图   在尽可能少的维度上捕获尽可能多的数据可变性。 PCA<br>往往会突出数据的大规模结构，但会扭曲局部   邻里。嵌入式投影机计算前10名委托人   组件，您可以从中选择两个或三个来查看。<br>自定义：对您的水平和垂直轴进行线性投影   在数据中指定使用标签。你可以定义水平轴   实例，通过给“左”和“右”的文本模式。嵌入<br>投影机查找标签与“左”模式相匹配的所有点   计算该集合的质心;类似的“右”。线路通过   通过这两个质心定义横轴。垂直轴是<br>同样根据与“上”和“下”匹配的点的质心计算，   文本模式。</p>
<p>其他有用的文章是 如何有效地使用t-SNE 主成分分析直观解释。</p>
<h3><span id="勘探">勘探</span></h3><p>您可以通过使用自然缩放，旋转和平移进行视觉探索 点击并拖动手势。将鼠标悬停在某个点上会显示任何内容 这一点的元数据。你也可以检查最近的邻居<br>子集。单击一个点会导致右窗格列出最近的 邻居，以及与当前点的距离。最近的邻居 在投影中也突出了点。</p>
<p>将视图限制为点的一个子集并执行有时是有用的 只在这些点上进行预测。为此，您可以选择多个点 方法：</p>
<p>点击一个点后，最近的邻居也被选中。 搜索后，选择与查询匹配的点。 启用选择，单击一个点并拖动定义一个选择   领域。</p>
<p>然后单击“检查器”窗格顶部的“隔离nnn点”按钮 在右手侧。下图显示了101个已选择和准备好的点 供用户点击“隔离101分”：</p>
<p><img src="https://www.tensorflow.org/images/embedding-
nearest-points.png" alt="Selection of nearest neighbors"></p>
<p>在嵌入数据集的单词中选择“重要”的最近邻居。</p>
<p>高级提示：使用自定义投影进行过滤可能会很强大下面，我们 过滤了“政治”最近的100个邻居，并把它们投射到了“ “最差” - “最好”的矢量作为x轴。<br>y轴是随机的。结果，一个 找到右边的“思想”，“科学”，“视角”，“新闻”等等 左“危机”，“暴力”和“冲突”。</p>
<p><img src="https://www.tensorflow.org/images/embedding-custom-
controls.png" alt="Custom controls panel"> |  <img src="https://www.tensorflow.org/images
/embedding-custom-projection.png" alt="Custom projection"><br>—|—<br>Custom projection controls.  |  Custom projection of neighbors of “politics”<br>onto “best” - “worst” vector.  </p>
<p>要分享您的发现，您可以使用右下方的书签面板 保存当前状态（包括计算出的坐标） 投影）作为一个小文件。投影机可以被指向一组<br>或更多这些文件，生产下面的面板。其他用户可以走 通过一系列书签。</p>
<p><img src="https://www.tensorflow.org/images/embedding-bookmark.png" alt="Bookmark panel"></p>
<h3><span id="元数据">元数据</span></h3><p>如果你正在使用嵌入，你可能会想要附加 标签/图像到数据点。您可以通过生成元数据文件来完成此操作 包含每个点的标签并点击数据面板中的“加载数据” 嵌入式投影机</p>
<p>元数据可以是标签或图像，也可以是 存储在一个单独的文件。对于标签，格式应该 成为TSV文件 （制表符以红色显示），其第一行包含列标题<br>（以粗体显示）和后续行包含元数据值。例如：</p>
<p>Word \ Frequency Airplane \ t345 Car \ t241 …</p>
<p>元数据文件中行的顺序被假定为匹配顺序 嵌入变量中的矢量，除了标题。因此， （i + 1）行对应于嵌入的第i行<br>变量。如果TSV元数据文件只有一个列，那么我们不这样做 期望一个标题行，并假设每行是嵌入的标签。我们 包括这个例外，因为它匹配了常用的“vocab文件”<br>格式。</p>
<p>要将图像用作元数据，您必须生成一个 精灵图像， 由小缩略图组成，每个矢量在嵌入中一个。该 精灵应该按行先存储缩略图：放置第一个数据点<br>在左上角，最后一个数据点在右下角，尽管是最后一个 行不必填写，如下所示。</p>
<table>
<thead>
<tr>
<th>0</th>
<th>1</th>
<th>2  </th>
</tr>
</thead>
<tbody>
<tr>
<td>3</td>
<td>4</td>
<td>5  </td>
</tr>
<tr>
<td>6</td>
<td>7</td>
<td></td>
</tr>
</tbody>
</table>
<p>按照这个链接 在嵌入式投影仪中查看缩略图的有趣示例。</p>
<h2><span id="迷你常见问题解答">迷你常见问题解答</span></h2><p>是“嵌入”一个行动还是一个事物？ 都。人们谈论嵌入在向量空间（行动）和关于词 产生词嵌入（东西）。两者共同的是嵌入的概念<br>作为从离散对象到矢量的映射。创建或应用它 映射是一个动作，但映射本身是一件事情。</p>
<p>是嵌入高维或低维？ 这取决于。例如，单词和短语的300维向量空间， 通常被称为低维（和密集）相比，数百万 它可以包含的单词和短语。但数学上它是高维的，<br>展示了许多与我们的人类大不相同的特性 直觉了解了二维和三维空间。</p>
<p>嵌入层是否与嵌入层相同？ 没有。嵌入层是神经网络的一部分，但嵌入是一个更多 一般的概念。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/tensorboard_histograms/" title="TensorBoard直方图仪表板" itemprop="url">TensorBoard直方图仪表板</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="tensorboard直方图仪表板">TensorBoard直方图仪表板</span></h1><p>TensorBoard直方图仪表板显示一些分布的方式 TensorFlow图表中的<code>Tensor</code>随时间变化。它通过显示来实现<br>很多直方图可视化您的张量在不同的时间点。</p>
<h2><span id="一个基本的例子">一个基本的例子</span></h2><p>让我们从一个简单的例子开始：一个正态分布的变量，其中的平均值 随时间变化。 TensorFlow有一个操作 <code>tf.random_normal</code><br>这是完美的这个目的。和TensorBoard通常一样，我们 将使用摘要操作来摄取数据;在这种情况下， ‘tf.summary.histogram’。<br>有关总结如何工作的初步介绍，请参阅总结 TensorBoard教程。</p>
<p>这是一个代码片段，将生成一些直方图摘要包含 正态分布的数据，其中分布的均值增加 时间。</p>
<pre><code>import tensorflow as tf

k = tf.placeholder(tf.float32)

# Make a normal distribution, with a shifting mean
mean_moving_normal = tf.random_normal(shape=[1000], mean=(5*k), stddev=1)
# Record that distribution into a histogram summary
tf.summary.histogram(&quot;normal/moving_mean&quot;, mean_moving_normal)

# Setup a session and summary writer
sess = tf.Session()
writer = tf.summary.FileWriter(&quot;/tmp/histogram_example&quot;)

summaries = tf.summary.merge_all()

# Setup a loop and write the summaries to disk
N = 400
for step in range(N):
  k_val = step/float(N)
  summ = sess.run(summaries, feed_dict={k: k_val})
  writer.add_summary(summ, global_step=step)
</code></pre><p>一旦代码运行，我们可以通过命令行将数据加载到TensorBoard中：</p>
<pre><code>tensorboard --logdir=/tmp/histogram_example
</code></pre><p>一旦TensorBoard正在运行，将其加载到Chrome或Firefox并导航到 直方图仪表板。然后我们可以看到我们通常的直方图可视化 分布式数据。</p>
<p><img src="https://www.tensorflow.org/images/tensorboard/histogram_dashboard/1_moving_mean.png" alt=""></p>
<p><code>tf.summary.histogram</code>采取任意大小和形状的张量，并且 将其压缩成由许多分箱组成的直方图数据结构<br>宽度和数量。例如，假设我们要组织这些数字 <code>[0.5, 1.1, 1.3, 2.2, 2.9, 2.99]</code>分为箱子。我们可以做三个箱子：  一个箱子<br>包含从0到1的所有内容（它将包含一个元素，0.5），  一个箱子 包含1-2的所有内容（包含1.1和1.3两个元素），<br>*包含2-3的所有内容（它将包含三个元素：2.2， 2.9和2.99）。</p>
<p>TensorFlow使用类似的方法来创建垃圾箱，但不像我们的例子那样 不会创建整数箱。对于大型稀疏数据集，可能会导致 数千个垃圾箱。<br>相反，箱是指数分布的，许多箱接近0和 相当数量的箱子比较少。 然而，可视化指数分布的垃圾箱是棘手的;如果使用高度<br>对数字进行编码，然后更宽的箱子占用更多的空间，即使它们具有相同的空间 元素的数量。相反，在该地区编码计数使高度 比较不可能。相反，直方图重新采样数据<br>进入统一的箱子。这在某些情况下会导致不幸的文物。</p>
<p>直方图可视化器中的每个切片显示单个直方图。 切片按步骤组织; 较旧的切片（例如，步骤0）进一步“后退”而较暗，而较新的切片<br>（例如步骤400）靠近前景，并且颜色较浅。 右边的y轴显示步骤编号。</p>
<p>您可以将鼠标悬停在柱状图上，查看更详细的工具提示 信息。例如，在下图中我们可以看到直方图 在时间步骤176具有以2.25为中心的仓，在该仓中有177个元素。</p>
<p><img src="https://www.tensorflow.org/images/tensorboard/histogram_dashboard/2_moving_mean_tooltip.png" alt=""></p>
<p>此外，您可能会注意到，直方图切片并不总是均匀分布在中 步数或时间。这是因为TensorBoard使用 水库取样保持一个<br>所有直方图的子集，以节省内存。油藏采样保证 每个样本都有相同的被包含的可能性，但是因为它是 一个随机的算法，选择的样本不会在偶数阶段出现。</p>
<h2><span id="覆盖模式">覆盖模式</span></h2><p>仪表板左侧有一个控件，可以切换 直方图模式从“偏移”到“覆盖”：</p>
<p><img src="https://www.tensorflow.org/images/tensorboard/histogram_dashboard/3_overlay_offset.png" alt=""></p>
<p>在“偏移”模式下，可视化旋转45度，使个人 直方图切片不再分散，而是全部绘制 在同一个Y轴上。</p>
<p><img src="https://www.tensorflow.org/images/tensorboard/histogram_dashboard/4_overlay.png" alt=""><br>现在，每个切片都是图表上的一个单独的行，y轴显示该项目 在每个桶内计数。较深的线条较旧，较早的步骤较轻<br>线条是更新的，后面的步骤。再次，您可以将鼠标悬停在图表上 看到一些额外的信息。</p>
<p><img src="https://www.tensorflow.org/images/tensorboard/histogram_dashboard/5_overlay_tooltips.png" alt=""></p>
<p>一般来说，如果要直接进行比较，覆盖可视化是有用的 不同直方图的计数。</p>
<h2><span id="多模式分配">多模式分配</span></h2><p>直方图仪表板非常适合可视化多模式 分布。让我们通过连接构造一个简单的双峰分布 来自两个不同正态分布的输出。代码看起来像 这个：</p>
<pre><code>import tensorflow as tf

k = tf.placeholder(tf.float32)

# Make a normal distribution, with a shifting mean
mean_moving_normal = tf.random_normal(shape=[1000], mean=(5*k), stddev=1)
# Record that distribution into a histogram summary
tf.summary.histogram(&quot;normal/moving_mean&quot;, mean_moving_normal)

# Make a normal distribution with shrinking variance
variance_shrinking_normal = tf.random_normal(shape=[1000], mean=0, stddev=1-(k))
# Record that distribution too
tf.summary.histogram(&quot;normal/shrinking_variance&quot;, variance_shrinking_normal)

# Let&apos;s combine both of those distributions into one dataset
normal_combined = tf.concat([mean_moving_normal, variance_shrinking_normal], 0)
# We add another histogram summary to record the combined distribution
tf.summary.histogram(&quot;normal/bimodal&quot;, normal_combined)

summaries = tf.summary.merge_all()

# Setup a session and summary writer
sess = tf.Session()
writer = tf.summary.FileWriter(&quot;/tmp/histogram_example&quot;)

# Setup a loop and write the summaries to disk
N = 400
for step in range(N):
  k_val = step/float(N)
  summ = sess.run(summaries, feed_dict={k: k_val})
  writer.add_summary(summ, global_step=step)
</code></pre><p>你已经记得我们的例子中的“移动均值”正态分布 以上。现在我们也有一个“收缩差异”的分布。他们并排 看起来像这样：<br><img src="https://www.tensorflow.org/images/tensorboard/histogram_dashboard/6_two_distributions.png" alt=""></p>
<p>当我们把它们连接起来的时候，我们得到一张清楚地显示出不同的图表， 双峰结构：<br><img src="https://www.tensorflow.org/images/tensorboard/histogram_dashboard/7_bimodal.png" alt=""></p>
<h2><span id="更多的分布">更多的分布</span></h2><p>为了好玩，让我们生成并可视化一些更多的发行版，然后 将它们组合成一个图表。以下是我们将使用的代码：</p>
<pre><code>import tensorflow as tf

k = tf.placeholder(tf.float32)

# Make a normal distribution, with a shifting mean
mean_moving_normal = tf.random_normal(shape=[1000], mean=(5*k), stddev=1)
# Record that distribution into a histogram summary
tf.summary.histogram(&quot;normal/moving_mean&quot;, mean_moving_normal)

# Make a normal distribution with shrinking variance
variance_shrinking_normal = tf.random_normal(shape=[1000], mean=0, stddev=1-(k))
# Record that distribution too
tf.summary.histogram(&quot;normal/shrinking_variance&quot;, variance_shrinking_normal)

# Let&apos;s combine both of those distributions into one dataset
normal_combined = tf.concat([mean_moving_normal, variance_shrinking_normal], 0)
# We add another histogram summary to record the combined distribution
tf.summary.histogram(&quot;normal/bimodal&quot;, normal_combined)

# Add a gamma distribution
gamma = tf.random_gamma(shape=[1000], alpha=k)
tf.summary.histogram(&quot;gamma&quot;, gamma)

# And a poisson distribution
poisson = tf.random_poisson(shape=[1000], lam=k)
tf.summary.histogram(&quot;poisson&quot;, poisson)

# And a uniform distribution
uniform = tf.random_uniform(shape=[1000], maxval=k*10)
tf.summary.histogram(&quot;uniform&quot;, uniform)

# Finally, combine everything together!
all_distributions = [mean_moving_normal, variance_shrinking_normal,
                     gamma, poisson, uniform]
all_combined = tf.concat(all_distributions, 0)
tf.summary.histogram(&quot;all_combined&quot;, all_combined)

summaries = tf.summary.merge_all()

# Setup a session and summary writer
sess = tf.Session()
writer = tf.summary.FileWriter(&quot;/tmp/histogram_example&quot;)

# Setup a loop and write the summaries to disk
N = 400
for step in range(N):
  k_val = step/float(N)
  summ = sess.run(summaries, feed_dict={k: k_val})
  writer.add_summary(summ, global_step=step)
</code></pre><h3><span id="伽玛分布">伽玛分布</span></h3><p><img src="https://www.tensorflow.org/images/tensorboard/histogram_dashboard/8_gamma.png" alt=""></p>
<h3><span id="统一分配">统一分配</span></h3><p><img src="https://www.tensorflow.org/images/tensorboard/histogram_dashboard/9_uniform.png" alt=""></p>
<h3><span id="泊松分布">泊松分布</span></h3><p><img src="https://www.tensorflow.org/images/tensorboard/histogram_dashboard/10_poisson.png" alt=""><br>泊松分布是在整数上定义的。所以，所有的价值 被生成是完美的整数。直方图压缩移动数据 进入浮点箱，导致可视化显示很少 颠覆整数值而不是完美的尖峰。</p>
<h3><span id="现在都在一起了">现在都在一起了</span></h3><p>最后，我们可以将所有的数据连接成一个有趣的曲线。<br><img src="https://www.tensorflow.org/images/tensorboard/histogram_dashboard/11_all_combined.png" alt=""></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/debugger/" title="调试TensorFlow程序" itemprop="url">调试TensorFlow程序</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="调试tensorflow程序">调试TensorFlow程序</span></h1><p>TensorFlow调试器（tfdbg）是TensorFlow的专用调试器。它 让您查看运行TensorFlow图的内部结构和状态<br>在训练和推理过程中，这是很难与通用调试 调试器，例如由于TensorFlow的计算图范例而导致的Python <code>pdb</code>。</p>
<blockquote>
<p>注意：支持的外部平台上的tfdbg的系统要求包括 下列。在Mac OS X上，<code>ncurses</code>库是必需的。有可能 与<code>brew install
homebrew/dupes/ncurses</code>一起安装。在Windows上，<code>pyreadline</code><br>是必须的。如果您使用Anaconda3，则可以使用命令进行安装 如<code>&quot;C:\Program Files\Anaconda3\Scripts\pip.exe&quot;
install pyreadline</code>。</p>
</blockquote>
<p>本教程演示如何使用tfdbg命令行界面 （CLI）来调试<code>nan</code>的外观 和<code>inf</code>，这是一个经常遇到的问题 TensorFlow模型开发中的错误类型。<br>以下示例适用于使用低级别的用户 <code>Session</code> API TensorFlow。本文档的后面部分介绍了如何使用tfdbg 采用更高级别的API，即tf-<br>learn <code>Estimator</code>和<code>Experiment</code>。 要观察这样的问题，运行下面的命令没有调试器（ 源代码可以找到 这里）：</p>
<pre><code>python -m tensorflow.python.debug.examples.debug_mnist
</code></pre><p>此代码为MNIST数字图像识别训练一个简单的神经网络。 请注意，在第一个训练步骤之后，准确度略有增加，但是 然后卡在一个很低的（几率）水平：</p>
<pre><code>Accuracy at step 0: 0.1113
Accuracy at step 1: 0.3183
Accuracy at step 2: 0.098
Accuracy at step 3: 0.098
Accuracy at step 4: 0.098
</code></pre><p>想知道什么可能会出错，你怀疑在某些节点 训练图生成错误的数值，如<code>inf</code>和<code>nan</code>，因为 这是这种训练失败的常见原因。<br>我们使用tfdbg来调试这个问题，并精确定位这个节点 数字问题首先浮出水面。</p>
<h2><span id="用tfdbg包装tensorflow会话">用tfdbg包装TensorFlow会话</span></h2><p>在我们的例子中添加对tfdbg的支持，只需要添加 遵循以下代码行并用调试器包装器包装Session对象。 这个代码已经被添加进去了<br>debug_mnist.py， 因此您可以在命令行中使用<code>--debug</code>标志激活tfdbg CLI。</p>
<pre><code># Let your BUILD target depend on &quot;//tensorflow/python/debug:debug_py&quot;
# (You don&apos;t need to worry about the BUILD dependency if you are using a pip
#  install of open-source TensorFlow.)
from tensorflow.python import debug as tf_debug

sess = tf_debug.LocalCLIDebugWrapperSession(sess)
</code></pre><p>这个包装与Session具有相同的接口，因此启用调试需要 没有其他更改的代码。包装提供了额外的功能， 包含：</p>
<p>在<code>Session.run()</code>呼叫前后拨打CLI，让你 控制执行并检查图形的内部状态。 允许您为张量值注册特殊的<code>filters</code>，以方便使用<br>问题的诊断。</p>
<p>在这个例子中，我们已经注册了一个叫做张量过滤器 <code>tfdbg.has_inf_or_nan</code>， 它只是确定是否有任何<code>nan</code>或<code>inf</code>值<br>中间张量（既不是输入也不是输出的张量） <code>Session.run()</code>的调用，但是都在从输入到输出的路径上<br>输出）。该滤波器适用于<code>nan</code>，而<code>inf</code>则是一种常见的用例 我们用它运送它 <code>debug_data</code> 模块。</p>
<p>注意：您也可以编写自己的自定义过滤器。看到 API文档 <code>DebugDumpDir.find()</code>的更多信息。</p>
<h2><span id="用tfdbg调试模型训练">用tfdbg调试模型训练</span></h2><p>让我们再次尝试训练模型，但这次添加了<code>--debug</code>标志：</p>
<pre><code>python -m tensorflow.python.debug.examples.debug_mnist --debug
</code></pre><p>调试包装会话将提示您何时执行第一个 <code>Session.run()</code>调用，提供有关取出张量和进给的信息 字典显示在屏幕上。</p>
<p><img src="https://www.tensorflow.org/images/tfdbg_screenshot_run_start.png" alt="tfdbg run-start
UI"></p>
<p>这就是我们所说的运行启动CLI。它列出了提要和提取 到当前的<code>Session.run</code>调用，在执行任何事情之前。</p>
<p>如果屏幕尺寸太小，则无法在其中显示消息的内容 完整，你可以调整它。</p>
<p>使用PageUp / PageDown / Home / End键导航 屏幕输出。在大多数键盘上缺少这些键Fn + Up / Fn +向下/ Fn +向右/<br>Fn +向左将工作。</p>
<p>在命令提示符处输入<code>run</code>命令（或者只是<code>r</code>）：</p>
<pre><code>tfdbg&gt; run
</code></pre><p><code>run</code>命令导致tfdbg执行，直到下一个结束 <code>Session.run()</code>调用，它使用测试数据计算模型的准确性 组。<br>tfdbg扩展运行时图形以转储所有中间张量。 运行结束后，tfdbg将显示所有转储的张量值 运行结束CLI。例如：</p>
<p><img src="https://www.tensorflow.org/images/tfdbg_screenshot_run_end_accuracy.png" alt="tfdbg run-end UI:
accuracy"></p>
<p>之后可以通过运行命令<code>lt</code>来获得张量列表 执行<code>run</code>。</p>
<h3><span id="tfdbg-cli经常使用的命令">tfdbg CLI经常使用的命令</span></h3><p>请在<code>tfdbg&gt;</code>提示符处尝试以下命令（参考中的代码）<br><code>tensorflow/python/debug/examples/debug_mnist.py</code>）：</p>
<table>
<thead>
<tr>
<th>Command</th>
<th>Syntax or Option</th>
<th>Explanation</th>
<th>Example  </th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><code>lt</code></strong></td>
<td></td>
<td><strong>List dumped tensors.</strong></td>
<td><code>lt</code>  </td>
</tr>
<tr>
<td></td>
<td><code>-n &lt;name_pattern&gt;</code></td>
<td>List dumped tensors with names matching given</td>
</tr>
<tr>
<td>regular-expression pattern.</td>
<td><code>lt -n Softmax.*</code>  </td>
</tr>
<tr>
<td></td>
<td><code>-t &lt;op_pattern&gt;</code></td>
<td>List dumped tensors with op types matching given</td>
</tr>
<tr>
<td>regular-expression pattern.</td>
<td><code>lt -t MatMul</code>  </td>
</tr>
<tr>
<td></td>
<td><code>s &lt;sort_key&gt;</code></td>
<td>Sort the output by given <code>sort_key</code>, whose possible values</td>
</tr>
<tr>
<td>are <code>timestamp</code> (default), <code>dump_size</code>, <code>op_type</code> and <code>tensor_name</code>.</td>
<td>`lt -s</td>
</tr>
</tbody>
</table>
<p>dump_size<code>|</code>-r<code>| Sort in reverse order. |</code>lt -r -s dump_size<code>**</code>pt<code>** |  | **Print value of a dumped tensor.** |  
|</code>pt <tensor><code>|  Print tensor value. |</code>pt hidden/Relu:0<code>|</code>pt <tensor>[slicing]<code>| Print a subarray of tensor, using
[numpy](http://www.numpy.org/)-style array slicing. |</code>pt<br>hidden/Relu:0[0:50,:]<code>|</code>-a<code>| Print the entirety of a large tensor, without using ellipses. (May
take a long time for large tensors.) |</code>pt -a hidden/Relu:0[0:50,:]<code>|</code>-r <range><code>| Highlight elements falling into specified numerical range.
Multiple ranges can be used in conjunction. |</code>pt hidden/Relu:0 -a -r<br>[[-inf,-1],[1,inf]]<code>|</code>-s<code>| Include a summary of the numeric values of the tensor (applicable
only to non-empty tensors with Boolean and numeric types such as</code>int<em><code>and</code>float</em><code>.) |</code>pt -s hidden/Relu:0[0:50,:]<code>**</code>@[coordinates]<code>** |  |  Navigate to specified element in</code>pt<code>output. |</code>@[10,0]<code>or</code>@10,0<code>**</code>/regex<code>** |  | [less](https://linux.die.net/man/1/less)-style search for
given regular expression. |</code>/inf<code>**</code>/<code>** |  |  Scroll to the next line with matches to the searched regex (if
any). |</code>/<code>**</code>pf<code>** |  | **Print a value in the feed_dict to</code>Session.run<code>.** |  
|</code>pf <feed_tensor_name><code>|  Print the value of the feed. Also note that the</code>pf<code>command has the</code>-a<code>,</code>-r<code>and</code>-s<code>flags (not listed below), which have
the same syntax and semantics as the identically-named flags of</code>pt<code>. |</code>pf<br>input_xs:0<code>**eval** |  | **Evaluate arbitrary Python and numpy expression.** |  
|</code>eval <expression><code>|  Evaluate a Python / numpy expression, with numpy
available as</code>np<code>and debug tensor names enclosed in backticks. |</code>eval<br>“np.matmul((<code>output/Identity:0</code> / <code>Softmax:0</code>).T, <code>Softmax:0</code>)”<code>|</code>-a<code>| Print a large-sized evaluation result in its entirety, i.e., without
using ellipses. |</code>eval -a ‘np.sum(<code>Softmax:0</code>, axis=1)’<code>**</code>ni<code>** |  | **Display node information.** |  
|</code>-a<code>|  Include node attributes in the output. |</code>ni -a hidden/Relu<code>|</code>-d<code>| List the debug dumps available from the node. |</code>ni -d hidden/Relu<code>|</code>-t<code>| Display the Python stack trace of the node&#39;s creation. |</code>ni -t<br>hidden/Relu<code>**</code>li<code>** |  | **List inputs to node** |  
|</code>-r<code>|  List the inputs to node, recursively (the input tree.) |</code>li -r<br>hidden/Relu:0<code>|</code>-d <max_depth><code>| Limit recursion depth under the</code>-r<code>mode. |</code>li -r -d 3<br>hidden/Relu:0<code>|</code>-c<code>| Include control inputs. |</code>li -c -r hidden/Relu:0<code>**</code>lo<code>** |  | **List output recipients of node** |  
|</code>-r<code>|  List the output recipients of node, recursively (the output tree.) |</code>lo -r hidden/Relu:0<code>|</code>-d <max_depth><code>| Limit recursion depth under the</code>-r<code>mode. |</code>lo -r -d 3<br>hidden/Relu:0<code>|</code>-c<code>| Include recipients via control edges. |</code>lo -c -r hidden/Relu:0<code>**</code>ls<code>** |  | **List Python source files involved in node creation.** |  
|</code>-p <path_pattern><code>|  Limit output to source files matching given regular-
expression path pattern. |</code>ls -p .<em>debug_mnist.</em><code>|</code>-n<code>| Limit output to node names matching given regular-expression pattern.
|</code>ls -n Softmax.<em><code>**</code>ps<code>** |  | **Print Python source file.** |  
|</code>ps <file_path><code>|  Print given Python source file source.py, with the lines
annotated with the nodes created at each of them (if any). |</code>ps<br>/path/to/source.py<code>|</code>-t<code>| Perform annotation with respect to Tensors, instead of the default,
nodes. |</code>ps -t /path/to/source.py<code>|</code>-b <line_number><code>| Annotate source.py beginning at given line. |</code>ps -b 30<br>/path/to/source.py<code>|</code>-m <max_elements><code>| Limit the number of elements in the annotation for
each line. |</code>ps -m 100 /path/to/source.py<code>**</code>run<code>** |  | **Proceed to the next Session.run()** |</code>run<code>|</code>-n<code>|  Execute through the next</code>Session.run<code>without debugging, and drop
to CLI right before the run after that. |</code>run -n<code>|</code>-t <t><code>| Execute</code>Session.run<code></code>T - 1<code>times without debugging, followed
by a run with debugging. Then drop to CLI right after the debugged run. |</code>run<br>-t 10<code>|</code>-f <filter_name><code>| Continue executing</code>Session.run<code>until any intermediate
tensor triggers the specified Tensor filter (causes the filter to return</code>True<code>). |</code>run -f has_inf_or_nan<code>|</code>–node_name_filter <pattern><code>| Execute the next</code>Session.run<code>, watching
only nodes with names matching the given regular-expression pattern. |</code>run<br>–node_name_filter Softmax.</pattern></filter_name></t></max_elements></line_number></file_path></em><code>|</code>–op_type_filter <pattern><code>| Execute the next</code>Session.run<code>, watching only
nodes with op types matching the given regular-expression pattern. |</code>run<br>–op_type_filter Variable.<em><code>|</code>–tensor_dtype_filter <pattern><code>| Execute the next</code>Session.run<code>, dumping
only Tensors with data types (</code>dtype<code>s) matching the given regular-expression
pattern. |</code>run –tensor_dtype_filter int.</pattern></em><code>|</code>-p<code>| Execute the next</code>Session.run<code>call in profiling mode. |</code>run -p<code>**</code>ri<code>** |  | **Display information about the run the current run, including
fetches and feeds.** |</code>ri<code>**</code>help<code>** |  | **Print general help information** |</code>help<code>|</code>help <command><code>|  Print help for given command. |</code>help lt`  </pattern></path_pattern></max_depth></max_depth></expression></feed_tensor_name></range></tensor></tensor></p>
<p>请注意，每当您输入一个命令，一个新的屏幕输出 会出现。这有点类似于浏览器中的网页。您可以 点击<code>&lt;--</code>和 CLI左上角附近的<code>--&gt;</code>文本箭头。</p>
<h3><span id="tfdbg-cli的其他功能">tfdbg CLI的其他功能</span></h3><p>除了上面列出的命令外，tfdbg CLI还提供了以下内容 附加功能：</p>
<p>要浏览以前的tfdbg命令，请输入几个字符     接着是向上或向下箭头键。 tfdbg会告诉你的历史     以这些字符开始的命令。<br>要浏览屏幕输出的历史记录，请执行以下任一操作     以下： 使用<code>prev</code>和<code>next</code>命令。 点击下划线旁边的<code>&lt;--</code>和<code>--&gt;</code>链接左上角<br>屏幕。 Tab完成命令和一些命令参数。 要将屏幕输出重定向到文件而不是屏幕，请结束     命令与bash风格的重定向。例如，下面的命令<br>将pt命令的输出重定向到<code>/tmp/xent_value_slices.txt</code>     文件：</p>
<blockquote>
<p>tfdbg&gt; pt cross_entropy / Log：0 [:, 0:10]&gt; /tmp/xent_value_slices.txt</p>
</blockquote>
<h3><span id="寻找nan和inf">寻找<code>nan</code>和<code>inf</code></span></h3><p>在这首<code>Session.run()</code>调用中，碰巧没有问题的数字 值。您可以使用命令<code>run</code>或其命令进行下一次运行 速记<code>r</code>。</p>
<blockquote>
<p>提示：如果您重复输入<code>run</code>或<code>r</code>，您将可以移动 <code>Session.run()</code>按顺序调用。<br>您也可以使用<code>-t</code>标志前进一些<code>Session.run()</code>呼叫 一次，例如： tfdbg&gt; run -t 10</p>
</blockquote>
<p>而不是反复输入<code>run</code>并手动搜索<code>nan</code> 每次<code>inf</code>调用后的<code>Session.run()</code>在运行结束UI（例如，通过使用<br><code>pt</code>的命令如上表所示），可以使用以下命令 命令让调试器无需重复执行<code>Session.run()</code>调用<br>停止在运行开始或运行结束提示符，直到第一台<code>nan</code>或<code>inf</code> 值在图中显示。这类似于中的条件断点 一些程序语言调试器：</p>
<pre><code>tfdbg&gt; run -f has_inf_or_nan
</code></pre><blockquote>
<p>注：上述命令正常工作，因为张量过滤器被称为 <code>has_inf_or_nan</code>已经在包装会话时注册 创建。该滤波器检测<code>nan</code>和<code>inf</code>（如前所述）。<br>如果你已经注册了其他的过滤器，你可以 使用“运行-f”使tfdbg运行，直到任何张量触发该过滤器（原因 过滤器返回True）。 def<br>my_filter_callable（数据，张量）：   ＃一个检测零值标量的过滤器。   返回len（tensor.shape）== 0和张量== 0.0<br>sess.add_tensor_filter（’my_filter’，my_filter_callable）<br>然后在tfdbg运行启动提示符运行，直到您的过滤器被触发： tfdbg&gt;运行-f my_filter</p>
</blockquote>
<p>看到这个API文档 以获取更多关于预期签名和返回值的信息 <code>Callable</code>与<code>add_tensor_filter()</code>一起使用。</p>
<p><img src="https://www.tensorflow.org/images/tfdbg_screenshot_run_end_inf_nan.png" alt="tfdbg run-end UI: infs and
nans"></p>
<p>当屏幕显示在第一行时，首先触发<code>has_inf_or_nan</code>滤波器 在第四次<code>Session.run()</code>呼叫期间：一个 亚当优化器<br>图上前进后退训练传球。在这个运行中，36（总数中 95）中间张量包含<code>nan</code>或<code>inf</code>值。这些张力被列出 按照时间顺序，左边显示时间戳。在顶部<br>的列表中，可以看到第一个张量中的数值不好 首先浮出水面：<code>cross_entropy/Log:0</code>。</p>
<p>要查看张量的值，请单击带下划线的张量名称 <code>cross_entropy/Log:0</code>或输入等效命令：</p>
<pre><code>tfdbg&gt; pt cross_entropy/Log:0
</code></pre><p>向下滚动一下，你会注意到一些零散的<code>inf</code>值。如果 <code>inf</code>和<code>nan</code>的实例难以一目了然，您可以使用 以下命令执行正则表达式搜索并突出显示输出：</p>
<pre><code>tfdbg&gt; /inf
</code></pre><p>或者，或者：</p>
<pre><code>tfdbg&gt; /(inf|nan)
</code></pre><p>您也可以使用<code>-s</code>或<code>--numeric_summary</code>命令快速总结 张量中的数值类型：</p>
<pre><code>tfdbg&gt; pt -s cross_entropy/Log:0
</code></pre><p>从总结中，可以看到1000个元素中的几个 <code>cross_entropy/Log:0</code>张量器是<code>-inf</code>s（负无穷）。</p>
<p>为什么出现这些无穷大？为了进一步调试，显示更多信息 通过单击带下划线的<code>cross_entropy/Log</code>菜单关于节点<code>node_info</code><br>项目顶部或输入相应的node_info（<code>ni</code>）命令：</p>
<pre><code>tfdbg&gt; ni cross_entropy/Log
</code></pre><p><img src="https://www.tensorflow.org/images/tfdbg_screenshot_run_end_node_info.png" alt="tfdbg run-end UI: infs and
nans"></p>
<p>你可以看到这个节点的操作类型是<code>Log</code> 其输入是节点<code>softmax/Softmax</code>。运行以下命令 仔细看一下输入张量：</p>
<pre><code>tfdbg&gt; pt softmax/Softmax:0
</code></pre><p>检查输入张量中的值，搜索零：</p>
<pre><code>tfdbg&gt; /0\.000
</code></pre><p>确实有零。现在很清楚，数字的来源是不好的 值为节点<code>cross_entropy/Log</code>记录零。为了找出答案<br>Python源代码中的罪魁祸首，使用<code>-t</code>命令的<code>ni</code>标志 显示节点构造的回溯：</p>
<pre><code>tfdbg&gt; ni -t cross_entropy/Log
</code></pre><p>如果您点击屏幕顶部的“node_info”，tfdbg会自动显示 回溯节点的构造。</p>
<p>从追溯，你可以看到，操作是在以下构建 线： <code>debug_mnist.py</code>：</p>
<pre><code>diff = y_ * tf.log(y)
</code></pre><p>tfdbg有一个功能，可以很容易地跟踪张量和操作回来 Python源文件中的行。它可以注释一个Python文件的行 他们创造的ops或张量。要使用此功能，<br>只需单击堆栈跟踪输出中的带下划线的行号即可 <code>ni -t &lt;op_name&gt;</code>命令，或者使用<code>ps</code>（或<code>print_source</code>）命令，例如： <code>ps
/path/to/source.py</code>。例如，以下屏幕截图显示了输出 <code>ps</code>命令。</p>
<p><img src="https://www.tensorflow.org/images/tfdbg_screenshot_run_end_annotated_source.png" alt="tfdbg run-end UI: annotated Python source
file"></p>
<h3><span id="解决问题">解决问题</span></h3><p>要解决这个问题，编辑<code>debug_mnist.py</code>，改变原来的行：</p>
<pre><code>diff = -(y_ * tf.log(y))
</code></pre><p>到softmax交叉熵的内置数值稳定实现：</p>
<pre><code>diff = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=logits)
</code></pre><p>重新运行<code>--debug</code>标志如下：</p>
<pre><code>python -m tensorflow.python.debug.examples.debug_mnist --debug
</code></pre><p>在<code>tfdbg&gt;</code>提示符处，输入以下命令：</p>
<pre><code>run -f has_inf_or_nan`
</code></pre><p>确认没有张量被标记为包含<code>nan</code>或<code>inf</code>值，并且 精度现在继续上升而不是卡住。成功！</p>
<h2><span id="调试tf学习估计器和实验">调试tf学习估计器和实验</span></h2><p>本节介绍如何调试使用<code>Estimator</code>的TensorFlow程序 和<code>Experiment</code> API。这些API所提供的部分便利是<br>他们在内部管理<code>Session</code>。这使得<code>LocalCLIDebugWrapperSession</code> 在前面的章节中描述不适用。幸运的是，你仍然可以<br>使用<code>hook</code>提供的<code>tfdbg</code>进行调试。</p>
<h3><span id="调试tfcontriblearn估计器">调试tf.contrib.learn估计器</span></h3><p>目前，<code>tfdbg</code>可以进行调试 <code>fit()</code> <code>evaluate()</code> 学习<code>Estimator</code>s的方法。为了调试<code>Estimator.fit()</code>，<br>创建一个<code>LocalCLIDebugHook</code>并在<code>monitors</code>参数中提供。例如：</p>
<pre><code># First, let your BUILD target depend on &quot;//tensorflow/python/debug:debug_py&quot;
# (You don&apos;t need to worry about the BUILD dependency if you are using a pip
#  install of open-source TensorFlow.)
from tensorflow.python import debug as tf_debug

# Create a LocalCLIDebugHook and use it as a monitor when calling fit().
hooks = [tf_debug.LocalCLIDebugHook()]

classifier.fit(x=training_set.data,
               y=training_set.target,
               steps=1000,
               monitors=hooks)
</code></pre><p>要调试<code>Estimator.evaluate()</code>，请将钩子分配给<code>hooks</code>参数，如 下面的例子：</p>
<pre><code>accuracy_score = classifier.evaluate(x=test_set.data,
                                     y=test_set.target,
                                     hooks=hooks)[&quot;accuracy&quot;]
</code></pre><p>debug_tflearn_iris.py， 基于{$ tflearn $ tf-learn的虹膜教程}，包含了一个完整的例子<br>与<code>Estimator</code>一起使用tfdbg。要运行这个例子，请执行：</p>
<pre><code>python -m tensorflow.python.debug.examples.debug_tflearn_iris --debug
</code></pre><h3><span id="调试tfcontriblearn实验">调试tf.contrib.learn实验</span></h3><p><code>Experiment</code>是<code>tf.contrib.learn</code>中的一种构建体 <code>Estimator</code>。 它提供了一个单一的界面来训练和评估一个模型。调试<br><code>train()</code>和<code>evaluate()</code>调用<code>Experiment</code>对象，您可以<br>当分别使用关键字参数<code>train_monitors</code>和<code>eval_hooks</code>时 调用它的构造函数。例如：</p>
<pre><code># First, let your BUILD target depend on &quot;//tensorflow/python/debug:debug_py&quot;
# (You don&apos;t need to worry about the BUILD dependency if you are using a pip
#  install of open-source TensorFlow.)
from tensorflow.python import debug as tf_debug

hooks = [tf_debug.LocalCLIDebugHook()]

ex = experiment.Experiment(classifier,
                           train_input_fn=iris_input_fn,
                           eval_input_fn=iris_input_fn,
                           train_steps=FLAGS.train_steps,
                           eval_delay_secs=0,
                           eval_steps=1,
                           train_monitors=hooks,
                           eval_hooks=hooks)

ex.train()
accuracy_score = ex.evaluate()[&quot;accuracy&quot;]
</code></pre><p>要在<code>debug_tflearn_iris</code>模式下构建并运行<code>Experiment</code>示例，请执行以下操作：</p>
<pre><code>python -m tensorflow.python.debug.examples.debug_tflearn_iris \
    --use_experiment --debug
</code></pre><p><code>LocalCLIDebugHook</code>还允许您配置<code>watch_fn</code>，该<code>Tensor</code>可以<br>用于灵活指定在不同的<code>Session.run()</code>上观看的<code>fetches</code><br>呼叫，作为<code>feed_dict</code>和<code>LocalCLIDebugWrapperSession</code>等状态的功能。看到 这个API文档 更多细节。</p>
<h2><span id="用tfdbg调试keras模型">用TFDBG调试Keras模型</span></h2><p>要使用Keras的TFDBG，请让Keras后端使用 一个TFDBG包装的Session对象。例如，要使用CLI包装器：</p>
<pre><code>import tensorflow as tf
from keras import backend as keras_backend
from tensorflow.python import debug as tf_debug

keras_backend.set_session(tf_debug.LocalCLIDebugWrapperSession(tf.Session()))

# Define your keras model, called &quot;model&quot;.
model.fit(...)  # This will break into the TFDBG CLI.
</code></pre><h2><span id="用tfdbg调试tf-slim">用TFDBG调试tf-slim</span></h2><p>TFDBG目前只支持训练 TF-渺茫。 为了调试培训过程，请提供<code>session_wrapper</code><br><code>slim.learning.train()</code>的<code>offline_analyzer</code>参数。例如：</p>
<pre><code>import tensorflow as tf
from tensorflow.python import debug as tf_debug

# ... Code that creates the graph and the train_op ...
tf.contrib.slim.learning_train(
    train_op,
    logdir,
    number_of_steps=10,
    session_wrapper=tf_debug.LocalCLIDebugWrapperSession)
</code></pre><h2><span id="脱机调试远程运行的会话">脱机调试远程运行的会话</span></h2><p>通常情况下，您的模型运行在远程机器上或者您没有的进程中 有终端访问权限。要在这种情况下执行模型调试，可以使用<br><code>tfdbg</code>的二元<code>Session</code>（下面描述）。它运行 转储的数据目录。这可以对较低级别的<code>Estimator</code> API完成<br>以及更高级别的<code>Experiment</code>和<code>tf.Session</code> API。</p>
<h3><span id="调试远程tfsessions">调试远程tf.Sessions</span></h3><p>如果您直接与<code>python</code>中的<code>RunOptions</code> API交互，则可以<br>配置您称为<code>Session.run()</code>方法的<code>tfdbg.watch_graph</code>原型 用<code>Session.run()</code>方法进行。<br>这将导致中间张量和运行时图被转储到一个 发生<code>offline_analyzer</code>呼叫时，您选择的共享存储位置 （以较慢的性能为代价）。例如：</p>
<pre><code>from tensorflow.python import debug as tf_debug

# ... Code where your session and graph are set up...

run_options = tf.RunOptions()
tf_debug.watch_graph(
      run_options,
      session.graph,
      debug_urls=[&quot;file:///shared/storage/location/tfdbg_dumps_1&quot;])
# Be sure to specify different directories for different run() calls.

session.run(fetches, feed_dict=feeds, options=run_options)
</code></pre><p>之后，在您有终端访问权的环境中（例如，本地 可以访问代码中指定的共享存储位置的计算机 上面），您可以加载和检查共享上的转储目录中的数据<br>通过使用<code>tfdbg</code>的<code>Session</code>二进制文件进行存储。例如：</p>
<pre><code>python -m tensorflow.python.debug.cli.offline_analyzer \
    --dump_dir=/shared/storage/location/tfdbg_dumps_1
</code></pre><p><code>DumpingDebugWrapperSession</code>包装机<code>tf_debug.DumpingDebugWrapperSession</code>提供了一个更容易，更多<br>灵活的方式来生成可离线分析的文件系统转储。 要使用它，只需将您的会话包装在<code>watch_fn</code>中即可。 例如：</p>
<pre><code># Let your BUILD target depend on &quot;//tensorflow/python/debug:debug_py
# (You don&apos;t need to worry about the BUILD dependency if you are using a pip
#  install of open-source TensorFlow.)
from tensorflow.python import debug as tf_debug

sess = tf_debug.DumpingDebugWrapperSession(
    sess, &quot;/shared/storage/location/tfdbg_dumps_1/&quot;, watch_fn=my_watch_fn)
</code></pre><p><code>Callable</code>参数接受<code>tensor</code>，允许您配置 <code>Session.run()</code>可以在不同的<code>fetches</code>呼叫上观看，作为<br><code>feed_dict</code>和<code>run()</code>到<code>debug_options</code>的呼叫等状态。</p>
<h3><span id="c-和其他语言">C ++和其他语言</span></h3><p>如果你的模型代码是用C ++或其他语言编写的，你也可以 修改<code>RunOptions</code>的<code>Estimator</code>字段以生成调试转储 可以离线检查。看到<br>原始的定义 更多细节。</p>
<h3><span id="调试远程运行tf学习估计器和实验">调试远程运行tf学习估计器和实验</span></h3><p>如果您的远程TensorFlow服务器运行<code>DumpingDebugHook</code>， 您可以使用非交互式<code>hook</code>。例如：</p>
<pre><code># Let your BUILD target depend on &quot;//tensorflow/python/debug:debug_py
# (You don&apos;t need to worry about the BUILD dependency if you are using a pip
#  install of open-source TensorFlow.)
from tensorflow.python import debug as tf_debug

hooks = [tf_debug.DumpingDebugHook(&quot;/shared/storage/location/tfdbg_dumps_1&quot;)]
</code></pre><p>那么这个<code>LocalCLIDebugHook</code>可以像<code>Estimator</code>一样使用 如前所述。<br>作为<code>Experiment</code>或<code>/shared/storage/location/tfdbg_dumps_1/run_&lt;epoch_timestamp_microsec&gt;_&lt;uuid&gt;</code>的培训和/或评估<br>发生，tfdbg创建具有以下名称模式的目录： <code>Session.run()</code>。 每个目录对应于底层的<code>fit()</code>呼叫<br><code>evaluate()</code>或<code>offline_analyzer</code>呼叫。你可以加载这些目录并检查 他们在一个命令行界面中以离线方式使用<br>由tfdbg提供的<code>lt</code>。例如：</p>
<pre><code>python -m tensorflow.python.debug.cli.offline_analyzer \
    --dump_dir=&quot;/shared/storage/location/tfdbg_dumps_1/run_&lt;epoch_timestamp_microsec&gt;_&lt;uuid&gt;&quot;
</code></pre><h2><span id="经常问的问题">经常问的问题</span></h2><p>问：<code>tfdbg&gt; run -p</code>输出左侧的时间戳是否反映了实际情况        性能在非调试会话？</p>
<p>答：不可以。调试器将额外的专用调试节点插入到        图表来记录中间张量的值。这些节点        减慢图形执行速度。如果你有兴趣分析你的<br>模型，检查出来</p>
<p>tfdbg的分析模式：<code>Session</code>。 tfprof       和其他TensorFlow分析工具。</p>
<p>问：如何将tfdbg与Bazel中的<code>&quot;//tensorflow:tensorflow_py&quot;</code>链接起来？我为什么看到一个<br>错误，如“ImportError：无法导入名称调试”？</p>
<p>答：在您的BUILD规则中，声明依赖关系：        <code>&quot;//tensorflow/python/debug:debug_py&quot;</code>和<code>Session</code>。<br>第一个是你甚至包括使用TensorFlow的依赖        没有调试器的支持;第二个启用调试器。        然后，在你的Python文件中，添加：</p>
<pre><code>from tensorflow.python import debug as tf_debug

# Then wrap your TensorFlow Session with the local-CLI wrapper.
sess = tf_debug.LocalCLIDebugWrapperSession(sess)
</code></pre><p>问：tfdbg是否帮助调试运行时错误，如形状不匹配？</p>
<p>答：是的。 tfdbg截取运行时产生的错误并呈现        在CLI中给用户一些调试指令的错误。        看例子：</p>
<pre><code># Debugging shape mismatch during matrix multiplication.
python -m tensorflow.python.debug.examples.debug_errors \
    --error shape_mismatch --debug

# Debugging uninitialized variable.
python -m tensorflow.python.debug.examples.debug_errors \
    --error uninitialized_variable --debug
</code></pre><p>问：如何让我的tfdbg包装的会话或挂钩运行调试模式 只从主线程？</p>
<p>A： 这是一个常见的用例，其中<code>thread_name_filter</code>对象是从多个使用的 线程并发。通常，子线程负责后台任务<br>如运行入队操作。通常情况下，你只想调试主 线程（或不太频繁，只有一个子线程）。你可以使用<br><code>LocalCLIDebugWrapperSession</code>的<code>Session</code>关键字参数 实现这种类型的线程选择性调试。例如，要从中调试<br>主线程，构建包装<code>MainThread</code>如下：</p>
<pre><code>sess = tf_debug.LocalCLIDebugWrapperSession(sess, thread_name_filter=&quot;MainThread$&quot;)
</code></pre><p>上面的例子依赖于Python中的主线程有这个事实 默认名称<code>tf.while_loop</code>。</p>
<p>问：我正在调试的模型非常大。数据由tfdbg转储 填补我的磁盘的可用空间。我能做什么？</p>
<p>A： 在以下任何情况下，您可能会遇到此问题：</p>
<p>具有许多中间张量的模型 非常大的中间张量 许多<code>LocalCLIDebugWrapperSession</code>迭代</p>
<p>有三种可能的解决方法或解决方案：</p>
<p><code>LocalCLIDebugHook</code>和<code>dump_root</code>的制造商    提供关键字参数<code>.*hidden.*</code>来指定路径<br>tfdbg将转储调试数据。你可以用它来让tfdbg转储    调试具有较大可用空间的磁盘上的数据。例如：</p>
<p>```python    ＃对于LocalCLIDebugWrapperSession    sess =<br>tf_debug.LocalCLIDebugWrapperSession（dump_root =“/ with / lots / of / space”）</p>
<p>＃对于LocalCLIDebugHook    hooks = [tf_debug.LocalCLIDebugHook（dump_root =“/ with<br>/ lots / of / space”）]    <code>`    确保dump_root指向的目录是空的或不存在的。    tfdbg在退出之前清理转储目录。
*减少运行过程中使用的批量。 *使用tfdbg&#39;srun</code>命令的过滤选项只能观察特定的    图中的节点。例如：</p>
<p>tfdbg&gt; run –node_name_filter。<em> hidden。</em>    tfdbg&gt;运行–op_type_filter变量。<em><br>tfdbg&gt; run –tensor_dtype_filter int。</em></p>
<p>上面的第一个命令只监视名字匹配的节点    正则表达模式<code>Variable.*</code>。第二个命令只监视    名称与<code>int.*</code>型号匹配的操作。第三个手表<br>只有与<code>int32</code>型（例如<code>mouse off</code>）匹配的张量。</p>
<p>问：为什么我不能在tfdbg CLI中选择文本？</p>
<p>答：这是因为tfdbg CLI通过在终端中启用鼠标事件        默认。这个鼠标掩码模式        覆盖默认的终端交互，包括文本选择。您<br>可以使用命令<code>m off</code>或者重新启用文本选择        <code>a</code>。</p>
<p>问：为什么在调试下面的代码时，tfdbg CLI显示没有转储张量？</p>
<pre><code>a = tf.ones([10], name=&quot;a&quot;)
b = tf.add(a, a, name=&quot;b&quot;)
sess = tf.Session()
sess = tf_debug.LocalCLIDebugWrapperSession(sess)
sess.run(b)
</code></pre><p>- 答：你看到没有数据倾倒的原因是因为在每个节点        执行的TensorFlow图形由TensorFlow运行时间不断折叠。<br>在这个层面上，<code>b</code>是一个常数张量;因此，取而代之        张量<code>a</code>也是一个常量张量。 TensorFlow的图表<br>优化将包含<code>b</code>和<code>tfdbg</code>的图形折叠成一个        以加速图形的未来运行，这也是<code>a</code>的原因<br>不会产生任何中间张量转储。但是，如果<code>tf.Variable</code>是一个        <code>tfdbg</code>，如下例所示：</p>
<pre><code>import numpy as np

a = tf.Variable(np.ones[10], name=&quot;a&quot;)
b = tf.add(a, a, name=&quot;b&quot;)
sess = tf.Session()
sess.run(tf.global_variables_initializer())
sess = tf_debug.LocalCLIDebugWrapperSession(sess)
sess.run(b)
</code></pre><p>CXJ743-HDK-53L将不会出现恒定折叠的情况 张量转储。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/summaries_and_tensorboard/" title="TensorBoard：可视化学习" itemprop="url">TensorBoard：可视化学习</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="tensorboard可视化学习">TensorBoard：可视化学习</span></h1><p>你将使用TensorFlow进行计算 - 就像训练一个巨大的 深度神经网络 - 可能是复杂和混乱的。为了更容易<br>理解，调试和优化TensorFlow程序，我们已经包含了一套 可视化工具称为TensorBoard。您可以使用TensorBoard进行可视化<br>您的TensorFlow图表，绘制关于您的执行的量化指标 图表，并显示其他数据，如通过它的图像。什么时候 TensorBoard完全配置，看起来像这样：</p>
<p><img src="https://www.tensorflow.org/images/mnist_tensorboard.png" alt="MNIST TensorBoard"></p>
<p>本教程旨在让您开始使用简单的TensorBoard。 还有其他资源可用！ TensorBoard的GitHub<br>有更多关于TensorBoard使用情况的信息，包括提示和技巧 调试信息。</p>
<h2><span id="序列化数据">序列化数据</span></h2><p>TensorBoard通过读取包含摘要的TensorFlow事件文件来操作 运行TensorFlow时可以生成的数据。一般来说<br>TensorBoard中的摘要数据的生命周期。</p>
<p>首先，创建您想要收集摘要的TensorFlow图表 数据，并决定你想注释哪个节点 总结操作。</p>
<p>例如，假设你正在训练一个卷积神经网络 识别MNIST数字。你想记录如何学习率 随时间变化，目标函数如何变化。通过收集这些<br>附加<code>tf.summary.scalar</code>操作 到分别输出学习率和损失的节点。然后，给<br>每个<code>scalar_summary</code>一个有意义的<code>tag</code>，就像<code>&#39;learning rate&#39;</code>或“损失 功能’。</p>
<p>也许你也想看到即将到来的激活分布 关闭特定层，或者分布梯度或权重。搜集 这个数据通过附加 <code>tf.summary.histogram</code>选择<br>梯度输出和分别保存你的权重的变量。</p>
<p>有关所有可用摘要操作的详细信息，请查看文档 总结操作。</p>
<p>在运行之前，TensorFlow中的操作不会执行任何操作 取决于他们的输出。我们刚刚创建的摘要节点是 你的图形的外围设备：你当前运行的操作系统都不依赖于它<br>他们。所以，为了生成摘要，我们需要运行所有这些汇总节点。 用手来管理它们将是乏味的，所以使用 <code>tf.summary.merge_all</code><br>将它们组合成一个单独的操作来生成所有的汇总数据。</p>
<p>然后，您可以运行合并的摘要操作，这将生成一个序列化 <code>Summary</code> protobuf对象与给定步骤中的所有摘要数据。<br>最后，要将这个汇总数据写入磁盘，请将summary protobuf传递给一个 <code>tf.summary.FileWriter</code>。</p>
<p><code>FileWriter</code>在其构造函数中使用了一个logdir - 这个logdir是相当的 重要的是，这是所有事件将被写出的目录。<br>而且，<code>FileWriter</code>可以选择在其构造器中使用<code>Graph</code>。 如果它收到一个<code>Graph</code>对象，那么TensorBoard将显示您的图形<br>连同张量形状信息。这会给你一个更好的感觉 图中流动的东西：看 张量形状信息。</p>
<p>现在你已经修改了你的图表，并有一个<code>FileWriter</code>，你准备好了 开始运行你的网络！如果你愿意，你可以运行合并的摘要操作<br>每一步，并记录大量的训练数据。这可能更多 数据比你需要，虽然。相反，请考虑运行合并的摘要操作 每个<code>n</code>步骤。</p>
<p>下面的代码示例是对其的修改 简单的MNIST教程， 我们在其中添加了一些摘要操作，并且每十步执行一次。如果你 运行这个，然后启动<code>tensorboard
--logdir=/tmp/tensorflow/mnist</code>，你就可以 统计数据的可视化，例如权重或准确度如何变化 训练。下面的代码是摘录;完整的来源是<br>这里。</p>
<pre><code>def variable_summaries(var):
  &quot;&quot;&quot;Attach a lot of summaries to a Tensor (for TensorBoard visualization).&quot;&quot;&quot;
  with tf.name_scope(&apos;summaries&apos;):
    mean = tf.reduce_mean(var)
    tf.summary.scalar(&apos;mean&apos;, mean)
    with tf.name_scope(&apos;stddev&apos;):
      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))
    tf.summary.scalar(&apos;stddev&apos;, stddev)
    tf.summary.scalar(&apos;max&apos;, tf.reduce_max(var))
    tf.summary.scalar(&apos;min&apos;, tf.reduce_min(var))
    tf.summary.histogram(&apos;histogram&apos;, var)

def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):
  &quot;&quot;&quot;Reusable code for making a simple neural net layer.

  It does a matrix multiply, bias add, and then uses relu to nonlinearize.
  It also sets up name scoping so that the resultant graph is easy to read,
  and adds a number of summary ops.
  &quot;&quot;&quot;
  # Adding a name scope ensures logical grouping of the layers in the graph.
  with tf.name_scope(layer_name):
    # This Variable will hold the state of the weights for the layer
    with tf.name_scope(&apos;weights&apos;):
      weights = weight_variable([input_dim, output_dim])
      variable_summaries(weights)
    with tf.name_scope(&apos;biases&apos;):
      biases = bias_variable([output_dim])
      variable_summaries(biases)
    with tf.name_scope(&apos;Wx_plus_b&apos;):
      preactivate = tf.matmul(input_tensor, weights) + biases
      tf.summary.histogram(&apos;pre_activations&apos;, preactivate)
    activations = act(preactivate, name=&apos;activation&apos;)
    tf.summary.histogram(&apos;activations&apos;, activations)
    return activations

hidden1 = nn_layer(x, 784, 500, &apos;layer1&apos;)

with tf.name_scope(&apos;dropout&apos;):
  keep_prob = tf.placeholder(tf.float32)
  tf.summary.scalar(&apos;dropout_keep_probability&apos;, keep_prob)
  dropped = tf.nn.dropout(hidden1, keep_prob)

# Do not apply softmax activation yet, see below.
y = nn_layer(dropped, 500, 10, &apos;layer2&apos;, act=tf.identity)

with tf.name_scope(&apos;cross_entropy&apos;):
  # The raw formulation of cross-entropy,
  #
  # tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.softmax(y)),
  #                               reduction_indices=[1]))
  #
  # can be numerically unstable.
  #
  # So here we use tf.nn.softmax_cross_entropy_with_logits on the
  # raw outputs of the nn_layer above, and then average across
  # the batch.
  diff = tf.nn.softmax_cross_entropy_with_logits(targets=y_, logits=y)
  with tf.name_scope(&apos;total&apos;):
    cross_entropy = tf.reduce_mean(diff)
tf.summary.scalar(&apos;cross_entropy&apos;, cross_entropy)

with tf.name_scope(&apos;train&apos;):
  train_step = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(
      cross_entropy)

with tf.name_scope(&apos;accuracy&apos;):
  with tf.name_scope(&apos;correct_prediction&apos;):
    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
  with tf.name_scope(&apos;accuracy&apos;):
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
tf.summary.scalar(&apos;accuracy&apos;, accuracy)

# Merge all the summaries and write them out to /tmp/mnist_logs (by default)
merged = tf.summary.merge_all()
train_writer = tf.summary.FileWriter(FLAGS.summaries_dir + &apos;/train&apos;,
                                      sess.graph)
test_writer = tf.summary.FileWriter(FLAGS.summaries_dir + &apos;/test&apos;)
tf.global_variables_initializer().run()
</code></pre><p>在我们初始化了<code>FileWriters</code>之后，我们必须添加总结 <code>FileWriters</code>在我们训练和测试模型。</p>
<pre><code># Train the model, and also write summaries.
# Every 10th step, measure test-set accuracy, and write test summaries
# All other steps, run train_step on training data, &amp; add training summaries

def feed_dict(train):
  &quot;&quot;&quot;Make a TensorFlow feed_dict: maps data onto Tensor placeholders.&quot;&quot;&quot;
  if train or FLAGS.fake_data:
    xs, ys = mnist.train.next_batch(100, fake_data=FLAGS.fake_data)
    k = FLAGS.dropout
  else:
    xs, ys = mnist.test.images, mnist.test.labels
    k = 1.0
  return {x: xs, y_: ys, keep_prob: k}

for i in range(FLAGS.max_steps):
  if i % 10 == 0:  # Record summaries and test-set accuracy
    summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(False))
    test_writer.add_summary(summary, i)
    print(&apos;Accuracy at step %s: %s&apos; % (i, acc))
  else:  # Record train set summaries, and train
    summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(True))
    train_writer.add_summary(summary, i)
</code></pre><p>您现在已经开始使用TensorBoard将这些数据可视化了。</p>
<h2><span id="启动tensorboard">启动TensorBoard</span></h2><p>要运行TensorBoard，请使用以下命令（或者使用python -m tensorboard.main）</p>
<pre><code>tensorboard --logdir=path/to/log-directory
</code></pre><p><code>logdir</code>指向<code>FileWriter</code>串行化的目录 数据。如果这个<code>logdir</code>目录包含包含子目录<br>序列化的数据从单独的运行，然后TensorBoard将可视化的数据 从所有这些运行。一旦TensorBoard正在运行，浏览您的网页浏览器<br>以<code>localhost:6006</code>来查看张量板。</p>
<p>在看TensorBoard时，你会看到右上角的导航标签 角。每个选项卡代表一组可以可视化的序列化数据。</p>
<p>有关如何使用图形选项卡可视化图形的深入信息， 参见TensorBoard：Graph Visualization。</p>
<p>有关TensorBoard的更多使用信息，请参阅TensorBoard的GitHub。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  


  <nav id="page-nav" class="clearfix">
    <a class="extend prev" rel="prev" href="/page/120/"><span></span>Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/119/">119</a><a class="page-number" href="/page/120/">120</a><span class="page-number current">121</span><a class="page-number" href="/page/122/">122</a><a class="page-number" href="/page/123/">123</a><span class="space">&hellip;</span><a class="page-number" href="/page/157/">157</a><a class="extend next" rel="next" href="/page/122/">Next<span></span></a>
  </nav>

</div>

      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- side-bar-ad -->
<ins class="adsbygoogle"
     style="display:block; overflow:hidden;"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="2232545787"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


  


  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/javascript/" title="javascript">javascript<sup>207</sup></a></li>
			
		
			
				<li><a href="/tags/java/" title="java">java<sup>205</sup></a></li>
			
		
			
				<li><a href="/tags/html/" title="html">html<sup>203</sup></a></li>
			
		
			
				<li><a href="/tags/python/" title="python">python<sup>199</sup></a></li>
			
		
			
				<li><a href="/tags/bash/" title="bash">bash<sup>198</sup></a></li>
			
		
			
				<li><a href="/tags/php/" title="php">php<sup>197</sup></a></li>
			
		
			
				<li><a href="/tags/css/" title="css">css<sup>88</sup></a></li>
			
		
			
				<li><a href="/tags/shell/" title="shell">shell<sup>78</sup></a></li>
			
		
			
				<li><a href="/tags/jquery/" title="jquery">jquery<sup>61</sup></a></li>
			
		
			
				<li><a href="/tags/linux/" title="linux">linux<sup>57</sup></a></li>
			
		
			
				<li><a href="/tags/机器学习/" title="机器学习">机器学习<sup>41</sup></a></li>
			
		
			
				<li><a href="/tags/unix/" title="unix">unix<sup>30</sup></a></li>
			
		
			
				<li><a href="/tags/mysql/" title="mysql">mysql<sup>17</sup></a></li>
			
		
			
				<li><a href="/tags/html5/" title="html5">html5<sup>16</sup></a></li>
			
		
			
				<li><a href="/tags/xml/" title="xml">xml<sup>13</sup></a></li>
			
		
			
				<li><a href="/tags/http/" title="http">http<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/区块链/" title="区块链">区块链<sup>1</sup></a></li>
			
		
			
		
			
		
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
        
          <li>
            
            	<a href="https://tracholar.github.io" target="_blank" title="个人博客">个人博客</a>
            
          </li>
        
    </ul>
</div>

  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS</a>
</div>

</aside>
</div>

    </div>
    <footer><div id="footer" >
	
	
	<section class="info">
		<p> To be or not to be, that is a question. <br/>
			This is my blog,believe it or not.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		版权所有 © 2018 本站文章未经同意，禁止转载！作者：
		
		<a href="/about" target="_blank" title="zhizi">zhizi</a>
		


		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>












<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->





<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="Back to Top"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
