
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>智子</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="zhizi">
    

    
    <meta name="description" content="IT技术、编程、web开发以及新兴的技术翻译与总结">
<meta property="og:type" content="website">
<meta property="og:title" content="智子">
<meta property="og:url" content="https://www.tracholar.top/page/121/index.html">
<meta property="og:site_name" content="智子">
<meta property="og:description" content="IT技术、编程、web开发以及新兴的技术翻译与总结">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="智子">
<meta name="twitter:description" content="IT技术、编程、web开发以及新兴的技术翻译与总结">

    
    <link rel="alternative" href="/atom.xml" title="智子" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">

    <!-- ad start -->
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-6300557868920774",
    enable_page_level_ads: true
  });
</script>

    <!-- ad end -->

    <!--  stat -->
    <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?4036f580b1119e720db871571faa68cc";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-78529611-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-78529611-1');
</script>

    <!-- end stat -->
</head>

  <body>
    <header>
      
<div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="智子">智子</a></h1>
				<h2 class="blog-motto">智子之家</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:www.tracholar.top">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main">


   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/02/how-to-check-whether-a-checkbox-is-checked-in-jquery/" title="如何检查复选框是否在jQuery中检查？" itemprop="url">如何检查复选框是否在jQuery中检查？</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-02T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-02</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>我需要检查复选框的<code>checked</code>属性，并使用jQuery根据选中的属性执行操作。</p>
<p>例如，如果年龄复选框被选中，那么我需要显示一个文本框输入年龄，否则隐藏文本框。</p>
<p>但是下面的代码默认返回<code>false</code>：</p>
<pre><code>if($(&apos;#isAgeSelected&apos;).attr(&apos;checked&apos;)) {
    $(&quot;#txtAge&quot;).show();
} else {
    $(&quot;#txtAge&quot;).hide();
}
</code></pre><p>如何成功查询<code>checked</code>属性？</p>
        
        
        <p class="article-more-link">
          
            <a href="/2018/01/02/how-to-check-whether-a-checkbox-is-checked-in-jquery/#more">Read More</a>
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/javascript/">javascript</a><a href="/tags/jquery/">jquery</a><a href="/tags/html/">html</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  
      <ins class="adsbygoogle"
     style="display:block;  overflow:hidden;"
     data-ad-format="fluid"
     data-ad-layout-key="-ej+6f-q-c7+ou"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="5206371097"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/02/auto-scale-textview-text-to-fit-within-bounds/" title="自动缩放TextView文本以适合边界" itemprop="url">自动缩放TextView文本以适合边界</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-02T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-02</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>我正在寻找一个最佳方式来调整<code>TextView</code>中的包装文本的大小，以便它适合在其getHeight和getWidth范围内。我不是简单地寻找一种方式来包装文本</p>
<ul>
<li>我想确保它包装和足够小，完全适合在屏幕上。</li>
</ul>
<p>我在StackOverflow上看到了一些需要自动调整大小的例子，但是它们或者是非常特殊的黑客解决方案，没有解决方案，或者是递归地重新绘制<code>TextView</code>，直到它足够小（这是内存激烈的，用户每次递归观看文本缩小步骤）。</p>
<p>但是我确定有人在那里找到了一个不涉及我所做事情的好方法：编写几个沉重的例程来分析和测量文本，调整文本的大小，并重复，直到找到适当的小尺寸。</p>
<p><code>TextView</code>使用哪些例程来包装文本？难道不能以某种方式来预测文字是否足够小？</p>
<p>tl; dr：是否有一种最佳实践方式来自动调整<code>TextView</code>的大小，使其适合包装在其getHeight和getWidth范围内？</p>
        
        
        <p class="article-more-link">
          
            <a href="/2018/01/02/auto-scale-textview-text-to-fit-within-bounds/#more">Read More</a>
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/android_build/" title="在Android上构建TensorFlow" itemprop="url">在Android上构建TensorFlow</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="在android上构建tensorflow">在Android上构建TensorFlow</span></h1><p>为了让您开始在Android上使用TensorFlow，我们将介绍两个 如何构建我们的TensorFlow移动演示并在Android上进行部署<br>设备。首先是Android Studio，它可以让你在一个 IDE。第二个是与Bazel合作，并与ADB一起部署 线。</p>
<p>为什么要选择这些方法之一？</p>
<p>在Android上使用TensorFlow最简单的方法就是使用Android Studio。如果你<br>不打算自定义您的TensorFlow构建，或者如果你想使用 Android Studio的编辑器和其他功能来构建一个应用程序，只是想添加<br>TensorFlow，我们推荐使用Android Studio。</p>
<p>如果您正在使用自定义操作，或有其他原因来构建TensorFlow 从头开始，向下滚动并查看我们的说明 用于与Bazel一起构建演示。</p>
<h2><span id="使用android-studio构建演示">使用Android Studio构建演示</span></h2><p>先决条件</p>
<p>如果还没有，请做以下两件事：</p>
<p>安装Android Studio，   遵循其网站上的指示。 从Github克隆TensorFlow存储库： git clone<br><a href="https://github.com/tensorflow/tensorflow" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow</a></p>
<p>建造</p>
<p>打开Android Studio，然后从欢迎屏幕中选择打开一个现有的    Android Studio项目。<br>在出现的打开文件或项目窗​​口中，导航至并选择     从克隆的<code>tensorflow/examples/android</code>目录     TensorFlow<br>Github回购。点击OK。 如果它要求您执行Gradle同步，请单击确定。 您可能还需要安装各种平台和工具<br>像“无法找到与哈希字符串’android-23’目标和类似的错误。 打开<code>build.gradle</code>文件（可以在侧面板中进入1：Project<br>并在Android下的Gradle Scripts zippy下找到它）。寻找<br><code>nativeBuildSystem</code>变量，如果它尚未设置为<code>none</code>： //设置为“bazel”，“cmake”，“makefile”，“none”<br>def nativeBuildSystem =’none’ 点击运行按钮（绿色箭头）或使用运行 - &gt;运行’android’从顶部菜单。<br>如果要求您使用“即时运行”，请单击“不进行即时运行”。 此外，你需要有一个Android设备插入开发人员选项 在此启用 点。看到这里<br>有关设置开发人员设备的更多细节。</p>
<p>这会在您的手机上安装三个全部属于TensorFlow的应用程序 演示。有关更多信息，请参阅Android示例应用程序 他们。</p>
<h2><span id="使用android-studio将tensorflow添加到您的应用程序">使用Android Studio将TensorFlow添加到您的应用程序</span></h2><p>要在您的Android上添加TensorFlow到您自己的应用程序，最简单的方法是添加 跟随你的Gradle构建文件的行：</p>
<pre><code>allprojects {
    repositories {
        jcenter()
    }
}

dependencies {
    compile &apos;org.tensorflow:tensorflow-android:+&apos;
}
</code></pre><p>这会自动下载TensorFlow的最新稳定版本作为AAR 并将其安装到您的项目中。</p>
<h2><span id="使用bazel构建演示">使用Bazel构建演示</span></h2><p>在Android上使用TensorFlow的另一种方法是构建一个APK 使用Bazel并将其加载到您的设备上 使用亚行。这个<br>需要一些构建系统和Android开发人员工具的知识，但我们会 引导你通过这里的基础知识。</p>
<p>首先，按照我们的说明进行安装   源。这也将引导你通过安装Bazel和克隆   TensorFlow代码。 下载Android SDK<br>和NDK，如果你这样做   还没有他们。你至少需要版本12b的NDK，和23的   SDK。 在您的TensorFlow源的副本中，更新   工作区<br>文件与您的SDK和NDK的位置，它表示   和。 运行Bazel构建演示APK： bazel build -c opt // tensorflow /<br>examples / android：tensorflow_demo 用亚行来   将APK安装到您的设备上： adb install -r bazel-<br>bin / tensorflow / examples / android / tensorflow_demo.apk</p>
<p>注意：一般来说，当您需要使用Bazel编译Android时 Bazel命令行上的<code>--config=android</code>，尽管在这种情况下是这样的<br>特别的例子是Android，所以你不需要它。</p>
<p>这会在您的手机上安装三个全部属于TensorFlow的应用程序 演示。有关更多信息，请参阅Android示例应用程序 他们。</p>
<h2><span id="android示例应用程序">Android示例应用程序</span></h2><p>该 Android示例代码是 一个项目，建立和安装三个示例应用程序，都使用 相同的底层代码。示例应用程序都从电话的视频输入 相机：</p>
<p>TF Classify使用Inception v3模型来标记指向的对象   来自Imagenet的课程。 Imagenet只有1000个类别，<br>它错过了大多数的日常物品，包括很多你不太可能的东西   经常在现实生活中遇到，所以结果往往会相当有趣。对于<br>例如没有“人物”类别，相反，它会经常猜测它的事情   知道经常与人的照片，如安全带相关联   或氧气面罩。如果你想要自定义这个例子来识别<br>你关心的对象，你可以使用   该   TensorFlow for Poets codelab as   一个如何根据自己的数据来训练模型的例子。 TF<br>Detect使用一个多盒子模型试图绘制周围的边界框   人在摄像机的位置。这些框用注释   对每个检测结果都有信心。结果将不会完美，因为这一点<br>对象检测仍然是一个活跃的研究课题。演示也   包括光学追踪物体在帧之间移动的时间   比TensorFlow推断更频繁。这改善了用户<br>经验以来，表观帧率更快，但它也给了   能够估计哪些方框指的是帧之间的同一个对象，   对于随着时间的推移计数对象是重要 TF<br>Stylize在相机上实现实时样式的传输算法   饲料。您可以选择使用哪种样式，并使用它们在它们之间进行混合   在屏幕底部的调色板，也切换出的分辨率<br>处理去更高或更低雷斯。</p>
<p>当您构建并安装演示程序时，您会在手机上看到三个应用程序图标， 每个演示一个。点击他们应该打开应用程序，让你<br>探索他们做什么。您可以通过点击在屏幕上启用分析统计 音量提高按钮，而他们正在运行。</p>
<h3><span id="android推理库">Android推理库</span></h3><p>由于Android应用程序需要用Java编写，核心TensorFlow用C ++编写， TensorFlow有一个JNI库来连接两者。它的接口是针对的<br>只有在推理，所以它提供了加载图形，设置输入， 并运行模型来计算特定的输出。你可以看到满的 文档中的最小的一套方法<br>TensorFlowInferenceInterface.java</p>
<p>演示应用程序使用这个接口，所以他们是一个好地方寻找 示例用法。您可以下载预先构建的二进制罐 在 ci.tensorflow.org。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/mandelbrot/" title="Mandelbrot集合" itemprop="url">Mandelbrot集合</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="mandelbrot集合">Mandelbrot集合</span></h1><p>可视化Mandelbrot集 和机器学习没有任何关系，但是却很有趣 例如如何使用TensorFlow进行一般数学。这是<br>实际上是一个非常朴素的可视化实现，但它使得 点。 （我们最终可能会提供更详尽的实施 产生更真实美丽的图像。）</p>
<h2><span id="基本设置">基本设置</span></h2><p>我们需要一些导入来开始。</p>
<pre><code># Import libraries for simulation
import tensorflow as tf
import numpy as np

# Imports for visualization
import PIL.Image
from io import BytesIO
from IPython.display import Image, display
</code></pre><p>现在我们将定义一个函数来实际显示图像 迭代计数。</p>
<pre><code>def DisplayFractal(a, fmt=&apos;jpeg&apos;):
  &quot;&quot;&quot;Display an array of iteration counts as a
     colorful picture of a fractal.&quot;&quot;&quot;
  a_cyclic = (6.28*a/20.0).reshape(list(a.shape)+[1])
  img = np.concatenate([10+20*np.cos(a_cyclic),
                        30+50*np.sin(a_cyclic),
                        155-80*np.cos(a_cyclic)], 2)
  img[a==a.max()] = 0
  a = img
  a = np.uint8(np.clip(a, 0, 255))
  f = BytesIO()
  PIL.Image.fromarray(a).save(f, fmt)
  display(Image(data=f.getvalue()))
</code></pre><h2><span id="会话和变量初始化">会话和变量初始化</span></h2><p>为了像这样玩耍，我们经常使用交互式会话，但是经常使用 会议也将工作。</p>
<pre><code>sess = tf.InteractiveSession()
</code></pre><p>我们可以自由地混合NumPy和TensorFlow。</p>
<pre><code># Use NumPy to create a 2D array of complex numbers

Y, X = np.mgrid[-1.3:1.3:0.005, -2:1:0.005]
Z = X+1j*Y
</code></pre><p>现在我们定义并初始化TensorFlow张量。</p>
<pre><code>xs = tf.constant(Z.astype(np.complex64))
zs = tf.Variable(xs)
ns = tf.Variable(tf.zeros_like(xs, tf.float32))
</code></pre><p>TensorFlow要求您在使用变量之前明确地初始化变量。</p>
<pre><code>tf.global_variables_initializer().run()
</code></pre><h2><span id="定义和运行计算">定义和运行计算</span></h2><p>现在我们指定更多的计算…</p>
<pre><code># Compute the new values of z: z^2 + x
zs_ = zs*zs + xs

# Have we diverged with this new value?
not_diverged = tf.abs(zs_) &lt; 4

# Operation to update the zs and the iteration count.
#
# Note: We keep computing zs after they diverge! This
#       is very wasteful! There are better, if a little
#       less simple, ways to do this.
#
step = tf.group(
  zs.assign(zs_),
  ns.assign_add(tf.cast(not_diverged, tf.float32))
  )
</code></pre><p>…并运行它几百步</p>
<pre><code>for i in range(200): step.run()
</code></pre><p>让我们看看我们有什么。</p>
<pre><code>DisplayFractal(ns.eval())
</code></pre><p><img src="https://www.tensorflow.org/images/mandelbrot_output.jpg" alt="jpeg"></p>
<p>不错！</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/kernel_methods/" title="用显式核方法改进线性模型" itemprop="url">用显式核方法改进线性模型</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="用显式核方法改进线性模型">用显式核方法改进线性模型</span></h1><p>在本教程中，我们将演示如何组合（显式）的内核方法 线性模型可以大大提高后者的预测质量 而不会显着增加训练和推理时间。不像双重<br>内核方法，显式（原始）内核方法可以很好地扩展 训练数据集在训练/推理时间和方面 内存要求。</p>
<p>目标读者：即使我们提供了概念的高层次概述 与显式内核方法相关，本教程主要针对读者 已经至少有内核方法和支持向量的基本知识<br>机器（SVM）。如果您对内核方法不熟悉，请参阅以下任一内核方法 以下来源介绍：</p>
<p>如果你有一个强大的数学背景： 机器学习中的核心方法 内核方法维基百科页面</p>
<p>目前，TensorFlow仅支持密集特征的显式核心映射; TensorFlow将在稍后的版本中提供对稀疏功能的支持。</p>
<p>本教程使用tf.contrib.learn （TensorFlow的高级机器学习API）我们的ML模型的估计器。<br>如果你不熟悉这个API，tf.estimator快速入门 是一个开始的好地方。我们将使用MNIST数据集。教程包括 以下步骤：</p>
<p>加载并准备MNIST数据进行分类。 构建一个简单的线性模型，对其进行训练，并在评估数据上进行评估。 用线性模型替换线性模型，重新训练和 重新评估。</p>
<h2><span id="加载并准备mnist数据进行分类">加载并准备MNIST数据进行分类</span></h2><p>运行以下实用程序命令加载MNIST数据集：</p>
<pre><code>data = tf.contrib.learn.datasets.mnist.load_mnist()
</code></pre><p>上述方法加载整个MNIST数据集（包含70K个样本）和 将其分为55K，5K和10K样本的训练，验证和测试数据<br>分别。每个拆分包含一个numpy阵列的图像（与形状 [sample_size，784]），另一个用于标签（形状为[sample_size，1]）。在这<br>教程，我们只使用火车和验证分组来训练和评估我们的 模型。</p>
<p>为了将数据提供给tf.contrib.learn估算器，转换是有帮助的 它对张量。为此，我们将使用添加Ops的<code>input function</code><br>TensorFlow图表，当执行时，创建要使用的小批量的张量 下游。有关输入功能的更多背景信息，请检查 用tf.contrib.learn构建输入函数。在这<br>例如，我们将使用除转换之外的<code>tf.train.shuffle_batch</code> Op num数组到Tensors，允许我们指定batch_size和是否<br>每次执行input_fn Ops时随机化输入（随机化 通常在训练期间加速收敛）。完整的代码加载和 准备数据显示在下面的代码片段中。在这个例子中，我们使用<br>256个小批量培训和整个样本（5K条目） 评价。随意尝试不同的批量大小。</p>
<pre><code>import numpy as np
import tensorflow as tf

def get_input_fn(dataset_split, batch_size, capacity=10000, min_after_dequeue=3000):

  def _input_fn():
    images_batch, labels_batch = tf.train.shuffle_batch(
        tensors=[dataset_split.images, dataset_split.labels.astype(np.int32)],
        batch_size=batch_size,
        capacity=capacity,
        min_after_dequeue=min_after_dequeue,
        enqueue_many=True,
        num_threads=4)
    features_map = {&apos;images&apos;: images_batch}
    return features_map, labels_batch

  return _input_fn

data = tf.contrib.learn.datasets.mnist.load_mnist()

train_input_fn = get_input_fn(data.train, batch_size=256)
eval_input_fn = get_input_fn(data.validation, batch_size=5000)
</code></pre><h2><span id="培训一个简单的线性模型">培训一个简单的线性模型</span></h2><p>现在我们可以在MNIST数据集上训练一个线性模型。我们将使用 <code>tf.contrib.learn.LinearClassifier</code>估计器有10个类代表<br>10位数字。输入特征形成一个784维密集的矢量，可以 具体说明如下：</p>
<pre><code>image_column = tf.contrib.layers.real_valued_column(&apos;images&apos;, dimension=784)
</code></pre><p>用于构建，训练和评估LinearClassifier的完整代码 估算器如下：</p>
<pre><code>import time

# Specify the feature(s) to be used by the estimator.
image_column = tf.contrib.layers.real_valued_column(&apos;images&apos;, dimension=784)
estimator = tf.contrib.learn.LinearClassifier(feature_columns=[image_column], n_classes=10)

# Train.
start = time.time()
estimator.fit(input_fn=train_input_fn, steps=2000)
end = time.time()
print(&apos;Elapsed time: {} seconds&apos;.format(end - start))

# Evaluate and report metrics.
eval_metrics = estimator.evaluate(input_fn=eval_input_fn, steps=1)
print(eval_metrics)
</code></pre><p>下表总结了评估数据的结果。</p>
<table>
<thead>
<tr>
<th>metric</th>
<th>value  </th>
</tr>
</thead>
<tbody>
<tr>
<td>loss</td>
<td>0.25 to 0.30  </td>
</tr>
<tr>
<td>accuracy</td>
<td>92.5%  </td>
</tr>
<tr>
<td>training time</td>
<td>~25 seconds on my machine  </td>
</tr>
</tbody>
</table>
<p>注意：度量标准会根据各种因素而有所不同。</p>
<p>除了尝试（培训）批量大小和数量 训练步骤，还有其他一些可以调整的参数。 例如，您可以更改用于最小化损失的优化方法 通过显式选择集合中的另一个优化器<br>可用的优化器。 作为一个例子，下面的代码构造了一个LinearClassifier估计器 使用遵循正则化领导者（FTRL）的优化策略<br>具体学习率和L2正则化。</p>
<pre><code>optimizer = tf.train.FtrlOptimizer(learning_rate=5.0, l2_regularization_strength=1.0)
estimator = tf.contrib.learn.LinearClassifier(
    feature_columns=[image_column], n_classes=10, optimizer=optimizer)
</code></pre><p>无论参数的值如何，最大精度都是一个线性模型 可以在这个数据集上达到93％左右。</p>
<h2><span id="使用线性模型的显式核映射">使用线性模型的显式核映射。</span></h2><p>MNIST上线性模型的相对较高的误差（〜7％）表明 输入数据不是线性可分的。我们将使用显式的内核映射 减少分类错误。</p>
<p>直觉：高层次的想法是使用非线性映射来转换 输入空间到另一个特征空间（可能更高的维度） （变换）的特征是（几乎）线性可分的，然后应用一个线性的<br>模型映射的功能。如下图所示：</p>
<p><img src="https://www.tensorflow.org/versions/master/images/kernel_mapping.png" alt=""></p>
<h3><span id="技术细节">技术细节</span></h3><p>在这个例子中，我们将使用随机傅立叶特征，在中引入 “大规模内核机器的随机特性” 由Rahimi和Recht撰写的论文来绘制输入数据。随机傅立叶特征映射a<br>（\ mathbf {x} \ in \ mathbb {R} ^ d \）到\（\ mathbf {x’} \ in \ mathbb {R} ^ D<br>\） 通过以下映射：</p>
<p>$$ RFFM(\cdot): \mathbb{R}^d \to \mathbb{R}^D, \quad RFFM(\mathbf{x}) =<br>\cos(\mathbf{\Omega} \cdot \mathbf{x}+ \mathbf{b}) $$</p>
<p>其中\（\ mathbf {\ Omega} \ in \ mathbb {R} ^ {D \ times d} \）， \（\ mathbf {x} \<br>in \ mathbb {R} ^ d，\）\（\ mathbf {b} \ in \ mathbb {R} ^ D \）和 余弦应用于元素明智的。</p>
<p>在这个例子中，\（\ mathbf {\ Omega} \）和\（\ mathbf {b} \）的条目是 从分布取样，使映射满足以下内容 属性：</p>
<p>$$ RFFM(\mathbf{x})^T \cdot RFFM(\mathbf{y}) \approx e^{-\frac{|\mathbf{x} -<br>\mathbf{y}|^2}{2 \sigma^2}} $$</p>
<p>上面表达式的右边的量被称为RBF（或 高斯）核函数。这个函数是使用最广泛的内核之一 在机器学习中的功能并且隐含地测量不同的， 比原来的尺寸高得多。看到<br>径向基函数内核 更多细节。</p>
<h3><span id="内核分类器">内核分类器</span></h3><p><code>tf.contrib.kernel_methods.KernelLinearClassifier</code>是预包装的<br><code>tf.contrib.learn</code>估算器结合了显式核映射的功能 与线性模型。它的构造函数几乎和 LinearClassifier估计器与附加选项指定的列表<br>明确的内核映射被应用到分类器使用的每个特征。该 以下代码片段演示了如何用LinearClassifier替换 KernelLinearClassifier。</p>
<pre><code># Specify the feature(s) to be used by the estimator. This is identical to the
# code used for the LinearClassifier.
image_column = tf.contrib.layers.real_valued_column(&apos;images&apos;, dimension=784)
optimizer = tf.train.FtrlOptimizer(
   learning_rate=50.0, l2_regularization_strength=0.001)

kernel_mapper = tf.contrib.kernel_methods.RandomFourierFeatureMapper(
  input_dim=784, output_dim=2000, stddev=5.0, name=&apos;rffm&apos;)
kernel_mappers = {image_column: [kernel_mapper]}
estimator = tf.contrib.kernel_methods.KernelLinearClassifier(
   n_classes=10, optimizer=optimizer, kernel_mappers=kernel_mappers)

# Train.
start = time.time()
estimator.fit(input_fn=train_input_fn, steps=2000)
end = time.time()
print(&apos;Elapsed time: {} seconds&apos;.format(end - start))

# Evaluate and report metrics.
eval_metrics = estimator.evaluate(input_fn=eval_input_fn, steps=1)
print(eval_metrics)
</code></pre><p>传递给<code>KernelLinearClassifier</code>的唯一附加参数是字典 从feature_columns到要应用于内核映射的列表<br>对应的功能栏。以下几行指示分类器 首先将初始784维图像映射到2000维矢量 随机傅立叶特征，然后学习转换后的线性模型 向量：</p>
<pre><code>kernel_mapper = tf.contrib.kernel_methods.RandomFourierFeatureMapper(
  input_dim=784, output_dim=2000, stddev=5.0, name=&apos;rffm&apos;)
kernel_mappers = {image_column: [kernel_mapper]}
estimator = tf.contrib.kernel_methods.KernelLinearClassifier(
   n_classes=10, optimizer=optimizer, kernel_mappers=kernel_mappers)
</code></pre><p>注意<code>stddev</code>参数。这是标准偏差（\（\ sigma \））的 近似的RBF核和控制中使用的相似性度量 分类。<br><code>stddev</code>通常通过超参数调整来确定。</p>
<p>运行上述代码的结果汇总在下表中。 我们可以通过增加输出尺寸来进一步提高精度 映射和调整标准偏差。</p>
<table>
<thead>
<tr>
<th>metric</th>
<th>value  </th>
</tr>
</thead>
<tbody>
<tr>
<td>loss</td>
<td>0.10  </td>
</tr>
<tr>
<td>accuracy</td>
<td>97%  </td>
</tr>
<tr>
<td>training time</td>
<td>~35 seconds on my machine  </td>
</tr>
</tbody>
</table>
<h3><span id="stddev">STDDEV</span></h3><p>分类质量对stddev的值非常敏感。该 下表显示了分类器在eval数据上的准确性 不同的stddev值。最佳值是stddev = 5.0。注意也是如此<br>小或太高的stddev值可以大大降低的准确性 分类。</p>
<table>
<thead>
<tr>
<th>stddev</th>
<th>eval accuracy  </th>
</tr>
</thead>
<tbody>
<tr>
<td>1.0</td>
<td>0.1362  </td>
</tr>
<tr>
<td>2.0</td>
<td>0.4764  </td>
</tr>
<tr>
<td>4.0</td>
<td>0.9654  </td>
</tr>
<tr>
<td>5.0</td>
<td>0.9766  </td>
</tr>
<tr>
<td>8.0</td>
<td>0.9714  </td>
</tr>
<tr>
<td>16.0</td>
<td>0.8878  </td>
</tr>
</tbody>
</table>
<h3><span id="输出维度">输出维度</span></h3><p>直观地说，映射的输出维数越大， 两个映射向量的内积近似于内核，这通常是 转换为更好的分类准确性。另一种思考方式是 输出维数等于线性模型的权数;该<br>这个尺寸越大，模型的“自由度”就越大。 但是，经过一定的门槛后，产出规模越来越大 准确度很低，同时使训练需要更多的时间。这显示在<br>下面的两幅图描绘了作为一个函数的评估精度 输出维数和训练时间。</p>
<p><img src="https://www.tensorflow.org/versions/master/images/acc_vs_outdim.png" alt="image"><br><img src="https://www.tensorflow.org/versions/master/images/acc-vs-
trn_time.png" alt="image"></p>
<h2><span id="概要">概要</span></h2><p>显式核映射将非线性模型的预测能力与 线性模型的可扩展性。与传统的双核方法不同， 显式的内核方法可以扩展到数百万甚至数亿<br>样本。在使用显式内核映射时，请考虑以下提示：</p>
<p>随机傅立叶特征可以对密集的数据集特别有效 特征。 内核映射的参数通常是数据相关的。模型质量 可以对这些参数非常敏感。使用超参数调整来查找 最佳值。<br>如果你有多个数字特征，把它们连成一个单一的 多维特征并将内核映射应用到串联 向量。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/deep_cnn/" title="卷积神经网络" itemprop="url">卷积神经网络</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="卷积神经网络">卷积神经网络</span></h1><blockquote>
<p>注意：本教程适用于TensorFlow的高级用户 并承担机器学习方面的专业知识和经验。</p>
</blockquote>
<h2><span id="概观">概观</span></h2><p>CIFAR-10分类是机器学习中常见的基准问题。该 问题是分类10个类别的RGB 32x32像素图像：</p>
<pre><code>airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck.
</code></pre><p>有关更多详细信息，请参阅CIFAR-10页面 和一份技术报告 Alex Krizhevsky。</p>
<h3><span id="目标">目标</span></h3><p>本教程的目标是建立一个相对较小的卷积神经网络 网络（CNN） 识别图像。在这个过程中，本教程：</p>
<p>突出了一个规范的网络架构组织， 培训和评估。 为构建更大更复杂的模型提供了一个模板。</p>
<p>选择CIFAR-10的原因是它足够复杂 TensorFlow的大部分功能可以扩展到大型模型。与此同时， 该模型足够小，可以快速训练，这是尝试的理想选择<br>新的想法和新技术的尝试。</p>
<h3><span id="教程的亮点">教程的亮点</span></h3><p>CIFAR-10教程演示了几个重要的构造 在TensorFlow中设计更大更复杂的模型：</p>
<p>核心数学组件包括卷积 （维基） 纠正线性激活 （维基） 最大池 （维基） 和本地响应正常化 （第3.3章 AlexNet论文）。 可视化<br>训练期间的网络活动，包括输入图像， 激活和渐变的损失和分布。 用于计算的例程 移动平均线 学习的参数和使用这些平均值 在评估期间提高预测性能。 执行一个<br>学习率计划 随着时间的推移有系统地减少。 预取队列 输入 数据隔离模型从磁盘延迟和昂贵的图像预处理。</p>
<p>我们也提供了一个多GPU版本 该模型的演示：</p>
<p>配置一个模型来并行训练多个GPU卡。 在多个GPU之间共享和更新变量。</p>
<p>我们希望这个教程提供了一个启动点来构建更大的CNN 视觉任务在TensorFlow。</p>
<h3><span id="模型架构">模型架构</span></h3><p>这个CIFAR-10教程中的模型是一个多层体系结构 交替卷积和非线性。这些层完全跟随 连接层导致softmax分类器。模型遵循 架构所描述的<br>亚历克斯Krizhevsky，几个 在最上面几层的差异。</p>
<p>这个模型在几个小时内达到了高达86％的精度 在GPU上的训练时间。请参阅下面的代码 了解详情。它由1,068,298个可学习的参数组成，需要大约<br>19.5M乘加操作来计算单个图像的推理。</p>
<h2><span id="代码组织">代码组织</span></h2><p>本教程的代码驻留在 <code>models/tutorials/image/cifar10/</code>。</p>
<table>
<thead>
<tr>
<th>File</th>
<th>Purpose  </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<p><a href="https://www.tensorflow.org/code/tensorflow_models/tutorials/image/cifar10/cifar10_input.py" target="_blank" rel="noopener"><code>cifar10_input.py</code></a><br>| Reads the native CIFAR-10 binary file format.<br><a href="https://www.tensorflow.org/code/tensorflow_models/tutorials/image/cifar10/cifar10.py" target="_blank" rel="noopener"><code>cifar10.py</code></a><br>| Builds the CIFAR-10 model.<br><a href="https://www.tensorflow.org/code/tensorflow_models/tutorials/image/cifar10/cifar10_train.py" target="_blank" rel="noopener"><code>cifar10_train.py</code></a><br>| Trains a CIFAR-10 model on a CPU or GPU.<br><a href="https://www.tensorflow.org/code/tensorflow_models/tutorials/image/cifar10/cifar10_multi_gpu_train.py" target="_blank" rel="noopener"><code>cifar10_multi_gpu_train.py</code></a><br>| Trains a CIFAR-10 model on multiple GPUs.<br><a href="https://www.tensorflow.org/code/tensorflow_models/tutorials/image/cifar10/cifar10_eval.py" target="_blank" rel="noopener"><code>cifar10_eval.py</code></a><br>| Evaluates the predictive performance of a CIFAR-10 model.  </p>
<h2><span id="cifar-10型号">CIFAR-10型号</span></h2><p>CIFAR-10网络主要包含在内 <code>cifar10.py</code>。 完整的培训 图形包含大约765个操作。我们发现我们可以使代码最多<br>通过使用以下模块构建图表可重复使用：</p>
<p>型号输入：<code>inputs()</code>和<code>distorted_inputs()</code>添加 操作，读取和预处理CIFAR图像进行评估和培训， 分别。<br>型号预测：<code>inference()</code> 增加对提供的图像执行推断（即，分类）的操作。 型号培训：<code>loss()</code>和<code>train()</code> 添加计算损失的操作，<br>渐变，可变更新和可视化摘要。</p>
<h3><span id="模型输入">模型输入</span></h3><p>该型号的输入部分由功能<code>inputs()</code>和 <code>distorted_inputs()</code>从CIFAR-10二进制数据文件读取图像。<br>这些文件包含固定的字节长度记录，所以我们使用 <code>tf.FixedLengthRecordReader</code>。 请参阅读取数据<br>详细了解<code>Reader</code>的工作原理。</p>
<p>图像处理如下：</p>
<p>他们被裁剪为24 x 24像素，集中评估或    随机进行培训。 他们大约变白了    使模型对动态范围不敏感。</p>
<p>对于训练，我们另外应用一系列的随机失真 人为地增加数据集的大小：</p>
<p>随机从左到右翻转图像。 随机扭曲图像的亮度。 随机扭曲的图像对比度。</p>
<p>请参阅图像页面的列表 可用的扭曲。我们也附上一个 <code>tf.summary.image</code>的图像 以便我们可以在TensorBoard中将它们可视化。<br>这是验证输入是否正确构建的良好实践。</p>
<p><img src="https://www.tensorflow.org/images/cifar_image_summary.png" alt=""></p>
<p>从磁盘读取图像和扭曲它们可以使用不平凡的数量 处理时间。为了防止这些操作放慢训练，我们运行 它们在16个独立的线程内连续填充一个TensorFlow 队列。</p>
<h3><span id="模型预测">模型预测</span></h3><p>该模型的预测部分由<code>inference()</code>功能构建 这增加了计算预测的逻辑的操作。那部分 该模型组织如下：</p>
<table>
<thead>
<tr>
<th>Layer Name</th>
<th>Description  </th>
</tr>
</thead>
<tbody>
<tr>
<td><code>conv1</code></td>
<td></td>
</tr>
</tbody>
</table>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d" target="_blank" rel="noopener">convolution</a> and<br><a href="https://www.tensorflow.org/api_docs/python/tf/nn/relu" target="_blank" rel="noopener">rectified linear</a><br>activation.<br><code>pool1</code> | <a href="https://www.tensorflow.org/api_docs/python/tf/nn/max_pool" target="_blank" rel="noopener">max<br>pooling</a>.<br><code>norm1</code> | <a href="https://www.tensorflow.org/api_docs/python/tf/nn/local_response_normalization" target="_blank" rel="noopener">local response<br>normalization</a>.<br><code>conv2</code> |<br><a href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d" target="_blank" rel="noopener">convolution</a> and<br><a href="https://www.tensorflow.org/api_docs/python/tf/nn/relu" target="_blank" rel="noopener">rectified linear</a><br>activation.<br><code>norm2</code> | <a href="https://www.tensorflow.org/api_docs/python/tf/nn/local_response_normalization" target="_blank" rel="noopener">local response<br>normalization</a>.<br><code>pool2</code> | <a href="https://www.tensorflow.org/api_docs/python/tf/nn/max_pool" target="_blank" rel="noopener">max<br>pooling</a>.<br><code>local3</code> | <a href="https://www.tensorflow.org/api_guides/python/nn" target="_blank" rel="noopener">fully connected layer with rectified linear<br>activation</a>.<br><code>local4</code> | <a href="https://www.tensorflow.org/api_guides/python/nn" target="_blank" rel="noopener">fully connected layer with rectified linear<br>activation</a>.<br><code>softmax_linear</code> | linear transformation to produce logits.  </p>
<p>这是一个由TensorBoard生成的图形，描述了推理操作：</p>
<p><img src="https://www.tensorflow.org/images/cifar_graph.png" alt=""></p>
<blockquote>
<p>练习：<code>inference</code>的输出是非标准化的对象。尝试编辑 网络体系结构返回归一化预测使用 <code>tf.nn.softmax</code>。</p>
</blockquote>
<p><code>inputs()</code>和<code>inference()</code>功能提供所有组件 进行模型评估是必要的。我们现在把重点转移到了 建立操作模型的训练。</p>
<blockquote>
<p>练习：<code>inference()</code>中的模型架构与之不同 在CIFAR-10模型中指定 CUDA-convnet。特别是顶部<br>亚历克斯的原始模型的层是本地连接，并没有完全连接。 尝试编辑体系结构以准确重现本地连接 架构在顶层。</p>
</blockquote>
<h3><span id="模型训练">模型训练</span></h3><p>训练网络执行N路分类的通常方法是 多项式逻辑回归， 又名。 softmax回归。 Softmax回归应用a softmax非线性的 网络的输出和计算 交叉熵<br>在标准化的预测与a 标签的1热编码。 为了正规化，我们也应用通常的 所有学习的重量衰减损失 变量。该模型的目标函数是交叉熵的和<br>以及<code>loss()</code>功能返回的所有这些重量衰减条款。</p>
<p>我们使用<code>tf.summary.scalar</code>在TensorBoard中将其可视化：</p>
<p><img src="https://www.tensorflow.org/images/cifar_loss.png" alt="CIFAR-10 Loss"></p>
<p>我们使用标准来训练模型 梯度下降 算法（请参阅其他方法的培训） 学习率是 呈指数衰减 随着时间的推移。</p>
<p><img src="https://www.tensorflow.org/images/cifar_lr_decay.png" alt="CIFAR-10 Learning Rate
Decay"></p>
<p><code>train()</code>功能通过添加所需的操作来最小化目标 计算梯度和更新学习的变量（见 <code>tf.train.GradientDescentOptimizer</code><br>详情）。它返回一个执行所有计算的操作 需要训练和更新一批图像的模型。</p>
<h2><span id="启动和训练模型">启动和训练模型</span></h2><p>我们已经建立了模型，现在启动它并运行训练操作 脚本<code>cifar10_train.py</code>。</p>
<pre><code>python cifar10_train.py
</code></pre><blockquote>
<p>注：第一次在CIFAR-10教程中运行任何目标时， CIFAR-10数据集自动下载。数据集是〜160MB 所以你可能想为你的第一次尝试拿一杯咖啡。</p>
</blockquote>
<p>你应该看到输出：</p>
<pre><code>Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2015-11-04 11:45:45.927302: step 0, loss = 4.68 (2.0 examples/sec; 64.221 sec/batch)
2015-11-04 11:45:49.133065: step 10, loss = 4.66 (533.8 examples/sec; 0.240 sec/batch)
2015-11-04 11:45:51.397710: step 20, loss = 4.64 (597.4 examples/sec; 0.214 sec/batch)
2015-11-04 11:45:54.446850: step 30, loss = 4.62 (391.0 examples/sec; 0.327 sec/batch)
2015-11-04 11:45:57.152676: step 40, loss = 4.61 (430.2 examples/sec; 0.298 sec/batch)
2015-11-04 11:46:00.437717: step 50, loss = 4.59 (406.4 examples/sec; 0.315 sec/batch)
...
</code></pre><p>该脚本报告每10步的总损失以及速度 最后一批数据被处理。几点意见：</p>
<p>第一批数据可能非常慢（如几分钟） 预处理线程用20,000处理的CIFAR填充混洗队列 图片。 报告的损失是最近一批的平均损失。请记住<br>这个损失是交叉熵和所有重量衰减项之和。 密切关注批次的处理速度。上面显示的数字是 在Tesla K40c上获得。如果您在CPU上运行，则性能会降低。</p>
<blockquote>
<p>练习：在试验时，有时候第一个很烦人 训练步骤可能需要很长时间。尝试减少图像的数量<br>最初填满队列。搜索<code>min_fraction_of_examples_in_queue</code> 在<code>cifar10_input.py</code>中。</p>
</blockquote>
<p><code>cifar10_train.py</code>定期保存 所有的模型参数 检查点文件 但它不评估模型。检查点文件 将被<code>cifar10_eval.py</code>用于测量预测值<br>性能（请参阅下面的评估模型）。</p>
<p>如果你按照前面的步骤，那么你现在已经开始训练 一个CIFAR-10模型。恭喜！</p>
<p>从<code>cifar10_train.py</code>返回的终端文本提供了最小的洞察力 模型是如何训练的。我们希望在培训期间更深入地了解模型：</p>
<p>损失是真的减少还是只是噪音？ 模型是否提供了适当的图像？ 梯度，激活和权重是否合理？ 目前的学习率是多少？</p>
<p>TensorBoard提供了这个 功能，显示<code>cifar10_train.py</code>定期输出的数据 一个 <code>tf.summary.FileWriter</code>。</p>
<p>比如，我们可以看到激活的分布和度数 <code>local3</code>特性中的稀疏性在训练过程中发展：</p>
<p><img src="https://www.tensorflow.org/images/cifar_sparsity.png" alt=""><br><img src="https://www.tensorflow.org/images/cifar_activations.png" alt=""></p>
<p>个人损失函数以及全部损失尤其如此 有趣的跟踪时间。但是，损失表现出相当的数量 由于培训使用小批量的噪音。实际上我们发现<br>除了原始数据之外，还可以看到他们的移动平均线 值。看看脚本如何使用 <code>tf.train.ExponentialMovingAverage</code> 以此目的。</p>
<h2><span id="评估一个模型">评估一个模型</span></h2><p>现在让我们来评估训练好的模型在保持数据集上的表现如何。 该模型由<code>cifar10_eval.py</code>脚本进行评估。它构建了模型<br>与<code>inference()</code>功能一起使用，并在评估套件中使用全部10,000张图像 CIFAR-10。它计算的精度为1：最高预测的频率 匹配图像的真实标签。</p>
<p>为了监测训练期间模型的改进情况，评估脚本运行 定期在<code>cifar10_train.py</code>创建的最新检查点文件上。</p>
<pre><code>python cifar10_eval.py
</code></pre><blockquote>
<p>小心不要在同一个GPU上运行评估和训练二进制文件 否则你可能会用完内存。考虑运行评估 一个单独的GPU（如果可用）或在运行时挂起训练二进制文件<br>在同一个GPU上进行评估。</p>
</blockquote>
<p>你应该看到输出：</p>
<pre><code>2015-11-06 08:30:44.391206: precision @ 1 = 0.860
...
</code></pre><p>脚本只是定期返回精度@ 1，在这种情况下 它返回了86％的准确性。 <code>cifar10_eval.py</code>也<br>出口摘要可能在TensorBoard中可视化。这些总结 在评估过程中提供对模型的更多见解。</p>
<p>训练脚本计算 移动平均线 所有学习变量的版本。评估脚本替代 所有学习的移动平均版本的模型参数。这个 替代在评估时提升模型表现。</p>
<blockquote>
<p>练习：使用平均参数可以提高预测性能 按精度@ 1测量约3％。编辑<code>cifar10_eval.py</code>不使用 模型的平均参数和验证预测性能 下降。</p>
</blockquote>
<h2><span id="使用多个gpu卡培训模型">使用多个GPU卡培训模型</span></h2><p>现代工作站可能包含多个GPU进行科学计算。 TensorFlow可以利用这个环境来运行培训操作 同时跨多个卡。</p>
<p>以平行，分布式的方式训练模型需要 协调培训流程。以下我们称为模型副本 成为数据子集模型训练的一个副本。</p>
<p>天真地使用模型参数的异步更新 导致次优训练绩效 因为一个单独的模型副本可能会被过时训练 模型参数的副本。相反，采用完全同步 更新将会像最慢的模型副本一样慢。</p>
<p>在具有多个GPU卡的工作站中，每个GPU将具有相似的速度 并包含足够的内存来运行整个CIFAR-10模型。因此，我们选择 按照以下方式设计我们的培训系统：</p>
<p>在每个GPU上放置一个模型副本。 等待所有的GPU完成，同步更新模型参数 处理一批数据。</p>
<p>这是这个模型的图表：</p>
<p><img src="https://www.tensorflow.org/images/Parallelism.png" alt=""></p>
<p>请注意，每个GPU计算推理以及独特的渐变 一批数据。这种设置有效地允许分割更大的批次 的GPU数据。</p>
<p>此设置要求所有GPU共享模型参数。一个众所周知的 事实上从GPU传输数据的速度相当慢。为了这 原因，我们决定存储和更新CPU上的所有模型参数（请参阅<br>绿色框）。一组新的模型参数被传送到GPU 当一批新的数据被所有GPU处理时。</p>
<p>GPU在运行中同步。所有的渐变都是从 GPU和平均值（见绿框）。模型参数用更新 所有模型副本的平均梯度。</p>
<h3><span id="在设备上放置变量和操作">在设备上放置变量和操作</span></h3><p>在设备上放置操作和变量需要一些特殊的东西 抽象。</p>
<p>我们需要的第一个抽象是一个计算推理的功能 单个模型副本的渐变。在代码中我们称这个抽象 一个“塔”。我们必须为每个塔设置两个属性：</p>
<p>塔内所有操作的唯一名称。 <code>tf.name_scope</code>提供 这个独特的名字通过预先的范围。例如，所有的操作 第一塔预先装有<code>tower_0</code>，例如，<br><code>tower_0/conv1/Conv2D</code>。 在塔内运行操作的首选硬件设备。 <code>tf.device</code>具体说明了这一点。对于<br>实例中，第一塔的所有操作都驻留在<code>device(&#39;/device:GPU:0&#39;)</code>内 范围指示它们应该在第一个GPU上运行。</p>
<p>所有变量都被固定到CPU并通过访问 <code>tf.get_variable</code> 以便在多GPU版本中共享它们。 查看如何共享变量。</p>
<h3><span id="在多个gpu卡上启动和训练模型">在多个GPU卡上启动和训练模型</span></h3><p>如果您的计算机上安装了多个GPU卡，则可以使用它们 用<code>cifar10_multi_gpu_train.py</code>脚本更快地训练模型。这个<br>训练脚本的版本在多个GPU卡上并行化模型。</p>
<pre><code>python cifar10_multi_gpu_train.py --num_gpus=2
</code></pre><p>请注意，所使用的GPU卡数量默认为1.此外，如果只有1 GPU在你的机器上是可用的，所有的计算都将被放置在它上面，即使 你要求更多。</p>
<blockquote>
<p>练习：<code>cifar10_train.py</code>的默认设置是<br>在批处理大小128上运行。尝试在2个GPU上运行<code>cifar10_multi_gpu_train.py</code> 批量大小为64，比较训练速度。</p>
</blockquote>
<h2><span id="下一步">下一步</span></h2><p>恭喜！你有 完成了CIFAR-10教程。</p>
<p>如果你现在有兴趣开发和培养自己的形象 分类系统，我们建议分叉这个教程并替换 组件来解决你的图像分类问题。</p>
<blockquote>
<p>练习：下载 街景房屋号码（SVHN）数据集。 分叉CIFAR-10教程和交换在SVHN作为输入数据。尝试适应 网络架构来提高预测性能。</p>
</blockquote>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/get_started/" title="TensorFlow入门" itemprop="url">TensorFlow入门</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="tensorflow入门">TensorFlow入门</span></h1><p>本指南让您开始在TensorFlow中编程。在使用本指南之前， 安装TensorFlow。为了充分利用 本指南中，您应该了解以下内容：</p>
<p>如何用Python编程。 至少有一点关于数组。 理想的是，关于机器学习的东西。但是，如果你知道的很少或     没有关于机器学习，那么这仍然是你的第一个指导<br>应该读。</p>
<p>TensorFlow提供了多个API。最低级别的API - TensorFlow Core– 为您提供完整的编程控制。我们推荐TensorFlow<br>Core 机器学习研究人员和其他需要精细控制的人员 他们的模型。更高层次的API建立在TensorFlow核心之上。这些 比TensorFlow<br>Core更高级别的API通常更容易学习和使用。在 此外，更高级别的API使重复性任务更容易和更一致<br>在不同的用户之间像tf.estimator这样的高级API可以帮助您管理 数据集，估计器，训练和推断。</p>
<p>本指南从TensorFlow核心教程开始。后来我们 演示如何在tf.estimator中实现相同的模型。会心<br>TensorFlow核心原则会给你一个很好的思维模式 当您使用更紧凑的更高级别的API时在内部工作。</p>
<h1><span id="张量">张量</span></h1><p>TensorFlow中的数据中心单位是张量。张量由一个 将原始值集合整形成任意数量维度的数组。一个 张量的等级是它的维数。这里有一些例子 张量：</p>
<pre><code>3 # a rank 0 tensor; a scalar with shape []
[1., 2., 3.] # a rank 1 tensor; a vector with shape [3]
[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3]
[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]
</code></pre><h2><span id="tensorflow核心教程">TensorFlow核心教程</span></h2><h3><span id="导入张量流">导入张量流</span></h3><p>TensorFlow程序的规范导入语句如下所示：</p>
<pre><code>import tensorflow as tf
</code></pre><p>这使得Python可以访问所有TensorFlow的类，方法和符号。 大多数文档假定您已经完成了这个工作。</p>
<h3><span id="计算图">计算图</span></h3><p>你可能会想到TensorFlow核心程序由两个离散的组成 部分：</p>
<p>构建计算图。 运行计算图。</p>
<p>计算图是一系列排列成a的TensorFlow操作 节点图。 我们来构建一个简单的计算图。每个节点都是零 或更多的张量作为输入，并产生张量作为输出。一种节点<br>是一个常数。像所有的TensorFlow常量一样，它不需要输入，而是输出 它存储在内部的值。我们可以创建两个浮点张量<code>node1</code> 和<code>node2</code>如下：</p>
<pre><code>node1 = tf.constant(3.0, dtype=tf.float32)
node2 = tf.constant(4.0) # also tf.float32 implicitly
print(node1, node2)
</code></pre><p>最后的打印声明产生</p>
<pre><code>Tensor(&quot;Const:0&quot;, shape=(), dtype=float32) Tensor(&quot;Const_1:0&quot;, shape=(), dtype=float32)
</code></pre><p>请注意，打印节点时不会输出<code>3.0</code>和<code>4.0</code>的值 可能期望。相反，它们是在评估时会产生3.0的节点 和4.0，分别。为了实际评估节点，我们必须运行<br>会话内的计算图。会话封装了控件和 TensorFlow运行时的状态。</p>
<p>以下代码创建一个<code>Session</code>对象，然后调用其<code>run</code>方法 运行足够的计算图来评估<code>node1</code>和<code>node2</code>。通过 在会话中运行计算图如下：</p>
<pre><code>sess = tf.Session()
print(sess.run([node1, node2]))
</code></pre><p>我们看到了3.0和4.0的预期值：</p>
<pre><code>[3.0, 4.0]
</code></pre><p>通过将<code>Tensor</code>节点组合起来，可以构建更复杂的计算 操作（操作也是节点）。例如，我们可以添加我们的两个 常量节点，并产生一个新的图形如下：</p>
<pre><code>from __future__ import print_function
node3 = tf.add(node1, node2)
print(&quot;node3:&quot;, node3)
print(&quot;sess.run(node3):&quot;, sess.run(node3))
</code></pre><p>最后两个打印语句产生</p>
<pre><code>node3: Tensor(&quot;Add:0&quot;, shape=(), dtype=float32)
sess.run(node3): 7.0
</code></pre><p>TensorFlow提供了一个名为TensorBoard的实用程序，可以显示图片 计算图。这里是一个截图显示如何TensorBoard 可视化图形：</p>
<p><img src="https://www.tensorflow.org/images/getting_started_add.png" alt="TensorBoard
screenshot"></p>
<p>就目前而言，这张图并不特别有趣，因为它总是如此 产生一个不变的结果。图形可以被参数化来接受外部的 输入，称为占位符。占位符是提供一个的承诺 稍后的价值。</p>
<pre><code>a = tf.placeholder(tf.float32)
b = tf.placeholder(tf.float32)
adder_node = a + b  # + provides a shortcut for tf.add(a, b)
</code></pre><p>前面的三行有点像我们的函数或者lambda 定义两个输入参数（a和b），然后对它们进行操作。我们可以 使用feed_dict参数来评估具有多个输入的图形<br>运行方法 将具体值提供给占位符：</p>
<pre><code>print(sess.run(adder_node, {a: 3, b: 4.5}))
print(sess.run(adder_node, {a: [1, 3], b: [2, 4]}))
</code></pre><p>导致输出</p>
<pre><code>7.5
[ 3.  7.]
</code></pre><p>在TensorBoard中，图形如下所示：</p>
<p><img src="https://www.tensorflow.org/images/getting_started_adder.png" alt="TensorBoard
screenshot"></p>
<p>我们可以通过添加另一个操作来使计算图更加复杂。 例如，</p>
<pre><code>add_and_triple = adder_node * 3.
print(sess.run(add_and_triple, {a: 3, b: 4.5}))
</code></pre><p>产生输出</p>
<pre><code>22.5
</code></pre><p>在TensorBoard中，上面的计算图如下所示：</p>
<p><img src="https://www.tensorflow.org/images/getting_started_triple.png" alt="TensorBoard
screenshot"></p>
<p>在机器学习中，我们通常需要一个可以任意使用的模型 输入，比如上面的那个。为了使模型可训练，我们需要能够 修改图形以获得具有相同输入的新输出。变量允许<br>我们将可训练参数添加到图形中。他们是用一种类型和 初始值：</p>
<pre><code>W = tf.Variable([.3], dtype=tf.float32)
b = tf.Variable([-.3], dtype=tf.float32)
x = tf.placeholder(tf.float32)
linear_model = W*x + b
</code></pre><p>当您调用<code>tf.constant</code>时，常量被初始化，并且它们的值永远不会被初始化 更改。相比之下，当您调用<code>tf.Variable</code>时，变量不会被初始化。<br>要初始化TensorFlow程序中的所有变量，必须明确 调用一个特殊的操作如下：</p>
<pre><code>init = tf.global_variables_initializer()
sess.run(init)
</code></pre><p>实现<code>init</code>是TensorFlow子图的一个句柄 初始化所有的全局变量。直到我们称之为<code>sess.run</code>，变量 未初始化。</p>
<p>由于<code>x</code>是一个占位符，我们可以评估<code>linear_model</code>的几个值 <code>x</code>同时如下：</p>
<pre><code>print(sess.run(linear_model, {x: [1, 2, 3, 4]}))
</code></pre><p>产生输出</p>
<pre><code>[ 0.          0.30000001  0.60000002  0.90000004]
</code></pre><p>我们已经创建了一个模型，但我们不知道它有多好。评估 模型训练数据，我们需要一个<code>y</code>占位符来提供所需的值， 我们需要写一个损失函数。</p>
<p>亏损功能衡量的是多远 目前的模型是从提供的数据。我们将使用一个标准的损失模型 线性回归，它将电流之间的三角形的平方相加 模型和提供的数据。<br><code>linear_model - y</code>创建一个向量 元素是相应示例的错误增量。我们称之为<code>tf.square</code><br>平方那个错误。然后，我们总结所有的平方误差来创建一个标量 使用<code>tf.reduce_sum</code>提取所有示例的错误：</p>
<pre><code>y = tf.placeholder(tf.float32)
squared_deltas = tf.square(linear_model - y)
loss = tf.reduce_sum(squared_deltas)
print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))
</code></pre><p>产生损失价值</p>
<pre><code>23.66
</code></pre><p>我们可以通过将<code>W</code>和<code>b</code>的值重新分配给 -1和1的完美值。一个变量被初始化为提供的值<br><code>tf.Variable</code>，但可以使用<code>tf.assign</code>等操作进行更改。例如， <code>W=-1</code>和<code>b=1</code>是我们模型的最佳参数。我们可以改变<code>W</code>和<br><code>b</code>相应的：</p>
<pre><code>fixW = tf.assign(W, [-1.])
fixb = tf.assign(b, [1.])
sess.run([fixW, fixb])
print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))
</code></pre><p>最后的印刷品显示现在的损失是零。</p>
<pre><code>0.0
</code></pre><p>我们猜测<code>W</code>和<code>b</code>的“完美”价值，但是机器的全部重点 学习是自动找到正确的模型参数。我们将展示 如何在下一节中做到这一点。</p>
<h2><span id="tftrain-api">tf.train API</span></h2><p>机器学习的完整讨论超出了本教程的范围。 但是，TensorFlow提供的优化器可以缓慢地改变每个变量 为了尽量减少损失的功能。最简单的优化器是渐变的<br>血统。它根据的大小修改每个变量 与该变量有关的损失的导数。一般来说，计算符号 衍生品手工是乏味和容易出错。因此，TensorFlow可以<br>自动产生的衍生物只给出了使用模型的描述 功能<code>tf.gradients</code>。为了简单起见，优化器通常会这样做 为你。例如，</p>
<pre><code>optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss)



sess.run(init) # reset values to incorrect defaults.
for i in range(1000):
  sess.run(train, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})

print(sess.run([W, b]))
</code></pre><p>导致最终的模型参数：</p>
<pre><code>[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]
</code></pre><p>现在我们已经完成了机器学习！虽然这个简单的线性 回归模型不需要太多的TensorFlow核心代码，比较复杂<br>将数据提供给模型的模型和方法需要更多的代码。从而， TensorFlow为常见的模式，结构， 和功能。我们将学习如何使用这些抽象中的一些 下一节。</p>
<h3><span id="完整的程序">完整的程序</span></h3><p>完成的可训练线性回归模型如下所示：</p>
<pre><code>import tensorflow as tf

# Model parameters
W = tf.Variable([.3], dtype=tf.float32)
b = tf.Variable([-.3], dtype=tf.float32)
# Model input and output
x = tf.placeholder(tf.float32)
linear_model = W*x + b
y = tf.placeholder(tf.float32)

# loss
loss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares
# optimizer
optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss)

# training data
x_train = [1, 2, 3, 4]
y_train = [0, -1, -2, -3]
# training loop
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init) # reset values to wrong
for i in range(1000):
  sess.run(train, {x: x_train, y: y_train})

# evaluate training accuracy
curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})
print(&quot;W: %s b: %s loss: %s&quot;%(curr_W, curr_b, curr_loss))
</code></pre><p>运行时产生</p>
<pre><code>W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11
</code></pre><p>请注意，损失是非常小的数字（非常接近零）。如果你跑步 这个程序，你的损失可能与上述损失不完全一样 因为模型是用伪随机值初始化的。</p>
<p>这个更复杂的程序仍然可以在TensorBoard中可视化 <img src="https://www.tensorflow.org/images/getting_started_final.png" alt="TensorBoard final model
visualization"></p>
<h2><span id="tfestimator"><code>tf.estimator</code></span></h2><p><code>tf.estimator</code>是一个高级的TensorFlow库，可以简化 机器学习机制包括以下内容：</p>
<p>运行训练循环 运行评估循环 管理数据集</p>
<p>tf.estimator定义了许多常见的模型。</p>
<h3><span id="基本用法">基本用法</span></h3><p>注意线性回归程序变得简单多了 <code>tf.estimator</code>：</p>
<pre><code># NumPy is often used to load, manipulate and preprocess data.
import numpy as np
import tensorflow as tf

# Declare list of features. We only have one numeric feature. There are many
# other types of columns that are more complicated and useful.
feature_columns = [tf.feature_column.numeric_column(&quot;x&quot;, shape=[1])]

# An estimator is the front end to invoke training (fitting) and evaluation
# (inference). There are many predefined types like linear regression,
# linear classification, and many neural network classifiers and regressors.
# The following code provides an estimator that does linear regression.
estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)

# TensorFlow provides many helper methods to read and set up data sets.
# Here we use two data sets: one for training and one for evaluation
# We have to tell the function how many batches
# of data (num_epochs) we want and how big each batch should be.
x_train = np.array([1., 2., 3., 4.])
y_train = np.array([0., -1., -2., -3.])
x_eval = np.array([2., 5., 8., 1.])
y_eval = np.array([-1.01, -4.1, -7, 0.])
input_fn = tf.estimator.inputs.numpy_input_fn(
    {&quot;x&quot;: x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)
train_input_fn = tf.estimator.inputs.numpy_input_fn(
    {&quot;x&quot;: x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)
eval_input_fn = tf.estimator.inputs.numpy_input_fn(
    {&quot;x&quot;: x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)

# We can invoke 1000 training steps by invoking the  method and passing the
# training data set.
estimator.train(input_fn=input_fn, steps=1000)

# Here we evaluate how well our model did.
train_metrics = estimator.evaluate(input_fn=train_input_fn)
eval_metrics = estimator.evaluate(input_fn=eval_input_fn)
print(&quot;train metrics: %r&quot;% train_metrics)
print(&quot;eval metrics: %r&quot;% eval_metrics)
</code></pre><p>运行时，会产生类似的东西</p>
<pre><code>train metrics: {&apos;average_loss&apos;: 1.4833182e-08, &apos;global_step&apos;: 1000, &apos;loss&apos;: 5.9332727e-08}
eval metrics: {&apos;average_loss&apos;: 0.0025353201, &apos;global_step&apos;: 1000, &apos;loss&apos;: 0.01014128}
</code></pre><p>请注意我们的评估数据是如何有更高的损失，但仍然接近于零。 这意味着我们正在正确地学习。</p>
<h3><span id="自定义模型">自定义模型</span></h3><p><code>tf.estimator</code>不会将您锁定在预定义的型号中。假设我们 想要创建一个自定义模型，而不是内置到TensorFlow中。我们仍然可以<br>保留数据集，喂养，培训等的高层次抽象 <code>tf.estimator</code>。为了说明，我们将展示如何实现我们自己的<br>等同于<code>LinearRegressor</code>的模型使用我们的较低水平的知识 TensorFlow API。</p>
<p>要定义一个适用于<code>tf.estimator</code>的自定义模型，我们需要使用 <code>tf.estimator.Estimator</code>。<br><code>tf.estimator.LinearRegressor</code>其实是 <code>tf.estimator.Estimator</code>的一个子类。而不是分类<br><code>Estimator</code>，我们只是简单地提供<code>Estimator</code>功能<code>model_fn</code>，告诉 <code>tf.estimator</code>如何评估预测，训练步骤和<br>失利。代码如下：</p>
<pre><code>import numpy as np
import tensorflow as tf

# Declare list of features, we only have one real-valued feature
def model_fn(features, labels, mode):
  # Build a linear model and predict values
  W = tf.get_variable(&quot;W&quot;, [1], dtype=tf.float64)
  b = tf.get_variable(&quot;b&quot;, [1], dtype=tf.float64)
  y = W*features[&apos;x&apos;] + b
  # Loss sub-graph
  loss = tf.reduce_sum(tf.square(y - labels))
  # Training sub-graph
  global_step = tf.train.get_global_step()
  optimizer = tf.train.GradientDescentOptimizer(0.01)
  train = tf.group(optimizer.minimize(loss),
                   tf.assign_add(global_step, 1))
  # EstimatorSpec connects subgraphs we built to the
  # appropriate functionality.
  return tf.estimator.EstimatorSpec(
      mode=mode,
      predictions=y,
      loss=loss,
      train_op=train)

estimator = tf.estimator.Estimator(model_fn=model_fn)
# define our data sets
x_train = np.array([1., 2., 3., 4.])
y_train = np.array([0., -1., -2., -3.])
x_eval = np.array([2., 5., 8., 1.])
y_eval = np.array([-1.01, -4.1, -7., 0.])
input_fn = tf.estimator.inputs.numpy_input_fn(
    {&quot;x&quot;: x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)
train_input_fn = tf.estimator.inputs.numpy_input_fn(
    {&quot;x&quot;: x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)
eval_input_fn = tf.estimator.inputs.numpy_input_fn(
    {&quot;x&quot;: x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)

# train
estimator.train(input_fn=input_fn, steps=1000)
# Here we evaluate how well our model did.
train_metrics = estimator.evaluate(input_fn=train_input_fn)
eval_metrics = estimator.evaluate(input_fn=eval_input_fn)
print(&quot;train metrics: %r&quot;% train_metrics)
print(&quot;eval metrics: %r&quot;% eval_metrics)
</code></pre><p>运行时产生</p>
<pre><code>train metrics: {&apos;loss&apos;: 1.227995e-11, &apos;global_step&apos;: 1000}
eval metrics: {&apos;loss&apos;: 0.01010036, &apos;global_step&apos;: 1000}
</code></pre><p>注意习惯<code>model_fn()</code>功能的内容是如何非常相似的 到我们的低级API的手动模型训练循环。</p>
<h2><span id="下一步">下一步</span></h2><p>现在您已经掌握了TensorFlow的基础知识。我们有几个 更多的教程，你可以看看了解更多。如果你是一个初学者 机器学习参见MNIST初学者，<br>否则请参阅Deep MNIST专家。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/graphs/" title="图表和会话" itemprop="url">图表和会话</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="图表和会话">图表和会话</span></h1><p>TensorFlow使用数据流图来表示您的计算 个别操作之间的依赖关系。这导致了一个低层次 编程模型，在其中您首先定义数据流图，然后创建一个<br>TensorFlow会话跨部分图形运行一组本地和 远程设备。</p>
<p>如果您打算使用低级编程，本指南将非常有用 直接模型。更高级别的API，如<code>tf.estimator.Estimator</code>和Keras<br>从最终用户隐藏图表和会话的细节，但本指南可能 如果你想了解这些API是如何实现的，也是有用的。</p>
<h2><span id="为什么使用数据流图">为什么使用数据流图？</span></h2><p><img src="https://www.tensorflow.org/images/tensors_flowing.gif" alt=""></p>
<p>数据流是常见的 并行计算的编程模型。在数据流图中，节点 表示计算的单位，边表示消耗的数据<br>计算产生的。例如，在TensorFlow图中，<code>tf.matmul</code> 操作将对应于具有两个传入边的单个节点（ 矩阵相乘）和一个传出边缘（的结果 乘法）。</p>
<p>数据流有几个优点，当执行你的TensorFlow时， 程式：</p>
<p>并行。通过使用显式边来表示之间的依赖关系   操作，系统很容易识别可执行的操作   在平行下。 分布式执行。通过使用显式边来表示值<br>在操作之间流动，TensorFlow可能会分割你的   程序跨多个设备（CPU，GPU和TPU）附加到不同的   机器。<br>TensorFlow插入必要的沟通和协调   设备之间。 汇编。 TensorFlow的XLA编译器可以   使用数据流图中的信息来生成更快的代码<br>例如，通过融合相邻的操作。 可移植性。数据流图是一种与语言无关的表示   的模型中的代码。你可以用Python构建一个数据流图，存储它<br>在SavedModel中，并在C ++程序中恢复它   低延迟推断。</p>
<h2><span id="什么是tfgraph">什么是<code>tf.Graph</code>？</span></h2><p><code>tf.Graph</code>包含两种相关的信息：</p>
<p>图结构。图的节点和边，指示如何   个别的操作是组合在一起的，但没有规定它们如何   应该使用。图结构就像汇编代码：检查它可以<br>传达一些有用的信息，但并不包含所有有用的信息   源代码传达的上下文。 图表集合。 TensorFlow提供了一个通用的存储机制<br><code>tf.Graph</code>中的元数据集合。 <code>tf.add_to_collection</code>功能<br>使您可以将对象列表与一个键（其中<code>tf.GraphKeys</code>）关联   定义了一些标准键），<code>tf.get_collection</code>使您可以<br>查找与某个键关联的所有对象。 TensorFlow的很多部分   库使用这个工具：例如，当你创建一个<code>tf.Variable</code>，它<br>被默认添加到代表“全局变量”的集合中   “可训练变量”。当你以后来创建一个<code>tf.train.Saver</code>或者<br><code>tf.train.Optimizer</code>，这些集合中的变量被用作为   默认参数。</p>
<h2><span id="建立一个tfgraph">建立一个<code>tf.Graph</code></span></h2><p>大多数TensorFlow程序从数据流图构建阶段开始。在这 阶段，您将调用构建新<code>tf.Operation</code>的TensorFlow API函数<br>（节点）和<code>tf.Tensor</code>（边缘）对象并将它们添加到<code>tf.Graph</code> 实例。 TensorFlow提供了一个默认图形，这是一个隐含的参数<br>到同一上下文中的所有API函数。例如：</p>
<p>调用<code>tf.constant(42.0)</code>创建一个单一的<code>tf.Operation</code>生产<br>值<code>42.0</code>，将其添加到默认图形，并返回一个<code>tf.Tensor</code>   代表常数的值。 调用<code>tf.matmul(x,
y)</code>将创建一个乘法的单个<code>tf.Operation</code>   将<code>tf.Tensor</code>对象<code>x</code>和<code>y</code>的值添加到默认图形中，<br>并返回表示乘法结果的<code>tf.Tensor</code>。 执行<code>v = tf.Variable(0)</code>增加了图表<code>tf.Operation</code>，将<br>存储在<code>tf.Session.run</code>呼叫之间持续的可写张量值。   <code>tf.Variable</code>对象包装了这个操作，可以像a一样使用<br>张量，它会读取当前的值   储值。 <code>tf.Variable</code>对象也有类似的方法   <code>assign</code>和<code>assign_add</code><br>创建<code>tf.Operation</code>对象，执行时更新存储的值。   （有关变量的更多信息，请参阅变量。）<br>调用<code>tf.train.Optimizer.minimize</code>将增加操作和张量   计算梯度的默认图表，并返回一个<code>tf.Operation</code>，<br>运行时，会将这些渐变应用于一组变量。</p>
<p>大多数程序仅依赖于默认图形。然而， 有关更多信息，请参阅处理多个图表 高级用例。高级API，如<code>tf.estimator.Estimator</code> API<br>以您的名义管理默认图表，例如 - 可能会创建不同的图表 图表进行培训和评估。</p>
<p>注意：调用TensorFlow API中的大部分函数只是添加操作 和张量到默认图形，但不执行实际<br>计算。相反，直到你有一个<code>tf.Tensor</code>，你才能完成这些功能 或代表整体计算的<code>tf.Operation</code>，如执行 一步梯度下降 -<br>然后将该物体传递给<code>tf.Session</code> 执行计算。请参阅“在<code>tf.Session</code>中执行图表” 更多细节。</p>
<h2><span id="命名操作">命名操作</span></h2><p><code>tf.Graph</code>对象定义了<code>tf.Operation</code>对象的名称空间 包含的内容。 TensorFlow自动为每个操作选择一个唯一的名称<br>你的图形，但给操作描述性名称可以使你的程序更容易 读取和调试。 TensorFlow API提供了两种覆盖名称的方法 一个手术：</p>
<p>每个创建新<code>tf.Operation</code>的API函数或返回一个新的   <code>tf.Tensor</code>接受可选的<code>name</code>参数。例如，<br><code>tf.constant(42.0, name=&quot;answer&quot;)</code>创建了一个新的<code>tf.Operation</code><br><code>&quot;answer&quot;</code>，并返回名为<code>tf.Tensor</code>的<code>&quot;answer:0&quot;</code>。如果默认图<br>已经包含了一个名为<code>&quot;answer&quot;</code>的操作，TensorFlow将被添加   <code>&quot;_1&quot;</code>，<code>&quot;_2&quot;</code>等名称，以使其独一无二。<br><code>tf.name_scope</code>功能可以添加名称范围前缀   到在特定环境中创建的所有操作。当前名称范围<br>前缀是<code>&quot;/&quot;</code>分隔的所有活动<code>tf.name_scope</code>名称列表   情境经理。如果名称范围已经在当前使用<br>上下文中，TensorFlow出现<code>&quot;_1&quot;</code>，<code>&quot;_2&quot;</code>等。例如：</p>
<blockquote>
<p>c_0 = tf.constant（0，name =“c”）＃=&gt;名为“c”的操作 ＃已经使用的名字将是“独一无二的”。 c_1 =<br>tf.constant（2，name =“c”）＃=&gt;名为“c_1”的操作 ＃名称作用域为在同一个上下文中创建的所有操作添加一个前缀。<br>与tf.name_scope（“外部”）：   c_2 = tf.constant（2，name =“c”）＃=&gt;操作名为“outer / c”<br>＃命名作用域在分层文件系统中像路径一样嵌套。   与tf.name_scope（“内部”）：     c_3 = tf.constant（3，name<br>=“c”）＃=&gt;名为“outer / inner / c”的操作   ＃退出名称范围上下文将返回到以前的前缀。   c_4 =<br>tf.constant（4，name =“c”）＃=&gt;操作名为“outer / c_1”   ＃已经使用的名称范围将是“独特的”。<br>与tf.name_scope（“内部”）：     c_5 = tf.constant（5，name =“c”）＃=&gt;名为“outer / inner_1<br>/ c”的操作</p>
</blockquote>
<p>图表可视化工具使用名称范围对操作进行分组并减少视觉效果 图的复杂性。请参阅可视化您的图表 更多信息。</p>
<p>请注意，<code>tf.Tensor</code>对象以<code>tf.Operation</code> 产生张量作为输出。张量名称形式为<code>&quot;&lt;OP_NAME&gt;:&lt;i&gt;&quot;</code> 哪里：</p>
<p><code>&quot;&lt;OP_NAME&gt;&quot;</code>是生成它的操作的名称。 <code>&quot;&lt;i&gt;&quot;</code>是表示该张量之间的索引的整数   操作的输出。</p>
<h2><span id="将操作放置在不同的设备上">将操作放置在不同的设备上</span></h2><p>如果你想让你的TensorFlow程序使用多个不同的设备， <code>tf.device</code>功能提供了一种方便的方式来请求所有操作<br>创建在一个特定的上下文被放置在相同的设备（或类型） 设备）。</p>
<p>设备规范具有以下形式：</p>
<pre><code>/job:&lt;JOB_NAME&gt;/task:&lt;TASK_INDEX&gt;/device:&lt;DEVICE_TYPE&gt;:&lt;DEVICE_INDEX&gt;
</code></pre><p>哪里：</p>
<p><code>&lt;JOB_NAME&gt;</code>是一个不以数字开头的字母数字字符串。 <code>&lt;DEVICE_TYPE&gt;</code>是注册设备类型（如<code>GPU</code>或<code>CPU</code>）。<br><code>&lt;TASK_INDEX&gt;</code>是一个表示任务索引的非负整数<br>在名为<code>&lt;JOB_NAME&gt;</code>的作业中。有关说明，请参阅<code>tf.train.ClusterSpec</code>   的工作和任务。<br><code>&lt;DEVICE_INDEX&gt;</code>是一个非负整数，表示的索引   设备，例如，以区分不同的GPU设备中使用的   同样的过程。</p>
<p>您不需要指定设备规范的每个部分。例如， 如果您正在单GPU配置的单机配置中运行，那么您 可能会使用<code>tf.device</code>将一些操作固定到CPU和GPU上：</p>
<pre><code># Operations created outside either context will run on the &quot;best possible&quot;
# device. For example, if you have a GPU and a CPU available, and the operation
# has a GPU implementation, TensorFlow will choose the GPU.
weights = tf.random_normal(...)

with tf.device(&quot;/device:CPU:0&quot;):
  # Operations created in this context will be pinned to the CPU.
  img = tf.decode_jpeg(tf.read_file(&quot;img.jpg&quot;))

with tf.device(&quot;/device:GPU:0&quot;):
  # Operations created in this context will be pinned to the GPU.
  result = tf.matmul(weights, img)
</code></pre><p>如果您正在部署典型的分布式TensorFlow 配置，您可以指定作业名称和任务ID以放置变量 参数服务器作业（<code>&quot;/job:ps&quot;</code>）中的任务以及其他操作<br>工作任务（<code>&quot;/job:worker&quot;</code>）中的任务：</p>
<pre><code>with tf.device(&quot;/job:ps/task:0&quot;):
  weights_1 = tf.Variable(tf.truncated_normal([784, 100]))
  biases_1 = tf.Variable(tf.zeroes([100]))

with tf.device(&quot;/job:ps/task:1&quot;):
  weights_2 = tf.Variable(tf.truncated_normal([100, 10]))
  biases_2 = tf.Variable(tf.zeroes([10]))

with tf.device(&quot;/job:worker&quot;):
  layer_1 = tf.matmul(train_batch, weights_1) + biases_1
  layer_2 = tf.matmul(train_batch, weights_2) + biases_2
</code></pre><p><code>tf.device</code>为您提供了很大的灵活性，可以为个人选择展示位置 操作或TensorFlow图形的广泛区域。在很多情况下，有<br>简单的启发式运作良好。例如， <code>tf.train.replica_device_setter</code> API可与<code>tf.device</code>配合使用<br>数据并行分布式培训的操作。例如， 以下代码片段显示了<code>tf.train.replica_device_setter</code>的应用<br><code>tf.Variable</code>对象和其他操作的不同放置策略：</p>
<pre><code>with tf.device(tf.train.replica_device_setter(ps_tasks=3)):
  # tf.Variable objects are, by default, placed on tasks in &quot;/job:ps&quot; in a
  # round-robin fashion.
  w_0 = tf.Variable(...)  # placed on &quot;/job:ps/task:0&quot;
  b_0 = tf.Variable(...)  # placed on &quot;/job:ps/task:1&quot;
  w_1 = tf.Variable(...)  # placed on &quot;/job:ps/task:2&quot;
  b_1 = tf.Variable(...)  # placed on &quot;/job:ps/task:0&quot;

  input_data = tf.placeholder(tf.float32)     # placed on &quot;/job:worker&quot;
  layer_0 = tf.matmul(input_data, w_0) + b_0  # placed on &quot;/job:worker&quot;
  layer_1 = tf.matmul(layer_0, w_1) + b_1     # placed on &quot;/job:worker&quot;
</code></pre><h2><span id="张量类物体">张量类物体</span></h2><p>许多TensorFlow操作将一个或多个<code>tf.Tensor</code>对象作为参数。<br>例如，<code>tf.matmul</code>带有两个<code>tf.Tensor</code>物体，<code>tf.add_n</code>带 <code>n</code> <code>tf.Tensor</code>物品清单。为了方便，这些功能将被接受<br>一个张量样物体代替<code>tf.Tensor</code>，并将其隐式转换 到<code>tf.Tensor</code>使用<code>tf.convert_to_tensor</code>方法。张量类物体<br>包括以下类型的元素：</p>
<p><code>tf.Tensor</code> <code>tf.Variable</code> <code>numpy.ndarray</code> <code>list</code>（以及张量状物体列表）<br>标量Python类型：<code>bool</code>，<code>float</code>，<code>int</code>，<code>str</code></p>
<p>您可以使用注册额外张量类型 <code>tf.register_tensor_conversion_function</code>。</p>
<p>注意：默认情况下，TensorFlow会在每次使用时创建一个新的<code>tf.Tensor</code> 相同的张量状物体。如果张量状物体很大（例如a<br><code>numpy.ndarray</code>包含一组训练实例），您可以多次使用它 次，你可能会用完内存。要避免这种情况，请手动调用<br><code>tf.convert_to_tensor</code>上的张量状物体一次并使用返回 <code>tf.Tensor</code>来代替。</p>
<h2><span id="执行tfsession中的图表">执行<code>tf.Session</code>中的图表</span></h2><p>TensorFlow使用<code>tf.Session</code>类来表示连接 客户端程序—通常是一个Python程序，虽然有一个类似的界面 可用其他语言—和C<br>++运行库。一个<code>tf.Session</code>对象 提供对本地机器中的设备以及使用该设备的远程设备的访问 分布式TensorFlow运行时。它也缓存关于你的信息<br><code>tf.Graph</code>，以便您可以高效地运行相同的计算多次。</p>
<h3><span id="创建一个tfsession">创建一个<code>tf.Session</code></span></h3><p>如果您使用低级别的TensorFlow API，则可以创建<code>tf.Session</code> 对于当前的默认图形如下：</p>
<pre><code># Create a default in-process session.
with tf.Session() as sess:
  # ...

# Create a remote session.
with tf.Session(&quot;grpc://example.org:2222&quot;):
  # ...
</code></pre><p>由于<code>tf.Session</code>拥有物理资源（如GPU和GPU） 网络连接），通常用作上下文管理器（在<code>with</code>中） 块），当你退出块时自动关闭会话。它是<br>也可以在不使用<code>with</code>模块的情况下创建一个会话，但应该这样做 清楚地呼叫<code>tf.Session.close</code>时，请将其释放 资源。</p>
<p>注：更高级的API，如<code>tf.train.MonitoredTrainingSession</code>或<br><code>tf.estimator.Estimator</code>将为您创建和管理<code>tf.Session</code>。这些<br>API接受可选的<code>target</code>和<code>config</code>参数（直接或者作为 <code>tf.estimator.RunConfig</code>物体的一部分），其含义与<br>如下面所描述的。</p>
<p><code>tf.Session.__init__</code>接受三个可选参数：</p>
<p><code>target</code>。如果这个参数是空的（默认），会话将会   只能在本地机器上使用设备。不过，你也可以指定一个   <code>grpc://</code><br>URL指定一个TensorFlow服务器的地址，它给出了   会话访问此服务器控制的机器上的所有设备。看到<br><code>tf.train.Server</code>了解如何创建TensorFlow的详细信息   服务器。例如，在常见的图形间复制中<br><code>tf.Session</code>与<code>tf.train.Server</code>相同   作为客户进行处理。分布式的TensorFlow   部署指南介绍了其他常见场景。<br><code>graph</code>。默认情况下，新的<code>tf.Session</code>将被绑定到—并且只能使用   在—当前的默认图中运行操作。如果你使用多个<br>在您的程序中的图形（请参阅多个编程   图表更多细节），你可以指定   一个显式的<code>tf.Graph</code>，当你构建会话。<br><code>config</code>。这个参数允许你指定一个<code>tf.ConfigProto</code>   控制会话的行为。例如，一些配置   选项包括：<br><code>allow_soft_placement</code>。将其设置为<code>True</code>以启用“软”设备     放置算法，忽略尝试的<code>tf.device</code>注释<br>将仅CPU操作放置在GPU设备上，并将其放置在CPU上     代替。 <code>cluster_def</code>。当使用分布式TensorFlow时，这个选项允许你<br>指定在计算中使用哪些机器，并提供映射     作业名称，任务索引和网络地址之间。看到<br><code>tf.train.ClusterSpec.as_cluster_def</code>的详细信息。<br><code>graph_options.optimizer_options</code>。提供对优化的控制     TensorFlow在执行之前在您的图表上执行。<br><code>gpu_options.allow_growth</code>。将其设置为<code>True</code>以更改GPU内存     分配器，以便逐渐增加分配的内存量，<br>而不是在启动时分配大部分内存。</p>
<h3><span id="使用tfsessionrun执行操作">使用<code>tf.Session.run</code>执行操作</span></h3><p><code>tf.Session.run</code>方法是运行<code>tf.Operation</code>的主要机制<br>或评估<code>tf.Tensor</code>。您可以通过一个或多个<code>tf.Operation</code>或<br><code>tf.Tensor</code>对象到<code>tf.Session.run</code>，TensorFlow将执行 计算结果所需的操作。</p>
<p><code>tf.Session.run</code>要求您指定一个确定的提取列表 返回值，可能是<code>tf.Operation</code>，<code>tf.Tensor</code>或<br>像<code>tf.Variable</code>那样的张量型。这些提取 确定整个<code>tf.Graph</code>的哪个子图必须执行 产生结果：这是包含所有名为in的操作的子图<br>读取列表以及所有其输出用于计算值的操作 的取货。例如，下面的代码片段显示了如何不同 <code>tf.Session.run</code>的参数会导致不同的子图被执行：</p>
<pre><code>x = tf.constant([[37.0, -23.0], [1.0, 4.0]])
w = tf.Variable(tf.random_uniform([2, 2]))
y = tf.matmul(x, w)
output = tf.nn.softmax(y)
init_op = w.initializer

with tf.Session() as sess:
  # Run the initializer on `w`.
  sess.run(init_op)

  # Evaluate `output`. `sess.run(output)` will return a NumPy array containing
  # the result of the computation.
  print(sess.run(output))

  # Evaluate `y` and `output`. Note that `y` will only be computed once, and its
  # result used both to return `y_val` and as an input to the `tf.nn.softmax()`
  # op. Both `y_val` and `output_val` will be NumPy arrays.
  y_val, output_val = sess.run([y, output])
</code></pre><p><code>tf.Session.run</code>也可以选择一个饲料字典，这是一个 从<code>tf.Tensor</code>物体（通常为<code>tf.placeholder</code>张量）映射到<br>值（通常是Python标量，列表或NumPy数组） 代替执行中的张量。例如：</p>
<pre><code># Define a placeholder that expects a vector of three floating-point values,
# and a computation that depends on it.
x = tf.placeholder(tf.float32, shape=[3])
y = tf.square(x)

with tf.Session() as sess:
  # Feeding a value changes the result that is returned when you evaluate `y`.
  print(sess.run(y, {x: [1.0, 2.0, 3.0]})  # =&gt; &quot;[1.0, 4.0, 9.0]&quot;
  print(sess.run(y, {x: [0.0, 0.0, 5.0]})  # =&gt; &quot;[0.0, 0.0, 25.0]&quot;

  # Raises `tf.errors.InvalidArgumentError`, because you must feed a value for
  # a `tf.placeholder()` when evaluating a tensor that depends on it.
  sess.run(y)

  # Raises `ValueError`, because the shape of `37.0` does not match the shape
  # of placeholder `x`.
  sess.run(y, {x: 37.0})
</code></pre><p><code>tf.Session.run</code>也支持可选的<code>options</code>参数 指定关于呼叫的选项，以及可选的<code>run_metadata</code>参数<br>使您能够收集有关执行的元数据。例如，你可以使用 这些选项一起收集有关执行的跟踪信息：</p>
<pre><code>y = tf.matmul([[37.0, -23.0], [1.0, 4.0]], tf.random_uniform([2, 2]))

with tf.Session() as sess:
  # Define options for the `sess.run()` call.
  options = tf.RunOptions()
  options.output_partition_graphs = True
  options.trace_level = tf.RunOptions.FULL_TRACE

  # Define a container for the returned metadata.
  metadata = tf.RunMetadata()

  sess.run(y, options=options, run_metadata=metadata)

  # Print the subgraphs that executed on each device.
  print(metadata.partition_graphs)

  # Print the timings of each operation that executed.
  print(metadata.step_stats)
</code></pre><h2><span id="可视化你的图形">可视化你的图形</span></h2><p>TensorFlow包含的工具可以帮助您理解图表中的代码。 图表可视化器是TensorBoard的一个组件， 在浏览器中可视化结构。最简单的方法来创建一个<br>可视化是在创建<code>tf.Graph</code>时通过 <code>tf.summary.FileWriter</code>：</p>
<pre><code># Build your graph.
x = tf.constant([[37.0, -23.0], [1.0, 4.0]])
w = tf.Variable(tf.random_uniform([2, 2]))
y = tf.matmul(x, w)
# ...
loss = ...
train_op = tf.train.AdagradOptimizer(0.01).minimize(loss)

with tf.Session() as sess:
  # `sess.graph` provides access to the graph used in a `tf.Session`.
  writer = tf.summary.FileWriter(&quot;/tmp/log/...&quot;, sess.graph)

  # Perform your computation...
  for i in range(1000):
    sess.run(train_op)
    # ...

  writer.close()
</code></pre><p>注意：如果您使用<code>tf.estimator.Estimator</code>，图表（和任何 摘要）将自动记录到您指定的<code>model_dir</code> 当创建估计器。</p>
<p>然后可以打开<code>tensorboard</code>中的日志，导航到“图形”选项卡，然后 看到图形结构的高级可视化。请注意，一个典型的 张量流图 -<br>特别是自动计算的训练图 渐变—有太多的节点，一次可视化。图形可视化工具 使用名称范围将相关操作分组为“超级”节点。您可以<br>点击这些超级节点上的橙色“+”按钮来展开 子图里面。</p>
<p><img src="https://www.tensorflow.org/images/mnist_deep.png" alt=""></p>
<p>有关使用TensorFlow应用程序可视化的更多信息 TensorBoard，请参阅TensorBoard教程。</p>
<h2><span id="用多个图表编程">用多个图表编程</span></h2><p>注意：在训练模型时，组织代码的常用方法是使用一个 用于训练模型的图表，以及用于评估或执行的单独图形 推理与训练有素的模型。在许多情况下，推理图将是<br>与训练图不同：例如，丢失和丢失等技术 批量标准化在每种情况下使用不同的操作。而且，通过<br>如<code>tf.train.Saver</code>的默认实用程序使用<code>tf.Variable</code>对象的名称 （其名称基于<code>tf.Operation</code>）来识别每一个<br>在保存的检查点中变量。用这种方式编程时，可以使用 完全分离Python进程来构建和执行图，或者你可以 在同一个过程中使用多个图。本节介绍如何使用<br>在同一个过程中的多个图表。</p>
<p>如上所述，TensorFlow提供了一个隐式传递的“默认图” 到同一上下文中的所有API函数。对于许多应用程序，一个图形<br>足够了。但是，TensorFlow也提供了操作的方法 默认图形，这在更高级的用例中可能是有用的。例如：</p>
<p><code>tf.Graph</code>定义<code>tf.Operation</code>对象的名称空间：每个对象   在单个图表中操作必须具有唯一的名称。 TensorFlow将会<br>通过附加<code>&quot;_1&quot;</code>，<code>&quot;_2&quot;</code>等来“独立”操作的名称   他们的名字，如果请求的名字已经被采取。明确使用多个   创建的图表让您更多地控制给每个名称<br>操作。 默认图表存储有关<code>tf.Operation</code>和<code>tf.Tensor</code>的信息   <code>tf.Graph</code>曾被添加到它。如果你的程序创建一个大数字<br>没有连接的子图，使用不同的子图可能更有效率   <code>tf.Graph</code>构建每个子图，这样无关的状态可以被垃圾回收   集。</p>
<p>您可以使用默认的图形安装不同的<code>tf.Graph.as_default</code> <code>tf.get_default_graph</code>上下文管理器：</p>
<pre><code>g_1 = tf.Graph()
with g_1.as_default():
  # Operations created in this scope will be added to `g_1`.
  c = tf.constant(&quot;Node in g_1&quot;)

  # Sessions created in this scope will run operations from `g_1`.
  sess_1 = tf.Session()

g_2 = tf.Graph()
with g_2.as_default():
  # Operations created in this scope will be added to `g_2`.
  d = tf.constant(&quot;Node in g_2&quot;)

# Alternatively, you can pass a graph when constructing a `tf.Session`:
# `sess_2` will run operations from `g_2`.
sess_2 = tf.Session(graph=g_2)

assert c.graph is g_1
assert sess_1.graph is g_1

assert d.graph is g_2
assert sess_2.graph is g_2
</code></pre><p>要检查当前的默认图形，请拨打<code>tf.Graph</code> 返回一个CXJ743-HDK-53L对象：</p>
<pre><code># Print all of the operations in the default graph.
g = tf.get_default_graph()
print(g.get_operations())
</code></pre>
        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/prepare_models/" title="为移动部署准备模型" itemprop="url">为移动部署准备模型</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="为移动部署准备模型">为移动部署准备模型</span></h1><p>训练期间存储模型信息的要求非常高 与您想要将其作为移动应用程序的一部分发布时不同。本节 涵盖了从训练模型转换到某种东西所涉及的工具 在生产中可释放。</p>
<h2><span id="什么是所有不同的保存文件格式">什么是所有不同的保存文件格式？</span></h2><p>你可能会发现自己被所有不同的方式所困惑 TensorFlow可以保存图表。为了帮助，这里是一些破解 不同的组件，以及它们的用途。对象大都是定义的<br>并作为协议缓冲区序列化：</p>
<p>NodeDef：   定义模型中的单个操作。它有一个独特的名字，一个名单   它从其中获取输入的其他节点的名称，它实现的操作类型<br>（例如<code>Add</code>或<code>Mul</code>）以及控制所需的任何属性   那个操作。这是TensorFlow的基本计算单位<br>通过遍历这些节点的网络来完成工作，应用每个节点   反过来。 <code>Const</code>是一款值得了解的特殊操作类型，<br>因为这持有关于常数的信息。这可能是一个单一的标量   数字或字符串，但它也可以保存整个多维张量   阵列。<br><code>Const</code>的值存储在<code>NodeDef</code>内部，如此大   序列化时，常量会占用很多空间。 检查点。另一个<br>存储模型值的方法是使用<code>Variable</code>操作系统。与<code>Const</code>不同   ops，它们不把它们的内容存储为<code>NodeDef</code>的一部分，所以它们占用了<br><code>GraphDef</code>文件中的空间很小。相反，他们的价值观被保留在   计算正在运行的RAM，然后作为检查点保存到磁盘<br>文件定期。这通常发生在一个神经网络正在   训练和权重更新，所以这是一个时间关键的操作，它可能   发生在许多工作人员的分布式，所以文件格式必须<br>既快又灵活。它们被存储为多个检查点文件，   以及描述包含内容的元数据文件   检查站。当你指的是API中的检查点（例如，<br>当传递一个文件名作为命令行参数），你将使用通用的   一组相关文件的前缀。如果你有这些文件： /tmp/model/model-<br>chkpt-1000.data-00000-of-00002 /tmp/model/model-chkpt-1000.data-00001-of-00002<br>/tmp/model/model-chkpt-1000.index /tmp/model/model-chkpt-1000.meta<br>你可以把它们称为<code>/tmp/model/chkpt-1000</code>。 GraphDef：   有一个<code>NodeDefs</code>的列表，它们一起定义了计算图<br>执行。在训练期间，其中一些节点将是<code>Variables</code>，如果是这样的话   你想有一个完整的图表，你可以运行，包括权重，你会的<br>需要调用恢复操作来从中提取这些值   检查站。因为检查点加载必须灵活处理所有   培训要求，这可能是棘手的实施在移动和<br>嵌入式设备，特别是那些没有适当的文件系统可用   iOS版。这是哪里   该   <code>freeze_graph.py</code>脚本<br>派上用场。如上所述，<code>Const</code>操作将其值存储为一部分   <code>NodeDef</code>，所以如果所有的<code>Variable</code>砝码都转换成<code>Const</code>节点，<br>那么我们只需要一个<code>GraphDef</code>文件来保存模型架构   重量。冻结图形处理加载的过程<br>检查点，然后将所有Consts转换为Variables。你可以加载   生成的文件在一次调用中，而不必恢复变量值<br>从检查站。有一件事要注意与<code>GraphDef</code>文件是   有时它们以文本格式存储以便于检查。这些版本<br>通常有一个’.pbtxt’文件名后缀，而二进制文件结尾   “.pb”。 FunctionDefLibrary：<br>这出现在<code>GraphDef</code>中，实际上是一组子图，每个子图都带有   有关他们的输入和输出节点的信息。每个子图都可以<br>在主图中作为op使用，允许不同的实例化   节点，类似于函数如何封装其他语言的代码。 MetaGraphDef：<br>一个普通的<code>GraphDef</code>只有关于计算网络的信息，但是   没有关于模型的任何额外的信息或者它是如何的   用过的。<br><code>MetaGraphDef</code>包含<code>GraphDef</code>定义的计算部分   模型，还包括像“签名”这样的信息   关于您可能想要调用模型的输入和输出的建议<br>与关于如何和在哪里检查点文件被保存的数据以及便利性   将ops分组在一起以便于使用的标签。 SavedModel：<br>想要拥有依赖于a的不同版本的图形是很常见的   常见的一组变量检查点。例如，你可能需要一个GPU和一个   相同图形的CPU版本，但保持相同的权重。你可以<br>还需要一些额外的文件（如标签名称）作为你的一部分   模型。该   SavedModel格式   通过让您保存同一图形的多个版本来满足这些需求<br>没有重复的变量，也存储在同一个资产文件   束。在引擎盖下，它使用<code>MetaGraphDef</code>和检查点文件   与额外的元数据文件。这是你想要使用的格式<br>例如，使用TensorFlow Serving部署Web API。</p>
<h2><span id="你如何得到一个你可以在手机上使用的模型">你如何得到一个你可以在手机上使用的模型？</span></h2><p>在大多数情况下，用TensorFlow训练一个模型会给你一个文件夹 包含<code>GraphDef</code>文件（通常以<code>.pb</code>或<code>.pbtxt</code>扩展结尾）和<br>一组检查点文件。你需要的移动或嵌入式部署是一个 单个<code>GraphDef</code>文件被“冻结”，或将其变量转换为<br>内联常量，所以一切都在一个文件中。为了处理转换，你会的 需要使用<code>freeze_graph.py</code>脚本<br><code>tensorflow/python/tools/freeze_graph.py</code>。你会像这样运行它：</p>
<pre><code>bazel build tensorflow/tools:freeze_graph
bazel-bin/tensorflow/tools/freeze_graph \
--input_graph=/tmp/model/my_graph.pb \
--input_checkpoint=/tmp/model/model.ckpt-1000 \
--output_graph=/tmp/frozen_graph.pb \
--output_node_names=output_node \
</code></pre><p><code>input_graph</code>参数应指向<code>GraphDef</code>文件 模型建筑。您的<code>GraphDef</code>可能已存储在文本中<br>格式化，在这种情况下，可能会以<code>.pbtxt</code>而不是<code>.pb</code>结束， 您应该为命令添加一个额外的<code>--input_binary=false</code>标志。</p>
<p><code>input_checkpoint</code>应该是最近保存的检查点。如上所述 在检查点部分，你需要给这个集合赋予通用前缀 检查点在这里，而不是一个完整的文件名。</p>
<p><code>output_graph</code>定义了冷冻<code>GraphDef</code>的位置 保存。因为它可能包含很多重量值，占用一个<br>文本格式的大量空间，它总是保存为一个二进制protobuf。</p>
<p><code>output_node_names</code>是要提取的节点的名称列表 从你的图形的结果。这是需要的，因为冻结过程 需要了解图的哪些部分实际上是需要的，哪些是<br>训练过程中的文物，如汇总操作。只有那个 有助于计算给定的输出节点将被保留。如果你知道如何 你的图将被使用，这些应该只是你的节点的名字<br>作为您的抓取目标传入<code>Session::Run()</code>。最简单的方法来找到 节点名称是检查节点对象，同时在python中构建图形。<br>在TensorBoard中检查图形是另一种简单的方法。你可以得到一些 通过运行<code>summarize_graph</code>工具可能的输出建议。</p>
<p>由于TensorFlow的输出格式随着时间的推移而变化，所以有一个 其他各种不太常用的标志也可用，如<code>input_saver</code>，但是<br>希望你不应该需要这些在与现代版本的训练图 框架。</p>
<h2><span id="使用图形变换工具">使用图形变换工具</span></h2><p>在设备上高效运行模型需要做很多事情 通过图形变换可用 工具。这个 命令行工具将输入<code>GraphDef</code>文件，应用该套重写<br>你要求的规则，然后把结果写成<code>GraphDef</code>。看到了 文档了解如何构建和运行此工具的更多信息。</p>
<h3><span id="删除仅限培训的节点">删除仅限培训的节点</span></h3><p>培训代码所生产的TensorFlow <code>GraphDefs</code>包含了所有的功能 计算也是反向传播和权重更新所需要的<br>作为输入的排队和解码，以及节省检查点。所有的 这些节点在推理过程中不再需要，还有一些操作 像检查点保存甚至在移动平台上都不支持。创建一个<br>模型文件，你可以加载设备上，你需要删除那些不需要的 通过在图形变换工具中运行<code>strip_unused_nodes</code>规则进行操作。</p>
<p>这个过程中最棘手的部分是找出你的节点名称 希望在推理期间用作输入和输出。无论如何，你将需要这些 一旦你开始推理，但你也需要在这里这样的<br>变换可以计算哪些节点是不需要的只是推论 路径。这些可能不是显而易见的训练码。最简单的方法 确定节点名称是用TensorBoard来浏览图形。</p>
<p>请记住，移动应用程序通常从传感器收集数据 将其作为内存中的数组，而培训通常涉及加载和 解码存储在磁盘上的数据的表示。 Inception v3的情况<br>例如，在设计的图表开始处有一个<code>DecodeJpeg</code>操作 从磁盘检索的文件中获取JPEG编码的数据并将其转换为<br>任意大小的图像。之后，有一个<code>BilinearResize</code>可以调整 预期的大小，其次是一些转换字节数据的其他操作<br>进入浮动状态，并按照图形的其余部分缩放值的大小 预计。一个典型的移动应用程序将跳过这些步骤的大部分，因为它越来越<br>它直接从一个实时摄像机输入，所以你实际上是输入节点 在这种情况下，<code>Mul</code>节点的输出将是输出。</p>
<p><img src="https://www.tensorflow.org/images/inception_input.png" alt=""></p>
<p>你需要做一个类似的检查过程来找出正确的 输出节点。</p>
<p>如果您刚刚获得一个冷冻<code>GraphDef</code>文件，并不确定 内容，请尝试使用<code>summarize_graph</code>工具打印出信息<br>关于它从图结构中找到的输入和输出。这是一个 例如原始的Inception v3文件：</p>
<pre><code>bazel run tensorflow/tools/graph_transforms:summarize_graph -- 
--in_graph=tensorflow_inception_graph.pb
</code></pre><p>一旦你了解了输入和输出节点的内容，你可以喂它们 进入图形转换工具<code>--input_names</code>和<code>--output_names</code><br>参数，并调用<code>strip_unused_nodes</code>变换，如下所示：</p>
<pre><code>bazel run tensorflow/tools/graph_transforms:transform_graph --
--in_graph=tensorflow_inception_graph.pb
--out_graph=optimized_inception_graph.pb --inputs=&apos;Mul&apos; --outputs=&apos;softmax&apos;
--transforms=&apos;
  strip_unused_nodes(type=float, shape=&quot;1,299,299,3&quot;)
  fold_constants(ignore_errors=true)
  fold_batch_norms
  fold_old_batch_norms&apos;
</code></pre><p>有一点需要注意的是，你需要指定大小和类型 你想要你的投入。这是因为你想要的任何值 作为输入推理需要被送到特殊的<code>Placeholder</code>操作<br>节点，如果它们不存在，转换可能需要创建它们。在 例如，以Inception v3为例，<code>Placeholder</code>节点取代了旧的<br><code>Mul</code>节点，用于输出调整大小和重新调整大小的图像数组，因为我们是 在我们称之为TensorFlow之前，我们会自己处理这个过程。它使<br>原来的名字，这就是为什么我们总是在输入到<code>Mul</code>时，我们 使用我们修改后的Inception图表运行一个会话。</p>
<p>运行这个过程之后，你将会看到一个只包含实际的图表 您需要运行预测过程的节点。这是它的地方 在图上运行指标变得有用，所以值得运行<br><code>summarize_graph</code>再次了解你的模型是什么。</p>
<h2><span id="你应该在手机上包含哪些操作">你应该在手机上包含哪些操作？</span></h2><p>TensorFlow中有数百个操作，每个都有 针对不同数据类型的多个实现。在移动平台上，大小 编译后产生的可执行二进制文件的重要性，因为<br>应用程序下载捆绑包需要尽可能小，以供最好的用户使用 经验。如果所有操作和数据类型都被编译到TensorFlow中 库，那么编译的库的总大小可以是几十兆，所以<br>默认情况下只包含ops和数据类型的一个子集。</p>
<p>这意味着如果您加载在桌面上受过训练的模型文件 机器，您可能会看到错误“没有OpKernel被注册为支持操作”时<br>你在手机上加载它。首先要尝试的是确保你已经剥离 在任何只有训练的节点上，因为错误会在加载时发生，即使是 op从不执行。如果一旦完成，您仍然遇到同样的问题，<br>您需要考虑将操作添加到构建的库中。</p>
<p>包括操作和类型的标准分为几类：</p>
<p>它们仅在反向传播中用于渐变吗？由于移动是   重点推断，我们不包括这些。 它们主要用于其他培训需求，如检查点保存？   这些我们离开了。<br>他们是否依赖并不总是在移动设备上提供的框架，比如   libjpeg的？为了避免额外的依赖，我们不包括像<code>DecodeJpeg</code>这样的操作系统。<br>有没有经常使用的类型？我们不包含布尔变量   例如ops，因为我们在典型的推理中没有看到太多的用处   图表。</p>
<p>这些操作被默认设置为优化，以便在移动设备上进行推理 可能改变一些构建文件来改变默认值。交替之后<br>建立文件，你将需要重新编译TensorFlow。请参阅下面的更多细节 在如何做到这一点，也看到优化 更多关于减少你的二进制大小。</p>
<h3><span id="找到实施">找到实施</span></h3><p>操作分为两部分。首先是op的定义，哪个 声明操作的签名，输入，输出和属性 它有。这些占用的空间非常小，所以默认情况下都包含在内。该<br>操作计算的实现是在内核中完成的 <code>tensorflow/core/kernels</code>文件夹。您需要编译包含的C ++文件 你需要的库的内核实现。弄清楚<br>哪个文件即可以搜索源中的操作名称 文件。</p>
<p>这里是一个在github中的示例搜索。</p>
<p>你会发现这个搜索正在寻找<code>Mul</code>的操作实现 在<code>tensorflow/core/kernels/cwise_op_mul_1.cc</code>中找到它。你需要寻找<br>以<code>REGISTER</code>开头的宏，以你所关心的op名称作为其中之一 字符串参数。</p>
<p>在这种情况下，这些实现实际上是在多个<code>.cc</code>上分解的 文件，所以你需要在你的版本中包含所有的文件。如果你更多<br>舒服的使用命令行进行代码搜索，这里是一个grep命令 如果从TensorFlow的根目录运行它，也会找到正确的文件 库：</p>
<p><code>grep &#39;REGISTER.*&quot;Mul&quot;&#39; tensorflow/core/kernels/*.cc</code></p>
<h3><span id="将实现添加到构建">将实现添加到构建</span></h3><p>如果您使用Bazel，并为Android构建，则需要添加这些文件 你已经找到了 该 <code>android_extended_ops_group1</code>或<br><code>android_extended_ops_group2</code>目标。您 可能还需要包含它们依赖的任何.cc文件。如果构建 抱怨缺少头文件，添加需要的.h’s 该<br><code>android_extended_ops</code>目标。</p>
<p>如果您使用的是面向iOS，树莓派等的makefile，请转到 <code>tensorflow/contrib/makefile/tf_op_files.txt</code>和<br>在那里添加正确的实现文件。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/saved_model/" title="保存和恢复" itemprop="url">保存和恢复</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="保存和恢复">保存和恢复</span></h1><p>本文档介绍了如何保存和恢复 变量和模型。</p>
<h2><span id="保存和恢复变量">保存和恢复变量</span></h2><p>TensorFlow变量提供了表示共享，持久性的最佳方式 状态由你的程序操纵。 （详见变量） 本节介绍如何保存和恢复变量。<br>请注意，估算器会自动保存和恢复变量 （在<code>model_dir</code>中）。</p>
<p><code>tf.train.Saver</code>类提供了保存和恢复模型的方法。 <code>tf.train.Saver</code>构造器增加了<code>save</code>和<code>restore</code> ops到图<br>为图表中的所有变量或指定的列表。 <code>Saver</code> 对象提供了运行这些操作的方法，指定检查点的路径 要写入或读取的文件。</p>
<p>保存器将恢复已经在模型中定义的所有变量。如果你是 加载一个模型，而不知道如何建立它的图形（例如，如果你是 编写一个通用程序来加载模型），然后阅读<br>保存和恢复模型概述部分 稍后在这个文件中。</p>
<p>TensorFlow将变量保存在二进制检查点文件中， 大致来说，将变量名称映射到张量值。</p>
<h3><span id="保存变量">保存变量</span></h3><p>用<code>Saver</code>创建一个<code>tf.train.Saver()</code>来管理所有变量 模型。例如，下面的代码演示了如何调用<br><code>tf.train.Saver.save</code>方法将变量保存到检查点文件：</p>
<pre><code># Create some variables.
v1 = tf.get_variable(&quot;v1&quot;, shape=[3], initializer = tf.zeros_initializer)
v2 = tf.get_variable(&quot;v2&quot;, shape=[5], initializer = tf.zeros_initializer)

inc_v1 = v1.assign(v1+1)
dec_v2 = v2.assign(v2-1)

# Add an op to initialize the variables.
init_op = tf.global_variables_initializer()

# Add ops to save and restore all the variables.
saver = tf.train.Saver()

# Later, launch the model, initialize the variables, do some work, and save the
# variables to disk.
with tf.Session() as sess:
  sess.run(init_op)
  # Do some work with the model.
  inc_v1.op.run()
  dec_v2.op.run()
  # Save the variables to disk.
  save_path = saver.save(sess, &quot;/tmp/model.ckpt&quot;)
  print(&quot;Model saved in file: %s&quot; % save_path)
</code></pre><h3><span id="恢复变量">恢复变量</span></h3><p><code>tf.train.Saver</code>对象不仅将变量保存到检查点文件中 还恢复变量。请注意，当你从文件恢复变量 不必事先初始化它们。例如，下面的代码片段<br>演示如何调用<code>tf.train.Saver.restore</code>方法进行恢复 来自检查点文件的变量：</p>
<pre><code>tf.reset_default_graph()

# Create some variables.
v1 = tf.get_variable(&quot;v1&quot;, shape=[3])
v2 = tf.get_variable(&quot;v2&quot;, shape=[5])

# Add ops to save and restore all the variables.
saver = tf.train.Saver()

# Later, launch the model, use the saver to restore variables from disk, and
# do some work with the model.
with tf.Session() as sess:
  # Restore variables from disk.
  saver.restore(sess, &quot;/tmp/model.ckpt&quot;)
  print(&quot;Model restored.&quot;)
  # Check the values of the variables
  print(&quot;v1 : %s&quot; % v1.eval())
  print(&quot;v2 : %s&quot; % v2.eval())
</code></pre><h3><span id="选择要保存和恢复的变量">选择要保存和恢复的变量</span></h3><p>如果您没有将任何参数传递给<code>tf.train.Saver()</code>，那么保存程序将处理所有的数据 图中的变量。每个变量都保存在传递的名字下 当变量被创建时。</p>
<p>显式指定变量的名字有时是有用的 检查点文件。例如，您可能已经用一个变量训练了一个模型 命名为<code>&quot;weights&quot;</code>，其值要恢复到一个名为<br><code>&quot;params&quot;</code>。</p>
<p>仅保存或恢复一部分变量也是有用的 由模型使用。例如，你可能已经训练了五个神经网络 你现在想要训练一个六层的新模型来重用这个模型<br>现有的五个训练层的权重。您可以使用保存程序进行恢复 只有前五层的权重。</p>
<p>您可以通过传递来轻松指定要保存或加载的名称和变量 <code>tf.train.Saver()</code>的构造函数如下：</p>
<p>变量列表（将以自己的名字存储）。 一个Python字典，其中键是要使用的名称，值是 要管理的变量。</p>
<p>继续前面的保存/恢复示例：</p>
<pre><code>tf.reset_default_graph()
# Create some variables.
v1 = tf.get_variable(&quot;v1&quot;, [3], initializer = tf.zeros_initializer)
v2 = tf.get_variable(&quot;v2&quot;, [5], initializer = tf.zeros_initializer)

# Add ops to save and restore only `v2` using the name &quot;v2&quot;
saver = tf.train.Saver({&quot;v2&quot;: v2})

# Use the saver object normally after that.
with tf.Session() as sess:
  # Initialize v1 since the saver will not.
  v1.initializer.run()
  saver.restore(sess, &quot;/tmp/model.ckpt&quot;)

  print(&quot;v1 : %s&quot; % v1.eval())
  print(&quot;v2 : %s&quot; % v2.eval())
</code></pre><p>笔记：</p>
<p>如果需要保存并且可以创建任意数量的<code>Saver</code>对象    恢复模型变量的不同子集。相同的变量可以    列在多个保存对象中;它的价值只有在改变的时候<br><code>Saver.restore()</code>方法运行。 如果您仅在a的开始处恢复模型变量的子集    会话，你必须运行其他变量的初始化操作。看到<br><code>tf.variables_initializer</code>了解更多信息。 要检查检查点中的变量，可以使用    <code>inspect_checkpoint</code><br>库，特别是<code>print_tensors_in_checkpoint_file</code>功能。<br>默认情况下，<code>Saver</code>使用<code>tf.Variable.name</code>属性的值    为每个变量。但是，当您创建一个<code>Saver</code>对象时，您可以<br>可以选择检查点文件中变量的名称。</p>
<h2><span id="保存和恢复模型概述">保存和恢复模型概述</span></h2><p>当你想保存和加载变量，图形，和 图表的元数据 - 基本上，当你想保存或恢复 你的模型 - 我们推荐使用SavedModel。<br>SavedModel是一种语言中立，可恢复，密封 序列化格式。 SavedModel启用更高级别的系统 以及生产，消费和改造TensorFlow模型的工具。<br>TensorFlow提供了多种与之交互的机制 SavedModel，包括tf.saved_model API，Estimator API和CLI。</p>
<h2><span id="api来构建和加载savedmodel">API来构建和加载SavedModel</span></h2><p>本节重点介绍用于构建和加载SavedModel的API， 特别是在使用低级别的TensorFlow API时。</p>
<h3><span id="建立一个savedmodel">建立一个SavedModel</span></h3><p>我们提供了一个SavedModel的Python实现 建设者。 <code>SavedModelBuilder</code>类提供功能 保存多台<code>MetaGraphDef</code>。<br>MetaGraph是一个数据流图，加上 其关联的变量，资产和签名。 <code>MetaGraphDef</code> 是MetaGraph的协议缓冲表示。签名是<br>图表的输入和输出的集合。</p>
<p>如果资产需要保存，写入或复制到磁盘，可以提供 当第一台<code>MetaGraphDef</code>被添加时。如果多个<code>MetaGraphDef</code>是<br>与同名资产相关联，只保留第一个版本。</p>
<p>每个添加到SavedModel的<code>MetaGraphDef</code>都必须注明 用户指定的标签。标签提供了一种方法来识别具体的<br><code>MetaGraphDef</code>加载和恢复，以及共享的一组变量 和资产。这些标签 通常使用其功能注释<code>MetaGraphDef</code>（例如，<br>服务或培训）以及可选的硬件特定方面（对于 例如，GPU）。</p>
<p>例如，下面的代码提示了一个典型的使用方法 <code>SavedModelBuilder</code>构建SavedModel：</p>
<pre><code>export_dir = ...
...
builder = tf.saved_model_builder.SavedModelBuilder(export_dir)
with tf.Session(graph=tf.Graph()) as sess:
  ...
  builder.add_meta_graph_and_variables(sess,
                                       [tag_constants.TRAINING],
                                       signature_def_map=foo_signatures,
                                       assets_collection=foo_assets)
...
# Add a second MetaGraphDef for inference.
with tf.Session(graph=tf.Graph()) as sess:
  ...
  builder.add_meta_graph([tag_constants.SERVING])
...
builder.save()
</code></pre><h3><span id="在python中加载savedmodel">在Python中加载SavedModel</span></h3><p>SavedModel的Python版本 装载机 为SavedModel提供加载和恢复功能。 <code>load</code>操作 需要以下信息：</p>
<p>在其中恢复图形定义和变量的会话。 用于标识要加载的MetaGraphDef的标签。 SavedModel的位置（目录）。</p>
<p>加载时，作为其一部分提供的变量，资产和签名的子集 具体的MetaGraphDef将被恢复到提供的会话中。</p>
<pre><code>export_dir = ...
...
with tf.Session(graph=tf.Graph()) as sess:
  tf.saved_model.loader.load(sess, [tag_constants.TRAINING], export_dir)
  ...
</code></pre><h3><span id="使用c-加载savedmodel">使用C ++加载Savedmodel</span></h3><p>SavedModel的C ++版本 装载机 提供了一个API来从路径加载SavedModel，同时允许<br><code>SessionOptions</code>和<code>RunOptions</code>。 您必须指定与要加载的图形关联的标签。<br>SavedModel的加载版本被称为<code>SavedModelBundle</code> 并包含MetaGraphDef和加载它的会话。</p>
<pre><code>const string export_dir = ...
SavedModelBundle bundle;
...
LoadSavedModel(session_options, run_options, export_dir, {kSavedModelTagTrain},
               &amp;bundle);
</code></pre><h3><span id="标准常量">标准常量</span></h3><p>SavedModel提供了构建和加载TensorFlow图形的灵活性 各种各样的用例。对于最常见的用例，SavedModel的API 在Python和C<br>++中提供一组易于使用的常量 一致地重复使用和分享各种工具</p>
<h4><span id="标准的metagraphdef标签">标准的MetaGraphDef标签</span></h4><p>您可以使用一组标签来唯一标识一个<code>MetaGraphDef</code>中保存的 SavedModel。常用标签的一个子集是在以下中指定的：</p>
<p>蟒蛇 C ++</p>
<h4><span id="标准signaturedef常量">标准SignatureDef常量</span></h4><p>SignatureDef 是定义计算签名的协议缓冲区 由图形支持。 常用的输入键，输出键和方法名是 定义在：</p>
<p>蟒蛇 C ++</p>
<h2><span id="使用带估计器的savedmodel">使用带估计器的SavedModel</span></h2><p>在培训<code>Estimator</code>型号后，您可能需要创建一项服务 从那个接受请求并返回结果的模型开始。你可以运行这样的<br>在您的计算机上进行本地服务或在云中进行可扩展部署。</p>
<p>要准备一个训练有素的评估服务器，您必须将其导出到标准中 SavedModel格式。本节介绍如何：</p>
<p>指定输出节点和相应的   蜜蜂   可以服务（分类，回归或预测）。 将您的模型导出到SavedModel格式。 从本地服务器提供模型并请求预测。</p>
<h3><span id="准备服务投入">准备服务投入</span></h3><p>在培训期间，<code>input_fn()</code>摄取数据并准备好 由模型使用。在服务时间，同样，<code>serving_input_receiver_fn()</code><br>接受推理请求并为模型做好准备。这个功能 有以下目的：</p>
<p>将占位符添加到服务系统将要馈送的图形中    有推理请求。 添加需要从输入格式转换数据的任何额外的操作    进入模型期望的<code>Tensor</code>功能。</p>
<p>该函数返回一个<code>tf.estimator.export.ServingInputReceiver</code>对象， 将占位符和结果特征<code>Tensor</code>封装在一起。</p>
<p>典型的模式是推理请求以序列化的形式到达 <code>tf.Example</code>s，所以<code>serving_input_receiver_fn()</code>创建一个单一的字符串<br>占位符来接收它们。 <code>serving_input_receiver_fn()</code>也是 负责通过添加<code>tf.Example</code><br>op来解析<code>tf.parse_example</code> 图表。</p>
<p>在编写这样的<code>serving_input_receiver_fn()</code>时，您必须通过解析 规范到<code>tf.parse_example</code>告诉解析器什么功能名称<br>期望以及如何将它们映射到<code>Tensor</code>。解析规范采用<br>从功能名称的字典形式到<code>tf.FixedLenFeature</code>，<code>tf.VarLenFeature</code>，<br>和<code>tf.SparseFeature</code>。注意这个解析规范不应该包含 任何标签或重量栏，因为那些不会在服务 时间 -<br>与<code>input_fn()</code>中使用的解析规范相反 训练时间。</p>
<p>结合起来，那么：</p>
<pre><code>feature_spec = {&apos;foo&apos;: tf.FixedLenFeature(...),
                &apos;bar&apos;: tf.VarLenFeature(...)}

def serving_input_receiver_fn():
  &quot;&quot;&quot;An input receiver that expects a serialized tf.Example.&quot;&quot;&quot;
  serialized_tf_example = tf.placeholder(dtype=tf.string,
                                         shape=[default_batch_size],
                                         name=&apos;input_example_tensor&apos;)
  receiver_tensors = {&apos;examples&apos;: serialized_tf_example}
  features = tf.parse_example(serialized_tf_example, feature_spec)
  return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)
</code></pre><p><code>tf.estimator.export.build_parsing_serving_input_receiver_fn</code>实用程序<br>功能为常见情况提供了输入接收器。</p>
<blockquote>
<p>注意：使用本地的Predict API训练要提供的模型时 服务器，解析步骤是不需要的，因为模型将接收原始 特征数据。</p>
</blockquote>
<p>即使你不需要解析或其他输入处理 - 也就是说， 服务系统将直接馈送功能<code>Tensor</code>s - 您仍然必须提供<br>为该功能创建占位符的<code>serving_input_receiver_fn()</code> <code>Tensor</code>s并通过它们。该<br><code>tf.estimator.export.build_raw_serving_input_receiver_fn</code>实用程序提供 这个。</p>
<p>如果这些工具不能满足您的需求，您可以自由编写自己的 <code>serving_input_receiver_fn()</code>。一个可能需要的情况是如果你的<br>培训<code>input_fn()</code>包含一些必须预处理的逻辑 在服务时间重述。为了减少服务歪斜的风险，我们 建议将这样的处理封装在一个被调用的函数中<br>来自<code>input_fn()</code>和<code>serving_input_receiver_fn()</code>。</p>
<p>请注意，<code>serving_input_receiver_fn()</code>也决定输入 签名的一部分。就是在写一个<br><code>serving_input_receiver_fn()</code>，你必须告诉解析器什么签名 期望以及如何将它们映射到您的模型的预期输入。<br>相比之下，签名的输出部分由模型确定。</p>
<h3><span id="执行导出">执行导出</span></h3><p>要导出已训练的估算器，请致电 <code>tf.estimator.Estimator.export_savedmodel</code>与出口基地路径和<br><code>serving_input_receiver_fn</code>。</p>
<pre><code>estimator.export_savedmodel(export_dir_base, serving_input_receiver_fn)
</code></pre><p>这个方法先建立一个新的图形， <code>serving_input_receiver_fn()</code>获得功能<code>Tensor</code>s，然后调用<br>这台<code>Estimator</code>的<code>model_fn()</code>可以生成基于这些模型的图形 特征。它启动一个新的<code>Session</code>，并且默认情况下，恢复最近的 检查点。<br>（如果需要，可以通过不同的检查点。） 最后，它会在给定的下面创建一个带时间戳的导出目录<br><code>export_dir_base</code>（即<code>export_dir_base/&lt;timestamp&gt;</code>），并写入一个<br>包含一个单独的<code>MetaGraphDef</code>的SavedModel 会话。</p>
<blockquote>
<p>注意：您有责任垃圾回收旧出口。 否则，连续出口将在<code>export_dir_base</code>下积累。</p>
</blockquote>
<h3><span id="指定自定义模型的输出">指定自定义模型的输出</span></h3><p>在编写定制<code>model_fn</code>时，必须填写<code>export_outputs</code>元件<br>的<code>tf.estimator.EstimatorSpec</code>返回值。这是一个字典 <code>{name: output}</code>描述输出签名在输出和使用期间 服务。</p>
<p>在通常情况下做出单一的预测，这个字典包含 一个元素，<code>name</code>是不重要的。在一个多头模型，每个头<br>是由这个字典中的条目代表。在这种情况下，<code>name</code>是一个字符串 可以用来请求服务时间的特定头部。</p>
<p>每个<code>output</code>值必须是<code>ExportOutput</code>等对象 <code>tf.estimator.export.ClassificationOutput</code>，<br><code>tf.estimator.export.RegressionOutput</code>，或 <code>tf.estimator.export.PredictOutput</code>。</p>
<p>这些输出类型直接映射到 TensorFlow服务API， 并确定哪些请求类型将被兑现。</p>
<p>注意：在多头情况下，将为每个<code>SignatureDef</code>生成一个<code>export_outputs</code><br>从model_fn返回的<code>SignatureDef</code>字典的元素，用using命名 相同的键。这些<code>ExportOutput</code>仅在其输出方面有所不同，如<br>由相应的<code>serving_input_receiver_fn</code>条目提供。输入总是<br>那些由<code>signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY</code>提供的。<br>推理请求可以通过名称指定头部。一个头必须命名 使用<code>SignatureDef</code> 指示推理请求时<code>$export_dir_base</code>将被提供 没有指定一个。</p>
<h3><span id="在本地提供导出的模型">在本地提供导出的模型</span></h3><p>对于本地部署，您可以使用您的模型 TensorFlow Serving，一个开源项目，加载一个 SavedModel并将其公开为gRPC服务。</p>
<p>首先，安装TensorFlow服务。</p>
<p>然后构建并运行本地模型服务器，替换为<code>prediction_service_pb2</code> 上面导出的SavedModel的路径：</p>
<pre><code>bazel build //tensorflow_serving/model_servers:tensorflow_model_server
bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_base_path=$export_dir_base
</code></pre><p>现在，您有一台服务器在端口9000上通过gRPC监听推理请求！</p>
<h3><span id="从本地服务器请求预测">从本地服务器请求预测</span></h3><p>服务器响应gRPC请求根据 PredictionService gRPC API服务定义。 （嵌套的协议缓冲区在 各种相邻的文件）。</p>
<p>从API服务定义中，gRPC框架生成客户端库 以各种语言提供对API的远程访问。在一个项目中使用 Bazel构建工具，这些库是自动构建的，并通过提供<br>这样的依赖关系（例如使用Python）：</p>
<pre><code>deps = [
  &quot;//tensorflow_serving/apis:classification_proto_py_pb2&quot;,
  &quot;//tensorflow_serving/apis:regression_proto_py_pb2&quot;,
  &quot;//tensorflow_serving/apis:predict_proto_py_pb2&quot;,
  &quot;//tensorflow_serving/apis:prediction_service_proto_py_pb2&quot;
]
</code></pre><p>Python客户端代码可以导入这些库：</p>
<pre><code>from tensorflow_serving.apis import classification_pb2
from tensorflow_serving.apis import regression_pb2
from tensorflow_serving.apis import predict_pb2
from tensorflow_serving.apis import prediction_service_pb2
</code></pre><blockquote>
<p>注：<code>classification_pb2</code>定义整体服务等 总是需要的。但是一个典型的客户只需要一个<br><code>regression_pb2</code>，<code>predict_pb2</code>和<code>ClassificationResponse</code>，取决于 请求类型。</p>
</blockquote>
<p>然后通过组装一个协议缓冲器来发送一个gRPC请求 包含请求数据并将其传递给服务存根。注意如何 请求协议缓冲区被创建为空，然后通过 生成的协议缓冲区API。</p>
<pre><code>from grpc.beta import implementations

channel = implementations.insecure_channel(host, int(port))
stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)

request = classification_pb2.ClassificationRequest()
example = request.input.example_list.examples.add()
example.features.feature[&apos;x&apos;].float_list.value.extend(image[0].astype(float))

result = stub.Classify(request, 10.0)  # 10 secs timeout
</code></pre><p>本例中返回的结果是<code>ClassificationRequest</code>协议 缓冲。</p>
<p>这是一个骨架的例子。请参阅Tensorflow服务 文档和例子 更多细节。</p>
<blockquote>
<p>注：<code>RegressionRequest</code>和<code>tensorflow.serving.Input</code>包含一个<br><code>tensorflow.Example</code>协议缓冲区，其中又包含一个列表 <code>PredictRequest</code>协议缓冲区。相比之下，<code>TensorProto</code>，<br>包含从功能名称到通过<code>Classify</code>编码的值的映射。 相应地：当使用<code>Regress</code>和<code>tf.Example</code> API时，TensorFlow<br>将<code>serving_input_receiver_fn()</code>s连续传送到图表，以便您的 <code>tf.parse_example()</code>应包含一个<code>Predict</code><br>Op。 但是，使用通用<code>serving_input_receiver_fn()</code> API时，TensorFlow Serving会以原始数据提供<br>功能数据到图形中，所以通过<code>SignatureDef</code> 应该使用。</p>
</blockquote>
<h2><span id="cli检查并执行savedmodel">CLI检查并执行SavedModel</span></h2><p>您可以使用SavedModel命令行界面（CLI）来检查和 执行一个SavedModel。<br>例如，您可以使用CLI检查型号的<code>bin\saved_model_cli</code>。 CLI使您能够快速确认输入 张量dtype和形状匹配模型。而且，如果你<br>想要测试你的模型，你可以使用CLI做一个完整的检查 以各种格式传递示例输入（例如，Python 表达式），然后获取输出。</p>
<h3><span id="安装savedmodel-cli">安装SavedModel CLI</span></h3><p>一般来说，你可以在下面的任何一个中安装TensorFlow 两种方式：</p>
<p>通过安装预构建的TensorFlow二进制文件。 通过从源代码构建TensorFlow。</p>
<p>如果您通过预先构建的TensorFlow二进制文件安装了TensorFlow， 那么SavedModel CLI已经安装在您的系统上<br>路径名为<code>saved_model_cli</code>。</p>
<p>如果您从源代码构建TensorFlow，则必须运行以下命令 额外的命令来建立<code>MetaGraphDef</code>：</p>
<pre><code>$ bazel build tensorflow/python/tools:saved_model_cli
</code></pre><h3><span id="命令概述">命令概述</span></h3><p>SavedModel CLI在a上支持以下两个命令 <code>show</code>在SavedModel：</p>
<p><code>MetaGraphDef</code>，显示SavedModel中<code>run</code>的计算。 <code>MetaGraphDef</code>，在<code>show</code>上运行计算。</p>
<h3><span id="metagraphdef命令"><code>MetaGraphDef</code>命令</span></h3><p>SavedModel包含一个或多个<code>SignatureDef</code>，由其标签集标识。 为了服务一个模型，你<br>可能想知道每种型号的<code>show</code>是什么样的，它们是什么 投入和产出。 <code>SignatureDef</code>命令让你检查的内容<br>SavedModel按层次顺序排列。这里是语法：</p>
<pre><code>usage: saved_model_cli show [-h] --dir DIR [--all]
[--tag_set TAG_SET] [--signature_def SIGNATURE_DEF_KEY]
</code></pre><p>例如，以下命令显示所有可用的 SavedModel中的MetaGraphDef标签集：</p>
<pre><code>$ saved_model_cli show --dir /tmp/saved_model_dir
The given SavedModel contains the following tag-sets:
serve
serve, gpu
</code></pre><p>以下命令显示所有可用的<code>MetaGraphDef</code>键 <code>MetaGraphDef</code>：</p>
<pre><code>$ saved_model_cli show --dir /tmp/saved_model_dir --tag_set serve
The given SavedModel `MetaGraphDef` contains `SignatureDefs` with the
following keys:
SignatureDef key: &quot;classify_x2_to_y3&quot;
SignatureDef key: &quot;classify_x_to_y&quot;
SignatureDef key: &quot;regress_x2_to_y3&quot;
SignatureDef key: &quot;regress_x_to_y&quot;
SignatureDef key: &quot;regress_x_to_y2&quot;
SignatureDef key: &quot;serving_default&quot;
</code></pre><p>如果<code>SignatureDef</code>在标签集中有多个标签，则必须指定 所有标签，每个标签用逗号分隔。例如：</p>
<pre><code>$ saved_model_cli show --dir /tmp/saved_model_dir --tag_set serve,gpu
</code></pre><p>要显示特定<code>SignatureDef</code>的所有输入和输出TensorInfo，请传入<br><code>signature_def</code>钥匙到<code>--all</code>选件。这是非常有用的，当你 想要知道张量键值，输入张量的dtype和shape 稍后执行计算图。例如：</p>
<pre><code>$ saved_model_cli show --dir \
/tmp/saved_model_dir --tag_set serve --signature_def serving_default
The given SavedModel SignatureDef contains the following input(s):
inputs[&apos;x&apos;] tensor_info:
    dtype: DT_FLOAT
    shape: (-1, 1)
    name: x:0
The given SavedModel SignatureDef contains the following output(s):
outputs[&apos;y&apos;] tensor_info:
    dtype: DT_FLOAT
    shape: (-1, 1)
    name: y:0
Method name is: tensorflow/serving/predict
</code></pre><p>要显示SavedModel中的所有可用信息，请使用<code>run</code>选件。 例如：</p>
<pre><code>$ saved_model_cli show --dir /tmp/saved_model_dir --all
MetaGraphDef with tag-set: &apos;serve&apos; contains the following SignatureDefs:

signature_def[&apos;classify_x2_to_y3&apos;]:
The given SavedModel SignatureDef contains the following input(s):
inputs[&apos;inputs&apos;] tensor_info:
    dtype: DT_FLOAT
    shape: (-1, 1)
    name: x2:0
The given SavedModel SignatureDef contains the following output(s):
outputs[&apos;scores&apos;] tensor_info:
    dtype: DT_FLOAT
    shape: (-1, 1)
    name: y3:0
Method name is: tensorflow/serving/classify

...

signature_def[&apos;serving_default&apos;]:
The given SavedModel SignatureDef contains the following input(s):
inputs[&apos;x&apos;] tensor_info:
    dtype: DT_FLOAT
    shape: (-1, 1)
    name: x:0
The given SavedModel SignatureDef contains the following output(s):
outputs[&apos;y&apos;] tensor_info:
    dtype: DT_FLOAT
    shape: (-1, 1)
    name: y:0
Method name is: tensorflow/serving/predict
</code></pre><h3><span id="run命令"><code>run</code>命令</span></h3><p>调用<code>run</code>命令来运行图计算，通过 输入，然后显示（并可选地保存）输出。 这里是语法：</p>
<pre><code>usage: saved_model_cli run [-h] --dir DIR --tag_set TAG_SET --signature_def
                           SIGNATURE_DEF_KEY [--inputs INPUTS]
                           [--input_exprs INPUT_EXPRS] [--outdir OUTDIR]
                           [--overwrite] [--tf_debug]
</code></pre><p><code>--inputs</code>命令提供以下两种方式将输入传递给模型：</p>
<p><code>--input_exprs</code>选项使您能够在文件中传递numpy ndarray。 <code>--inputs</code>选项使您能够传递Python表达式。</p>
<h4><span id="-inputs"><code>--inputs</code></span></h4><p>要在文件中传递输入数据，请指定<code>&lt;input_key&gt;=&lt;filename&gt;</code>选项， 遵循一般格式：</p>
<pre><code>--inputs &lt;INPUTS&gt;
</code></pre><p>INPUTS是以下格式之一：</p>
<p><code>&lt;input_key&gt;=&lt;filename&gt;[&lt;variable_name&gt;]</code> <code>saved_model_cli</code></p>
<p>您可能会传递多个输入。如果您传递多个输入，请使用分号 分开每个输入。</p>
<p><code>numpy.load</code>使用<code>.npy</code>加载文件名。 文件名可以是以下任何一种格式：</p>
<p><code>.npz</code> <code>.npy</code> 泡菜格式</p>
<p>一个<code>.npy</code>文件总是包含一个numpy的ndarray。因此，从何时加载 一个<code>.npy</code>文件，内容将直接分配给指定的输入<br>张量。如果用<code>.npz</code>文件指定变量名称， variable_name将被忽略，并发出警告。</p>
<p>从<code>variable_name</code>（zip）文件加载时，可以选择指定一个 variable_name来标识要加载的zip文件中的变量<br>输入张量键。如果你没有指定一个variable_name，SavedModel CLI将检查压缩文件中是否只包含一个文件并加载它 为指定的输入张量键。</p>
<p>从pickle文件加载时，如果没有指定<code>--inputs_exprs</code> 方括号，无论是在pickle文件里面都会传递给<br>指定的输入张量键。否则，SavedModel CLI会假设一个 字典存储在pickle文件和相应的值中 将使用variable_name。</p>
<h4><span id="-input_exprs"><code>--input_exprs</code></span></h4><p>要通过Python表达式传递输入，请指定<code>SignatureDef</code>选项。 这对于您没有数据时可能会有用 躺在身边的文件，但仍然希望用一些简单的理智检查模型<br>输入符合型号<code>numpy</code>的dtype和形状。 例如：</p>
<pre><code>`input_key=[[1], [2], [3]]`
</code></pre><p>除了Python表达式之外，你还可以传递numpy函数。对于 例：</p>
<pre><code>input_key=np.ones((32, 32, 3))
</code></pre><p>（请注意，<code>np</code>模块已经可以作为<code>--outdir</code>使用。）</p>
<h4><span id="保存输出">保存输出</span></h4><p>默认情况下，SavedModel CLI将输出写入标准输出。如果一个目录是 传递到<code>--overwrite</code>选项，输出将被保存为以.d命名的npy文件<br>输出给定目录下的张量键。</p>
<p>使用<code>--tf_debug</code>覆盖现有的输出文件。</p>
<h4><span id="tensorflow调试器tfdbg集成">TensorFlow调试器（tfdbg）集成</span></h4><p>如果设置了<code>run</code>选项，SavedModel CLI将使用 TensorFlow调试器（tfdbg）来观察中间张量和运行时间<br>图形或子图，同时运行SavedModel。</p>
<h4><span id="x1的完整示例"><code>x1</code>的完整示例</span></h4><p>鉴于：</p>
<p>您的型号只需添加<code>x2</code>和<code>y</code>即可获得输出<code>(-1, 1)</code>。 所有型号的张力器都有型号<code>npy</code>。 你有两个<code>/tmp/my_data1.npy</code>文件：<br><code>[[1], [2], [3]]</code>，其中包含一个nndary ndarray <code>/tmp/my_data2.npy</code>。 <code>[[0.5], [0.5],
[0.5]]</code>，其中包含另一个numpy       ndarray <code>npy</code>。</p>
<p>要通过模型运行这两个<code>y</code>文件以获得输出<code>.npy</code>，请发出 以下命令：</p>
<pre><code>$ saved_model_cli run --dir /tmp/saved_model_dir --tag_set serve \
--signature_def x1_x2_to_y --inputs x1=/tmp/my_data1.npy;x2=/tmp/my_data2.npy \
--outdir /tmp/out
Result for output key y:
[[ 1.5]
 [ 2.5]
 [ 3.5]]
</code></pre><p>让我们稍微改变一下前面的例子。这一次，而不是两个 <code>.npz</code>文件，您现在有一个<code>x2</code>文件和一个泡菜文件。此外， 你想覆盖任何现有的输出文件。这是命令：</p>
<pre><code>$ saved_model_cli run --dir /tmp/saved_model_dir --tag_set serve \
--signature_def x1_x2_to_y \
--inputs x1=/tmp/my_data1.npz[x];x2=/tmp/my_data2.pkl --outdir /tmp/out \
--overwrite
Result for output key y:
[[ 1.5]
 [ 2.5]
 [ 3.5]]
</code></pre><p>您可以指定python表达式而不是输入文件。例如， 以下命令用Python表达式替换输入<code>assets</code>：</p>
<pre><code>$ saved_model_cli run --dir /tmp/saved_model_dir --tag_set serve \
--signature_def x1_x2_to_y --inputs x1=/tmp/my_data1.npz[x] \
--input_exprs &apos;x2=np.ones((3,1))&apos;
Result for output key y:
[[ 2]
 [ 3]
 [ 4]]
</code></pre><p>要使用TensorFlow调试器运行模型，请发出 以下命令：</p>
<pre><code>$ saved_model_cli run --dir /tmp/saved_model_dir --tag_set serve \
--signature_def serving_default --inputs x=/tmp/data.npz[x] --tf_debug
</code></pre><h2><span id="savedmodel目录的结构">SavedModel目录的结构</span></h2><p>当您以SavedModel格式保存模型时，会创建TensorFlow 由以下子目录组成的SavedModel目录 和文件：</p>
<pre><code>assets/
assets.extra/
variables/
    variables.data-?????-of-?????
    variables.index
saved_model.pb|saved_model.pbtxt
</code></pre><p>哪里：</p>
<p><code>MetaGraphDef</code>是一个包含辅助（外部）文件的子文件夹，   如词汇表。资产被复制到SavedModel位置<br>并且可以在加载特定的<code>assets.extra</code>时读取。 <code>variables</code>是高级库和用户可以使用的子文件夹   添加自己的资源，与模型共存，但不加载<br>图表。这个子文件夹不是由SavedModel库管理的。 <code>tf.train.Saver</code>是包含输出的子文件夹   <code>saved_model.pb</code>。<br><code>saved_model.pbtxt</code>或<code>MetaGraphDef</code>是SavedModel协议缓冲区。<br>它包括图形定义为<code>MetaGraphDef</code>协议缓冲区。</p>
<p>一个SavedModel可以表示多个图形。在这种情况下，所有的 SavedModel中的图形共享一组检查点（变量）<br>和资产。例如，下图显示了一个SavedModel 包含三个CXJ743-HDK-53L，所有这三个共享相同的集合 检查站和资产：</p>
<p><img src="https://www.tensorflow.org/images/SavedModel.svg" alt="SavedModel represents checkpoints, assets, and one or more
MetaGraphDefs"></p>
<p>每个图形都与一组特定的标签相关联，这些标签启用 加载或恢复操作期间的识别。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  


  <nav id="page-nav" class="clearfix">
    <a class="extend prev" rel="prev" href="/page/120/"><span></span>Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/119/">119</a><a class="page-number" href="/page/120/">120</a><span class="page-number current">121</span><a class="page-number" href="/page/122/">122</a><a class="page-number" href="/page/123/">123</a><span class="space">&hellip;</span><a class="page-number" href="/page/157/">157</a><a class="extend next" rel="next" href="/page/122/">Next<span></span></a>
  </nav>

</div>

      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- side-bar-ad -->
<ins class="adsbygoogle"
     style="display:block; overflow:hidden;"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="2232545787"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


  


  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/javascript/" title="javascript">javascript<sup>207</sup></a></li>
			
		
			
				<li><a href="/tags/java/" title="java">java<sup>205</sup></a></li>
			
		
			
				<li><a href="/tags/html/" title="html">html<sup>203</sup></a></li>
			
		
			
				<li><a href="/tags/python/" title="python">python<sup>199</sup></a></li>
			
		
			
				<li><a href="/tags/bash/" title="bash">bash<sup>198</sup></a></li>
			
		
			
				<li><a href="/tags/php/" title="php">php<sup>197</sup></a></li>
			
		
			
				<li><a href="/tags/css/" title="css">css<sup>88</sup></a></li>
			
		
			
				<li><a href="/tags/shell/" title="shell">shell<sup>78</sup></a></li>
			
		
			
				<li><a href="/tags/jquery/" title="jquery">jquery<sup>61</sup></a></li>
			
		
			
				<li><a href="/tags/linux/" title="linux">linux<sup>57</sup></a></li>
			
		
			
				<li><a href="/tags/机器学习/" title="机器学习">机器学习<sup>41</sup></a></li>
			
		
			
				<li><a href="/tags/unix/" title="unix">unix<sup>30</sup></a></li>
			
		
			
				<li><a href="/tags/mysql/" title="mysql">mysql<sup>17</sup></a></li>
			
		
			
				<li><a href="/tags/html5/" title="html5">html5<sup>16</sup></a></li>
			
		
			
				<li><a href="/tags/xml/" title="xml">xml<sup>13</sup></a></li>
			
		
			
				<li><a href="/tags/http/" title="http">http<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/区块链/" title="区块链">区块链<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://tracholar.github.io" target="_blank" title="个人博客">个人博客</a>
            
          </li>
        
    </ul>
</div>

  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

</aside>
</div>

    </div>
    <footer><div id="footer" >
	
	
	<section class="info">
		<p> To be or not to be, that is a question. <br/>
			This is my blog,believe it or not.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		版权所有 © 2018 本站文章未经同意，禁止转载！作者：
		
		<a href="/about" target="_blank" title="zhizi">zhizi</a>
		


		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>












<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->





<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
