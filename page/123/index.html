
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>智子</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="zhizi">
    

    
    <meta name="description" content="IT技术、编程、web开发以及新兴的技术翻译与总结">
<meta property="og:type" content="website">
<meta property="og:title" content="智子">
<meta property="og:url" content="https://www.tracholar.top/page/123/index.html">
<meta property="og:site_name" content="智子">
<meta property="og:description" content="IT技术、编程、web开发以及新兴的技术翻译与总结">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="智子">
<meta name="twitter:description" content="IT技术、编程、web开发以及新兴的技术翻译与总结">

    
    <link rel="alternative" href="/atom.xml" title="智子" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">

    <!-- ad start -->
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-6300557868920774",
    enable_page_level_ads: true
  });
</script>

    <!-- ad end -->

    <!--  stat -->
    <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?4036f580b1119e720db871571faa68cc";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-78529611-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-78529611-1');
</script>

    <!-- end stat -->
</head>

  <body>
    <header>
      
<div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="智子">智子</a></h1>
				<h2 class="blog-motto">智子之家</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:www.tracholar.top">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main">


   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/using_gpu/" title="使用GPU" itemprop="url">使用GPU</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="使用gpu">使用GPU</span></h1><h2><span id="支持的设备">支持的设备</span></h2><p>在典型的系统上，有多个计算设备。在TensorFlow中， 支持的设备类型是<code>CPU</code>和<code>GPU</code>。它们表示为<code>strings</code>。 例如：</p>
<p><code>&quot;/cpu:0&quot;</code>：您的机器的CPU。 <code>&quot;/device:GPU:0&quot;</code>：您的机器的GPU，如果有的话。<br><code>&quot;/device:GPU:1&quot;</code>：您机器的第二个GPU等</p>
<p>如果TensorFlow操作同时具有CPU和GPU，则GPU设备 将操作分配给设备时将被赋予优先权。例如，<br><code>matmul</code>具有CPU和GPU内核。在装有<code>cpu:0</code>和CXJ743的系统上 将选择<code>gpu:0</code>，<code>gpu:0</code>来运行<code>matmul</code>。</p>
<h2><span id="记录设备的位置">记录设备的位置</span></h2><p>要找出您的操作和张量分配给哪些设备，请创建 与<code>log_device_placement</code>配置选项设置为<code>True</code>的会话。</p>
<pre><code># Creates a graph.
a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name=&apos;a&apos;)
b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name=&apos;b&apos;)
c = tf.matmul(a, b)
# Creates a session with log_device_placement set to True.
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# Runs the op.
print(sess.run(c))
</code></pre><p>您应该看到以下输出：</p>
<pre><code>Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: Tesla K40c, pci bus
id: 0000:05:00.0
b: /job:localhost/replica:0/task:0/device:GPU:0
a: /job:localhost/replica:0/task:0/device:GPU:0
MatMul: /job:localhost/replica:0/task:0/device:GPU:0
[[ 22.  28.]
 [ 49.  64.]]
</code></pre><h2><span id="手动设备放置">手动设备放置</span></h2><p>如果您希望特定的操作在您选择的设备上运行 您可以使用<code>with tf.device</code>，而不是自动为您选择 创建一个设备上下文，以便该上下文中的所有操作都可以<br>具有相同的设备分配。</p>
<pre><code># Creates a graph.
with tf.device(&apos;/cpu:0&apos;):
  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name=&apos;a&apos;)
  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name=&apos;b&apos;)
c = tf.matmul(a, b)
# Creates a session with log_device_placement set to True.
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# Runs the op.
print(sess.run(c))
</code></pre><p>您将看到现在<code>a</code>和<code>b</code>分配给<code>cpu:0</code>。由于设备是 对于<code>MatMul</code>操作没有明确指定，TensorFlow运行时将会<br>根据操作和可用的设备（<code>gpu:0</code>）选择一个 例如），并根据需要在设备之间自动复制张量。</p>
<pre><code>Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: Tesla K40c, pci bus
id: 0000:05:00.0
b: /job:localhost/replica:0/task:0/cpu:0
a: /job:localhost/replica:0/task:0/cpu:0
MatMul: /job:localhost/replica:0/task:0/device:GPU:0
[[ 22.  28.]
 [ 49.  64.]]
</code></pre><h2><span id="允许gpu内存增长">允许GPU内存增长</span></h2><p>默认情况下，TensorFlow映射几乎所有GPU的GPU内存（受限于 <code>CUDA_VISIBLE_DEVICES</code>）<br>对过程可见。这样做是为了更有效地使用相对 通过减少内存来降低设备上宝贵的GPU内存资源 碎片。</p>
<p>在某些情况下，过程只需要分配一个子集 可用的内存，或只增加进程所需的内存使用量。<br>TensorFlow在Session上提供了两个Config选项来控制这个选项。</p>
<p>首先是<code>allow_growth</code>选项，它只尝试分配尽可能多的数据 基于运行时分配的GPU内存：它开始分配很少<br>内存，随着会话的运行和更多的GPU内存的需求，我们扩展GPU 内存区域由TensorFlow进程所需。请注意，我们不释放<br>内存，因为这可能导致更糟糕的内存碎片。要打开这个 选项，在ConfigProto中设置选项：</p>
<pre><code>config = tf.ConfigProto()
config.gpu_options.allow_growth = True
session = tf.Session(config=config, ...)
</code></pre><p>第二种方法是<code>per_process_gpu_memory_fraction</code>选项 确定每个可见GPU的总内存量的一部分<br>应该分配。例如，你可以告诉TensorFlow只分配40％ 每个GPU的内存总量：</p>
<pre><code>config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.4
session = tf.Session(config=config, ...)
</code></pre><p>如果要真正限制可用的GPU内存量，这非常有用 TensorFlow流程。</p>
<h2><span id="在多gpu系统上使用单个gpu">在多GPU系统上使用单个GPU</span></h2><p>如果您的系统中有多个GPU，则ID最低的GPU将会是 默认选中。如果你想在不同的GPU上运行，你将需要 明确指定偏好：</p>
<pre><code># Creates a graph.
with tf.device(&apos;/device:GPU:2&apos;):
  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name=&apos;a&apos;)
  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name=&apos;b&apos;)
  c = tf.matmul(a, b)
# Creates a session with log_device_placement set to True.
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# Runs the op.
print(sess.run(c))
</code></pre><p>如果你指定的设备不​​存在，你会得到 <code>InvalidArgumentError</code>：</p>
<pre><code>InvalidArgumentError: Invalid argument: Cannot assign a device to node &apos;b&apos;:
Could not satisfy explicit device specification &apos;/device:GPU:2&apos;
   [[Node: b = Const[dtype=DT_FLOAT, value=Tensor&lt;type: float shape: [3,2]
   values: 1 2 3...&gt;, _device=&quot;/device:GPU:2&quot;]()]]
</code></pre><p>如果你想TensorFlow自动选择一个现有和支持 设备运行的情况下，指定的一个不存在，你可以<br>创建时将<code>allow_soft_placement</code>设置为配置选项中的<code>True</code> 会议。</p>
<pre><code># Creates a graph.
with tf.device(&apos;/device:GPU:2&apos;):
  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name=&apos;a&apos;)
  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name=&apos;b&apos;)
  c = tf.matmul(a, b)
# Creates a session with allow_soft_placement and log_device_placement set
# to True.
sess = tf.Session(config=tf.ConfigProto(
      allow_soft_placement=True, log_device_placement=True))
# Runs the op.
print(sess.run(c))
</code></pre><h2><span id="使用多个gpu">使用多个GPU</span></h2><p>如果你想在多个GPU上运行TensorFlow，你可以构建你的 模型在一个多塔的时尚，其中每个塔被分配到不同的GPU。 例如：</p>
<pre><code># Creates a graph.
c = []
for d in [&apos;/device:GPU:2&apos;, &apos;/device:GPU:3&apos;]:
  with tf.device(d):
    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3])
    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2])
    c.append(tf.matmul(a, b))
with tf.device(&apos;/cpu:0&apos;):
  sum = tf.add_n(c)
# Creates a session with log_device_placement set to True.
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# Runs the op.
print(sess.run(sum))
</code></pre><p>您将看到以下输出。</p>
<pre><code>Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -&gt; device: 0, name: Tesla K20m, pci bus
id: 0000:02:00.0
/job:localhost/replica:0/task:0/device:GPU:1 -&gt; device: 1, name: Tesla K20m, pci bus
id: 0000:03:00.0
/job:localhost/replica:0/task:0/device:GPU:2 -&gt; device: 2, name: Tesla K20m, pci bus
id: 0000:83:00.0
/job:localhost/replica:0/task:0/device:GPU:3 -&gt; device: 3, name: Tesla K20m, pci bus
id: 0000:84:00.0
Const_3: /job:localhost/replica:0/task:0/device:GPU:3
Const_2: /job:localhost/replica:0/task:0/device:GPU:3
MatMul_1: /job:localhost/replica:0/task:0/device:GPU:3
Const_1: /job:localhost/replica:0/task:0/device:GPU:2
Const: /job:localhost/replica:0/task:0/device:GPU:2
MatMul: /job:localhost/replica:0/task:0/device:GPU:2
AddN: /job:localhost/replica:0/task:0/cpu:0
[[  44.   56.]
 [  98.  128.]]
</code></pre><p>cifar10教程就是一个很好的例子 演示如何使用多个GPU进行训练。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  
      <ins class="adsbygoogle"
     style="display:block;  overflow:hidden;"
     data-ad-format="fluid"
     data-ad-layout-key="-ej+6f-q-c7+ou"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="5206371097"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>

  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/seq2seq/" title="神经机器翻译（seq2seq）教程" itemprop="url">神经机器翻译（seq2seq）教程</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="神经机器翻译seq2seq教程">神经机器翻译（seq2seq）教程</span></h1><p>作者：Thang Luong，Eugene Brevdo，赵锐</p>
<p>本教程的这个版本需要TensorFlow版本1.4+。 警告：Beam Search的错误修复不在TensorFlow 1.4中。</p>
<h1><span id="介绍">介绍</span></h1><p>序列 - 序列（seq2seq）模型 （Sutskever等，2014， Cho等，2014） 在机器翻译，演讲等各种工作中取得了巨大的成功<br>识别和文本摘要。本教程给读者一个完整的 了解seq2seq模型，并展示如何建立一个有竞争力的seq2seq<br>模型从头开始。我们专注于神经机器翻译（NMT）的任务， 这是seq2seq模型的第一个测试平台 野生 成功。该 包括代码是轻量级，高质量，生产就绪，并入<br>有最新的研究思路。我们通过以下方式达到这个</p>
<p>使用最近的解码器/注意力    包装纸    API，    TensorFlow 1.2数据迭代器 结合我们强大的专业知识，建立经常性和seq2seq模型<br>提供建立最好的NMT模型和复制的技巧和窍门    Google的NMT（GNMT）系统。</p>
<p>我们相信提供人们可以轻松掌握的基准是非常重要的 复制。因此，我们提供了全面的实验结果 在以下公开可用的数据集上对模型进行预训练：</p>
<p>小规模：英语 - 越南语TED会话平行语料库（133K句子    双）由提供    该    IWSLT评估活动。<br>大规模：提供德英平行语料库（4.5M句子对）    由WMT评估运动。</p>
<p>我们首先建立一些关于NMT seq2seq模型的基本知识，解释 如何建立和训练一个香草NMT模型。第二部分将详细介绍<br>建立具有注意机制的竞争性NMT模型。我们然后讨论 提示和技巧，以建立最好的NMT模型（速度和速度）<br>翻译质量），如TensorFlow最佳实践（配料，桶装）， 双向RNN，波束搜索以及使用GNMT注意力扩展到多个GPU。</p>
<h1><span id="基本">基本</span></h1><h2><span id="神经机器翻译的背景">神经机器翻译的背景</span></h2><p>早在过去，传统的基于短语的翻译系统就被执行了 他们的任务是把源语句分解成多个块然后 把它们翻译成短语。这导致翻译不流利<br>产出，并不像我们人类的翻译。我们阅读整个 源句，理解它的意思，然后产生一个翻译。神经 机器翻译（NMT）模仿！</p>
<p><img src="https://www.tensorflow.org/images/seq2seq/encdec.jpg" alt=""> 图1.编码器 - 解码器架构 -<br>一个通用方法的例子 NMT。编码器将源语句转换为“含义”向量 通过解码器产生翻译。</p>
<p>具体而言，NMT系统首先使用编码器读取源句子 建立 一个 “思想”载体， 代表句子意思的数字序列;一个解码器，那么， 处理句子向量发出翻译，如图所示<br>图1.这通常被称为编码器 - 解码器架构。在 这种方式，NMT解决了传统的本地翻译问题 基于短语的方法：它可以捕捉语言的远程依赖关系，<br>例如性别协议;语法结构;等等，而且生产得更流畅 翻译如展示 通过 谷歌神经机器翻译系统。</p>
<p>NMT模型根据其确切的体系结构而有所不同。自然的选择 时序数据是大多数NMT模型使用的递归神经网络（RNN）。 编码器和解码器通常使用RNN。 RNN模型，<br>然而，不同的方面：（一）方向性 - 单向或 双向的; （b）深度 - 单层或多层;和（三）类型 - 往往 香草RNN，长期短期记忆（LSTM）或门控复发单位<br>（GRU）。有兴趣的读者可以在上找到关于RNN和LSTM的更多信息 这篇博文。</p>
<p>在本教程中，我们将深入多层RNN作为示例 单向，并使用LSTM作为经常性单位。我们展示一个这样的例子<br>模型如图2所示。在这个例子中，我们建立了一个模型来翻译源代码 把“我是学生”这句话变成目标句子“Je suisétudiant”。在一个很高的<br>NMT模型由两个递归神经网络组成：编码器 RNN仅仅消耗输入的源词而不作任何预测;该 另一方面，解码器在预测目标语句的同时对其进行处理 接下来的话。</p>
<p>有关更多信息，请参阅读者 到本教程的Luong（2016） 基于。</p>
<p><img src="https://www.tensorflow.org/images/seq2seq/seq2seq.jpg" alt=""> 图2.神经机器翻译 -<br>一个经常性的例子 由“我是学生”这个源语句翻译成的建筑 目标句子“Jesuisétudiant”。在这里，“＆lts＆gt”标志着 解码过程，而“＆lt;<br>s＆gt;”告诉解码器停止。</p>
<h2><span id="安装教程">安装教程</span></h2><p>要安装本教程，您需要在系统上安装TensorFlow。 本教程需要TensorFlow Nightly。要安装TensorFlow，请按照 安装说明在这里。</p>
<p>一旦安装了TensorFlow，您可以下载本教程的源代码 通过运行：</p>
<pre><code>git clone https://github.com/tensorflow/nmt/
</code></pre><h2><span id="培训-如何建立我们的第一个nmt系统">培训 - 如何建立我们的第一个NMT系统</span></h2><p>我们先来看看用具体代码构建NMT模型的核心 通过我们将更详细地解释图2的片段。我们推迟了数据 准备和后面的完整代码。这部分是指 文件 model.py。</p>
<p>在底层，编码器和解码器RNNs接收作为输入 如下：首先，源句子，然后是一个边界标记“\ ~~”其中 指示从编码到解码模式的过渡以及目标<br>句子。为了训练，我们将给系统提供以下张量， 它们在时间上是主要的格式，并包含单词索引：</p>
<p>encoder_inputs [max_encoder_time，batch_size]：源输入字。 decoder_inputs<br>[max_decoder_time，batch_size]：目标输入字。 decoder_outputs<br>[max_decoder_time，batch_size]：目标输出字，    这些是decode_inputs向左移一个时间步与一个<br>在右侧附加句末标签。</p>
<p>这里为了提高效率，我们用多个句子（batch_size）进行训练 一旦。测试稍有不同，所以我们稍后再讨论。</p>
<h3><span id="嵌入">嵌入</span></h3><p>鉴于单词的分类性质，该模型必须先查找来源 和目标嵌入来检索相应的词表示。对于 这个嵌入层的工作，首先为每种语言选择一个词汇。<br>通常，选择一个词汇量V，只有最常见的V个词是 视为独特。所有其他单词都转换为“未知”令牌和所有 得到相同的嵌入。嵌入权重，每种语言一组 通常在训练中学习。</p>
<pre><code># Embedding
embedding_encoder = variable_scope.get_variable(
    &quot;embedding_encoder&quot;, [src_vocab_size, embedding_size], ...)
# Look up embedding:
#   encoder_inputs: [max_time, batch_size]
#   encoder_emb_inp: [max_time, batch_size, embedding_size]
encoder_emb_inp = embedding_ops.embedding_lookup(
    embedding_encoder, encoder_inputs)
</code></pre><p>同样，我们可以构建embedding_decoder和decoder_emb_inp。注意一个 可以选择用预训练词表示来初始化嵌入权重<br>如word2vec或Glove矢量。一般来说，给予大量的培训 数据我们可以从头学习这些嵌入。</p>
<h3><span id="编码器">编码器</span></h3><p>一旦检索到，嵌入字就作为输入被馈送到主网络中， 它由两个多层RNN组成 - 一个用于源语言的编码器 目标语言的解码器。这两个RNN原则上可以共享<br>相同的重量;然而，在实践中，我们经常使用两个不同的RNN参数 （当拟合大量的训练数据集时，这样的模型做得更好）。该<br>编码器RNN使用零矢量作为其起始状态，并且构建如下：</p>
<pre><code># Build RNN cell
encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)

# Run Dynamic RNN
#   encoder_outpus: [max_time, batch_size, num_units]
#   encoder_state: [batch_size, num_units]
encoder_outputs, encoder_state = tf.nn.dynamic_rnn(
    encoder_cell, encoder_emb_inp,
    sequence_length=source_sequence_length, time_major=True)
</code></pre><p>请注意，句子有不同的长度，以避免浪费计算，我们告诉 dynamic_rnn确切的源句子的长度<br>source_sequence_length。由于我们的投入是主要的时间，我们设置 time_major<br>=真。在这里，我们只建立一个单层的LSTM，encoder_cell。我们 将描述如何构建多层LSTM，添加丢失，并引起注意 稍后的部分。</p>
<h3><span id="解码器">解码器</span></h3><p>解码器还需要访问源信息，还有一个 简单的方法来实现，就是用最后一个隐藏状态来初始化它<br>编码器，encoder_state。在图2中，我们从源代码中传递隐藏状态 单词“学生”到解码器端。</p>
<pre><code># Build RNN cell
decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)



# Helper
helper = tf.contrib.seq2seq.TrainingHelper(
    decoder_emb_inp, decoder_lengths, time_major=True)
# Decoder
decoder = tf.contrib.seq2seq.BasicDecoder(
    decoder_cell, helper, encoder_state,
    output_layer=projection_layer)
# Dynamic decoding
outputs, _ = tf.contrib.seq2seq.dynamic_decode(decoder, ...)
logits = outputs.rnn_output
</code></pre><p>在这里，这个代码的核心部分是BasicDecoder对象，解码器，这个<br>接收decoder_cell（类似于encoder_cell），helper和previous<br>encoder_state作为输入。通过分离解码器和帮助器，我们可以重用 不同的代码库，例如，TrainingHelper可以被替换<br>GreedyEmbeddingHelper做贪心解码。查看更多 在 helper.py。</p>
<p>最后，我们还没有提到projection_layer这是一个密集的矩阵转向 我们说明了这一点 过程在图2的顶部。</p>
<pre><code>projection_layer = layers_core.Dense(
    tgt_vocab_size, use_bias=False)
</code></pre><h3><span id="失利">失利</span></h3><p>鉴于上面的逻辑，我们现在准备计算我们的训练损失：</p>
<pre><code>crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(
    labels=decoder_outputs, logits=logits)
train_loss = (tf.reduce_sum(crossent * target_weights) /
    batch_size)
</code></pre><p>这里，target_weights是一个大小与之相同的零一个矩阵 decoder_outputs。它掩盖了目标序列之外的填充位置 长度值为0。</p>
<p>重要提示：值得指出的是，我们将损失除以 batch_size，所以我们的超参数对batch_size是“不变的”。有些人 用（batch_size *<br>num_time_steps）来划分损失，这就淡化了 短句错误。更微妙的是，我们的超参数（应用于 以前的方式）不能用于后一种方式。例如，如果两者都接近<br>使用SGD学习1.0，后一种方法有效地使用了很多 1 / num_time_steps较小的学习率。</p>
<h3><span id="梯度计算和优化">梯度计算和优化</span></h3><p>现在我们已经定义了NMT模型的正向通过。计算 反向传播只是几行代码的问题：</p>
<pre><code># Calculate and clip gradients
params = tf.trainable_variables()
gradients = tf.gradients(train_loss, params)
clipped_gradients, _ = tf.clip_by_global_norm(
    gradients, max_gradient_norm)
</code></pre><p>训练RNNs的重要步骤之一是渐变裁剪。在这里，我们剪辑 由全球规范。最大值max_gradient_norm通常设置为一个值<br>像5或1.最后一步是选择优化器。 Adam优化器是一个 共同的选择。我们也选择一个学习率。 learning_rate的值<br>通常可以在0.0001至0.001的范围内;并可以设置为减少 培训进展。</p>
<pre><code># Optimization
optimizer = tf.train.AdamOptimizer(learning_rate)
update_step = optimizer.apply_gradients(
    zip(clipped_gradients, params))
</code></pre><p>在我们自己的实验中，我们使用标准的SGD（tf.train.GradientDescentOptimizer） 随着学习速度的降低，这会产生更好的表现。看到<br>基准。</p>
<h2><span id="动手-让我们训练一个nmt模型">动手 - 让我们训练一个NMT模型</span></h2><p>让我们训练我们第一个NMT模型，从越南翻译成英文！ 我们的代码的入口点 是 nmt.py.</p>
<p>我们将使用一个小规模的TED演讲语料库（133K培训 例子）这个练习。我们在这里使用的所有数据都可以找到 在：<br><a href="https://nlp.stanford.edu/projects/nmt/。我们" target="_blank" rel="noopener">https://nlp.stanford.edu/projects/nmt/。我们</a><br>将使用tst2012作为我们的开发数据集，tst2013作为我们的测试数据集。</p>
<p>运行以下命令下载用于训练NMT模型的数据：\     <code>nmt/scripts/download_iwslt15.sh /tmp/nmt_data</code></p>
<p>运行以下命令开始训练：</p>
<pre><code>mkdir /tmp/nmt_model
python -m nmt.nmt \
    --src=vi --tgt=en \
    --vocab_prefix=/tmp/nmt_data/vocab  \
    --train_prefix=/tmp/nmt_data/train \
    --dev_prefix=/tmp/nmt_data/tst2012  \
    --test_prefix=/tmp/nmt_data/tst2013 \
    --out_dir=/tmp/nmt_model \
    --num_train_steps=12000 \
    --steps_per_stats=100 \
    --num_layers=2 \
    --num_units=128 \
    --dropout=0.2 \
    --metrics=bleu
</code></pre><p>以上命令训练一个128层隐藏单元的2层LSTM seq2seq模型 并嵌入12个时期。我们使用0.2的退出值（保持概率<br>0.8）。如果没有错误，我们应该看到类似于下面的日志递减 我们训练时的困惑价值。</p>
<pre><code># First evaluation, global step 0
  eval dev: perplexity 17193.66
  eval test: perplexity 17193.27
# Start epoch 0, step 0, lr 1, Tue Apr 25 23:17:41 2017
  sample train data:
    src_reverse: &lt;/s&gt; &lt;/s&gt; Điều đo , dĩ nhien , la cau chuyện trich ra từ học thuyết của Karl Marx .
    ref: That , of course , was the &lt;unk&gt; distilled from the theories of Karl Marx . &lt;/s&gt; &lt;/s&gt; &lt;/s&gt;
  epoch 0 step 100 lr 1 step-time 0.89s wps 5.78K ppl 1568.62 bleu 0.00
  epoch 0 step 200 lr 1 step-time 0.94s wps 5.91K ppl 524.11 bleu 0.00
  epoch 0 step 300 lr 1 step-time 0.96s wps 5.80K ppl 340.05 bleu 0.00
  epoch 0 step 400 lr 1 step-time 1.02s wps 6.06K ppl 277.61 bleu 0.00
  epoch 0 step 500 lr 1 step-time 0.95s wps 5.89K ppl 205.85 bleu 0.00
</code></pre><p>有关更多详细信息，请参阅train.py。</p>
<p>我们可以启动Tensorboard来查看训练过程中的模型摘要：</p>
<pre><code>tensorboard --port 22222 --logdir /tmp/nmt_model/
</code></pre><p>从英语和越南语的相反方向训练可以简单地通过改变：\     <code>--src=en --tgt=vi</code></p>
<h2><span id="推论-如何生成翻译">推论 - 如何生成翻译</span></h2><p>你正在训练你的NMT模型（一旦你有训练有素的模型），你 可以获得以前看不见的源句子的翻译。这个流程 被称为推理。训练和推理之间有明确的区别<br>（测试）：在推理的时候，我们只能访问源句子， 即encoder_inputs。有很多方法来执行解码。解码 方法包括贪婪，采样和波束搜索解码。在这里，我们会的<br>讨论贪婪的解码策略。</p>
<p>这个想法很简单，我们在图3中进行说明：</p>
<p>我们仍然按照与训练期间相同的方式对源句进行编码    获得一个encoder_state，并且这个encoder_state被用来初始化    解码器。<br>一旦解码器接收到解码（翻译）过程即开始    一个起始符号“\ <del>”（在我们的代码中称为tgt_sos_id）;<br>对于解码器端的每个时间步，我们将RNN的输出视为一组    logits。我们选择最可能的单词，与最大的相关联的ID<br>逻辑值，作为发出的词（这是“贪婪的”行为）。对于    在图3中的例子中，词“moi”具有最高的翻译概率<br>在第一个解码步骤中。然后，我们把这个单词作为下一个的输入    时间步长。 这个过程一直持续到产生结束标记“\</del> ”为止<br>一个输出符号（在我们的代码中称为tgt_eos_id）。</p>
<p><img src="https://www.tensorflow.org/images/seq2seq/greedy_dec.jpg" alt=""> 图3.贪婪解码 -<br>一个训练NMT模型如何产生一个例子 翻译源句子“Je suisétudiant”使用贪婪的搜索。</p>
<p>第三步是使得推论与训练不同。而不是总是 喂养正确的目标词作为输入，推理使用预测的词 该模型。这是实现贪婪解码的代码。这是非常相似的 训练解码器。</p>
<pre><code># Helper
helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(
    embedding_decoder,
    tf.fill([batch_size], tgt_sos_id), tgt_eos_id)

# Decoder
decoder = tf.contrib.seq2seq.BasicDecoder(
    decoder_cell, helper, encoder_state,
    output_layer=projection_layer)
# Dynamic decoding
outputs, _ = tf.contrib.seq2seq.dynamic_decode(
    decoder, maximum_iterations=maximum_iterations)
translations = outputs.sample_id
</code></pre><p>在这里，我们使用GreedyEmbeddingHelper而不是TrainingHelper。因为我们这样做<br>事先不知道目标序列长度，我们使用maximum_iterations来 限制翻译长度。一个启发式就是解码两倍的 源句子长度。</p>
<pre><code>maximum_iterations = tf.round(tf.reduce_max(source_sequence_length) * 2)
</code></pre><p>在训练完模型后，我们现在可以创建一个推理文件并翻译一些 句子：</p>
<pre><code>cat &gt; /tmp/my_infer_file.vi
# (copy and paste some sentences from /tmp/nmt_data/tst2013.vi)

python -m nmt.nmt \
    --out_dir=/tmp/nmt_model \
    --inference_input_file=/tmp/my_infer_file.vi \
    --inference_output_file=/tmp/nmt_model/output_infer

cat /tmp/nmt_model/output_infer # To view the inference as output
</code></pre><p>请注意，上述命令也可以在模型仍在训练时运行 只要有一个培训 检查点。有关更多详细信息，请参阅inference.py。</p>
<h1><span id="中间">中间</span></h1><p>经历了最基本的seq2seq模型，让我们更先进！至 建立最先进的神经机器翻译系统，我们将需要更多 “秘诀”：首先介绍的注意机制<br>由Bahdanau等人，2015年，然后再提炼 由Luong等人，2015等人提供。钥匙 关注机制的构想是建立直接的快捷连接<br>通过对相关来源的“关注”，在目标和来源之间 我们翻译的内容。关注机制的一个很好的副产品是一个 易于可视化源句子和目标句子之间的对齐矩阵（如 如图4所示）。</p>
<p><img src="https://www.tensorflow.org/images/seq2seq/attention_vis.jpg" alt=""> 图4.注意可视化 -<br>来源之间对齐的示例 和目标句子。图片取自（Bahdanau等，2015）。</p>
<p>请记住，在香草seq2seq模型中，我们传递最后的源状态 当开始解码过程时编码器到解码器。这很好 中短句子;然而，对于长句，单身<br>固定大小的隐藏状态成为信息瓶颈。而不是丢弃 在源RNN中计算的所有隐藏状态，关注机制 提供了一个方法，使解码器偷看他们（把他们当作一个<br>动态存储源信息）。通过这样做，注意机制 改善了较长句子的翻译。目前，关注机制是 事实上的标准，并已成功应用于许多其他任务 （包括图像标题生成，语音识别和文本<br>摘要）。</p>
<h2><span id="注意机制的背景">注意机制的背景</span></h2><p>我们现在描述（Luong et al 2015年），已被用于几个最先进的系统，包括 开放源代码工具包，如OpenNMT和TF 本教程中的seq2seq<br>API。我们还将提供到其他变体的连接 的关注机制。</p>
<p><img src="https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg" alt=""> 图5.注意机制</p>
<ul>
<li>基于注意的NMT系统的例子 如（Luong等，2015）中所述。我们详细地强调了第一步 关注计算。为了清楚起见，我们不显示嵌入和 图（2）中的投影层。</li>
</ul>
<p>如图5所示，关注计算发生在每个解码器 时间步。它由以下几个阶段组成：</p>
<p>将当前目标隐藏状态与所有源状态进行比较以导出    注意力权重（可以如图4所示）。 基于注意力权重，我们计算一个上下文向量作为加权    平均来源国。<br>将上下文向量与当前目标隐藏状态相结合以产生    最后关注矢量 注意向量作为下一个时间步的输入（输入    馈送）。前三个步骤可以用下面的等式来总结：</p>
<p><img src="https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg" alt=""></p>
<p>在这里，功能<code>score</code>用来比较目标隐藏状态\（h_t \） 与每个源隐藏状态\（\ overline {h} _s \），并将结果标准化为<br>产生注意力权重（一个分配源头位置）。有 评分功能的各种选择;流行的得分功能包括 乘法和加法形式在方程（4）。一旦计算，注意 矢量\（a_t<br>\）被用来导出softmax logit和损失。这与之类似 目标隐藏状态在香草seq2seq模型的顶层。功能 <code>f</code>也可以采取其他形式。</p>
<p><img src="https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg" alt=""></p>
<p>关注机制的各种实现可以找到 在 attention_wrapper.py。</p>
<p>关注机制中有什么关系？</p>
<p>正如上面的方程式所暗示的，有很多不同的注意变量。 这些变体取决于得分功能的形式和注意力 函数，以及是否使用之前的状态\（h_ {t-1} \）<br>（Bahdanau et al。， 2015年）。经验上，我们发现只有某些选择很重要。首先，基本 注意的形式，即目标与源之间的直接联系<br>出席。其次，将注意力向量输入下一个是很重要的 时间步骤通知网络关于过去的关注决定如在展示 （Luong等，2015）。最后，评分功能的选择常常会导致<br>在不同的表现。在基准测试结果中看到更多 部分。</p>
<h2><span id="注意包装api">注意包装API</span></h2><p>在我们的执行 该 AttentionWrapper， 我们借用一些术语 来自（Weston等人，2015）的工作 内存网络。而不是有可读可写的记忆，注意力<br>本教程中介绍的机制是只读内存。具体来说， 源隐藏状态集合（或它们的转换版本，例如， \（W \ overline {h} _s<br>\）在Luong的得分风格或\（W_2 \ overline {h} _s \）中 Bahdanau的得分风格）被称为“记忆”。在每个时间步骤，<br>我们使用当前目标隐藏状态作为“查询”来决定哪些部分 的内存来读取。通常，查询需要与键进行比较 对应于单独的内存插槽。在上面的介绍中<br>注意机制，我们碰巧使用了一组源隐藏状态（或它们的隐藏状态） 例如Bahdanau得分风格的\（W_1h_t \））<br>“键”。人们可以从这个记忆网络术语中得到启发 注意的形式！</p>
<p>感谢关注包装，扩展我们的香草seq2seq代码 注意力是微不足道的。这部分是指 文件attention_model.py</p>
<p>首先，我们需要定义一个注意机制，例如（Luong et al。， 2015年）：</p>
<pre><code># attention_states: [batch_size, max_time, num_units]
attention_states = tf.transpose(encoder_outputs, [1, 0, 2])

# Create an attention mechanism
attention_mechanism = tf.contrib.seq2seq.LuongAttention(
    num_units, attention_states,
    memory_sequence_length=source_sequence_length)
</code></pre><p>在之前的编码器部分，encoder_outputs是全部的集合 源顶层隐藏状态，形状为[max_time，<br>batch_size，num_units]（因为我们用time_major设置为dynamic_rnn 真正的效率）。对于注意机制，我们需要确保<br>传入的“内存”是批量专业，所以我们需要转置 attention_states。我们将source_sequence_length传递给关注机制<br>以确保注意力权重得到正确的标准化（非填充 职位）。</p>
<p>定义了关注机制后，我们使用AttentionWrapper来包装 解码单元格：</p>
<pre><code>decoder_cell = tf.contrib.seq2seq.AttentionWrapper(
    decoder_cell, attention_mechanism,
    attention_layer_size=num_units)
</code></pre><p>其余的代码和Section Decoder几乎一样！</p>
<h2><span id="动手-建立一个基于注意力的nmt模型">动手 - 建立一个基于注意力的NMT模型</span></h2><p>为了引起注意，我们需要使用<code>luong</code>，<code>scaled_luong</code>，<code>bahdanau</code><br>或<code>normed_bahdanau</code>作为训练期间<code>attention</code>标志的值。该 标志指定我们将使用哪种注意机制。另外，我们<br>需要为注意模型创建一个新的目录，所以我们不重用 以前训练过的基本NMT模型。</p>
<p>运行以下命令开始训练：</p>
<pre><code>mkdir /tmp/nmt_attention_model

python -m nmt.nmt \
    --attention=scaled_luong \
    --src=vi --tgt=en \
    --vocab_prefix=/tmp/nmt_data/vocab  \
    --train_prefix=/tmp/nmt_data/train \
    --dev_prefix=/tmp/nmt_data/tst2012  \
    --test_prefix=/tmp/nmt_data/tst2013 \
    --out_dir=/tmp/nmt_attention_model \
    --num_train_steps=12000 \
    --steps_per_stats=100 \
    --num_layers=2 \
    --num_units=128 \
    --dropout=0.2 \
    --metrics=bleu
</code></pre><p>训练结束后，我们可以使用与新的out_dir相同的推理命令 推理：</p>
<pre><code>python -m nmt.nmt \
    --out_dir=/tmp/nmt_attention_model \
    --inference_input_file=/tmp/my_infer_file.vi \
    --inference_output_file=/tmp/nmt_attention_model/output_infer
</code></pre><h1><span id="提示与技巧">提示与技巧</span></h1><h2><span id="构建训练评估和推理图">构建训练，评估和推理图</span></h2><p>在TensorFlow中构建机器学习模型时，通常最好进行构建 三个单独的图表：</p>
<p>培训图表，其中： 批次，桶和可能的子样本从一组输入数据    文件/外部输入。 包括forward和backprop操作。 构造优化器，并添加训练操作。<br>评估图，其中： 批处理和桶从一组文件/外部输入中输入数据。 包括培训前沿操作，以及额外的评估操作    不用于训练。 推理图，其中： 可能不批量输入数据。<br>不抽取或抽取输入数据。 从占位符中读取输入数据（数据可以直接输入到图形中    通过feed_dict或C ++ TensorFlow服务二进制文件）。<br>包括模型转发操作的一个子集，可能还有其他的    用于在session.run调用之间存储状态的特殊输入/输出。</p>
<p>构建独立的图有几个好处：</p>
<p>推理图通常与其他两个非常不同，所以它是成立的    感觉分开建造它。 评估图变得更简单，因为它不再有所有的附加    反向操作。<br>数据馈送可以针对每个图分别实施。 变量重用要简单得多。例如，在评估图中没有    需要重新打开变量范围重用= True只是因为培训<br>模型已经创建了这些变量。所以相同的代码可以重用    而不是随处可见地重复使用参数。 在分布式培训中，单独的员工表现是司空见惯的<br>训练，评估和推理。无论如何，这些都需要建立自己的图形。    所以通过这种方式构建系统可以为分布式培训做好准备。</p>
<p>复杂性的主要来源是如何在三者之间共享变量 图表在一台机器设置。这是通过使用单独的会话来解决的 为每个图。培训会定期保存检查点，<br>eval会话和推断会话从检查点恢复参数。该 下面的例子显示了两种方法的主要区别。</p>
<p>之前：三个模型在一个图中共享一个Session</p>
<pre><code>with tf.variable_scope(&apos;root&apos;):
  train_inputs = tf.placeholder()
  train_op, loss = BuildTrainModel(train_inputs)
  initializer = tf.global_variables_initializer()

with tf.variable_scope(&apos;root&apos;, reuse=True):
  eval_inputs = tf.placeholder()
  eval_loss = BuildEvalModel(eval_inputs)

with tf.variable_scope(&apos;root&apos;, reuse=True):
  infer_inputs = tf.placeholder()
  inference_output = BuildInferenceModel(infer_inputs)

sess = tf.Session()

sess.run(initializer)

for i in itertools.count():
  train_input_data = ...
  sess.run([loss, train_op], feed_dict={train_inputs: train_input_data})

  if i % EVAL_STEPS == 0:
    while data_to_eval:
      eval_input_data = ...
      sess.run([eval_loss], feed_dict={eval_inputs: eval_input_data})

  if i % INFER_STEPS == 0:
    sess.run(inference_output, feed_dict={infer_inputs: infer_input_data})
</code></pre><p>之后：三个图中的三个模型，三个会话共享相同的变量</p>
<pre><code>train_graph = tf.Graph()
eval_graph = tf.Graph()
infer_graph = tf.Graph()

with train_graph.as_default():
  train_iterator = ...
  train_model = BuildTrainModel(train_iterator)
  initializer = tf.global_variables_initializer()

with eval_graph.as_default():
  eval_iterator = ...
  eval_model = BuildEvalModel(eval_iterator)

with infer_graph.as_default():
  infer_iterator, infer_inputs = ...
  infer_model = BuildInferenceModel(infer_iterator)

checkpoints_path = &quot;/tmp/model/checkpoints&quot;

train_sess = tf.Session(graph=train_graph)
eval_sess = tf.Session(graph=eval_graph)
infer_sess = tf.Session(graph=infer_graph)

train_sess.run(initializer)
train_sess.run(train_iterator.initializer)

for i in itertools.count():

  train_model.train(train_sess)

  if i % EVAL_STEPS == 0:
    checkpoint_path = train_model.saver.save(train_sess, checkpoints_path, global_step=i)
    eval_model.saver.restore(eval_sess, checkpoint_path)
    eval_sess.run(eval_iterator.initializer)
    while data_to_eval:
      eval_model.eval(eval_sess)

  if i % INFER_STEPS == 0:
    checkpoint_path = train_model.saver.save(train_sess, checkpoints_path, global_step=i)
    infer_model.saver.restore(infer_sess, checkpoint_path)
    infer_sess.run(infer_iterator.initializer, feed_dict={infer_inputs: infer_input_data})
    while data_to_infer:
      infer_model.infer(infer_sess)
</code></pre><p>注意后一种方法是如何“准备好”转换为分布式的 版。</p>
<p>新方法的另一个区别是不使用feed_dicts 在每个session.run调用提供数据（从而执行我们自己的 批处理，数据处理和操作），我们使用有状态迭代器<br>对象。这些迭代器使输入流水线在两者中都变得更容易 单机和分布式设置。我们将覆盖新的输入数据 流水线（在TensorFlow 1.2中介绍）。</p>
<h2><span id="数据输入管道">数据输入管道</span></h2><p>在TensorFlow 1.2之前，用户有两种选择向数据提供数据 TensorFlow培训和评估管道：</p>
<p>在每个培训session.run调用直接通过feed_dict提供数据。 使用tf.train中的排队机制（例如tf.train.batch）和<br>tf.contrib.train。 使用更高级别的框架，如tf.contrib.learn或    tf.contrib.slim（有效地使用＃2）。</p>
<p>第一种方法对于不熟悉TensorFlow或者 需要做异国情调的输入修改（即他们自己的小批量排队） 只能在Python中完成。第二种和第三种方法更为标准<br>但有点不灵活;他们还需要启动多个python线程 （排队跑步者）。而且，如果使用不正确的队列会导致死锁 或不透明的错误信息。尽管如此，排队更有效率<br>比使用feed_dict和单机和标准 分布式培训。</p>
<p>从TensorFlow 1.2开始，有一个新的系统可以读取数据 进入TensorFlow模型：数据集迭代器，在tf.contrib.data中找到<br>模块。数据迭代器是灵活的，易于推理和操作，并且 通过利用TensorFlow C ++运行时提供效率和多线程。</p>
<p>数据集可以从批量数据张量，文件名或张量创建 包含多个文件名。一些例子：</p>
<pre><code># Training dataset consists of multiple files.
train_dataset = tf.contrib.data.TextLineDataset(train_files)

# Evaluation dataset uses a single file, but we may
# point to a different file for each evaluation round.
eval_file = tf.placeholder(tf.string, shape=())
eval_dataset = tf.contrib.data.TextLineDataset(eval_file)

# For inference, feed input data to the dataset directly via feed_dict.
infer_batch = tf.placeholder(tf.string, shape=(num_infer_examples,))
infer_dataset = tf.contrib.data.Dataset.from_tensor_slices(infer_batch)
</code></pre><p>所有的数据集可以通过输入处理类似的处理。这包括 阅读和清理数据，分类（在训练和评估的情况下） 过滤和配料。</p>
<p>为了将每个句子转换成单词串的向量，例如，我们使用 数据集图转换：</p>
<pre><code>dataset = dataset.map(lambda string: tf.string_split([string]).values)
</code></pre><p>然后，我们可以将每个句子向量切换成包含两个向量的元组 和它的动态长度：</p>
<pre><code>dataset = dataset.map(lambda words: (words, tf.size(words))
</code></pre><p>最后，我们可以对每个句子进行词汇查询。给一个查询 表格对象表，这个映射将从一个向量中转换出第一个元组元素 字符串到整数的向量。</p>
<pre><code>dataset = dataset.map(lambda words, size: (table.lookup(words), size))
</code></pre><p>加入两个数据集也很容易。如果两个文件包含一行一行 互相翻译，每一个都被读入自己的数据集，然后一个新的 包含压缩行的元组的数据集可以通过以下方式创建：</p>
<pre><code>source_target_dataset = tf.contrib.data.Dataset.zip((source_dataset, target_dataset))
</code></pre><p>可变长度句子的分组很简单。下列 转换批量从source_target_dataset批处理batch_size元素，和<br>分别将源向量和目标向量填充到最长的长度 源和目标载体在每批。</p>
<pre><code>batched_dataset = source_target_dataset.padded_batch(
        batch_size,
        padded_shapes=((tf.TensorShape([None]),  # source vectors of unknown size
                        tf.TensorShape([])),     # size(source)
                       (tf.TensorShape([None]),  # target vectors of unknown size
                        tf.TensorShape([]))),    # size(target)
        padding_values=((src_eos_id,  # source vectors padded on the right with src_eos_id
                         0),          # size(source) -- unused
                        (tgt_eos_id,  # target vectors padded on the right with tgt_eos_id
                         0)))         # size(target) -- unused
</code></pre><p>从这个数据集发出的值将是张量有张量的嵌套元组 大小为batch_size的最左边的维度。结构将是：</p>
<p>迭代器[0] [0]具有批处理和填充的源句子矩阵。 迭代器[0] [1]具有成批的源大小向量。 迭代器[1] [0]具有批处理和填充的目标语句矩阵。<br>迭代器[1] [1]具有成批的目标大小向量。</p>
<p>最后，将批量相似大小的源语句一起分组 也有可能。请看 文件 utils / iterator_utils.py for 更多细节和全面实施。</p>
<p>从数据集中读取数据需要三行代码：创建迭代器， 获取它的值，并初始化它。</p>
<pre><code>batched_iterator = batched_dataset.make_initializable_iterator()

((source, source_lengths), (target, target_lenghts)) = batched_iterator.get_next()

# At initialization time.
session.run(batched_iterator.initializer, feed_dict={...})
</code></pre><p>一旦迭代器被初始化，每个访问源的session.run调用 或目标张量将要求来自底层数据集的下一个小批次。</p>
<h2><span id="更好的nmt模型的其他细节">更好的NMT模型的其他细节</span></h2><h3><span id="双向rnn">双向RNN</span></h3><p>编码器方面的双向性通常会带来更好的性能（使用 速度随着更多层的使用而降低）。在这里，我们给一个简化 如何建立一个单一的双向层编码器的例子：</p>
<pre><code># Construct forward and backward cells
forward_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)
backward_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)

bi_outputs, encoder_state = tf.nn.bidirectional_dynamic_rnn(
    forward_cell, backward_cell, encoder_emb_inp,
    sequence_length=source_sequence_length, time_major=True)
encoder_outputs = tf.concat(bi_outputs, -1)
</code></pre><p>可以以相同的方式使用变量encoder_outputs和encoder_state 如在部分编码器中。请注意，对于多个双向层，我们需要<br>操纵一下encoder_state，看model.py，方法 _build_bidirectional_rnn（）获取更多细节。</p>
<h3><span id="梁搜索">梁搜索</span></h3><p>而贪婪的解码可以给我们相当合理的翻译质量，一个梁 搜索解码器可进一步提升性能。梁搜索的想法是 更好地探索所有可能的翻译搜索空间，保持周围<br>我们翻译的一小组顶级候选人。梁的大小被称为 光束宽度;例如尺寸10的最小光束宽度通常就足够了。对于 更多的信息，请参阅第7.2.3节<br>Neubig，（2017）。这是一个例子 光束搜索可以做到：</p>
<pre><code># Replicate encoder infos beam_width times
decoder_initial_state = tf.contrib.seq2seq.tile_batch(
    encoder_state, multiplier=hparams.beam_width)

# Define a beam-search decoder
decoder = tf.contrib.seq2seq.BeamSearchDecoder(
        cell=decoder_cell,
        embedding=embedding_decoder,
        start_tokens=start_tokens,
        end_token=end_token,
        initial_state=decoder_initial_state,
        beam_width=beam_width,
        output_layer=projection_layer,
        length_penalty_weight=0.0)

# Dynamic decoding
outputs, _ = tf.contrib.seq2seq.dynamic_decode(decoder, ...)
</code></pre><p>请注意，使用相同的dynamic_decode（）API调用，类似于 部分解码器。一旦解码，我们可以访问翻译为 如下：</p>
<pre><code>translations = outputs.predicted_ids
# Make sure translations shape is [batch_size, beam_width, time]
if self.time_major:
   translations = tf.transpose(translations, perm=[1, 2, 0])
</code></pre><p>有关更多详细信息，请参阅model.py，_build_decoder（）方法。</p>
<h3><span id="超参数">超参数</span></h3><p>有几个超参数可以导致额外的 表演。在这里，我们根据自己的经验列出一些[免责声明： 别人可能不同意我们写的东西！ ]。</p>
<p>优化：亚当可以导致“陌生”的合理结果， 体系结构，带调度的SGD通常会导致更好的性能 你可以用SGD来训练。</p>
<p>注意：Bahdanau式的注意往往需要双向的 编码器端工作正常;而Luong式的注意力往往适用于 不同的设置。对于本教程的代码，我们建议使用这两个改进<br>Luong＆Bahdanau式的注意变体：scaled_luong＆normed bahdanau。</p>
<h3><span id="多gpu训练">多GPU训练</span></h3><p>培训一个NMT模型可能需要几天的时间。放置不同的RNN图层 不同的GPU可以提高训练速度。这是一个创建的例子 RNN层在多个GPU上。</p>
<pre><code>cells = []
for i in range(num_layers):
  cells.append(tf.contrib.rnn.DeviceWrapper(
      tf.contrib.rnn.LSTMCell(num_units),
      &quot;/gpu:%d&quot; % (num_layers % num_gpus)))
cell = tf.contrib.rnn.MultiRNNCell(cells)
</code></pre><p>另外，我们需要启用<code>colocate_gradients_with_ops</code>选项 <code>tf.gradients</code>并行化梯度计算。</p>
<p>您可能会注意到基于注意力的NMT模型的速度提高非常快 随着GPU数量的增加而变小。标准的一个主要缺点 注意体系结构正在使用顶层（最终）层的输出来查询<br>注意在每个时间步骤。这意味着每个解码步骤都必须等待 上一步完全完成;因此，我们不能并行解码 通过简单地在多个GPU上放置RNN层进行处理。</p>
<p>GNMT关注架构 通过使用底层（第一层）来并行解码器的计算 输出查询关注。因此，每个解码步骤可以尽快开始 其前一步的第一层和关注计算完成。我们<br>在中实现了架构 GNMTAttentionMultiCell， tf.contrib.rnn.MultiRNNCell的子类。这里是一个如何创建的例子<br>具有GNMTAttentionMultiCell的解码器单元。</p>
<pre><code>cells = []
for i in range(num_layers):
  cells.append(tf.contrib.rnn.DeviceWrapper(
      tf.contrib.rnn.LSTMCell(num_units),
      &quot;/gpu:%d&quot; % (num_layers % num_gpus)))
attention_cell = cells.pop(0)
attention_cell = tf.contrib.seq2seq.AttentionWrapper(
    attention_cell,
    attention_mechanism,
    attention_layer_size=None,  # don&apos;t add an additional dense layer.
    output_attention=False,)
cell = GNMTAttentionMultiCell(attention_cell, cells)
</code></pre><h1><span id="基准">基准</span></h1><h2><span id="iwslt英语-越南语">IWSLT英语 - 越南语</span></h2><p>训练：133K例子，vocab = vocab。（vi | en），train = train。（vi | en） 开发= tst2012（六| EN）。，<br>test = tst2013。（vi | en），下载脚本。</p>
<p>培训细节。我们训练双向512个单元的2层LSTM 编码器（即，用于编码器的1个双向层），嵌入暗淡 是512. LuongAttention（scale =<br>True）和drop_out_prob一起使用 0.8。所有的参数是统一的。学习率1.0的SGD使用如下： 列车12K步（约12个时代）;<br>8K步后，我们开始减半学习 每步1K。</p>
<p>结果。 TODO（rzhao）：添加英语 - 越南语训练模型的URL。</p>
<p>以下是2个模型的平均结果 （型号1， 模型2）。\ 我们用BLEU得分来衡量翻译质量（Papineni et al。，2002）。</p>
<table>
<thead>
<tr>
<th>Systems</th>
<th>tst2012 (dev)</th>
<th>test2013 (test)  </th>
</tr>
</thead>
<tbody>
<tr>
<td>NMT (greedy)</td>
<td>23.2</td>
<td>25.5  </td>
</tr>
<tr>
<td>NMT (beam=10)</td>
<td>23.8</td>
<td><strong>26.1</strong>  </td>
</tr>
</tbody>
</table>
<p><a href="https://nlp.stanford.edu/pubs/luong-manning-
iwslt15.pdf" target="_blank" rel="noopener">(Luong &amp; Manning, 2015)</a> |  - | 23.3  </p>
<p>训练速度：在TitanX上的K40m和（0.17s步进时间，32.2K wps）上（0.37s步进时间，15.3K wps）<br>在这里，步进时间是指运行一个小批量（128号）的时间。对于wps，我们计算来源和目标上的字数。</p>
<h2><span id="wmt德语-英语">WMT德语 - 英语</span></h2><p>训练：4.5M例子，vocab = vocab.bpe.32000。（de | en）， train =<br>train.tok.clean.bpe.32000。（de | en），dev = newstest2013.tok.bpe.32000。（de |<br>en）， 测试= newstest2015.tok.bpe.32000。（DE | EN） 下载脚本</p>
<p>培训细节。我们的训练超参数类似于 英语 - 越南语的实验除了以下细节。数据是 使用BPE拆分为子字单位<br>（32K操作）。我们训练双向1024个单元的4层LSTMs 编码器（即，用于编码器的2个双向层），嵌入暗淡<br>是1024.我们训练了350K步（〜10个纪元）。经过170K步，我们开始 每17K步减半学习率。</p>
<p>结果。 TODO（rzhao）：为德英培训模型添加网址。</p>
<p>前两行是2个模型的平均结果 （型号1， 模型2）。 第三行的结果是GNMT的关注 （模型） ;使用4个GPU进行训练。</p>
<table>
<thead>
<tr>
<th>Systems</th>
<th>newstest2013 (dev)</th>
<th>newstest2015  </th>
</tr>
</thead>
<tbody>
<tr>
<td>NMT (greedy)</td>
<td>27.1</td>
<td>27.6  </td>
</tr>
<tr>
<td>NMT (beam=10)</td>
<td>28.0</td>
<td>28.9  </td>
</tr>
<tr>
<td>NMT + GNMT attention (beam=10)</td>
<td>29.0</td>
<td><strong>29.9</strong>  </td>
</tr>
<tr>
<td><a href="http://matrix.statmt.org/" target="_blank" rel="noopener">WMT SOTA</a></td>
<td>-</td>
<td>29.3  </td>
</tr>
</tbody>
</table>
<p>这些结果表明我们的代码为NMT构建了强大的基线系统。 （请注意，WMT系统通常使用大量的单语数据，而目前我们没有。</p>
<p>Nvidia K40m和（0.7s step-time，8.7K wps）在Nvidia TitanX上的训练速度（2.1s step-time，3.4K<br>wps） 为了看到GNMT关注的加速，我们仅以K40m为基准：</p>
<table>
<thead>
<tr>
<th>Systems</th>
<th>1 gpu</th>
<th>4 gpus</th>
<th>8 gpus  </th>
</tr>
</thead>
<tbody>
<tr>
<td>NMT (4 layers)</td>
<td>2.2s, 3.4K</td>
<td>1.9s, 3.9K</td>
<td>-  </td>
</tr>
<tr>
<td>NMT (8 layers)</td>
<td>3.5s, 2.0K</td>
<td>-</td>
<td>2.9s, 2.4K  </td>
</tr>
<tr>
<td>NMT + GNMT attention (4 layers)</td>
<td>2.6s, 2.8K</td>
<td>1.7s, 4.3K</td>
<td>-  </td>
</tr>
<tr>
<td>NMT + GNMT attention (8 layers)</td>
<td>4.2s, 1.7K</td>
<td>-</td>
<td>1.9s, 3.8K  </td>
</tr>
</tbody>
</table>
<p>这些结果表明，没有GNMT的关注，使用多个gpus的收益是最小的。 在GNMT的关注下，我们从多个gpus中获得了50％-100％的加速。</p>
<h2><span id="wmt英语-德语-全面比较">WMT英语 - 德语 - 全面比较</span></h2><p>前两行是我们的GNMT模型 注意： 模型1（4层）， 模型2（8层）。</p>
<table>
<thead>
<tr>
<th>Systems</th>
<th>newstest2014</th>
<th>newstest2015  </th>
</tr>
</thead>
<tbody>
<tr>
<td><em>Ours</em> – NMT + GNMT attention (4 layers)</td>
<td>23.7</td>
<td>26.5  </td>
</tr>
<tr>
<td><em>Ours</em> – NMT + GNMT attention (8 layers)</td>
<td>24.4</td>
<td><strong>27.6</strong>  </td>
</tr>
<tr>
<td><a href="http://matrix.statmt.org/" target="_blank" rel="noopener">WMT SOTA</a></td>
<td>20.6</td>
<td>24.9  </td>
</tr>
<tr>
<td>OpenNMT <a href="https://arxiv.org/abs/1701.02810" target="_blank" rel="noopener">(Klein et al., 2017)</a></td>
<td>19.3</td>
<td>-  </td>
</tr>
<tr>
<td>tf-seq2seq <a href="https://arxiv.org/abs/1703.03906" target="_blank" rel="noopener">(Britz et al., 2017)</a></td>
<td>22.2</td>
<td></td>
</tr>
</tbody>
</table>
<p>25.2<br>GNMT <a href="https://research.google.com/pubs/pub45610.html" target="_blank" rel="noopener">(Wu et al., 2016)</a> |<br><strong>24.6</strong> |  -  </p>
<p>上述结果表明，我们的模型在类似架构的模型中是非常有竞争力的。<br>[请注意，OpenNMT使用较小的模型，目前最好的结果（截至撰写本文时）是由Transformer网络（Vaswani et<br>al。，2017）获得的28.4，具有明显不同的架构。</p>
<h2><span id="标准hparams">标准HParams</span></h2><p>我们提供了 一套标准的hparams 使用预先训练的检查点推断或训练NMT架构 在基准中使用。</p>
<p>我们将使用WMT16的德英数据，您可以通过下载数据 以下命令。</p>
<pre><code>nmt/scripts/wmt16_en_de.sh /tmp/wmt16
</code></pre><p>以下是加载预先训练的GNMT WMT德语 - 英语的示例命令 检查点推断。</p>
<pre><code>python -m nmt.nmt \
    --src=de --tgt=en \
    --ckpt=/path/to/checkpoint/translate.ckpt \
    --hparams_path=nmt/standard_hparams/wmt16_gnmt_4_layer.json \
    --out_dir=/tmp/deen_gnmt \
    --vocab_prefix=/tmp/wmt16/vocab.bpe.32000 \
    --inference_input_file=/tmp/wmt16/newstest2014.tok.bpe.32000.de \
    --inference_output_file=/tmp/deen_gnmt/output_infer \
    --inference_ref_file=/tmp/wmt16/newstest2014.tok.bpe.32000.en
</code></pre><p>这里是GNMT WMT德 - 英模型的示例命令。</p>
<pre><code>python -m nmt.nmt \
    --src=de --tgt=en \
    --hparams_path=nmt/standard_hparams/wmt16_gnmt_4_layer.json \
    --out_dir=/tmp/deen_gnmt \
    --vocab_prefix=/tmp/wmt16/vocab.bpe.32000 \
    --train_prefix=/tmp/wmt16/train.tok.clean.bpe.32000 \
    --dev_prefix=/tmp/wmt16/newstest2013.tok.bpe.32000 \
    --test_prefix=/tmp/wmt16/newstest2015.tok.bpe.32000
</code></pre><h1><span id="其他资源">其他资源</span></h1><p>深入阅读“神经机器翻译”和“序列到序列” 型号，我们强烈推荐以下材料 通过 Luong，Cho，Manning，（2016）; Luong，（2016）;<br>和Neubig（2017）。</p>
<p>建立seq2seq模型有各种各样的工具，所以我们选择一个 语言：\ 斯坦福大学NMT<br><a href="https://nlp.stanford.edu/projects/nmt/" target="_blank" rel="noopener">https://nlp.stanford.edu/projects/nmt/</a> [Matlab] \ TF-seq2seq<br><a href="https://github.com/google/seq2seq" target="_blank" rel="noopener">https://github.com/google/seq2seq</a> [TensorFlow] \ Nemantus<br><a href="https://github.com/rsennrich/nematus" target="_blank" rel="noopener">https://github.com/rsennrich/nematus</a> [Theano] \ OpenNMT <a href="http://opennmt.net/" target="_blank" rel="noopener">http://opennmt.net/</a><br>[火炬] \ OpenNMT-py <a href="https://github.com/OpenNMT/OpenNMT-py" target="_blank" rel="noopener">https://github.com/OpenNMT/OpenNMT-py</a> [PyTorch]</p>
<h1><span id="承认">承认</span></h1><p>我们要感谢Denny Britz，Anna Goldie，Derek Murray和Cinjon<br>Resnick为TensorFlow和seq2seq库带来的新功能。另外感谢Lukasz Kaiser在seq2seq代码库上的初步帮助。 Quoc<br>Le提出复制GNMT的建议;关于GNMT系统的细节，吴永辉和陈志峰;以及Google Brain团队的支持和反馈！</p>
<h1><span id="参考">参考</span></h1><p>Dzmitry Bahdanau，Kyunghyun Cho和Yoshua    Bengio。神经机器翻译通过共同学习来对齐和翻译。 ICLR。<br>Minh-Thang Luong，Hieu Pham和Christopher D.    曼宁。有效的基于注意力的神经机器翻译方法。 EMNLP。 Ilya<br>Sutskever，Oriol Vinyals和Quoc    V. Le。 2014年。序列学习与神经网络。 NIPS。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/tensors/" title="张量" itemprop="url">张量</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="张量">张量</span></h1><p>如名称所示，TensorFlow是定义和运行计算的框架 涉及张量。张量是向量和矩阵的推广 可能更高的尺寸。在内部，TensorFlow表示张量<br>基本数据类型的n维数组。</p>
<p>编写一个TensorFlow程序时，您操作并传递的主要对象 周围是<code>tf.Tensor</code>。 <code>tf.Tensor</code>对象表示一个部分定义的对象<br>计算，最终会产生一个价值。 TensorFlow程序工作 首先建立<code>tf.Tensor</code>物体的图形，详细说明每个张量是如何的<br>根据其他可用的张量计算，然后运行其中的一部分 图表来达到预期的效果。</p>
<p><code>tf.Tensor</code>具有以下特性：</p>
<p>数据类型（例如，<code>float32</code>，<code>int32</code>或<code>string</code>） 一个形状</p>
<p>张量中的每个元素具有相同的数据类型，并且数据类型始终为 众所周知。形状（也就是它的尺寸数量和尺寸 维度）可能只是部分已知的。大多数操作产生的张量<br>如果它们的输入形状也是完全已知的，但是是完全已知的形状 有些情况下只能在图执行时找到张量的形状 时间。</p>
<p>有些类型的张量是特殊的，这些将被其他的覆盖 程序员指南的单位。主要的是：</p>
<p><code>tf.Variable</code> <code>tf.Constant</code> <code>tf.Placeholder</code> <code>tf.SparseTensor</code></p>
<p>除了<code>tf.Variable</code>之外，张量的值是不变的 意味着在单个执行张量的情况下只有一个 值。然而，两次评估相同的张量可以返回不同的值;<br>例如张量可以是从磁盘读取数据的结果，或者 生成一个随机数。</p>
<h2><span id="秩">秩</span></h2><p><code>tf.Tensor</code>对象的等级是它的维数。同义词 排名包括顺序或程度或n维。 请注意，TensorFlow中的排名与数学中的矩阵排名并不相同。<br>如下表所示，TensorFlow中的每个等级对应于a 不同的数学实体：</p>
<table>
<thead>
<tr>
<th>Rank</th>
<th>Math entity  </th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Scalar (magnitude only)  </td>
</tr>
<tr>
<td>1</td>
<td>Vector (magnitude and direction)  </td>
</tr>
<tr>
<td>2</td>
<td>Matrix (table of numbers)  </td>
</tr>
<tr>
<td>3</td>
<td>3-Tensor (cube of numbers)  </td>
</tr>
<tr>
<td>n</td>
<td>n-Tensor (you get the idea)  </td>
</tr>
</tbody>
</table>
<h3><span id="等级0">等级0</span></h3><p>以下片段演示了创建几个0级变量：</p>
<pre><code>mammal = tf.Variable(&quot;Elephant&quot;, tf.string)
ignition = tf.Variable(451, tf.int16)
floating = tf.Variable(3.14159265359, tf.float64)
its_complicated = tf.Variable((12.3, -4.85), tf.complex64)
</code></pre><p>注意：一个字符串在TensorFlow中被视为单个项目，而不是作为一个序列 字符。标量字符串，字符串向量等是可能的</p>
<h3><span id="等级1">等级1</span></h3><p>要创建1级<code>tf.Tensor</code>对象，可以传递一个项目列表作为 初始值。例如：</p>
<pre><code>mystr = tf.Variable([&quot;Hello&quot;], tf.string)
cool_numbers  = tf.Variable([3.14159, 2.71828], tf.float32)
first_primes = tf.Variable([2, 3, 5, 7, 11], tf.int32)
its_very_complicated = tf.Variable([(12.3, -4.85), (7.5, -6.23)], tf.complex64)
</code></pre><h3><span id="排名较高">排名较高</span></h3><p>排名第2的<code>tf.Tensor</code>对象至少由一行组成，至少包含一行 一列：</p>
<pre><code>mymat = tf.Variable([[7],[11]], tf.int16)
myxor = tf.Variable([[False, True],[True, False]], tf.bool)
linear_squares = tf.Variable([[4], [9], [16], [25]], tf.int32)
squarish_squares = tf.Variable([ [4, 9], [16, 25] ], tf.int32)
rank_of_squares = tf.rank(squarish_squares)
mymatC = tf.Variable([[7],[11]], tf.int32)
</code></pre><p>较高等级的张量同样由一个n维数组组成。例如， 在图像处理过程中，使用了许多等级为4的张量 对应于批量示例，图像宽度，图像高度和颜色通道。</p>
<pre><code>my_image = tf.zeros([10, 299, 299, 3])  # batch x height x width x color
</code></pre><h3><span id="获取tftensor对象的等级">获取<code>tf.Tensor</code>对象的等级</span></h3><p>要确定<code>tf.Tensor</code>对象的等级，请调用<code>tf.rank</code>方法。 例如，以下方法以编程方式确定排名 上一节中定义的<code>tf.Tensor</code>：</p>
<pre><code>r = tf.rank(my3d)
# After the graph runs, r will hold the value 3.
</code></pre><h3><span id="参考tftensor切片">参考<code>tf.Tensor</code>切片</span></h3><p>由于<code>tf.Tensor</code>是一个n维的单元阵列，可以访问单个单元 在<code>tf.Tensor</code>中，您需要指定n个索引。</p>
<p>对于0级张量（标量），没有指数是必要的，因为它已经是一个 单号。</p>
<p>对于秩1张量（矢量），传递单个索引允许您访问一个 数：</p>
<pre><code>my_scalar = my_vector[2]
</code></pre><p>请注意，在<code>[]</code>内部传递的索引本身可以是标量<code>tf.Tensor</code>，如果 你想动态地从矢量中选择一个元素。</p>
<p>对于等级2或更高的张量，情况更有趣。为一个 等级2的<code>tf.Tensor</code>，按预期传递两个数字返回一个标量：</p>
<pre><code>my_scalar = my_matrix[1, 2]
</code></pre><p>但是，传递一个数字将返回一个矩阵的子向量，如下所示：</p>
<pre><code>my_row_vector = my_matrix[2]
my_column_vector = my_matrix[:, 3]
</code></pre><p><code>:</code>符号是“单独保留这个维度”的python切片语法。这个 在较高等级的张量中是有用的，因为它允许你访问它的子矢量， 子矩阵，甚至其他的副手。</p>
<h2><span id="形状">形状</span></h2><p>张量的形状是每个维度中元素的数量。 图形构建期间，TensorFlow自动推断形状。这些推断 形状可能已知或未知的级别。如果排名是已知的，每个的大小<br>维度可能是已知的或未知的。</p>
<p>TensorFlow文档使用三个符号约定来描述 张量维数：等级，形状和维数。下表 显示了这些如何相互关联：</p>
<table>
<thead>
<tr>
<th>Rank</th>
<th>Shape</th>
<th>Dimension number</th>
<th>Example  </th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>[]</td>
<td>0-D</td>
<td>A 0-D tensor. A scalar.  </td>
</tr>
<tr>
<td>1</td>
<td>[D0]</td>
<td>1-D</td>
<td>A 1-D tensor with shape [5].  </td>
</tr>
<tr>
<td>2</td>
<td>[D0, D1]</td>
<td>2-D</td>
<td>A 2-D tensor with shape [3, 4].  </td>
</tr>
<tr>
<td>3</td>
<td>[D0, D1, D2]</td>
<td>3-D</td>
<td>A 3-D tensor with shape [1, 4, 3].  </td>
</tr>
<tr>
<td>n</td>
<td>[D0, D1, … Dn-1]</td>
<td>n-D</td>
<td>A tensor with shape [D0, D1, … Dn-1].  </td>
</tr>
</tbody>
</table>
<p>形状可以通过Python列表/元组的int或者 <code>tf.TensorShape</code>。</p>
<h3><span id="获取tftensor物体的形状">获取<code>tf.Tensor</code>物体的形状</span></h3><p>有两种方法可以访问<code>tf.Tensor</code>的形状。在建设中 图，问什么是已知的张量常常是有用的<br>形状。这可以通过阅读<code>shape</code>对象的<code>tf.Tensor</code>属性来完成。 这个方法返回一个<code>TensorShape</code>对象，这是一个方便的方法<br>表示部分指定的形状（因为在构建图形时不是全部 形状将被完全知道）。</p>
<p><code>tf.Tensor</code>也可以代表完全定义 另一台<code>tf.Tensor</code>在运行时的形状。这是通过调用<code>tf.shape</code>完成的<br>操作。这样，你可以建立一个图形来处理形状 张量通过建立其他张量依赖于输入的动态形状 <code>tf.Tensor</code>。</p>
<p>例如，这里是如何做一个与零相同大小的零向量 给定矩阵中的列数：</p>
<pre><code>zeros = tf.zeros(tf.shape(my_matrix)[1])
</code></pre><h3><span id="改变tftensor的形状">改变<code>tf.Tensor</code>的形状</span></h3><p>张量元素的数量是其所有尺寸的乘积 形状。标量元素的数量总是<code>1</code>。因为经常有 许多不同的形状有相同数量的元素，通常是这样<br>方便可以改变<code>tf.Tensor</code>的形状，保持其元素 固定。这可以通过<code>tf.reshape</code>完成。</p>
<p>以下示例演示如何重构张量：</p>
<pre><code>rank_three_tensor = tf.ones([3, 4, 5])
matrix = tf.reshape(rank_three_tensor, [6, 10])  # Reshape existing content into
                                                 # a 6x10 matrix
matrixB = tf.reshape(matrix, [3, -1])  #  Reshape existing content into a 3x20
                                       # matrix. -1 tells reshape to calculate
                                       # the size of this dimension.
matrixAlt = tf.reshape(matrixB, [4, 3, -1])  # Reshape existing content into a
                                             #4x3x5 tensor

# Note that the number of elements of the reshaped Tensors has to match the
# original number of elements. Therefore, the following example generates an
# error because no possible value for the last dimension will match the number
# of elements.
yet_another = tf.reshape(matrixAlt, [13, 2, -1])  # ERROR!
</code></pre><h2><span id="数据类型">数据类型</span></h2><p>除了维度，张量有一个数据类型。参考 程序员指南中的<code>tf.DataType</code>页面提供了数据类型的完整列表。</p>
<p>具有多种数据类型的<code>tf.Tensor</code>是不可能的。它是 但是，也可以将任意数据结构序列化为<code>string</code>并存储 那些在<code>tf.Tensor</code>s。</p>
<p>可以使用<code>tf.Tensor</code>从一种数据类型转换为另一种数据类型 <code>tf.cast</code>：</p>
<pre><code># Cast a constant integer tensor into floating point.
float_tensor = tf.cast(tf.constant([1, 2, 3]), dtype=tf.float32)
</code></pre><p>要检查<code>tf.Tensor</code>的数据类型，请使用<code>Tensor.dtype</code>属性。</p>
<p>从python对象创建<code>tf.Tensor</code>时，可以选择指定 数据类型。如果你不这样做，TensorFlow会选择一个可以代表你的数据类型 数据。<br>TensorFlow将Python整数转换为<code>tf.int32</code>和python浮动<br>点号到<code>tf.float32</code>。否则，TensorFlow使用相同的规则numpy 转换为数组时使用。</p>
<h2><span id="评估张量">评估张量</span></h2><p>一旦计算图已经建立，你可以运行计算 生成一个特定的<code>tf.Tensor</code>并获取分配给它的值。这是 通常用于调试以及TensorFlow的许多要求 工作。</p>
<p>评估张量的最简单方法是使用<code>Tensor.eval</code>方法。对于 例：</p>
<pre><code>constant = tf.constant([1, 2, 3])
tensor = constant * constant
print tensor.eval()
</code></pre><p><code>eval</code>方法仅适用于默认<code>tf.Session</code>有效时（请参阅 图表和会话了解更多信息）。</p>
<p><code>Tensor.eval</code>返回与张量相同内容的numpy数组。</p>
<p>有时无法评估没有上下文的<code>tf.Tensor</code>，因为 其价值可能取决于不可用的动态信息。对于 例如，依赖于<code>Placeholder</code>s的张量不能被评估<br>为<code>Placeholder</code>提供了一个价值。</p>
<pre><code>p = tf.placeholder(tf.float32)
t = p + 1.0
t.eval()  # This will fail, since the placeholder did not get a value.
t.eval(feed_dict={p:2.0})  # This will succeed because we&apos;re feeding a value
                           # to the placeholder.
</code></pre><p>请注意，<code>tf.Tensor</code>是可能的，而不仅仅是占位符。</p>
<p>其他模型构造可能会使<code>tf.Tensor</code>评估 复杂。 TensorFlow无法直接评估内部定义的<code>tf.Tensor</code><br>功能或内部控制流程结构。如果一个<code>tf.Tensor</code>取决于一个值 从一个队列中，评估<code>tf.Tensor</code>只会有一些工作<br>排队;否则，评估会挂起。在处理队列时，请记住 在评估任何<code>tf.train.start_queue_runners</code>之前请拨打<code>tf.Tensor</code>。</p>
<h2><span id="打印张力">打印张力</span></h2><p>出于调试目的，您可能需要打印<code>tf.Tensor</code>的值。而  tfdbg提供了高级的调试支持，TensorFlow也有<br>操作直接打印<code>tf.Tensor</code>的值。</p>
<p>请注意，打印时很少使用以下模式 <code>tf.Tensor</code>：</p>
<pre><code>t = &lt;&lt;some tensorflow operation&gt;&gt;
print t  # This will print the symbolic tensor when the graph is being built.
         # This tensor does not have a value in this context.
</code></pre><p>此代码打印<code>tf.Tensor</code>对象（表示延迟计算） 而不是它的价值。相反，TensorFlow提供了<code>tf.Print</code>操作<br>返回它的第一个张量参数，同时打印该集合 <code>tf.Tensor</code>s作为第二个参数传递。</p>
<p>要正确使用<code>tf.Print</code>，必须使用其返回值。看下面的例子</p>
<pre><code>t = &lt;&lt;some tensorflow operation&gt;&gt;
tf.Print(t, [t])  # This does nothing
t = tf.Print(t, [t])  # Here we are using the value returned by tf.Print
result = t + 1  # Now when result is evaluated the value of `t` will be printed.
</code></pre><p>当您评估<code>result</code>时，您将评估<code>result</code>所依赖的一切 根据。由于<code>result</code>取决于<code>t</code>，而评估<code>t</code>有副作用<br>打印输入（<code>t</code>的旧值），<code>t</code>打印。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/image_retraining/" title="如何重新开始新类别的最后一层" itemprop="url">如何重新开始新类别的最后一层</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="如何重新开始新类别的最后一层">如何重新开始新类别的最后一层</span></h1><p>现代物体识别模型具有数百万个参数，可能需要数周时间 充分训练。转移学习是一个捷径，很多这个技术 通过为ImageNet等一系列类别提供完整的模型<br>从现有的新班级重新训练。在这个例子中，我们将会 重新训练最后一层，同时保持所有其他层不变。 有关可以看到的方法的更多信息 本文关于Decaf。</p>
<p>虽然这不如完整的训练，但这是非常有效的 对于许多应用程序，并可以运行在一个小小的三十分钟 笔记本电脑，而不需要GPU。本教程将向您展示如何运行<br>在你自己的图像上的脚本示例，并将解释你的一些选项 帮助控制培训过程。</p>
<p>注意：本教程的这个版本主要使用bazel。一个bazel免费版本是 也提供 作为codelab。</p>
<h2><span id="对花的培训">对花的培训</span></h2><p><img src="https://www.tensorflow.org/images/daisies.jpg" alt="Daisies by Kelly Sikkema"></p>
<p>图片由凯利Sikkema</p>
<p>在开始任何培训之前，您需要一组图像来教授网络 关于你想要认识的新课程。有一个后面的部分 解释如何准备自己的图像，但为了让我们轻松创建一个<br>最初使用的创作共享许可花照片档案。为了得到 花卉照片集，运行这些命令：</p>
<pre><code>cd ~
curl -O http://download.tensorflow.org/example_images/flower_photos.tgz
tar xzf flower_photos.tgz
</code></pre><p>一旦你有了这些图像，你可以从根本上像这样建立一个修剪器 您的TensorFlow源代码目录：</p>
<pre><code>bazel build tensorflow/examples/image_retraining:retrain
</code></pre><p>如果你有一台支持的机器 AVX指令集 （在过去几年中生产的x86 CPU中很常见），您可以改善运行<br>通过建筑物的再培训速度，就像这样（在<code>configure</code>中选择合适的选项后）：</p>
<pre><code>bazel build --config opt tensorflow/examples/image_retraining:retrain
</code></pre><p>然后可以这样运行retrainer：</p>
<pre><code>bazel-bin/tensorflow/examples/image_retraining/retrain --image_dir ~/flower_photos
</code></pre><p>该脚本加载预先训练的Inception v3模型，删除旧的顶层， 并在您下载的花卉照片上训练一个新的。没有一朵花<br>物种是在完整的网络培训的原始ImageNet类。 转移学习的魔力是经过训练的较低层次 区分一些对象可以重复用于许多识别任务 没有任何改动。</p>
<h2><span id="瓶颈">瓶颈</span></h2><p>脚本可能需要30分钟或更长时间才能完成，具体取决于速度 的机器。第一阶段分析磁盘上的所有图像并进行计算 他们每个人的瓶颈值。 “瓶颈”是一个非正式的术语<br>经常用于实际上最终输出层之前的层 分类。这个倒数第二层已被训练输出一组 值足以让分类器用来区分全部 它被要求承认的课程。这意味着它必须是一个有意义的<br>和图像的紧凑总结，因为它必须包含足够的信息 为分类器在一个非常小的值集合中做出一个好的选择。该 原因是我们的最后一层再培训可以在新班上工作，事实证明<br>需要的信息种类区分了所有1000个类别 ImageNet通常也可以用来区分新类型的对象。</p>
<p>因为在训练和计算过程中每个图像都被多次重复使用 每个瓶颈都需要花费大量的时间，这会加快速度 将这些瓶颈值缓存在磁盘上，这样就不必重复<br>重新计算。默认情况下，它们存储在<code>/tmp/bottleneck</code>目录中 如果你重新运行脚本，他们将被重用，所以你不必等待 部分再次。</p>
<h2><span id="训练">训练</span></h2><p>一旦瓶颈完成，最后一层的实际培训 网络开始。你会看到一系列的步骤输出，每个输出显示训练 准确性，验证准确性和交叉熵。训练的准确性<br>显示当前培训批次中使用的图像的百分比 标有正确的类。验证的准确性是a的精度 随机选择一组不同的图像。关键的区别是 训练的准确性是基于网络已经能够的图像<br>学习如此，网络可以适应训练数据中的噪声。一个 衡量网络性能的真正措施就是衡量其性能 一个没有包含在训练数据中的数据集 - 这是由<br>验证准确性。如果列车的准确度高但验证的准确性 仍然很低，这意味着网络过度配合和记忆特别 训练图像中的特征通常没有帮助。交叉<br>熵是一个损失函数，它可以窥见学习的好坏 进程正在进行中。培训的目标是使损失如此小 可能的，所以你可以通过密切关注学习是否有效<br>损失是否继续下降，忽略了短期的噪音。</p>
<p>默认情况下，这个脚本将运行4000个训练步骤。每一步选择十个 随机从训练集中找到图像，从缓存中找到它们的瓶颈， 并将它们馈送到最后一层以获得预测。那些预言是<br>然后与实际标签进行比较以更新最终图层的权重 通过反向传播过程。随着过程的继续，你应该看到 报告的准确性提高，毕竟所有的步骤都完成了，最后的测试<br>准确性评估运行在与训练分开的一组图像上 并验证图片。这个测试评估是如何的最好的估计 训练好的模型将在分类任务上执行。你应该看到一个<br>准确度在90％到95％之间，但确切的数值会随着运行而变化 因为在训练过程中存在随机性。这个数字是基于 测试集中图像的百分比是正确的标签 模型完成训练后。</p>
<h2><span id="用tensorboard可视化再训练">用TensorBoard可视化再训练</span></h2><p>该脚本包含TensorBoard摘要，使得更容易理解，调试和优化再培训。例如，您可以将图形和统计信息可视化，例如在训练期间权重或准确性如何变化。</p>
<p>要启动TensorBoard，请在再培训期间或之后运行此命令：</p>
<pre><code>tensorboard --logdir /tmp/retrain_logs
</code></pre><p>一旦TensorBoard正在运行，浏览您的网络浏览器到<code>localhost:6006</code>来查看TensorBoard。</p>
<p>该脚本默认将TensorBoard摘要记录到<code>/tmp/retrain_logs</code>。您可以使用<code>--summaries_dir</code>标志更改目录。</p>
<p>TensorBoard的GitHub有更多关于TensorBoard使用的信息，包括提示和技巧以及调试信息。</p>
<h2><span id="使用再培训模式">使用再培训模式</span></h2><p>该脚本将写出一个版本的Inception v3网络与决赛 层重新训练到您的类别/tmp/output_graph.pb和一个文本文件<br>包含标签到/tmp/output_labels.txt。这些都是在一个格式 C ++和Python图像分类的例子<br>可以阅读，所以你可以立即开始使用你的新模型。既然你已经 替换顶层，您将需要在脚本中指定新名称<br>如果您使用的是label_image，则使用<code>--output_layer=final_result</code>标志。</p>
<p>下面是一个如何构建和运行label_image示例的例子 再培训图表：</p>
<pre><code>bazel build tensorflow/examples/image_retraining:label_image &amp;&amp; \
bazel-bin/tensorflow/examples/image_retraining/label_image \
--graph=/tmp/output_graph.pb --labels=/tmp/output_labels.txt \
--output_layer=final_result:0 \
--image=$HOME/flower_photos/daisy/21652746_cc379e0eea_m.jpg
</code></pre><p>你应该看到一个花标签列表，在大多数情况下菊花在上面 （虽然每个重新训练的模型可能略有不同）。你可以更换<br><code>--image</code>参数与您自己的图像来尝试这些，并使用C ++代码 作为与您自己的应用程序集成的模板。</p>
<p>如果你想在自己的Python程序中使用再培训的模型，那么 以上 <code>label_image</code>脚本 是一个合理的出发点。</p>
<p>如果您发现默认的Inception v3模型对您来说太大或太慢 应用程序，看看其他模型体系结构部分 下面的选项可以加快你的网络。</p>
<h2><span id="根据自己的类别进行培训">根据自己的类别进行培训</span></h2><p>如果你已经设法让脚本在花图像上工作，你 可以开始看教学，以识别你关心的类别。 从理论上讲，你需要做的就是把它指向一组子文件夹，每个文件夹都被命名<br>在你的一个类别之后，只包含那个类别的图片。如果 你这样做，并传递子目录的根文件夹作为参数 <code>--image_dir</code>，剧本应该像对待花一样训练。</p>
<p>以下是鲜花档案的文件夹结构的样子，给你 以及脚本所寻找布局的例子：</p>
<p><img src="https://www.tensorflow.org/images/folder_structure.png" alt="Folder Structure"></p>
<p>在实践中，可能需要一些工作来获得所需的准确性。我会尝试 指导您解决下面可能遇到的一些常见问题。</p>
<h2><span id="创建一组训练图像">创建一组训练图像</span></h2><p>从第一个开始就是看你收集的图像，因为 我们在培训中看到的最常见的问题来自所馈入的数据。</p>
<p>为了使训练工作顺利，你至少应该收集一百张照片 你想认识的对象。你能收集的越多，越好 你的训练模型的准确性可能是。你还需要确保<br>照片是您的应用程序实际上的一个很好的代表 遭遇。例如，如果你把所有的照片都放在室内的墙上 而你的用户正试图识别户外的物体，你可能不会看到 当你部署好结果。</p>
<p>另一个要避免的缺陷是学习过程会随时随地进行 标记的图像彼此有共同的，如果你不是 小心这可能是没有用的东西。例如，如果你拍照<br>一种是蓝色的房间，另一种是绿色的，然后是模型 最终将基于其背景颜色的预测，而不是 你真正关心的对象。为了避免这种情况，请尝试使用as拍照<br>尽可能地在不同的时间和不同的情况下尽可能地处理各种情况 设备。如果你想知道更多关于这个问题，你可以阅读关于这个问题 经典（也可能是杜撰的） 坦克识别问题。</p>
<p>您可能还想考虑您使用的类别。这可能是值得的 将涵盖许多不同物理形式的大类分成几类 较小的那些在视觉上更明显。例如，而不是“车辆”<br>你可以使用“汽车”，“摩托车”和“卡车”。这也值得思考 无论你是“封闭的世界”还是“开放的世界”问题。在封闭的世界里，<br>你将被要求分类的唯一的东西是你的对象类 知道关于。这可能适用于您认识用户的植物识别应用程序 很可能会拍摄一朵花，所以你所要做的就是决定<br>哪些物种。相比之下，漫游机器人可能会看到各种各样的不同 通过它的相机，当它在世界各地漫游。在这种情况下，你会的<br>要分类器报告，如果它不知道它看到了什么。这可以 很难做好，但如果你经常收集大量典型的“背景” 没有相关对象的照片，您可以将它们添加到额外的“未知”<br>在你的图像文件夹中的类。</p>
<p>这也是值得检查，以确保所有的图像被标记 正确。为了我们的目的，用户生成的标签通常是不可靠的 例如使用#daisy为一个叫Daisy的人拍照。如果你经历过<br>你的图像，并剔除它可以做你的整体奇迹的任何错误 准确性。</p>
<h2><span id="培训步骤">培训步骤</span></h2><p>如果您对自己的图片感到满意，可以考虑改善效果 通过改变学习过程的细节。最简单的尝试是<br><code>--how_many_training_steps</code>。这默认为4,000，但如果你增加到 8000将训练两倍的时间。准确度提高的速度<br>减慢你训练的时间，并在某个时刻完全停止，但你 可以试验一下，看看你什么时候达到你的模型的极限。</p>
<h2><span id="扭曲">扭曲</span></h2><p>改善图像训练结果的常用方法是变形， 裁剪或以随机方式使训练输入增亮。这有 有利于扩大培训数据的有效规模 相同图像的可能变化，并倾向于帮助网络学习<br>应付所有在现实生活中会出现的扭曲现象 分类。在我们的脚本中使这些扭曲最大的缺点 是瓶颈缓存不再有用，因为输入图像永远不会<br>完全重用。这意味着培训过程需要更长的时间，所以我 建议尝试这种方式来微调你的模型，一旦你有一个 你相当满意。</p>
<p>您可以通过<code>--random_crop</code>，<code>--random_scale</code>和 <code>--random_brightness</code>到脚本。这些都是百分比值<br>控制每个图像应用了多少失真。它的 合理的，从他们每个人的5或10的值开始，然后进行实验 看看他们中的哪些人帮助您的应用程序。<br><code>--flip_left_right</code>将会 随机镜像一半的水平，这是有道理的，只要 这些反转可能发生在您的应用程序中。例如它<br>如果你试图识别字母，就不是一个好主意，因为翻转 他们破坏了他们的意思。</p>
<h2><span id="超参数">超参数</span></h2><p>还有其他几个参数可以尝试调整，看看他们是否有帮助 你的结果。 <code>--learning_rate</code>控制更新的大小 训练期间的最后一层。直观地说，如果这比学习小<br>将需要更长的时间，但最终可能会帮助整体精度。那不是 总是这样，所以你需要仔细试验，看看有什么作品 为你的情况。<br><code>--train_batch_size</code>控制检查的图像数量 在一个训练步骤中，并且因为学习速率是每批应用的 如果您有更大的批次以获得相同的整体，则需要减少它<br>影响。</p>
<h2><span id="培训验证和测试集">培训，验证和测试集</span></h2><p>当您将脚本指向文件夹时，脚本将在其中进行引导 的图像被分成三个不同的集合。最大的是通常 训练集是培训期间输入网络的所有图像，<br>结果用于更新模型的权重。你可能想知道我们为什么 不要使用所有的图像进行培训？我们正在做的一个很大的潜在问题 机器学习是我们的模型可能只是记住不相关的细节<br>培训图像拿出正确的答案。例如，你可以 想象一下，在每张照片背景中记住一个图案的网络 显示，并使用它来匹配标签与对象。它可以产生好的<br>结果在训练期间之前看到的所有图像，但是然后失败 图像，因为它没有学习对象的一般特征，只是 记住训练图像的不重要的细节。</p>
<p>这个问题被称为overfitting，为了避免它，我们保留了一些我们的数据 脱离训练过程，使模型不能记住它们。我们然后使用<br>这些图像作为检查，以确保过度配合不发生，因为如果 我们看到他们很好的准确性，这是一个好的迹象，网络不是过度配合。该<br>通常的分割是将80％的图像放入主训练集中，保持10％ 除了在培训期间经常作为验证运行，然后最终有10％ 作为一个测试集来预测真实世界的性能，使用较少<br>的分类器。这些比例可以使用 <code>--testing_percentage</code>和<code>--validation_percentage</code>标志。一般来说<br>你应该能够将这些值保留在默认值，因为你不会 通常找到任何有利于培训来调整他们。</p>
<p>请注意，该脚本使用图像文件名（而不是一个完全随机的 功能）在训练，验证和测试集之间划分图像。 这样做是为了确保图像不会在训练和测试之间移动<br>设置不同的运行，因为这可能是一个问题，如果图像已经 用于训练模型随后用于验证集合中。</p>
<p>您可能会注意到验证准确性在迭代中波动。许多 这种波动起因于验证随机子集的事实 每个验证准确度测量选择一组。波动可以<br>大大减少了，而以一些训练时间的增加为代价，通过选择 <code>--validation_batch_size=-1</code>，它使用整个验证集 准确性计算。</p>
<p>一旦培训完成，您可能会发现审查错误分类的洞察力 测试集中的图像。这可以通过添加标志来完成<br><code>--print_misclassified_test_images</code>。这可能会帮助你得到一个感觉 图像的类型最容易混淆的模型，以及哪些类别<br>最难区分。例如，你可能会发现一些 特定类别的子类型，或一些不寻常的照片角度 很难确定，这可能会鼓励你添加更多的训练图像<br>那个亚型。通常情况下，检查错误的图像也可以指向 输入数据集中的错误，如错误标记，低质量或含糊不清 图片。但是，通常应该避免在个别错误中加入点<br>测试集，因为它们很可能仅仅反映更为普遍的问题 （更大的）训练集。</p>
<h2><span id="其他模型架构">其他模型架构</span></h2><p>默认情况下，脚本使用Inception v3模型的预训练版本 建筑。这是一个很好的开始，因为它提供了高精度 结果，但如果你打算在移动设备或其他部署你的模型<br>资源受限的环境中，您可能需要权衡一些准确性 对于更小的文件或更快的速度。为了帮助，这个 retrain.py脚本<br>在Mobilenet架构上支持32种不同的变体。</p>
<p>这些比Inception v3精确一点，但可能会导致很多 较小的文件大小（小于一兆字节），可以快很多倍<br>跑步。用这些模型之一进行训练，通过<code>--architecture</code>标志， 例如：</p>
<pre><code>python tensorflow/examples/image_retraining/retrain.py \
    --image_dir ~/flower_photos --architecture mobilenet_0.25_128_quantized
</code></pre><p>这将在<code>/tmp/output_graph.pb</code>中创建一个941KB的模型文件，占25％<br>完整的Mobilenet的参数，采取128x128大小的输入图像，并与 它的权重量化到磁盘上的八位。你可以选择’1.0’，’0.75’，<br>‘0.50’或’0.25’来控制权重参数的数量等等文件 大小（在一定程度上是速度），“224”，“192”，“160”或“128”<br>图像大小，更小的尺寸提供更快的速度，并可选 在最后“_quantized”来指示文件是否应该包含8位或 32位浮点权重。</p>
<p>速度和尺寸的优势当然会损失精度，但对于许多人来说 这个目的并不重要。他们也可以有所抵消，改善 训练数据。例如，扭曲训练使我能够达到80％以上<br>即使使用上述的0.25 / 128 /量化图，花数据集也是精确的。</p>
<p>如果你打算在label_image中使用Mobilenet模型或者你自己的模型 程序，您需要将指定大小的图像转换为<br>将范围浮动到“输入”张量中。通常24位图像在范围内 [0,255]，你必须将它们转换为[-1,1]所预期的浮点范围 型号为<code>(image -
128.)/128.</code>。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/image_recognition/" title="图像识别" itemprop="url">图像识别</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="图像识别">图像识别</span></h1><p>我们的大脑让视觉看起来很容易。人类不需要付出任何努力 分辨一只狮子和一只捷豹，读一个标志，或者辨认一个人的脸。<br>但是，这些实际上是用计算机解决的难题：只有他们 看起来很容易，因为我们的大脑非常善于理解图像。</p>
<p>在过去的几年中，机器学习领域取得了巨大成就 在解决这些难题方面取得进展。特别是，我们已经 发现一种叫做“深”的模式 卷积神经网络<br>可以在硬视觉识别任务上达到合理的性能 - 在某些领域匹配或超过人的表现。</p>
<p>研究人员已经证明了稳定的进展 在计算机视觉中通过验证他们的工作 ImageNet - 计算机视觉的学术基准。 连续的模型继续表现出改进，每次都实现<br>一个新的最新的结果： QuocNet，AlexNet，Inception（GoogLeNet），BN-Inception-v2。<br>Google内部和外部的研究人员已经发表了描述所有内容的论文 这些模型但结果仍难以重现。 我们现在正在通过释放运行图像识别的代码来进行下一步<br>在我们最新的模型上，Inception-v3。</p>
<p>Inception-v3针对ImageNet大型视觉识别挑战进行了培训 使用2012年的数据。这是计算机视觉的标准任务， 模型试图分类整个<br>图像分为1000个类，如“斑马”，“达尔马提亚”和“洗碗机”。 例如，下面是AlexNet对一些图像进行分类的结果：</p>
<p><img src="https://www.tensorflow.org/images/AlexClassification.png" alt=""></p>
<p>为了比较模型，我们检查模型无法预测的频率 正确的答案作为他们的前5个猜测之一 - 被称为“前5的错误率”。<br>AlexNet通过在2012年设置15.3％的前5个错误率来实现 验证数据集;初始（GoogLeNet）达到6.67％; BN-Inception-<br>v2达到4.9％; Inception-v3达到3.46％。</p>
<blockquote>
<p>人类在ImageNet挑战上的表现如何？有一个博客帖子 试图衡量他自己的表现的Andrej Karpathy。他到了 5.1％前5的错误率。</p>
</blockquote>
<p>本教程将教你如何使用Inception-v3。你将学习如何 在Python或C ++中将图像分类为1000个类。我们也将讨论如何<br>从这个模型中提取更高层次的特征，可以重用其他特征 视觉任务。</p>
<p>我们很高兴看到社区将如何使用这个模型。</p>
<h2><span id="与python-api一起使用">与Python API一起使用</span></h2><p><code>classify_image.py</code>从<code>tensorflow.org</code>下载训练有素的型号 当程序第一次运行。你将需要大约200M的可用空间<br>可用在您的硬盘上。</p>
<p>首先克隆GitHub的TensorFlow模型回购。运行以下命令：</p>
<pre><code>cd models/tutorials/image/imagenet
python classify_image.py
</code></pre><p>上述命令将分类提供的一只熊猫的图像。</p>
<p><img src="https://www.tensorflow.org/images/cropped_panda.jpg" alt=""></p>
<p>如果模型正确运行，脚本将产生以下输出：</p>
<pre><code>giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca (score = 0.88493)
indri, indris, Indri indri, Indri brevicaudatus (score = 0.00878)
lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens (score = 0.00317)
custard apple (score = 0.00149)
earthstar (score = 0.00127)
</code></pre><p>如果您想提供其他JPEG图像，可以通过编辑来完成 <code>--image_file</code>的说法。</p>
<blockquote>
<p>如果您将模型数据下载到不同的目录中，您 需要将<code>--model_dir</code>指向所使用的目录。</p>
</blockquote>
<h2><span id="与c-api一起使用">与C ++ API一起使用</span></h2><p>您可以在C ++中运行相同的Inception-v3模型以用于生产 环境。您可以下载包含定义的GraphDef的存档<br>像这样的模型（从TensorFlow的根目录运行 库）：</p>
<pre><code>curl -L &quot;https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz&quot; |
  tar -C tensorflow/examples/label_image/data -xz
</code></pre><p>接下来，我们需要编译C ++二进制文件，其中包含加载和运行图形的代码。 如果你跟着 说明下载TensorFlow的源码安装<br>对于您的平台，您应该可以通过构建示例 从你的shell终端运行这个命令：</p>
<pre><code>bazel build tensorflow/examples/label_image/...
</code></pre><p>这应该创建一个二进制可执行文件，然后可以像这样运行：</p>
<pre><code>bazel-bin/tensorflow/examples/label_image/label_image
</code></pre><p>这使用框架附带的默认示例图像，应该 输出类似这样的东西：</p>
<pre><code>I tensorflow/examples/label_image/main.cc:206] military uniform (653): 0.834306
I tensorflow/examples/label_image/main.cc:206] mortarboard (668): 0.0218692
I tensorflow/examples/label_image/main.cc:206] academic gown (401): 0.0103579
I tensorflow/examples/label_image/main.cc:206] pickelhaube (716): 0.00800814
I tensorflow/examples/label_image/main.cc:206] bulletproof vest (466): 0.00535088
</code></pre><p>在这种情况下，我们使用的默认图像 格雷斯霍珀将军，你可以 看到网络正确识别她身着军装，身高很高 得分为0.8。</p>
<p><img src="https://www.tensorflow.org/images/grace_hopper.jpg" alt=""></p>
<p>接下来，通过提供–image =参数（例如，</p>
<pre><code>bazel-bin/tensorflow/examples/label_image/label_image --image=my_image.png
</code></pre><p>如果你看<code>tensorflow/examples/label_image/main.cc</code> 文件，你可以找到<br>怎么运行的。我们希望这个代码能帮助你将TensorFlow集成到 您自己的应用程序，所以我们将一步一步通过主要功能：</p>
<p>命令行标志控制文件的加载位置，以及输入图像的属性。 该模型预计将得到正方形299x299 RGB图像，所以那些是<code>input_width</code><br>和<code>input_height</code>标志。我们还需要从整数中缩放像素值 在图形操作的浮点值的0到255之间。<br>我们用<code>input_mean</code>和<code>input_std</code>标志来控制缩放比例：我们先减去<br><code>input_mean</code>从每个像素值，然后用<code>input_std</code>分开。</p>
<p>这些值可能看起来有些神奇，但是它们只是被定义的 基于他/她想用作输入图像的原始模型作者 训练。如果你有自己训练过的图表，你只需要<br>调整值以匹配您在训练过程中使用的任何值。</p>
<p>你可以看到它们是如何应用到图像中的 <code>ReadTensorFromImageFile()</code> 功能。</p>
<pre><code>// Given an image file name, read in the data, try to decode it as an image,
// resize it to the requested size, and then scale the values as desired.
Status ReadTensorFromImageFile(string file_name, const int input_height,
                               const int input_width, const float input_mean,
                               const float input_std,
                               std::vector&lt;Tensor&gt;* out_tensors) {
  tensorflow::GraphDefBuilder b;
</code></pre><p>我们首先创建一个<code>GraphDefBuilder</code>，这是一个我们可以使用的对象 指定要运行或加载的模型。</p>
<pre><code>string input_name = &quot;file_reader&quot;;
string output_name = &quot;normalized&quot;;
tensorflow::Node* file_reader =
    tensorflow::ops::ReadFile(tensorflow::ops::Const(file_name, b.opts()),
                              b.opts().WithName(input_name));
</code></pre><p>然后，我们开始为我们想要运行的小模型创建节点 加载，调整大小和缩放像素值，以获得主模型的结果<br>希望成为其投入。我们创建的第一个节点只是一个<code>Const</code>操作，它拥有一个 张量与我们想要加载的图像的文件名称。然后通过了 首先输入到<code>ReadFile</code><br>op。您可能会注意到我们正在通过<code>b.opts()</code>作为最后一个 所有创建函数的参数。参数确保节点被添加到<br>模型定义在<code>GraphDefBuilder</code>中。我们也命名<code>ReadFile</code> 通过拨打<code>WithName()</code>呼叫<code>b.opts()</code>。这给节点一个名字，<br>这是不必要的，因为如果你不这样做，会自动分配一个名字 这样做，但它确实使调试更容易一些。</p>
<pre><code>// Now try to figure out what kind of file it is and decode it.
const int wanted_channels = 3;
tensorflow::Node* image_reader;
if (tensorflow::StringPiece(file_name).ends_with(&quot;.png&quot;)) {
  image_reader = tensorflow::ops::DecodePng(
      file_reader,
      b.opts().WithAttr(&quot;channels&quot;, wanted_channels).WithName(&quot;png_reader&quot;));
} else {
  // Assume if it&apos;s not a PNG then it must be a JPEG.
  image_reader = tensorflow::ops::DecodeJpeg(
      file_reader,
      b.opts().WithAttr(&quot;channels&quot;, wanted_channels).WithName(&quot;jpeg_reader&quot;));
}
// Now cast the image data to float so we can do normal math on it.
tensorflow::Node* float_caster = tensorflow::ops::Cast(
    image_reader, tensorflow::DT_FLOAT, b.opts().WithName(&quot;float_caster&quot;));
// The convention for image ops in TensorFlow is that all images are expected
// to be in batches, so that they&apos;re four-dimensional arrays with indices of
// [batch, height, width, channel]. Because we only have a single image, we
// have to add a batch dimension of 1 to the start with ExpandDims().
tensorflow::Node* dims_expander = tensorflow::ops::ExpandDims(
    float_caster, tensorflow::ops::Const(0, b.opts()), b.opts());
// Bilinearly resize the image to fit the required dimensions.
tensorflow::Node* resized = tensorflow::ops::ResizeBilinear(
    dims_expander, tensorflow::ops::Const({input_height, input_width},
                                          b.opts().WithName(&quot;size&quot;)),
    b.opts());
// Subtract the mean and divide by the scale.
tensorflow::ops::Div(
    tensorflow::ops::Sub(
        resized, tensorflow::ops::Const({input_mean}, b.opts()), b.opts()),
    tensorflow::ops::Const({input_std}, b.opts()),
    b.opts().WithName(output_name));
</code></pre><p>然后，我们继续添加更多的节点，将文件数据解码为图像，来投射 整数转换为浮点值，重新调整它，然后最后运行 对像素值进行减法和除法运算。</p>
<pre><code>// This runs the GraphDef network definition that we&apos;ve just constructed, and
// returns the results in the output tensor.
tensorflow::GraphDef graph;
TF_RETURN_IF_ERROR(b.ToGraphDef(&amp;graph));
</code></pre><p>在这个结尾我们有 存储在b变量中的模型定义，我们将其转化为完整的图形 用<code>ToGraphDef()</code>功能定义。</p>
<pre><code>std::unique_ptr&lt;tensorflow::Session&gt; session(
    tensorflow::NewSession(tensorflow::SessionOptions()));
TF_RETURN_IF_ERROR(session-&gt;Create(graph));
TF_RETURN_IF_ERROR(session-&gt;Run({}, {output_name}, {}, out_tensors));
return Status::OK();
</code></pre><p>然后我们创建一个<code>tf.Session</code> 对象，这是实际运行图形的接口，并运行它， 指定我们想要从哪个节点获得输出，以及在哪里放置 输出数据。</p>
<p>这给了我们一个<code>Tensor</code>对象的矢量，在这种情况下，我们知道只会是一个 单个对象很长。您可以将<code>Tensor</code>视为一个多维数组<br>上下文，它拥有299像素高，299像素宽，3通道图像作为浮点 值。如果你已经在你的产品中有你自己的图像处理框架，那么你 应该可以使用它，只要你应用相同的转换<br>将图像输入主图之前</p>
<p>这是一个在C ++中动态创建一个小型TensorFlow图形的简单例子， 但是对于预先训练的Inception模型，我们希望从中加载更大的定义<br>一份文件。您可以在<code>LoadGraph()</code>功能中看到我们如何做到这一点。</p>
<pre><code>// Reads a model graph definition from disk, and creates a session object you
// can use to run it.
Status LoadGraph(string graph_file_name,
                 std::unique_ptr&lt;tensorflow::Session&gt;* session) {
  tensorflow::GraphDef graph_def;
  Status load_graph_status =
      ReadBinaryProto(tensorflow::Env::Default(), graph_file_name, &amp;graph_def);
  if (!load_graph_status.ok()) {
    return tensorflow::errors::NotFound(&quot;Failed to load compute graph at &apos;&quot;,
                                        graph_file_name, &quot;&apos;&quot;);
  }
</code></pre><p>如果你已经看过图像加载代码，很多的术语应该看起来很熟悉。而不是<br>使用<code>GraphDefBuilder</code>生成一个<code>GraphDef</code>对象，我们加载一个protobuf文件 直接包含<code>GraphDef</code>。</p>
<pre><code>  session-&gt;reset(tensorflow::NewSession(tensorflow::SessionOptions()));
  Status session_create_status = (*session)-&gt;Create(graph_def);
  if (!session_create_status.ok()) {
    return session_create_status;
  }
  return Status::OK();
}
</code></pre><p>然后我们从<code>GraphDef</code>创建一个Session对象 把它传回给调用者，以便以后可以运行它。</p>
<p>除了在这种情况下，<code>GetTopLabels()</code>功能与图像加载非常相似 我们想要运行主图的结果，并把它变成一个排序列表<br>的得分最高的标签。就像图像加载器一样，它创建一个 <code>GraphDefBuilder</code>，增加了一些节点，然后运行短图得到一个<br>输出张量对。在这种情况下，他们代表排序的分数和指数 最高的结果的位置。</p>
<pre><code>// Analyzes the output of the Inception graph to retrieve the highest scores and
// their positions in the tensor, which correspond to categories.
Status GetTopLabels(const std::vector&lt;Tensor&gt;&amp; outputs, int how_many_labels,
                    Tensor* indices, Tensor* scores) {
  tensorflow::GraphDefBuilder b;
  string output_name = &quot;top_k&quot;;
  tensorflow::ops::TopK(tensorflow::ops::Const(outputs[0], b.opts()),
                        how_many_labels, b.opts().WithName(output_name));
  // This runs the GraphDef network definition that we&apos;ve just constructed, and
  // returns the results in the output tensors.
  tensorflow::GraphDef graph;
  TF_RETURN_IF_ERROR(b.ToGraphDef(&amp;graph));
  std::unique_ptr&lt;tensorflow::Session&gt; session(
      tensorflow::NewSession(tensorflow::SessionOptions()));
  TF_RETURN_IF_ERROR(session-&gt;Create(graph));
  // The TopK node returns two outputs, the scores and their original indices,
  // so we have to append :0 and :1 to specify them both.
  std::vector&lt;Tensor&gt; out_tensors;
  TF_RETURN_IF_ERROR(session-&gt;Run({}, {output_name + &quot;:0&quot;, output_name + &quot;:1&quot;},
                                  {}, &amp;out_tensors));
  *scores = out_tensors[0];
  *indices = out_tensors[1];
  return Status::OK();
</code></pre><p><code>PrintTopLabels()</code>功能将这些分类结果打印出来并打印出来 友好的方式。 <code>CheckTopLabel()</code>功能非常相似，但只是确保<br>为了调试目的，最高标签是我们期望的。</p>
<p>最后，<code>main()</code> 把所有这些电话联系在一起。</p>
<pre><code>int main(int argc, char* argv[]) {
  // We need to call this to set up global state for TensorFlow.
  tensorflow::port::InitMain(argv[0], &amp;argc, &amp;argv);
  Status s = tensorflow::ParseCommandLineFlags(&amp;argc, argv);
  if (!s.ok()) {
    LOG(ERROR) &lt;&lt; &quot;Error parsing command line flags: &quot; &lt;&lt; s.ToString();
    return -1;
  }

  // First we load and initialize the model.
  std::unique_ptr&lt;tensorflow::Session&gt; session;
  string graph_path = tensorflow::io::JoinPath(FLAGS_root_dir, FLAGS_graph);
  Status load_graph_status = LoadGraph(graph_path, &amp;session);
  if (!load_graph_status.ok()) {
    LOG(ERROR) &lt;&lt; load_graph_status;
    return -1;
  }
</code></pre><p>我们加载主图。</p>
<pre><code>// Get the image from disk as a float array of numbers, resized and normalized
// to the specifications the main graph expects.
std::vector&lt;Tensor&gt; resized_tensors;
string image_path = tensorflow::io::JoinPath(FLAGS_root_dir, FLAGS_image);
Status read_tensor_status = ReadTensorFromImageFile(
    image_path, FLAGS_input_height, FLAGS_input_width, FLAGS_input_mean,
    FLAGS_input_std, &amp;resized_tensors);
if (!read_tensor_status.ok()) {
  LOG(ERROR) &lt;&lt; read_tensor_status;
  return -1;
}
const Tensor&amp; resized_tensor = resized_tensors[0];
</code></pre><p>加载，调整大小和处理输入图像。</p>
<pre><code>// Actually run the image through the model.
std::vector&lt;Tensor&gt; outputs;
Status run_status = session-&gt;Run({ {FLAGS_input_layer, resized_tensor}},
                                 {FLAGS_output_layer}, {}, &amp;outputs);
if (!run_status.ok()) {
  LOG(ERROR) &lt;&lt; &quot;Running model failed: &quot; &lt;&lt; run_status;
  return -1;
}
</code></pre><p>在这里，我们运行加载的图形作为输入图像。</p>
<pre><code>// This is for automated testing to make sure we get the expected result with
// the default settings. We know that label 866 (military uniform) should be
// the top label for the Admiral Hopper image.
if (FLAGS_self_test) {
  bool expected_matches;
  Status check_status = CheckTopLabel(outputs, 866, &amp;expected_matches);
  if (!check_status.ok()) {
    LOG(ERROR) &lt;&lt; &quot;Running check failed: &quot; &lt;&lt; check_status;
    return -1;
  }
  if (!expected_matches) {
    LOG(ERROR) &lt;&lt; &quot;Self-test failed!&quot;;
    return -1;
  }
}
</code></pre><p>出于测试目的，我们可以检查以确保我们得到我们期望的输出。</p>
<pre><code>// Do something interesting with the results we&apos;ve generated.
Status print_status = PrintTopLabels(outputs, FLAGS_labels);
</code></pre><p>最后我们打印我们找到的标签。</p>
<pre><code>if (!print_status.ok()) {
  LOG(ERROR) &lt;&lt; &quot;Running print failed: &quot; &lt;&lt; print_status;
  return -1;
}
</code></pre><p>这里的错误处理是使用TensorFlow的<code>Status</code> 对象，这是非常方便的，因为它让你知道是否有任何错误<br>与<code>ok()</code>检查器一起发生，然后可以打印出来以提供可读的错误 信息。</p>
<p>在这种情况下，我们正在展示对象识别，但你应该能够 在自己找到或训练过的其他模型上使用非常类似的代码 所有<br>种类的域名。我们希望这个小例子给你一些关于如何使用的想法 您自己的产品中的TensorFlow。</p>
<blockquote>
<p>练习：转移学习是一个想法，如果你知道如何解决一个好的任务，你 应该能够把一些理解转移到解决相关的问题 问题。执行转移学习的一种方法是删除最终的<br>网络的分类层和提取 CNN的倒数第二层，在这种情况下是2048维向量。 在how-to部分有一个指导。</p>
</blockquote>
<h2><span id="学习更多的资源">学习更多的资源</span></h2><p>一般来说，要学习神经网络，Michael Nielsen的 免费在线书 是一个很好的资源。对于卷积神经网络来说， 克里斯·奥拉有一些 漂亮的博客文章，<br>而Michael Nielsen的书有一个 伟大的篇章 覆盖他们。</p>
<p>要了解有关执行卷积神经网络的更多信息，可以跳转 到TensorFlow深度卷积网络教程， 或者用我们的轻轻一点开始 ML初学者或ML专家<br>MNIST初学者教程。最后，如果你想加快研究速度 在这方面，你可以 阅读本教程中引用的所有论文的最新工作。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/linear/" title="具有张量流的大规模线性模型" itemprop="url">具有张量流的大规模线性模型</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="具有张量流的大规模线性模型">具有张量流的大规模线性模型</span></h1><p>tf.estimator API为其提供了一套丰富的工具 在TensorFlow中使用线性模型。本文件提供了一个概述 那些工具。它解释说：</p>
<p>线性模型是什么。 为什么你可能想要使用线性模型。 tf.estimator如何使TensorFlow中的线性模型变得容易。<br>如何使用tf.estimator将线性模型与    深入学习以获得双方的优势。</p>
<p>阅读本概述以确定tf.estimator线性模型工具是否可能 对你有用。然后做线性模型教程 试一试。这个概述使用了教程中的代码示例，但是<br>教程更详细地介绍代码。</p>
<p>要理解这个概述，这将有助于一些熟悉 有基本的机器学习概念，还有tf.estimator。</p>
<h2><span id="什么是线性模型">什么是线性模型？</span></h2><p>线性模型使用单个加权和特征进行预测。 例如，如果你有数据 年龄，受教育年限和每周小时数 为一个人口工作，你可以学习每个这样的数字的权重<br>他们的加权总和估计一个人的工资。您也可以使用线性模型 进行分类。</p>
<p>一些线性模型将加权和转换成更方便的形式。对于 例如，逻辑回归将加权和插入逻辑 函数将输出转换为介于0和1之间的值。但是你仍然只是 每个输入特征都有一个权重。</p>
<h2><span id="你为什么要使用线性模型">你为什么要使用线性模型？</span></h2><p>为什么你要在最近的研究中使用这么简单的模型？ 展示了更复杂的多层神经网络的力量？</p>
<p>线性模型：</p>
<p>训练很快，比较深的神经网络。 可以在非常大的功能集上运行良好。 可以用不需要太多摆弄的算法来训练    学习率等 可以比神经网络更容易地解释和调试。<br>您可以检查分配给每个功能的权重来确定是什么    对预测影响最大。 为学习机器学习提供了一个很好的起点。 在工业中被广泛使用。</p>
<h2><span id="tfestimator如何帮助您构建线性模型">tf.estimator如何帮助您构建线性模型？</span></h2><p>您可以在TensorFlow中从头开始构建一个线性模型，而无需借助 特殊的API。但是tf.estimator提供了一些工具，使它更容易构建<br>有效的大型线性模型。</p>
<h3><span id="功能列和转换">功能列和转换</span></h3><p>设计线性模型的大部分工作都是转换原始数据 到合适的输入功能。 Tensorflow使用<code>FeatureColumn</code>抽象 启用这些转换。</p>
<p><code>FeatureColumn</code>代表数据中的单一功能。 <code>FeatureColumn</code> 可能代表像“高度”这样的数量，也可能代表类似的数量<br>‘eye_color’其中值是从一组离散的可能性中绘制的 {‘蓝色’，’棕色’，’绿色’}。</p>
<p>在“高度”和“分类”等连续特征的情况下 诸如“eye_color”之类的特征，数据中的单个值可能会被转换 在输入到模型中之前将其转换为数字序列。该<br><code>FeatureColumn</code>抽象允许您将该功能作为一个单独的操作 尽管如此，语义单位。你可以指定转换和 选择要包含的特征而不处理特定的索引<br>张量你喂入模型。</p>
<h4><span id="稀疏的列">稀疏的列</span></h4><p>线性模型中的分类特征通常会转换为稀疏分类 矢量，其中每个可能的值具有对应的索引或id。对于 例如，如果只有三种可能的眼睛颜色，您可以表示<br>‘eye_color’作为长度为3的矢量：’brown’会变成[1,0,0]，’blue’会变成<br>变成[0,1,0]，“绿色”变成[0,0,1]。这些载体被调用 “稀疏”，因为它们可能很长，有很多的零时，集合 可能的值非常大（比如所有的英文单词）。</p>
<p>虽然你不需要使用分类列来使用tf.estimator linear 模型，线性模型的优势之一就是他们处理的能力 大的稀疏矢量。稀疏特征是一个主要的用例<br>tf.estimator线性模型工具。</p>
<h5><span id="编码稀疏列">编码稀疏列</span></h5><p><code>FeatureColumn</code>处理分类值向量的转换 自动，与这样的代码：</p>
<pre><code>eye_color = tf.feature_column.categorical_column_with_vocabulary_list(
    &quot;eye_color&quot;, vocabulary_list=[&quot;blue&quot;, &quot;brown&quot;, &quot;green&quot;])
</code></pre><p>其中<code>eye_color</code>是源数据中列的名称。</p>
<p>您也可以生成<code>FeatureColumn</code>作为您的分类功能 不知道所有可能的价值。对于这种情况下，你会使用<br><code>categorical_column_with_hash_bucket()</code>，它使用散列函数来分配 指标的特征值。</p>
<pre><code>education = tf.feature_column.categorical_column_with_hash_bucket(
    &quot;education&quot;, hash_bucket_size=1000)
</code></pre><h5><span id="特色十字架">特色十字架</span></h5><p>因为线性模型分配独立的权重分离功能，他们 不能学习特定组合的相对重要性<br>值。如果你有一个功能’favorite_sport’和一个功能’home_city’和 你正在试图预测一个人是否喜欢穿红色，你的线性模型<br>将无法从圣路易斯学习棒球迷特别喜欢 穿红色。</p>
<p>您可以通过创建一个新功能来解决这个限制 ‘favorite_sport_x_home_city’。这个特性对于一个给定的人的价值是 只是两个源特征值的连接：<br>例如，’baseball_x_stlouis’。这种组合功能被称为 一个功能十字架。</p>
<p><code>crossed_column()</code>方法可以轻松设置特征十字：</p>
<pre><code>sport_x_city = tf.feature_column.crossed_column(
    [&quot;sport&quot;, &quot;city&quot;], hash_bucket_size=int(1e4))
</code></pre><h4><span id="连续的列">连续的列</span></h4><p>您可以像这样指定一个连续的功能：</p>
<pre><code>age = tf.feature_column.numeric_column(&quot;age&quot;)
</code></pre><p>虽然作为一个单一的实数，通常可以输入一个连续的特征 直接进入模型，Tensorflow为这种类型提供了有用的转换 的列也是如此。</p>
<h5><span id="桶化">桶化</span></h5><p>分行化将连续的列变成分类列。这个 转换可以让你在特征十字中使用连续的特征，或者学习 具体价值范围特别重要的案例。</p>
<p>分行化将可能值的范围划分为子范围 水桶：</p>
<pre><code>age_buckets = tf.feature_column.bucketized_column(
    age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])
</code></pre><p>值落入的桶成为分类标签 那个价值。</p>
<h4><span id="输入功能">输入功能</span></h4><p><code>FeatureColumn</code>为您的模型输入数据提供了一个规范， 指示如何表示和转换数据。但他们不提供 数据本身。您通过输入功能提供数据。</p>
<p>输入函数必须返回张量字典。每个键对应于 <code>FeatureColumn</code>的名称。每个键的值是一个张量包含的 所有数据实例的该功能的值。看到<br>使用tf.estimator为输入构建输入函数 更全面的看输入功能，和<code>input_fn</code>中 线性模型教程代码 作为输入函数的示例实现。</p>
<p>输入功能被传递给<code>train()</code>和<code>evaluate()</code>呼叫 开始培训和测试，如下一节所述。</p>
<h3><span id="线性估计器">线性估计器</span></h3><p>Tensorflow估算器类提供统一的培训和评估工具 用于回归和分类模型。他们照顾的细节 训练和评估循环，并允许用户专注于模型输入和 建筑。</p>
<p>要建立一个线性估计器，你可以使用 <code>tf.estimator.LinearClassifier</code>估算器或<br><code>tf.estimator.LinearRegressor</code>估算器，用于分类和 回归分别。</p>
<p>与所有张量流估计器一样，运行估算器只需要：</p>
<p>实例化估计器类。对于两个线性估计器类，    您将<code>FeatureColumn</code>的列表传递给构造函数。 调用估算器的<code>train()</code>方法进行训练。<br>调用估算器的<code>evaluate()</code>方法来看看它是如何工作的。</p>
<p>例如：</p>
<pre><code>e = tf.estimator.LinearClassifier(
    feature_columns=[
        native_country, education, occupation, workclass, marital_status,
        race, age_buckets, education_x_occupation,
        age_buckets_x_race_x_occupation],
    model_dir=YOUR_MODEL_DIRECTORY)
e.train(input_fn=input_fn_train, steps=200)
# Evaluate for one step (one pass through the test data).
results = e.evaluate(input_fn=input_fn_test)

# Print the stats for the evaluation.
for key in sorted(results):
    print(&quot;%s: %s&quot; % (key, results[key]))
</code></pre><h3><span id="广泛深入的学习">广泛深入的学习</span></h3><p>tf.estimator API还提供了一个可以联合使用的估计器类 训练线性模型和深度神经网络。这种新颖的方法结合了 线性模型用泛化“记忆”关键特征的能力<br>神经网络的能力。使用<code>tf.estimator.DNNLinearCombinedClassifier</code>来 创造这种“宽而深”的模式：</p>
<pre><code>e = tf.estimator.DNNLinearCombinedClassifier(
    model_dir=YOUR_MODEL_DIR,
    linear_feature_columns=wide_columns,
    dnn_feature_columns=deep_columns,
    dnn_hidden_units=[100, 50])
</code></pre><p>有关更多信息，请参阅广泛深入学习教程。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/wide/" title="TensorFlow线性模型教程" itemprop="url">TensorFlow线性模型教程</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="tensorflow线性模型教程">TensorFlow线性模型教程</span></h1><p>在本教程中，我们将使用TensorFlow中的tf.estimator API来解决这个问题 二元分类问题：给定一个人的普查数据，如年龄，<br>教育程度，婚姻状况和职业（特征），我们将尝试预测 无论这个人一年挣多5万美元（目标） 标签）。我们将训练逻辑回归模型，并给予个人的<br>我们的模型的信息将输出一个介于0和1之间的数字，这可以是 解释为个人年收入超过的概率 5万美元</p>
<h2><span id="建立">建立</span></h2><p>要尝试本教程的代码：</p>
<p>如果你还没有安装TensorFlow， 下载教程代码。 执行我们提供给您的数据下载脚本： $ python data_download.py<br>使用以下命令执行教程代码以训练线性 模型在本教程中描述： $ python wide_deep.py –model_type = wide</p>
<p>继续阅读以了解此代码如何构建其线性模型。</p>
<h2><span id="读取人口普查数据">读取人口普查数据</span></h2><p>我们将使用的数据集是 人口普查收入数据集。 我们提供了 data_download.py 下载代码并执行一些额外的清理。</p>
<p>由于任务是一个二元分类问题，我们将构造一个标签 列名为“标签”，如果收入超过5万，则为1 除此以外。有关参考，请参阅<code>input_fn</code><br>wide_deep.py。</p>
<p>接下来，我们来看看数据框，看看我们可以使用哪些列 预测目标标签。这些列可以分为两类 - 分类 和连续的列：</p>
<p>如果一个列的值只能是其中的一个，则该列被称为分类     有限集合中的类别。例如，一个人的关系状态     （妻子，丈夫，未婚等）或教育水平（高中，<br>大学等）是分类专栏。 如果某列的值可以是任何数值，则称该列为连续的     一个连续的范围。例如，一个人的资本收益（例如$ 14,084）<br>是一个连续的列。</p>
<p>以下是人口普查收入数据集中可用列的列表：</p>
<table>
<thead>
<tr>
<th>Column Name</th>
<th>Type</th>
<th>Description  </th>
</tr>
</thead>
<tbody>
<tr>
<td>age</td>
<td>Continuous</td>
<td>The age of the individual  </td>
</tr>
<tr>
<td>workclass</td>
<td>Categorical</td>
<td>The type of employer the individual has (government,</td>
</tr>
</tbody>
</table>
<p>military, private, etc.).<br>fnlwgt | Continuous | The number of people the census takers believe that<br>observation represents (sample weight). Final weight will not be used.<br>education | Categorical | The highest level of education achieved for that<br>individual.<br>education_num | Continuous | The highest level of education in numerical form.<br>marital_status | Categorical | Marital status of the individual.<br>occupation | Categorical | The occupation of the individual.<br>relationship | Categorical | Wife, Own-child, Husband, Not-in-family, Other-<br>relative, Unmarried.<br>race | Categorical | White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other,<br>Black.<br>gender | Categorical | Female, Male.<br>capital_gain | Continuous | Capital gains recorded.<br>capital_loss | Continuous | Capital Losses recorded.<br>hours_per_week | Continuous | Hours worked per week.<br>native_country | Categorical | Country of origin of the individual.<br>income | Categorical | “&gt;50K” or “&lt;=50K”, meaning whether the person makes<br>more than $50,000 annually.  </p>
<h2><span id="将数据转换为张量">将数据转换为张量</span></h2><p>在建立一个tf.estimator模型时，输入数据是通过一个 输入生成器功能。这个构建函数直到它才会被调用<br>后来传递给tf.estimator.Estimator方法，如<code>train</code>和<code>evaluate</code>。 这个功能的目的是构建输入数据，这是<br>以<code>tf.Tensor</code>或<code>tf.SparseTensor</code>的形式表示。 更详细地说，输入生成器函数将成对返回以下内容：</p>
<p><code>features</code>：从特征列名到<code>Tensors</code>的字典或     <code>SparseTensors</code>。 <code>labels</code>：含有标签柱的<code>Tensor</code>。</p>
<p><code>features</code>的键将用于构建下一个列 部分。因为我们想用<code>train</code>和<code>evaluate</code>方法来调用<br>不同的数据，我们定义一个方法返回一个输入函数的基础上 给出的数据。请注意，返回的输入函数将被调用 构建TensorFlow图，而不是在运行图时。这是什么<br>返回是输入数据表示的基本单位 TensorFlow计算，<code>Tensor</code>（或<code>SparseTensor</code>）。</p>
<p>列车中的每个连续列或测试数据将被转换成一个 <code>Tensor</code>，它通常是一种很好的格式来表示密集的数据。对于<br>分类数据，我们必须将数据表示为<code>SparseTensor</code>。这个数据 格式适合表示稀疏数据。我们的<code>input_fn</code>使用<code>tf.data</code><br>API，可以很容易地将转换应用于我们的数据集：</p>
<pre><code>def input_fn(data_file, num_epochs, shuffle, batch_size):
  &quot;&quot;&quot;Generate an input function for the Estimator.&quot;&quot;&quot;
  assert tf.gfile.Exists(data_file), (
      &apos;%s not found. Please make sure you have either run data_download.py or &apos;
      &apos;set both arguments --train_data and --test_data.&apos; % data_file)

  def parse_csv(value):
    print(&apos;Parsing&apos;, data_file)
    columns = tf.decode_csv(value, record_defaults=_CSV_COLUMN_DEFAULTS)
    features = dict(zip(_CSV_COLUMNS, columns))
    labels = features.pop(&apos;income_bracket&apos;)
    return features, tf.equal(labels, &apos;&gt;50K&apos;)

  # Extract lines from input files using the Dataset API.
  dataset = tf.data.TextLineDataset(data_file)

  if shuffle:
    dataset = dataset.shuffle(buffer_size=_SHUFFLE_BUFFER)

  dataset = dataset.map(parse_csv, num_parallel_calls=5)

  # We call repeat after shuffling, rather than before, to prevent separate
  # epochs from blending together.
  dataset = dataset.repeat(num_epochs)
  dataset = dataset.batch(batch_size)

  iterator = dataset.make_one_shot_iterator()
  features, labels = iterator.get_next()
  return features, labels
</code></pre><h2><span id="模型的选择和工程特性">模型的选择和工程特性</span></h2><p>选择和制作正确的特征列是学习的关键 有效的模式。一个特征列可以是其中的一个原始列 原始数据框（我们称之为基本特征列）或任何新的<br>基于在一个或多个基础上定义的一些转换创建的列 列（我们称之为派生特征列）。基本上“功能 列“是任何可以使用的原始或衍生变量的抽象概念 预测目标标签。</p>
<h3><span id="基本分类特征列">基本分类特征列</span></h3><p>要为分类特征定义特征列，我们可以创建一个 <code>CategoricalColumn</code>使用tf.feature_column API。如果你知道所有的集合<br>一个列的可能的特征值，只有其中的几个，你可以 使用<code>categorical_column_with_vocabulary_list</code>。列表中的每个键都会得到<br>分配从0开始的自动增量ID。例如，对于 <code>relationship</code>栏可以将特征字符串“丈夫”分配给一个整数 ID为0，“不在家”为1等，做法是：</p>
<pre><code>relationship = tf.feature_column.categorical_column_with_vocabulary_list(
    &apos;relationship&apos;, [
        &apos;Husband&apos;, &apos;Not-in-family&apos;, &apos;Wife&apos;, &apos;Own-child&apos;, &apos;Unmarried&apos;,
        &apos;Other-relative&apos;])
</code></pre><p>如果我们事先不知道可能的价值观呢？不是问题。我们 可以用<code>categorical_column_with_hash_bucket</code>代替：</p>
<pre><code>occupation = tf.feature_column.categorical_column_with_hash_bucket(
    &apos;occupation&apos;, hash_bucket_size=1000)
</code></pre><p><code>occupation</code>功能列中的每个可能的值将会发生什么 当我们在训练中遇到它们时将被散列为整数ID。看一个例子 插图如下：</p>
<table>
<thead>
<tr>
<th>ID</th>
<th>Feature  </th>
</tr>
</thead>
<tbody>
<tr>
<td>…</td>
<td></td>
</tr>
<tr>
<td>9</td>
<td><code>&quot;Machine-op-inspct&quot;</code>  </td>
</tr>
<tr>
<td>…</td>
<td></td>
</tr>
<tr>
<td>103</td>
<td><code>&quot;Farming-fishing&quot;</code>  </td>
</tr>
<tr>
<td>…</td>
<td></td>
</tr>
<tr>
<td>375</td>
<td><code>&quot;Protective-serv&quot;</code>  </td>
</tr>
<tr>
<td>…</td>
<td></td>
</tr>
</tbody>
</table>
<p>无论我们选择哪一种方式来定义<code>SparseColumn</code>，每个功能字符串 将通过查找一个固定的映射或散列来映射到一个整数ID。<br>请注意，散列冲突是可能的，但可能不会显着影响 模型质量。 <code>LinearModel</code>课程负责人 管理映射并创建<code>tf.Variable</code>来存储模型参数<br>（也称为模型权重）为每个功能ID。模型参数将是 通过模型培训过程了解到，我们稍后会经历。</p>
<p>我们将做类似的技巧来定义其他的分类特征：</p>
<pre><code>education = tf.feature_column.categorical_column_with_vocabulary_list(
    &apos;education&apos;, [
        &apos;Bachelors&apos;, &apos;HS-grad&apos;, &apos;11th&apos;, &apos;Masters&apos;, &apos;9th&apos;, &apos;Some-college&apos;,
        &apos;Assoc-acdm&apos;, &apos;Assoc-voc&apos;, &apos;7th-8th&apos;, &apos;Doctorate&apos;, &apos;Prof-school&apos;,
        &apos;5th-6th&apos;, &apos;10th&apos;, &apos;1st-4th&apos;, &apos;Preschool&apos;, &apos;12th&apos;])

marital_status = tf.feature_column.categorical_column_with_vocabulary_list(
    &apos;marital_status&apos;, [
        &apos;Married-civ-spouse&apos;, &apos;Divorced&apos;, &apos;Married-spouse-absent&apos;,
        &apos;Never-married&apos;, &apos;Separated&apos;, &apos;Married-AF-spouse&apos;, &apos;Widowed&apos;])

relationship = tf.feature_column.categorical_column_with_vocabulary_list(
    &apos;relationship&apos;, [
        &apos;Husband&apos;, &apos;Not-in-family&apos;, &apos;Wife&apos;, &apos;Own-child&apos;, &apos;Unmarried&apos;,
        &apos;Other-relative&apos;])

workclass = tf.feature_column.categorical_column_with_vocabulary_list(
    &apos;workclass&apos;, [
        &apos;Self-emp-not-inc&apos;, &apos;Private&apos;, &apos;State-gov&apos;, &apos;Federal-gov&apos;,
        &apos;Local-gov&apos;, &apos;?&apos;, &apos;Self-emp-inc&apos;, &apos;Without-pay&apos;, &apos;Never-worked&apos;])

# To show an example of hashing:
occupation = tf.feature_column.categorical_column_with_hash_bucket(
    &apos;occupation&apos;, hash_bucket_size=1000)
</code></pre><h3><span id="基本连续功能列">基本连续功能列</span></h3><p>同样，我们可以为每个连续特征列定义一个<code>NumericColumn</code> 我们想在模型中使用：</p>
<pre><code>age = tf.feature_column.numeric_column(&apos;age&apos;)
education_num = tf.feature_column.numeric_column(&apos;education_num&apos;)
capital_gain = tf.feature_column.numeric_column(&apos;capital_gain&apos;)
capital_loss = tf.feature_column.numeric_column(&apos;capital_loss&apos;)
hours_per_week = tf.feature_column.numeric_column(&apos;hours_per_week&apos;)
</code></pre><h3><span id="通过分解实现连续性特征的分类">通过分解实现连续性特征的分类</span></h3><p>有时连续特征和标签之间的关系不是 线性的。作为一个假设的例子，一个人的收入可能随着年龄的增长而增长 事业的早期阶段，那么增长速度可能会放慢，最后<br>退休后收入减少。在这种情况下，使用原始的<code>age</code>作为 一个实值特征列可能不是一个好的选择，因为该模型可以 只学习三种情况之一：</p>
<p>收入总是随着年龄增长而增长（正相关）， 收入总是随着年龄的增长而减少（负相关），或者 不论年龄多少，收入都保持不变（不相关）</p>
<p>如果我们想要学习收入与各个年龄之间的细微关联， 分组分组，可以利用分期付款。巴克化是一个过程 将连续特征的整个范围划分为一组连续的特征<br>箱/桶，然后将原始数字特征转换成桶 ID（作为分类特征），取决于该值落入哪个桶。<br>因此，我们可以通过<code>bucketized_column</code>定义<code>age</code>，如下所示：</p>
<pre><code>age_buckets = tf.feature_column.bucketized_column(
    age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])
</code></pre><p>其中<code>boundaries</code>是一个桶边界列表。在这种情况下，有 10个界限，导致11个年龄段桶（从17岁以下，18-24岁，<br>25-29，…，65以上）。</p>
<h3><span id="用crossedcolumn交叉多列">用CrossedColumn交叉多列</span></h3><p>单独使用每个基本特征列可能不足以解释数据。 例如，教育与标签之间的相关性（收入&gt; 50,000美元）<br>美元）可能会因不同的职业而有所不同。因此，如果我们只学习<br><code>education=&quot;Bachelors&quot;</code>和<code>education=&quot;Masters&quot;</code>的单一型号重量，我们 将无法捕获每一个教育职业组合（例如，<br>区分<code>education=&quot;Bachelors&quot; AND occupation=&quot;Exec-managerial&quot;</code><br>和<code>education=&quot;Bachelors&quot; AND occupation=&quot;Craft-repair&quot;</code>）。要学习<br>不同的功能组合之间的差异，我们可以添加交叉功能 模型列。</p>
<pre><code>education_x_occupation = tf.feature_column.crossed_column(
    [&apos;education&apos;, &apos;occupation&apos;], hash_bucket_size=1000)
</code></pre><p>我们也可以创建一个超过两列的<code>CrossedColumn</code>。每 组成列可以是分类的基础特征列<br>（<code>SparseColumn</code>），一个bucketized实值特征列（<code>BucketizedColumn</code>），<br>甚至另一台<code>CrossColumn</code>。这是一个例子：</p>
<pre><code>age_buckets_x_education_x_occupation = tf.feature_column.crossed_column(
    [age_buckets, &apos;education&apos;, &apos;occupation&apos;], hash_bucket_size=1000)
</code></pre><h2><span id="定义logistic回归模型">定义Logistic回归模型</span></h2><p>处理完输入数据并定义所有的特征列后，我们现在就完成了 准备把它们放在一起，建立一个Logistic回归模型。在里面<br>在上一节中，我们已经看到几种类型的基础和派生特征列， 包含：</p>
<p><code>CategoricalColumn</code> <code>NumericColumn</code> <code>BucketizedColumn</code> <code>CrossedColumn</code></p>
<p>所有这些都是抽象的<code>FeatureColumn</code>类的子类，可以是 添加到模型的<code>feature_columns</code>领域：</p>
<pre><code>base_columns = [
    education, marital_status, relationship, workclass, occupation,
    age_buckets,
]
crossed_columns = [
    tf.feature_column.crossed_column(
        [&apos;education&apos;, &apos;occupation&apos;], hash_bucket_size=1000),
    tf.feature_column.crossed_column(
        [age_buckets, &apos;education&apos;, &apos;occupation&apos;], hash_bucket_size=1000),
]

model_dir = tempfile.mkdtemp()
model = tf.estimator.LinearClassifier(
    model_dir=model_dir, feature_columns=base_columns + crossed_columns)
</code></pre><p>该模型还自动学习控制预测的偏差项 人们可以在不观察任何特征的情况下（参见“如何物流” 回归工程“以获得更多解释），学习的模型文件将被存储<br>在<code>model_dir</code>中。</p>
<h2><span id="培训和评估我们的模型">培训和评估我们的模型</span></h2><p>将所有的功能添加到模型后，现在让我们看看如何实际 训练模型。训练一个模型只是一个单一的命令使用 tf.estimator API：</p>
<pre><code>model.train(input_fn=lambda: input_fn(train_data, num_epochs, True, batch_size))
</code></pre><p>在模型被训练之后，我们可以评估我们的模型在预测方面有多好 坚持数据的标签：</p>
<pre><code>results = model.evaluate(input_fn=lambda: input_fn(
    test_data, 1, False, batch_size))
for key in sorted(results):
  print(&apos;%s: %s&apos; % (key, results[key]))
</code></pre><p>最终输出的第一行应该是这样的 <code>accuracy: 0.83557522</code>，表示准确率为83.6％。随意尝试更多 功能和转换，看看你能做得更好！</p>
<p>如果你想看到一个工作的端到端的例子，你可以下载我们的 示例代码 并将<code>model_type</code>标志设置为<code>wide</code>。</p>
<h2><span id="加入正则化来防止过度拟合">加入正则化来防止过度拟合</span></h2><p>正规化是一种避免过度拟合的技术。过度配合发生 当你的模型在训练的数据上表现良好，但在测试数据上更糟糕 这个模型以前没有见过，比如现场交通。过度配合一般<br>当模型过于复杂，如参数太多时会发生 相对于观察到的训练数据的数量。正规化允许你 控制你的模型的复杂性，使模型更一般化 看不见的数据。</p>
<p>在线性模型库中，可以将L1和L2正则化添加到模型中 如：</p>
<pre><code>model = tf.estimator.LinearClassifier(
    model_dir=model_dir, feature_columns=base_columns + crossed_columns,
    optimizer=tf.train.FtrlOptimizer(
        learning_rate=0.1,
        l1_regularization_strength=1.0,
        l2_regularization_strength=1.0))
</code></pre><p>L1和L2正则化之间的一个重要区别是L1 正则化倾向于使模型权重保持为零，创造更稀疏 模型，而L2正则化也试图使模型权重更接近<br>零但不一定是零。所以，如果你增加L1的实力 正规化，因为许多模型，你将有一个更小的模型大小 权重将为零。当特征空间非常大时，这通常是可取的<br>大但稀疏，当有资源限制，阻止你 为一个太大的模型提供服务。</p>
<p>在实践中，你应该尝试L1，L2正则化的各种组合 优势，并找到最好的控制过度和给予的最佳参数 你一个理想的模型大小。</p>
<h2><span id="逻辑回归如何工作">逻辑回归如何工作</span></h2><p>最后，让我们花一点时间来谈谈什么是Logistic回归模型 实际上看起来像你不熟悉它。我们会表示 标签为\（Y \），观察特征集为特征向量 \（\<br>mathbf {x} = [x_1，x_2，…，x_d] \）。我们定义\（Y = 1 \）如果一个人 赚取了5万美元以及\（Y = 0<br>\）。在Logistic回归中， 给定特征的标签为正（\（Y = 1 \））的概率 \（\ mathbf {x} \）给出如下：</p>
<p>$$ P(Y=1|\mathbf{x}) = \frac{1}{1+\exp(-(\mathbf{w}^T\mathbf{x}+b))}$$</p>
<p>其中\（\ mathbf {w} = [w_1，w_2，…，w_d] \）是 features \（\ mathbf {x} =<br>[x_1，x_2，…，x_d] \）。 \（b \）是一个常数 通常被称为模型的偏见。等式由两部分组成 线性模型和逻辑函数：</p>
<p>线性模型：首先，我们可以看到\（\ mathbf {w} ^ T \ mathbf {x} + b = b +     w_1x_1 + … +<br>w_dx_d \）是输出为线性的线性模型     输入要素的函数\（\ mathbf {x} \）。偏见\（b \）是<br>人们可以预测，而不会观察任何特征。模型重量     \（w_i \）反映特征\（x_i \）如何与正相关     标签。如果\（x_i<br>\）与正向标签正相关，那么     重量\（w_i \）增加，概率\（P（Y = 1 | \ mathbf {x}）\）将<br>接近1.另一方面，如果\（x_i \）是负相关的     与正面的标签，那么体重\（w_i \）减少和     概率\（P（Y = 1 | \ mathbf<br>{x}）\）将接近于0。 逻辑函数：其次，我们可以看到有一个逻辑函数     （也称为S形函数）\（S（t）= 1 /（1+ \ exp（-t））\）是<br>应用于线性模型。逻辑功能是用来转换的     从任何实数的线性模型输出（\ mathbf {w} ^ T \ mathbf {x} + b \）<br>数字放到\（[0，1] \）的范围内，可以解释为a     可能性。</p>
<p>模型训练是一个优化问题：目标是找到一组模型 权重（即模型参数）最小化定义的损失函数 训练数据，如逻辑回归模型的逻辑损失。亏损<br>函数测量地面实况标签和模型之间的差异 预测。如果预测非常接近地面实况标签，那就是损失 价值会很低;如果预测离标签很远，那么就是亏损 价值会很高。</p>
<h2><span id="深入学习">深入学习</span></h2><p>如果你有兴趣了解更多，请查看我们的 广泛和深度学习教程，我们将告诉你如何 联合线性模型和深度神经网络的优势 使用tf.estimator API来训练它们。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/graph_viz/" title="TensorBoard：图形可视化" itemprop="url">TensorBoard：图形可视化</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="tensorboard图形可视化">TensorBoard：图形可视化</span></h1><p>TensorFlow计算图功能强大但复杂。图表可视化可以帮助您理解和调试它们。这是一个可视化工作的例子。</p>
<p><img src="https://www.tensorflow.org/images/graph_vis_animation.gif" alt="Visualization of a TensorFlow
graph"><br>可视化TensorFlow图形。</p>
<p>要查看您自己的图形，请运行TensorBoard将其指向作业的日志目录，单击顶部窗格上的图形选项卡，然后使用左上角的菜单选择适当的运行。有关如何运行TensorBoard并确保记录所有必要信息的深入信息，请参阅TensorBoard：可视化学习。</p>
<h2><span id="命名范围和节点">命名范围和节点</span></h2><p>典型的TensorFlow图可以有成千上万的节点 - 太多看不到 很容易一次，甚至使用标准的图形工具布局。为了简化，<br>变量名称可以被作用域，可视化使用这个信息 在图中的节点上定义一个层次结构。默认情况下，只有这个的顶部 显示层次结构。下面是一个定义三个操作的例子<br><code>hidden</code>名称范围使用 <code>tf.name_scope</code>：</p>
<pre><code>import tensorflow as tf

with tf.name_scope(&apos;hidden&apos;) as scope:
  a = tf.constant(5, name=&apos;alpha&apos;)
  W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0), name=&apos;weights&apos;)
  b = tf.Variable(tf.zeros([1]), name=&apos;biases&apos;)
</code></pre><p>这导致了以下三个op名称：</p>
<p><code>hidden/alpha</code> <code>hidden/weights</code> <code>hidden/biases</code></p>
<p>默认情况下，可视化文件将全部折叠成标记为<code>hidden</code>的节点。 额外的细节不会丢失。您可以双击或单击 在<code>+</code>的橙色标志上右上角展开节点，然后你会看到<br><code>alpha</code>，<code>weights</code>和<code>biases</code>的三个子节点。</p>
<p>这是一个更复杂的节点在其最初和最后一个真实的例子 扩大的国家。</p>
<p><img src="https://www.tensorflow.org/images/pool1_collapsed.png" alt="Unexpanded name
scope"> |  <img src="https://www.tensorflow.org/images/pool1_expanded.png" alt="Expanded
name scope"><br>—|—<br>Initial view of top-level name scope <code>pool_1</code>. Clicking on the orange <code>+</code><br>button on the top right or double-clicking on the node itself will expand it.<br>|  Expanded view of <code>pool_1</code> name scope. Clicking on the orange <code>-</code> button on<br>the top right or double-clicking on the node itself will collapse the name<br>scope.  </p>
<p>按名称范围对节点进行分组对于制作清晰的图形至关重要。如果你是 建立一个模型，名称范围让你控制生成的可视化。 你的名字范围越好，你的可视化就越好。</p>
<p>上图说明了可视化的第二个方面。 TensorFlow 图有两种连接：数据依赖和控制 依赖。数据依赖性显示了两个操作符之间张量的流动<br>显示为实线箭头，而控制依赖关系使用虚线。在里面 展开视图（上图右侧）所有的连接都是数据 连接<code>CheckNumerics</code>的虚线除外<br>和<code>control_dependency</code>。</p>
<p>还有一个简化布局的技巧。大多数TensorFlow图有一个 很少有多个连接到其他节点的节点。例如，许多节点可能<br>对初始化步骤具有控制依赖性。绘制之间的所有边缘 <code>init</code>节点及其依赖关系将创建一个非常混乱的视图。</p>
<p>为了减少混乱，可视化将所有高度节点分离出来 在右边的辅助区域，并不画线来表示它们的边缘。 我们绘制小节点图标来代替连线。 分离出辅助节点通常不会消除关键<br>因为这些节点通常涉及簿记功能。 请参阅交互以了解如何在主图之间移动节点 和辅助区域。</p>
<p><img src="https://www.tensorflow.org/images/conv_1.png" alt="conv_1 is part of the main
graph"> |  <img src="https://www.tensorflow.org/images/save.png" alt="save is extracted as
auxiliary node"><br>—|—<br>Node <code>conv_1</code> is connected to <code>save</code>. Note the little <code>save</code> node icon on its<br>right.  |  <code>save</code> has a high degree, and will appear as an auxiliary node. The<br>connection with <code>conv_1</code> is shown as a node icon on its left. To further<br>reduce clutter, since <code>save</code> has a lot of connections, we show the first 5 and<br>abbreviate the others as <code>... 12 more</code>.  </p>
<p>最后一个结构简化是系列崩溃。顺序 图案 - 也就是说，名称相差数字的节点，并具有 同构结构 - 被折叠成一堆节点，如图所示<br>下面。对于长序列的网络，这大大简化了视图。如 通过分层节点，双击展开该系列。看到 互动如何禁用/启用系列崩溃的一个 特定的一组节点。</p>
<p><img src="https://www.tensorflow.org/images/series.png" alt="Sequence of nodes"> |<br><img src="https://www.tensorflow.org/images/series_expanded.png" alt="Expanded sequence of
nodes"><br>—|—<br>A collapsed view of a node sequence.  |  A small piece of the expanded view,<br>after double-click.  </p>
<p>最后，作为易读性的最后一个助手，可视化使用特殊的图标 常量和汇总节点。总结一下，下面是一个节点符号表：</p>
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Meaning  </th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://www.tensorflow.org/images/namespace_node.png" alt="Name scope"></td>
<td>_High-</td>
</tr>
</tbody>
</table>
<p>level_ node representing a name scope. Double-click to expand a high-level<br>node.<br><img src="https://www.tensorflow.org/images/horizontal_stack.png" alt="Sequence of unconnected
nodes"> |  Sequence of<br>numbered nodes that are not connected to each other.<br><img src="https://www.tensorflow.org/images/vertical_stack.png" alt="Sequence of connected
nodes"> | Sequence of<br>numbered nodes that are connected to each other.<br><img src="https://www.tensorflow.org/images/op_node.png" alt="Operation node"> | An<br>individual operation node.<br><img src="https://www.tensorflow.org/images/constant.png" alt="Constant node"> | A constant.<br><img src="https://www.tensorflow.org/images/summary.png" alt="Summary node"> | A summary<br>node.<br><img src="https://www.tensorflow.org/images/dataflow_edge.png" alt="Data flow edge"> | Edge<br>showing the data flow between operations.<br><img src="https://www.tensorflow.org/images/control_edge.png" alt="Control dependency edge"><br>| Edge showing the control dependency between operations.<br><img src="https://www.tensorflow.org/images/reference_edge.png" alt="Reference edge"> | A<br>reference edge showing that the outgoing operation node can mutate the<br>incoming tensor.  </p>
<h2><span id="相互作用">相互作用</span></h2><p>通过平移和缩放导航图形。点击并拖动以平移，然后使用 滚动手势进行缩放。双击一个节点，或点击其<code>+</code>按钮，即可 展开代表一组操作的名称范围。轻松保持<br>在缩放和平移时跟踪当前的视点，中有一个小地图 在右下角。</p>
<p>要关闭打开的节点，请再次双击或单击<code>-</code>按钮。您可以 也点击一次选择一个节点。它会变成一个较暗的颜色，和细节 关于它和它连接的节点将出现在上面的信息卡中<br>可视化的右上角。</p>
<p><img src="https://www.tensorflow.org/images/infocard.png" alt="Info card of a name scope"> |<br><img src="https://www.tensorflow.org/images/infocard_op.png" alt="Info card of operation
node"><br>—|—<br>Info card showing detailed information for the <code>conv2</code> name scope. The inputs<br>and outputs are combined from the inputs and outputs of the operation nodes<br>inside the name scope. For name scopes no attributes are shown.  |  Info card<br>showing detailed information for the <code>DecodeRaw</code> operation node. In addition<br>to inputs and outputs, the card shows the device and the attributes associated<br>with the current operation.  </p>
<p>TensorBoard提供了几种方法来改变图形的视觉布局。这个 不会改变图的计算语义，但它可以带来一些 网络结构清晰。通过右键单击节点或按<br>该节点信息卡底部的按钮，可以进行以下操作 改变其布局：</p>
<p>节点可以在主图表和辅助区域之间移动。 可以将一系列节点取消分组，从而使得该系列节点不会 出现在一起。未分组的系列也可以重新组合。</p>
<p>选择也可以帮助理解高度节点。选择任何 高度节点，以及其他连接的相应节点图标 也将被选中。例如，这可以很容易地看到哪些节点 正在被保存 - 而不是。</p>
<p>点击信息卡中的节点名称将选择它。如果有必要的话 视点将自动平移，使节点可见。</p>
<p>最后，您可以使用颜色菜单为图形选择两种配色方案 在传奇之上。默认的结构视图显示结构：当两个 高层节点具有相同的结构，它们出现在相同的颜色中<br>彩虹。结构独特的节点是灰色的。还有第二种看法，这表明 不同的操作在哪个设备上运行。名称范围是有颜色的 与其内部操作的设备比例成比例。</p>
<p>下面的图片给出了一张真实生活图的插图。</p>
<p><img src="https://www.tensorflow.org/images/colorby_structure.png" alt="Color by structure"><br>|  <img src="https://www.tensorflow.org/images/colorby_device.png" alt="Color by device"><br>—|—<br>Structure view: The gray nodes have unique structure. The orange <code>conv1</code> and<br><code>conv2</code> nodes have the same structure, and analogously for nodes with other<br>colors.  |  Device view: Name scopes are colored proportionally to the<br>fraction of devices of the operation nodes inside them. Here, purple means GPU<br>and the green is CPU.  </p>
<h2><span id="张量形状信息">张量形状信息</span></h2><p>当序列化的<code>GraphDef</code>包含张量形状时，图形可视化器 用张量维度标注边缘，边缘厚度反映总张量<br>尺寸。要在<code>GraphDef</code>中包含张量形状，请传递实际图形对象 （如在<code>sess.graph</code>中）连接到<code>FileWriter</code>。<br>下面的图片显示了具有张量形状信息的CIFAR-10模型：</p>
<p>![CIFAR-10 model with tensor shape</p>
<h2><span id="informationhttpswwwtensorfloworgimagestensor_shapespng">information]()  </span></h2><p>CIFAR-10 model with tensor shape information.  </p>
<h2><span id="运行时统计">运行时统计</span></h2><p>为运行收集运行时元数据（如总内存）通常很有用 使用情况，总计算时间和节点的张量形状。下面的代码示例 是从列车和测试部分的一个修改的片段<br>简单的MNIST教程， 其中我们记录了摘要和运行时统计信息。请参阅摘要教程 有关如何记录摘要的详细信息。 完整的源代码在这里。</p>
<pre><code># Train the model, and also write summaries.
# Every 10th step, measure test-set accuracy, and write test summaries
# All other steps, run train_step on training data, &amp; add training summaries

def feed_dict(train):
  &quot;&quot;&quot;Make a TensorFlow feed_dict: maps data onto Tensor placeholders.&quot;&quot;&quot;
  if train or FLAGS.fake_data:
    xs, ys = mnist.train.next_batch(100, fake_data=FLAGS.fake_data)
    k = FLAGS.dropout
  else:
    xs, ys = mnist.test.images, mnist.test.labels
    k = 1.0
  return {x: xs, y_: ys, keep_prob: k}

for i in range(FLAGS.max_steps):
  if i % 10 == 0:  # Record summaries and test-set accuracy
    summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(False))
    test_writer.add_summary(summary, i)
    print(&apos;Accuracy at step %s: %s&apos; % (i, acc))
  else:  # Record train set summaries, and train
    if i % 100 == 99:  # Record execution stats
      run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
      run_metadata = tf.RunMetadata()
      summary, _ = sess.run([merged, train_step],
                            feed_dict=feed_dict(True),
                            options=run_options,
                            run_metadata=run_metadata)
      train_writer.add_run_metadata(run_metadata, &apos;step%d&apos; % i)
      train_writer.add_summary(summary, i)
      print(&apos;Adding run metadata for&apos;, i)
    else:  # Record a summary
      summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(True))
      train_writer.add_summary(summary, i)
</code></pre><p>此代码将从步骤99开始每100步发出运行时统计信息。</p>
<p>当您启动tensorboard并转到图表选项卡，您现在将看到选项 在“会话运行”下对应于添加运行元数据的步骤。 选择其中一个运行将显示网络的快照<br>一步，淡出未使用的节点。在左边的控件中，你会的 能够通过总内存或总计算时间对节点着色。另外， 点击一个节点将显示确切的总内存，计算时间和 张量输出大小。</p>
<p><img src="https://www.tensorflow.org/images/colorby_compute_time.png" alt="Color by compute
time"> |  <img src="https://www.tensorflow.org/images/run_metadata_graph.png" alt="Run
metadata graph"> |<br><img src="https://www.tensorflow.org/images/run_metadata_infocard.png" alt="Run metadata info
card"><br>—|—|—</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/layers/" title="TF层指南：建立卷积神经网络" itemprop="url">TF层指南：建立卷积神经网络</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="tf层指南建立卷积神经网络">TF层指南：建立卷积神经网络</span></h1><p>TensorFlow <code>layers</code>模块提供了一个高级API 很容易构建一个神经网络。它提供了方便的方法 创建密集（完全连接）层和卷积层，增加<br>激活功能，并应用失落正则化。在本教程中， 您将学习如何使用<code>layers</code>构建卷积神经网络模型 识别MNIST数据集中的手写数字。</p>
<p><img src="https://www.tensorflow.org/images/mnist_0-9.png" alt="handwritten digits 0-9 from the MNIST data
set"></p>
<p>MNIST数据集包含60,000 训练实例和手写数字0-9的10000个测试例子， 格式化为28x28像素的单色图像。</p>
<h2><span id="入门">入门</span></h2><p>让我们为我们的TensorFlow程序设置骨架。创建一个名为的文件 <code>cnn_mnist.py</code>，并添加以下代码：</p>
<pre><code>from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

# Imports
import numpy as np
import tensorflow as tf

tf.logging.set_verbosity(tf.logging.INFO)

# Our application logic will be added here

if __name__ == &quot;__main__&quot;:
  tf.app.run()
</code></pre><p>在学习本教程时，您将添加代码来构建，训练和 评估卷积神经网络。完整的，最终的代码可以 在这里找到。</p>
<h2><span id="卷积神经网络简介">卷积神经网络简介</span></h2><p>卷积神经网络（CNN）是目前最先进的模型 图像分类任务的体系结构。 CNNs应用一系列的过滤器 图像的原始像素数据提取并学习更高级别的特征<br>该模型可以用于分类。 CNN包含三个组件：</p>
<p>卷积层，应用指定数量的卷积     过滤到图像。对于每个分区域，图层执行一组     数学运算在输出特征映射中产生单个值。     卷积层然后通常应用一个<br>ReLU激活功能     输出将非线性引入到模型中。 合并图层，其中     对图像数据进行下采样     由卷积层提取，以减少维数<br>功能图，以减少处理时间。一个常用的池     算法是最大池，提取特征地图的子区域     （例如，2×2像素的图块）保持其最大值，并丢弃所有其他图像<br>值。 密集（完全连接）图层，执行分类     由卷积层提取的特征和由下采样的特征     合并图层。在一个密集的图层中，图层中的每个节点都连接到<br>前一层中的每个节点。</p>
<p>通常，CNN是由一堆执行的卷积模块组成的 特征提取。每个模块由卷积层和后面的一个组成 合并图层。最后一个卷积模块之后是一个或多个密集的 执行分类的图层。<br>CNN中最后的密集层包含一个 模型中每个目标类的单个节点（所有可能的类） 模型可能预测），与一个 softmax激活功能<br>为每个节点生成0-1之间的值（所有这些softmax值的总和 等于1）。我们可以解释给定图像的softmax值 图像落入每个目标的可能性的相对测量 类。</p>
<blockquote>
<p>注意：有关CNN体系结构的更全面的演练，请参阅Stanford 大学的 卷积神经网络的视觉识别课程教材。</p>
</blockquote>
<h2><span id="建立cnn-mnist分类器">建立CNN MNIST分类器</span></h2><p>让我们建立一个模型来分类MNIST数据集中的图像 遵循CNN架构：</p>
<p>卷积层＃1：应用32个5x5滤波器（提取5x5像素     子区域），具有ReLU激活功能 池层＃1：使用2x2过滤器和2的步幅执行最大池化<br>（它指定汇集区域不重叠） 卷积层＃2：应用64个5x5滤波器，并激活ReLU     功能 池层＃2：同样，使用2x2过滤器执行最大池化     2的步幅<br>密集层＃1：1,024个神经元，丢失正则化率为0.4     （在训练期间任何给定元素将被丢弃的概率为0.4） 密集层＃2（Logits<br>Layer）：10个神经元，每个数字目标一个     类（0-9）。</p>
<p><code>tf.layers</code>模块包含创建三种图层类型的方法 以上：</p>
<p><code>conv2d()</code>。构造一个二维卷积层。号码     过滤器，过滤内核大小，填充和激活功能     参数。<br><code>max_pooling2d()</code>。构造一个二维池使用的层     最大池算法。采用过滤器大小和步幅作为参数。<br><code>dense()</code>。构建一个密集的图层。需要数量的神经元和激活     函数作为参数。</p>
<p>这些方法中的每一个都接受一个张量作为输入，并返回一个变换张量 作为输出。这使得连接一层到另一层变得很容易：<br>从一个图层创建方法输出，并将其作为输入提供给另一个。</p>
<p>打开<code>cnn_mnist.py</code>，添加以下<code>cnn_model_fn</code>功能 符合TensorFlow的Estimator<br>API所期望的界面（更多内容请参考这里 稍后在创建估算器）。 <code>cnn_mnist.py</code>需要 MNIST功能数据，标签和<br>模型模式（<code>TRAIN</code>，<code>EVAL</code>，<code>PREDICT</code>）作为参数; 配置CNN;并返回预测，丢失和训练操作：</p>
<pre><code>def cnn_model_fn(features, labels, mode):
  &quot;&quot;&quot;Model function for CNN.&quot;&quot;&quot;
  # Input Layer
  input_layer = tf.reshape(features[&quot;x&quot;], [-1, 28, 28, 1])

  # Convolutional Layer #1
  conv1 = tf.layers.conv2d(
      inputs=input_layer,
      filters=32,
      kernel_size=[5, 5],
      padding=&quot;same&quot;,
      activation=tf.nn.relu)

  # Pooling Layer #1
  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)

  # Convolutional Layer #2 and Pooling Layer #2
  conv2 = tf.layers.conv2d(
      inputs=pool1,
      filters=64,
      kernel_size=[5, 5],
      padding=&quot;same&quot;,
      activation=tf.nn.relu)
  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)

  # Dense Layer
  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])
  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)
  dropout = tf.layers.dropout(
      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)

  # Logits Layer
  logits = tf.layers.dense(inputs=dropout, units=10)

  predictions = {
      # Generate predictions (for PREDICT and EVAL mode)
      &quot;classes&quot;: tf.argmax(input=logits, axis=1),
      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the
      # `logging_hook`.
      &quot;probabilities&quot;: tf.nn.softmax(logits, name=&quot;softmax_tensor&quot;)
  }

  if mode == tf.estimator.ModeKeys.PREDICT:
    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)

  # Calculate Loss (for both TRAIN and EVAL modes)
  onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)
  loss = tf.losses.softmax_cross_entropy(
      onehot_labels=onehot_labels, logits=logits)

  # Configure the Training Op (for TRAIN mode)
  if mode == tf.estimator.ModeKeys.TRAIN:
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)
    train_op = optimizer.minimize(
        loss=loss,
        global_step=tf.train.get_global_step())
    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)

  # Add evaluation metrics (for EVAL mode)
  eval_metric_ops = {
      &quot;accuracy&quot;: tf.metrics.accuracy(
          labels=labels, predictions=predictions[&quot;classes&quot;])}
  return tf.estimator.EstimatorSpec(
      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)
</code></pre><p>以下部分（与上面每个代码块对应的标题） 更深入地介绍用于创建每个图层的<code>tf.layers</code>代码，以及如何实现 计算损失，配置训练op，并产生预测。如果<br>你已经有了CNN和TensorFlow <code>Estimator</code>的经验， 并找到上面的代码直观，你可能想略过这些部分或只是 跳到“培训和评估CNN<br>MNIST” 分类”。</p>
<h3><span id="输入层">输入层</span></h3><p><code>layers</code>模块中用于创建卷积层和汇聚层的方法 对于二维图像数据，期望输入张量具有一个形状<br>[batch_size，image_width，image_height， 渠道]，定义如下：</p>
<p><code>batch_size</code>。执行时要使用的示例子集的大小     训练期间的梯度下降。 <code>image_width</code>。示例图像的宽度。<br><code>image_height</code>。示例图像的高度。 <code>channels</code>。示例图像中的颜色通道数量。对于颜色<br>图像，通道数量是3（红色，绿色，蓝色）。对于单色     图像，只有1个通道（黑色）。</p>
<p>这里，我们的MNIST数据集是由单色的28x28像素图像组成的，所以 我们输入图层所需的形状是[batch_size，28,28， 1]。</p>
<p>为了把我们的输入特征图（<code>features</code>）转换成这个形状，我们可以执行这个 遵循<code>reshape</code>操作：</p>
<pre><code>input_layer = tf.reshape(features[&quot;x&quot;], [-1, 28, 28, 1])
</code></pre><p>请注意，我们已经指出了<code>-1</code>的批量大小，它指定了这一点 维度应根据输入值的数量动态计算 <code>features[&quot;x&quot;]</code>，其它尺寸的尺寸保持不变。这允许<br>我们把<code>batch_size</code>作为我们可以调节的超参数。例如，如果 我们分批举例将样品投入到5台<code>features[&quot;x&quot;]</code>中<br>3,920个值（每个图像中每个像素一个值），<code>input_layer</code>将会 具有<code>[5, 28, 28, 1]</code>的形状。同样，如果我们分批举例<br>100，<code>features[&quot;x&quot;]</code>将包含78,400个值，而<code>input_layer</code>将包含一个 <code>[100, 28, 28, 1]</code>的形状。</p>
<h3><span id="卷积层1">卷积层＃1</span></h3><p>在我们的第一个卷积图层中，我们希望将32个5x5滤波器应用于输入 层，具有ReLU激活功能。我们可以使用<code>conv2d()</code>方法<br><code>layers</code>模块创建此图层如下：</p>
<pre><code>conv1 = tf.layers.conv2d(
    inputs=input_layer,
    filters=32,
    kernel_size=[5, 5],
    padding=&quot;same&quot;,
    activation=tf.nn.relu)
</code></pre><p><code>inputs</code>参数指定了我们的输入张量，它必须具有形状 [batch_size，image_width，image_height，<br>信道]。在这里，我们正在连接我们的第一个卷积层 到<code>input_layer</code>，其形状为[batch_size，28,28， 1]。</p>
<blockquote>
<p>注意：<code>conv2d()</code>将改为接受一个形状 [channels，batch_size，image_width， image_height]传递参数时<br><code>data_format=channels_first</code>。</p>
</blockquote>
<p><code>filters</code>参数指定要应用的过滤器数（此处为32），以及 <code>kernel_size</code>将过滤器的尺寸指定为[宽度， 高度]（这里是<code>[5, 5]</code>）。</p>
<p>提示：如果过滤器宽度和高度具有相同的值，则可以改为指定一个 <code>kernel_size</code>的单个整数，例如<code>kernel_size=5</code>。</p>
<p><code>padding</code>参数指定了两个枚举值中的一个 （不区分大小写）：<code>valid</code>（默认值）或<code>same</code>。要指定的<br>输出张量应该具有与输入张量相同的宽度和高度值， 我们在这里设置了<code>padding=same</code>，它指示TensorFlow为其添加0值<br>输入张量的边缘保留28的宽度和高度。（没有填充， 在28x28张量上的5x5卷积将产生24x24的张量 24x24位置从28x28网格中提取5x5的图块。）</p>
<p><code>activation</code>参数指定要应用于的激活函数 卷积的输出。在这里，我们指定了ReLU激活 <code>tf.nn.relu</code>。</p>
<p>我们的<code>conv2d()</code>产生的输出张量有一个形状 <code>[ _batch_size_ , 28, 28, 32]</code>：宽度和高度相同<br>尺寸作为输入，但现在有32个通道保持每个输出 的过滤器。</p>
<h3><span id="池层1">池层＃1</span></h3><p>接下来，我们将我们的第一个池层连接到卷积层 创建。我们可以用<code>max_pooling2d()</code>中的<code>layers</code>方法构建一个<br>用2×2滤波器执行最大汇聚的层，步长为2：</p>
<pre><code>pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)
</code></pre><p>再一次，<code>inputs</code>指定输入张量，形状为 [batch_size，image_width，image_height，<br>信道]。在这里，我们的输入张量是来自<code>conv1</code>的输出 第一卷积层，其形状为[batch_size， 28，28，32]。</p>
<blockquote>
<p>注：与<code>conv2d()</code>一样，<code>max_pooling2d()</code>将改为 接受一个[channels，batch_size，<br>image_width，image_height]传递参数时 <code>data_format=channels_first</code>。</p>
</blockquote>
<p><code>pool_size</code>参数指定最大池过滤器的大小为 <code>[ _width_ , _height_ ]</code>（这里是<code>[2, 2]</code>）。如果两个<br>维度具有相同的值，您可以改为指定一个整数（例如， <code>pool_size=2</code>）。</p>
<p><code>strides</code>参数指定步幅的大小。在这里，我们迈出了一大步 2，这表明过滤器提取的子区域应该是 在宽度和高度尺寸上相隔2个像素（对于2×2滤波器，<br>这意味着没有任何提取的区域会重叠）。如果你想设置 不同的宽度和高度的跨度值，你可以改为指定一个元组或者 列表（例如，<code>stride=[3, 6]</code>）。</p>
<p>我们的<code>max_pooling2d()</code>（<code>pool1</code>）产生的张量具有 <code>[ _batch_size_ , 14, 14,
32]</code>：2x2滤波器可以减小宽度和 身高各减50％。</p>
<h3><span id="卷积层2和汇聚层2">卷积层＃2和汇聚层＃2</span></h3><p>我们可以使用第二个卷积和连接层来连接CNN <code>conv2d()</code>和<code>max_pooling2d()</code>。对于卷积层＃2，我们<br>使用ReLU激活配置64个5x5过滤器，并为第2层合并使用 与汇聚层＃1（跨度为2的2x2最大汇集过滤器）相同的规格：</p>
<pre><code>conv2 = tf.layers.conv2d(
    inputs=pool1,
    filters=64,
    kernel_size=[5, 5],
    padding=&quot;same&quot;,
    activation=tf.nn.relu)

pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)
</code></pre><p>请注意，卷积层＃2获取我们第一个池的输出张量 （<code>pool1</code>）作为输入，产生张量<code>conv2</code>作为输出。 <code>conv2</code> 具有<code>[
_batch_size_ , 14, 14, 64]</code>的形状，宽度相同 和<code>pool1</code>（由于<code>padding=&quot;same&quot;</code>）的高度，以及64通道的64<br>应用过滤器。</p>
<p>汇聚层＃2以<code>conv2</code>为输入，生成<code>pool2</code>作为输出。 <code>pool2</code> 具有形状<code>[ _batch_size_ , 7, 7,
64]</code>（减少50％的宽度 和<code>conv2</code>的高度）。</p>
<h3><span id="密集层">密集层</span></h3><p>接下来，我们要添加一个致密层（具有1024个神经元和ReLU激活） 我们的CNN对所提取的特征进行分类 卷积/合并图层。然而，在我们连接图层之前，我们会变平<br>我们的功能图（<code>pool2</code>）可以将[batch_size， 特征]，所以我们的张量只有两个维度：</p>
<pre><code>pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])
</code></pre><p>在上述<code>reshape()</code>操作中，<code>-1</code>表示<code>batch_size</code> 维度将根据我们的例子数量动态计算 输入数据。每个例子有7个（<code>pool2</code>宽度）<em><br>7（<code>pool2</code>高度）</em> 64 （<code>pool2</code>通道）功能，所以我们希望<code>features</code>尺寸有一个值 7 <em> 7 </em><br>64（总计3136）。输出张量<code>pool2_flat</code>具有形状 <code>[ _batch_size_ , 3136]</code>。</p>
<p>现在我们可以使用<code>dense()</code>中的<code>layers</code>方法来连接我们的密集层 如下：</p>
<pre><code>dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)
</code></pre><p><code>inputs</code>参数指定输入张量：我们的平坦特征图， <code>pool2_flat</code>。 <code>units</code>参数指定密度中的神经元数量 层（1,024）。<br><code>activation</code>参数采用激活功能;再次， 我们将使用<code>tf.nn.relu</code>添加ReLU激活。</p>
<p>为了帮助改进我们模型的结果，我们也应用了辍学正规化 使用<code>dropout</code>中的<code>layers</code>方法：</p>
<pre><code>dropout = tf.layers.dropout(
    inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)
</code></pre><p>再次，<code>inputs</code>规定了输入张量，这是我们的输出张量 致密层（<code>dense</code>）。</p>
<p><code>rate</code>参数指定丢失率;在这里，我们使用<code>0.4</code>，这意味着 40％的元素将在训练中随机退出。</p>
<p><code>training</code>参数采用布尔值来指定模型是否为 目前正在训练模式下运行;退出将只会被执行，如果<br><code>training</code>是<code>True</code>。在这里，我们检查<code>mode</code>是否传递给我们的模型功能 <code>cnn_model_fn</code>是<code>TRAIN</code>模式。</p>
<p>我们的输出张量<code>dropout</code>有形状<code>[ _batch_size_ , 1024]</code>。</p>
<h3><span id="logits图层">Logits图层</span></h3><p>在我们的神经网络的最后一层是logits层，它将返回 我们预测的原始值。我们创建了一个密集的10层神经元层（1层） 每个目标类0-9），线性激活（默认）：</p>
<pre><code>logits = tf.layers.dense(inputs=dropout, units=10)
</code></pre><p>CNN的最终输出张量<code>logits</code>已经形成 <code>[ _batch_size_ , 10]</code>。</p>
<h3><span id="生成预测">生成预测</span></h3><p>我们模型的logits层将我们的预测作为原始值返回给a <code>[ _batch_size_ , 10]</code>维张量。我们来转换这些<br>原始值转换为我们的模型函数可以返回的两种不同的格式：</p>
<p>每个示例的预测类别：0-9的数字。 每个例子的每个可能的目标类的概率：     例子的概率是0，是1，是2等等</p>
<p>对于给定的例子，我们预测的类是相应行中的元素 具有最高原始价值的logits张量。我们可以找到这个索引 元素使用<code>tf.argmax</code> 功能：</p>
<pre><code>tf.argmax(input=logits, axis=1)
</code></pre><p><code>input</code>参数指定从中提取最大值的张量 值 - 在这里<code>logits</code>。 <code>axis</code>自变量指定<code>input</code>的轴<br>张量沿其找到最大的价值。在这里，我们想找到最大的 指数为1的维度值与我们的预测相符 （回想一下，我们的logits<br>tensor已经形成[batch_size， 10]）。</p>
<p>我们可以通过应用softmax激活从我们的logits层中得出概率 使用<code>tf.nn.softmax</code>：</p>
<pre><code>tf.nn.softmax(logits, name=&quot;softmax_tensor&quot;)
</code></pre><blockquote>
<p>注意：我们使用<code>name</code>参数来明确命名这个操作 <code>softmax_tensor</code>，所以稍后可以参考。 （我们将设置日志记录<br>在“设置记录挂钩”中的softmax值。</p>
</blockquote>
<p>我们用一个字典来编译我们的预测，然后返回一个<code>EstimatorSpec</code>对象：</p>
<pre><code>predictions = {
    &quot;classes&quot;: tf.argmax(input=logits, axis=1),
    &quot;probabilities&quot;: tf.nn.softmax(logits, name=&quot;softmax_tensor&quot;)
}
if mode == tf.estimator.ModeKeys.PREDICT:
  return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)
</code></pre><h3><span id="计算损失">计算损失</span></h3><p>对于培训和评估，我们需要定义一个 损失功能 它衡量模型的预测与目标类别的匹配程度。对于 多类分类问题如MNIST， 通常使用交叉熵<br>作为损失度量。下面的代码计算模型的交叉熵 以<code>TRAIN</code>或<code>EVAL</code>模式运行：</p>
<pre><code>onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)
loss = tf.losses.softmax_cross_entropy(
    onehot_labels=onehot_labels, logits=logits)
</code></pre><p>让我们仔细看看上面发生的事情。</p>
<p>我们的<code>labels</code>张量包含了我们例子的预测列表， [1， 9，…]。为了计算交叉熵，首先我们需要转换<code>labels</code> 到相应的 热门编码：</p>
<pre><code>[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
 [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
 ...]
</code></pre><p>我们使用<code>tf.one_hot</code>功能 执行此转换。 <code>tf.one_hot()</code>有两个必需的参数：</p>
<p><code>indices</code>。单张张量中的位置将会“打开”     值“ - 即如上所示张量中的<code>1</code>值的位置。 <code>depth</code>。单热张量的深度 -<br>即目标类别的数量。     这里的深度是<code>10</code>。</p>
<p>以下代码为我们的标签<code>onehot_labels</code>创建了单张张量：</p>
<pre><code>onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)
</code></pre><p>由于<code>labels</code>包含0-9的一系列值，所以<code>indices</code>就是我们的 <code>labels</code>张量，值转换为整数。 <code>depth</code>是<code>10</code>，因为我们<br>有10个可能的目标类别，每个数字一个。</p>
<p>接下来，我们计算<code>onehot_labels</code>的交叉熵和最大值的softmax 来自我们的logits层的预测。<br><code>tf.losses.softmax_cross_entropy()</code>需要 <code>onehot_labels</code>和<code>logits</code>作为参数执行softmax激活<br><code>logits</code>计算交叉熵，并将<code>loss</code>作为标量<code>Tensor</code>返回：</p>
<pre><code>loss = tf.losses.softmax_cross_entropy(
    onehot_labels=onehot_labels, logits=logits)
</code></pre><h3><span id="配置培训操作">配置培训操作</span></h3><p>在上一节中，我们将CNN的损失定义为softmax logits层的交叉熵和我们的标签。让我们来配置我们的模型<br>在训练期间优化这个损失值。我们将使用0.001的学习率 随机梯度下降 作为优化算法：</p>
<pre><code>if mode == tf.estimator.ModeKeys.TRAIN:
  optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)
  train_op = optimizer.minimize(
      loss=loss,
      global_step=tf.train.get_global_step())
  return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)
</code></pre><blockquote>
<p>注意：要更深入地了解为Estimator模型配置培训操作 功能，请参阅“定义 在“创造估计”中的模型的训练 tf.estimator“教程。</p>
</blockquote>
<h3><span id="添加评估指标">添加评估指标</span></h3><p>为了在我们的模型中增加准确性度量，我们在EVAL中定义了<code>eval_metric_ops</code>字典 模式如下：</p>
<pre><code>eval_metric_ops = {
    &quot;accuracy&quot;: tf.metrics.accuracy(
        labels=labels, predictions=predictions[&quot;classes&quot;])}
return tf.estimator.EstimatorSpec(
    mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)
</code></pre><h2><span id="培训和评估cnn-mnist分类器">培训和评估CNN MNIST分类器</span></h2><p>我们编写了我们的MNIST CNN模型函数。现在我们准备好进行培训和评估 它。</p>
<h3><span id="加载训练和测试数据">加载训练和测试数据</span></h3><p>首先，让我们加载我们的训练和测试数据。添加<code>main()</code>功能 <code>cnn_mnist.py</code>使用以下代码：</p>
<pre><code>def main(unused_argv):
  # Load training and eval data
  mnist = tf.contrib.learn.datasets.load_dataset(&quot;mnist&quot;)
  train_data = mnist.train.images # Returns np.array
  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)
  eval_data = mnist.test.images # Returns np.array
  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)
</code></pre><p>我们存储训练特征数据（55000个图像的原始像素值） 手绘数字）和训练标签（相应的数值从0到9） 每个图像）作为numpy 阵列<br>分别在<code>train_data</code>和<code>train_labels</code>中。同样，我们存储的 <code>eval_data</code>评估特征数据（10,000张图像）和评估标签<br>和<code>eval_labels</code>。</p>
<h3><span id="创建估算器">创建估算器</span></h3><p>接下来，我们来创建一个<code>Estimator</code>（一个TensorFlow类，用于执行高级功能 模型训练，评估和推理）。添加下面的代码 以<code>main()</code>：</p>
<pre><code># Create the Estimator
mnist_classifier = tf.estimator.Estimator(
    model_fn=cnn_model_fn, model_dir=&quot;/tmp/mnist_convnet_model&quot;)
</code></pre><p><code>model_fn</code>参数指定用于训练的模型函数， 评估和预测;我们通过了我们创建的<code>cnn_model_fn</code> “建立CNN MNIST分类器”。该<br><code>model_dir</code>参数指定模型数据（检查点）所在的目录 保存（在这里，我们指定临时目录<code>/tmp/mnist_convnet_model</code>，但是<br>随意更改到您选择的另一个目录）。</p>
<blockquote>
<p>注意：有关TensorFlow <code>Estimator</code> API的深入演练，请参阅 教程“创建tf.estimator中的估计器”</p>
</blockquote>
<h3><span id="设置日志钩子">设置日志钩子</span></h3><p>由于CNN可能需要一段时间才能训练，所以我们建立一些日志记录，以便跟踪<br>培训期间的进展。我们可以使用TensorFlow的<code>tf.train.SessionRunHook</code>创建一个<br><code>tf.train.LoggingTensorHook</code> 这将记录来自CNN的softmax层的概率值。添加 遵循<code>main()</code>：</p>
<pre><code># Set up logging for predictions
  tensors_to_log = {&quot;probabilities&quot;: &quot;softmax_tensor&quot;}
  logging_hook = tf.train.LoggingTensorHook(
      tensors=tensors_to_log, every_n_iter=50)
</code></pre><p>我们存储了一张我们想要登录<code>tensors_to_log</code>的张量词典。每个关键是一个 我们选择的标签将被打印在日志输出中，而<br>对应的标签是TensorFlow图中<code>Tensor</code>的名称。在这里，我们的<br><code>probabilities</code>可以在<code>softmax_tensor</code>中找到，我们给的名字叫softmax<br>当我们在<code>cnn_model_fn</code>中产生概率时，我们可以更早地进行操作。</p>
<blockquote>
<p>注意：如果您未通过<code>name</code>明确指定操作名称 参数，TensorFlow将分配一个默认名称。一对简单的方法 发现应用到操作的名称是可视化您的图形<br>TensorBoard）或启用TensorFlow调试器 （tfdbg）。</p>
</blockquote>
<p>接下来，我们创建了<code>LoggingTensorHook</code>，通过了<code>tensors_to_log</code><br><code>tensors</code>的说法。我们设置了<code>every_n_iter=50</code>，它规定了概率 应在每50个步骤的训练后记录。</p>
<h3><span id="训练模型">训练模型</span></h3><p>现在我们准备培训我们的模型，我们可以通过创建<code>train_input_fn</code>来完成<br>在<code>train()</code>上调用<code>mnist_classifier</code>。将以下内容添加到<code>main()</code>中：</p>
<pre><code># Train the model
train_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={&quot;x&quot;: train_data},
    y=train_labels,
    batch_size=100,
    num_epochs=None,
    shuffle=True)
mnist_classifier.train(
    input_fn=train_input_fn,
    steps=20000,
    hooks=[logging_hook])
</code></pre><p>在<code>numpy_input_fn</code>调用中，我们将训练特征数据和标签传递给 <code>x</code>（作为字典）和<code>y</code>。我们设置<code>batch_size</code> <code>100</code>（其中<br>意味着模型将在每个步骤的100个示例的minibatches上进行训练）。 <code>num_epochs=None</code>表示模型将训练到指定的数量<br>步骤到达。我们还设置了<code>shuffle=True</code>来洗牌训练数据。 在<code>train</code>调用中，我们设置了<code>steps=20000</code><br>（这意味着该模型将训练总计20,000步）。我们通过我们的 <code>logging_hook</code>转换为<code>hooks</code>参数，以便在此期间触发 训练。</p>
<h3><span id="评估模型">评估模型</span></h3><p>一旦培训完成，我们要评估我们的模型来确定它的 MNIST测试集的准确性。我们称<code>evaluate</code>方法为评估<br>我们在<code>eval_metric_ops</code>的<code>model_fn</code>参数中指定的度量。 将以下内容添加到<code>main()</code>中：</p>
<pre><code># Evaluate the model and print results
eval_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={&quot;x&quot;: eval_data},
    y=eval_labels,
    num_epochs=1,
    shuffle=False)
eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)
print(eval_results)
</code></pre><p>为了创建<code>eval_input_fn</code>，我们设置了<code>num_epochs=1</code>，以便模型评估 一个数据时代的指标并返回结果。我们也设置<br><code>shuffle=False</code>按顺序循环访问数据。</p>
<h3><span id="运行模型">运行模型</span></h3><p>我们编写了CNN模型功能<code>Estimator</code>和培训/评估 逻辑;现在让我们看看结果。运行<code>cnn_mnist.py</code>。</p>
<blockquote>
<p>注意：培训CNN是相当计算密集型的。预计完成 <code>cnn_mnist.py</code>的时间将取决于您的处理器，但可能会有所不同<br>在CPU上超过1小时。为了更快地训练，你可以减少 <code>steps</code>的编号传给了<code>train()</code>，但是请注意这会影响准确性。</p>
</blockquote>
<p>模型训练时，您会看到如下所示的日志输出：</p>
<pre><code>INFO:tensorflow:loss = 2.36026, step = 1
INFO:tensorflow:probabilities = [[ 0.07722801  0.08618255  0.09256398, ...]]
...
INFO:tensorflow:loss = 2.13119, step = 101
INFO:tensorflow:global_step/sec: 5.44132
...
INFO:tensorflow:Loss for final step: 0.553216.

INFO:tensorflow:Restored model from /tmp/mnist_convnet_model
INFO:tensorflow:Eval steps [0,inf) for training step 20000.
INFO:tensorflow:Input iterator is exhausted.
INFO:tensorflow:Saving evaluation summary for step 20000: accuracy = 0.9733, loss = 0.0902271
{&apos;loss&apos;: 0.090227105, &apos;global_step&apos;: 20000, &apos;accuracy&apos;: 0.97329998}
</code></pre><p>在这里，我们的测试数据集已经达到了97.3％的准确率。</p>
<h2><span id="其他资源">其他资源</span></h2><p>要了解有关TensorFlow中的TensorFlow估算器和CNN的更多信息，请参阅 以下资源：</p>
<p>在tf.estimator中创建估计器一个     介绍了TensorFlow Estimator API     配置估算器，编写模型函数，计算损失，以及<br>定义一个训练操作。 专家深度MNIST：建立一个多层CNN。自助游     通过如何构建不使用图层的MNIST CNN分类模型<br>低层次的TensorFlow操作。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/variables/" title="变量" itemprop="url">变量</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> 发表于 2018-01-01</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1><span id="变量">变量</span></h1><p>TensorFlow变量是表示共享持久状态的最佳方式 由您的程序操纵。</p>
<p>变量通过<code>tf.Variable</code>类操纵。 <code>tf.Variable</code> 表示一个张量，其值可以通过运行op来改变。不像<br><code>tf.Tensor</code>对象，<code>tf.Variable</code>存在于单个环境之外 <code>session.run</code>呼叫。</p>
<p><code>tf.Variable</code>内部存储一个持续张量。具体的操作允许你 读取和修改张量的值。这些修改是可见的<br>跨越多个<code>tf.Session</code>，因此多位工作人员可以看到相同的值 <code>tf.Variable</code>。</p>
<h2><span id="创建一个变量">创建一个变量</span></h2><p>创建变量的最佳方法是调用<code>tf.get_variable</code> 功能。此功能要求您指定变量的名称。这个名字 将被其他副本使用来访问相同的变量，以及名称<br>检查点和导出模型时此变量的值。 <code>tf.get_variable</code> 还允许您重复使用以前创建的相同名称的变量 容易定义重复使用图层的模型。</p>
<p>要用<code>tf.get_variable</code>创建变量，只需提供名称和形状</p>
<pre><code>my_variable = tf.get_variable(&quot;my_variable&quot;, [1, 2, 3])
</code></pre><p>这将创建一个名为“my_variable”的变量，它是一个三维张量 与形状<code>[1, 2, 3]</code>。这个变量默认会有<code>dtype</code><br><code>tf.float32</code>和它的初始值将通过随机化 <code>tf.glorot_uniform_initializer</code>。</p>
<p>您可以选择将<code>dtype</code>和初始化程序指定为<code>tf.get_variable</code>。对于 例：</p>
<pre><code>my_int_variable = tf.get_variable(&quot;my_int_variable&quot;, [1, 2, 3], dtype=tf.int32, 
  initializer=tf.zeros_initializer)
</code></pre><p>TensorFlow提供了许多方便的初始化程序。或者，你可以 将<code>tf.Variable</code>初始化为具有<code>tf.Tensor</code>的值。例如：</p>
<pre><code>other_variable = tf.get_variable(&quot;other_variable&quot;, dtype=tf.int32, 
  initializer=tf.constant([23, 42]))
</code></pre><p>请注意，当初始化程序是<code>tf.Tensor</code>时，不应指定 变量的形状，因为初始化张量的形状将被使用。</p>
<h3><span id="变量集合">变量集合</span></h3><p>因为TensorFlow程序的断开部分可能需要创建 变量，有时候用单一的方法来访问所有的变量是有用的<br>他们。出于这个原因，TensorFlow提供了名为列表的集合 张量或其他对象，如<code>tf.Variable</code>实例。</p>
<p>默认情况下，每个<code>tf.Variable</code>都被放置在以下两个集合中：  <em> <code>tf.GraphKeys.GLOBAL_VARIABLES</code><br>-–可以共享的变量 多个设备，  </em> <code>tf.GraphKeys.TRAINABLE_VARIABLES</code> -– TensorFlow的变量<br>计算梯度。</p>
<p>如果你不想要一个变量是可训练的，把它添加到 <code>tf.GraphKeys.LOCAL_VARIABLES</code>集合代替。例如，以下<br>代码片段演示了如何将一个名为<code>my_local</code>的变量添加到此集合中：</p>
<pre><code>my_local = tf.get_variable(&quot;my_local&quot;, shape=(), 
collections=[tf.GraphKeys.LOCAL_VARIABLES])
</code></pre><p>或者，您可以指定<code>trainable=False</code>作为参数 <code>tf.get_variable</code>：</p>
<pre><code>my_non_trainable = tf.get_variable(&quot;my_non_trainable&quot;, 
                                   shape=(), 
                                   trainable=False)
</code></pre><p>您也可以使用自己的收藏。任何字符串都是有效的集合名称， 而且没有必要明确地创建一个集合。要添加一个变量（或 任何其他对象）在创建变量后调用集合<br><code>tf.add_to_collection</code>。例如，下面的代码添加一个现有的 名为<code>my_local</code>的变量命名为<code>my_collection_name</code>：</p>
<pre><code>tf.add_to_collection(&quot;my_collection_name&quot;, my_local)
</code></pre><p>并检索您放入的所有变量（或其他对象）的列表 您可以使用的集合：</p>
<pre><code>tf.get_collection(&quot;my_collection_name&quot;)
</code></pre><h3><span id="设备放置">设备放置</span></h3><p>就像任何其他TensorFlow操作一样，您可以将变量放在特定的位置 设备。例如，以下片段创建一个名为<code>v</code>的变量 将其放置在第二个GPU设备上：</p>
<pre><code>with tf.device(&quot;/device:GPU:1&quot;):
  v = tf.get_variable(&quot;v&quot;, [1])
</code></pre><p>变量在正确的设备中变得尤为重要 分布式设置。不小心把变量放在工人身上，而不是 参数服务器，例如，可以严重放慢训练，或在最坏的情况下<br>的情况下，让每个工人都快乐地开展自己的独立副本 变量。为此我们提供<code>tf.train.replica_device_setter</code>，<br>可以自动将变量放在参数服务器中。例如：</p>
<pre><code>cluster_spec = {
    &quot;ps&quot;: [&quot;ps0:2222&quot;, &quot;ps1:2222&quot;],
    &quot;worker&quot;: [&quot;worker0:2222&quot;, &quot;worker1:2222&quot;, &quot;worker2:2222&quot;]}
with tf.device(tf.train.replica_device_setter(cluster=cluster_spec)):
  v = tf.get_variable(&quot;v&quot;, shape=[20, 20])  # this variable is placed 
                                            # in the parameter server
                                            # by the replica_device_setter
</code></pre><h2><span id="初始化变量">初始化变量</span></h2><p>在你使用一个变量之前，它必须被初始化。如果你正在编程 低级别的TensorFlow API（也就是说，您明确地创建了自己的<br>图表和会话），您必须显式初始化变量。最 <code>tf.contrib.slim</code>，<code>tf.estimator.Estimator</code>等高层架构<br>在训练模型之前，<code>Keras</code>会自动初始化变量。</p>
<p>明确的初始化是有用的，因为它允许你不要重新运行 当从检查点重新加载模型时，可能需要昂贵的初始化器 以及在随机初始化变量在a中共享时允许确定性 分布式设置。</p>
<p>要在训练开始之前一次初始化所有可训练变量，请致电 <code>tf.global_variables_initializer()</code>。这个函数返回一个单一的操作<br>负责初始化中的所有变量 <code>tf.GraphKeys.GLOBAL_VARIABLES</code>系列运行此操作将初始化 所有变量。例如：</p>
<pre><code>session.run(tf.global_variables_initializer())
# Now all variables are initialized.
</code></pre><p>如果你确实需要自己初始化变量，你可以运行这个变量 初始化器操作。例如：</p>
<pre><code>session.run(my_variable.initializer)
</code></pre><p>你也可以问哪些变量还没有被初始化。例如， 下面的代码打印尚未被所有变量的名字 初始化：</p>
<pre><code>print(session.run(tf.report_uninitialized_variables()))
</code></pre><p>请注意，默认<code>tf.global_variables_initializer</code>没有指定 变量初始化的顺序。因此，如果一个初始值<br>变量取决于另一个变量的值，很可能你会得到一个 错误。任何时候你在一个上下文中使用变量的值不是全部 变量被初始化（比方说，如果你在初始化的时候使用变量的值<br>另一个变量），最好用<code>variable.initialized_value()</code>来代替 <code>variable</code>：</p>
<pre><code>v = tf.get_variable(&quot;v&quot;, shape=(), initializer=tf.zeros_initializer())
w = tf.get_variable(&quot;w&quot;, initializer=v.initialized_value() + 1)
</code></pre><h2><span id="使用变量">使用变量</span></h2><p>要在TensorFlow图形中使用<code>tf.Variable</code>的值，只需简单地对待它即可 一个正常的<code>tf.Tensor</code>：</p>
<pre><code>v = tf.get_variable(&quot;v&quot;, shape=(), initializer=tf.zeros_initializer())
w = v + 1  # w is a tf.Tensor which is computed based on the value of v.
           # Any time a variable is used in an expression it gets automatically
           # converted to a tf.Tensor representing its value.
</code></pre><p>要为变量赋值，请使用<code>assign</code>，<code>assign_add</code>和 <code>tf.Variable</code>类的朋友。例如，这里是如何调用这些 方法：</p>
<pre><code>v = tf.get_variable(&quot;v&quot;, shape=(), initializer=tf.zeros_initializer())
assignment = v.assign_add(1)
tf.global_variables_initializer().run()
assignment.run()
</code></pre><p>大多数TensorFlow优化器有专门的操作，有效地更新 根据某种梯度下降算法的变量值。看到<br><code>tf.train.Optimizer</code>用于说明如何使用优化器。</p>
<p>因为变量是可变的，所以知道某个版本的版本有时是有用的 变量的值在任何时间点被使用。强迫重新阅读 事情发生后，一个变量的值，你可以使用<br><code>tf.Variable.read_value</code>。例如：</p>
<pre><code>v = tf.get_variable(&quot;v&quot;, shape=(), initializer=tf.zeros_initializer())
assignment = v.assign_add(1)
with tf.control_dependencies([assignment]):
  w = v.read_value()  # w is guaranteed to reflect v&apos;s value after the
                      # assign_add operation.
</code></pre><h2><span id="共享变量">共享变量</span></h2><p>TensorFlow支持两种共享变量的方式：</p>
<p>明确传递<code>tf.Variable</code>对象。 在<code>tf.Variable</code>对象中隐式地包装<code>tf.variable_scope</code>对象。</p>
<p>虽然明确地传递变量的代码是非常清楚的，但是 有时可以方便地写出隐式使用的TensorFlow函数 变量在他们的实现。大部分功能层来自<br><code>tf.layer</code>使用这种方法，以及所有<code>tf.metrics</code>和其他一些 库工具。</p>
<p>变量作用域允许你在调用函数时控制变量的重用 隐式创建和使用变量。他们也允许你给你的变量命名 以分层和可理解的方式。</p>
<p>例如，假设我们写一个函数来创建一个卷积/ relu 层：</p>
<pre><code>def conv_relu(input, kernel_shape, bias_shape):
    # Create variable named &quot;weights&quot;.
    weights = tf.get_variable(&quot;weights&quot;, kernel_shape,
        initializer=tf.random_normal_initializer())
    # Create variable named &quot;biases&quot;.
    biases = tf.get_variable(&quot;biases&quot;, bias_shape,
        initializer=tf.constant_initializer(0.0))
    conv = tf.nn.conv2d(input, weights,
        strides=[1, 1, 1, 1], padding=&apos;SAME&apos;)
    return tf.nn.relu(conv + biases)
</code></pre><p>此功能使用短名称<code>weights</code>和<code>biases</code>，这对于 明晰。然而，在一个真正的模型中，我们需要很多这样的卷积图层 多次调用此函数将无法正常工作：</p>
<pre><code>input1 = tf.random_normal([1,10,10,32])
input2 = tf.random_normal([1,20,20,32])
x = conv_relu(input1, kernel_shape=[5, 5, 32, 32], bias_shape=[32])
x = conv_relu(x, kernel_shape=[5, 5, 32, 32], bias_shape = [32])  # This fails.
</code></pre><p>由于所需的行为不清楚（创建新的变量或重用 现有的？）TensorFlow将失败。在不同的范围调用<code>conv_relu</code>， 然而，澄清我们要创造新的变数：</p>
<pre><code>def my_image_filter(input_images):
    with tf.variable_scope(&quot;conv1&quot;):
        # Variables created here will be named &quot;conv1/weights&quot;, &quot;conv1/biases&quot;.
        relu1 = conv_relu(input_images, [5, 5, 32, 32], [32])
    with tf.variable_scope(&quot;conv2&quot;):
        # Variables created here will be named &quot;conv2/weights&quot;, &quot;conv2/biases&quot;.
        return conv_relu(relu1, [5, 5, 32, 32], [32])
</code></pre><p>如果你想要共享变量，你有两个选择。首先，你可以 使用<code>reuse=True</code>创建一个具有相同名称的示波器：</p>
<pre><code>with tf.variable_scope(&quot;model&quot;):
  output1 = my_image_filter(input1)
with tf.variable_scope(&quot;model&quot;, reuse=True):
  output2 = my_image_filter(input2)
</code></pre><p>您也可以拨打<code>scope.reuse_variables()</code>触发重复使用：</p>
<pre><code>with tf.variable_scope(&quot;model&quot;) as scope:
  output1 = my_image_filter(input1)
  scope.reuse_variables()
  output2 = my_image_filter(input2)
</code></pre><p>由于范围的确切字符串名称可能会感到危险，这也是 可能基于另一个初始化变量作用域：</p>
<pre><code>with tf.variable_scope(&quot;model&quot;) as scope:
  output1 = my_image_filter(input1)
with tf.variable_scope(scope, reuse=True):
  output2 = my_image_filter(input2)
</code></pre>
        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>




<div class="comments-count">
	
</div>

</footer>


    </article>





  


  <nav id="page-nav" class="clearfix">
    <a class="extend prev" rel="prev" href="/page/122/"><span></span>Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/121/">121</a><a class="page-number" href="/page/122/">122</a><span class="page-number current">123</span><a class="page-number" href="/page/124/">124</a><a class="page-number" href="/page/125/">125</a><span class="space">&hellip;</span><a class="page-number" href="/page/157/">157</a><a class="extend next" rel="next" href="/page/124/">Next<span></span></a>
  </nav>

</div>

      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- side-bar-ad -->
<ins class="adsbygoogle"
     style="display:block; overflow:hidden;"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="2232545787"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


  


  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/javascript/" title="javascript">javascript<sup>207</sup></a></li>
			
		
			
				<li><a href="/tags/java/" title="java">java<sup>205</sup></a></li>
			
		
			
				<li><a href="/tags/html/" title="html">html<sup>203</sup></a></li>
			
		
			
				<li><a href="/tags/python/" title="python">python<sup>199</sup></a></li>
			
		
			
				<li><a href="/tags/bash/" title="bash">bash<sup>198</sup></a></li>
			
		
			
				<li><a href="/tags/php/" title="php">php<sup>197</sup></a></li>
			
		
			
				<li><a href="/tags/css/" title="css">css<sup>88</sup></a></li>
			
		
			
				<li><a href="/tags/shell/" title="shell">shell<sup>78</sup></a></li>
			
		
			
				<li><a href="/tags/jquery/" title="jquery">jquery<sup>61</sup></a></li>
			
		
			
				<li><a href="/tags/linux/" title="linux">linux<sup>57</sup></a></li>
			
		
			
				<li><a href="/tags/机器学习/" title="机器学习">机器学习<sup>41</sup></a></li>
			
		
			
				<li><a href="/tags/unix/" title="unix">unix<sup>30</sup></a></li>
			
		
			
				<li><a href="/tags/mysql/" title="mysql">mysql<sup>17</sup></a></li>
			
		
			
				<li><a href="/tags/html5/" title="html5">html5<sup>16</sup></a></li>
			
		
			
				<li><a href="/tags/xml/" title="xml">xml<sup>13</sup></a></li>
			
		
			
				<li><a href="/tags/http/" title="http">http<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/区块链/" title="区块链">区块链<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://tracholar.github.io" target="_blank" title="个人博客">个人博客</a>
            
          </li>
        
    </ul>
</div>

  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

</aside>
</div>

    </div>
    <footer><div id="footer" >
	
	
	<section class="info">
		<p> To be or not to be, that is a question. <br/>
			This is my blog,believe it or not.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		版权所有 © 2018 本站文章未经同意，禁止转载！作者：
		
		<a href="/about" target="_blank" title="zhizi">zhizi</a>
		


		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>












<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->





<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
