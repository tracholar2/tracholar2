
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>导入数据 | 智子</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="zhizi">
    

    
    <meta name="description" content="导入数据Dataset API使您能够构建复杂的输入管道 简单，可重复使用的作品。例如，图像模型的管道可能会 从分布式文件系统中的文件汇总数据，随机应用扰动每个图像，并将随机选择的图像合并为一批 为了训练。文本模型的管道可能涉及提取符号 从原始文本数据，将其转换为查找嵌入标识符表，并将不同长度的序列分配在一起。 Dataset API 可以轻松处理大量的数据，不同的数据格式 复杂的转变。 Data">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="导入数据">
<meta property="og:url" content="https://www.tracholar.top/2018/01/01/datasets/index.html">
<meta property="og:site_name" content="智子">
<meta property="og:description" content="导入数据Dataset API使您能够构建复杂的输入管道 简单，可重复使用的作品。例如，图像模型的管道可能会 从分布式文件系统中的文件汇总数据，随机应用扰动每个图像，并将随机选择的图像合并为一批 为了训练。文本模型的管道可能涉及提取符号 从原始文本数据，将其转换为查找嵌入标识符表，并将不同长度的序列分配在一起。 Dataset API 可以轻松处理大量的数据，不同的数据格式 复杂的转变。 Data">
<meta property="og:updated_time" content="2018-01-16T14:34:50.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="导入数据">
<meta name="twitter:description" content="导入数据Dataset API使您能够构建复杂的输入管道 简单，可重复使用的作品。例如，图像模型的管道可能会 从分布式文件系统中的文件汇总数据，随机应用扰动每个图像，并将随机选择的图像合并为一批 为了训练。文本模型的管道可能涉及提取符号 从原始文本数据，将其转换为查找嵌入标识符表，并将不同长度的序列分配在一起。 Dataset API 可以轻松处理大量的数据，不同的数据格式 复杂的转变。 Data">

    
    <link rel="alternative" href="/atom.xml" title="智子" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">

    <!-- ad start -->
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-6300557868920774",
    enable_page_level_ads: true
  });
</script>

    <!-- ad end -->

    <!--  stat -->
    <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?4036f580b1119e720db871571faa68cc";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-78529611-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-78529611-1');
</script>

    <!-- end stat -->
</head>

  <body>
    <header>
      
<div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="智子">智子</a></h1>
				<h2 class="blog-motto">智子之家</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:www.tracholar.top">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody">
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/01/datasets/" title="导入数据" itemprop="url">导入数据</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="zhizi" target="_blank" itemprop="author">zhizi</a>
		
  <p class="article-time">
    <time datetime="2018-01-01T02:00:00.000Z" itemprop="datePublished"> Published 2018-01-01</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">Contents</strong>
		
			<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#undefined"><span class="toc-number">1.</span> <span class="toc-text">导入数据</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">1.1.</span> <span class="toc-text">基本力学</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.1.1.</span> <span class="toc-text">数据集结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.1.2.</span> <span class="toc-text">创建一个迭代器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.1.3.</span> <span class="toc-text">从迭代器中消费值</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">1.2.</span> <span class="toc-text">读取输入数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.2.1.</span> <span class="toc-text">使用NumPy数组</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.2.2.</span> <span class="toc-text">消费TFRecord数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.2.3.</span> <span class="toc-text">消费文本数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">1.3.</span> <span class="toc-text">用Dataset.map()预处理数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.3.1.</span> <span class="toc-text">解析tf.Example协议缓冲区信息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.3.2.</span> <span class="toc-text">解码图像数据并调整大小</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.3.3.</span> <span class="toc-text">应用tf.py_func()的任意Python逻辑</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">1.4.</span> <span class="toc-text">批处理数据集元素</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.4.1.</span> <span class="toc-text">简单的配料</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.4.2.</span> <span class="toc-text">用填料分批张量</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">1.5.</span> <span class="toc-text">培训工作流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.5.1.</span> <span class="toc-text">处理多个时代</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.5.2.</span> <span class="toc-text">随机洗牌输入数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.5.3.</span> <span class="toc-text">使用高级API</span></a></li></ol></li></ol></li></ol>
		
		</div>
		

        <ins class="adsbygoogle"
     style="display:block; text-align:center; overflow:hidden;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="6882414849"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


		<h1><span id="导入数据">导入数据</span></h1><p><code>Dataset</code> API使您能够构建复杂的输入管道 简单，可重复使用的作品。例如，图像模型的管道可能会 从分布式文件系统中的文件汇总数据，随机应用<br>扰动每个图像，并将随机选择的图像合并为一批 为了训练。文本模型的管道可能涉及提取符号 从原始文本数据，将其转换为查找嵌入标识符<br>表，并将不同长度的序列分配在一起。 <code>Dataset</code> API 可以轻松处理大量的数据，不同的数据格式 复杂的转变。</p>
<p><code>Dataset</code> API为TensorFlow引入了两个新的抽象：</p>
<p><code>tf.data.Dataset</code>代表一系列元素，其中   每个元素包含一个或多个<code>Tensor</code>对象。例如，在一个图像<br>管道，一个元素可能是一个训练的例子，有一对   张量表示图像数据和标签。有两个截然不同的   创建数据集的方法：<br>创建一个源（例如<code>Dataset.from_tensor_slices()</code>）构建一个     数据集     一个或多个<code>tf.Tensor</code>对象。<br>应用转换（例如<code>Dataset.batch()</code>）构建数据集     来自一个或多个<code>tf.data.Dataset</code>对象。<br>一个<code>tf.data.Iterator</code>提供了从一个提取元素的主要方法   数据集。由<code>Iterator.get_next()</code>返回的操作产生下一个<br><code>Dataset</code>的元件在执行时通常用作接口   输入管道代码和你的模型之间。最简单的迭代器是a   “一次迭代器”，它与一个特定的<code>Dataset</code>和<br>迭代一次。对于更复杂的用途，   <code>Iterator.initializer</code>操作使您能够重新初始化和参数化   一个具有不同数据集的迭代器，以便您可以迭代<br>在同一个程序中多次训练和验证数据。</p>
<h2><span id="基本力学">基本力学</span></h2><p>本指南的这一部分描述了创建不同种类的基础知识 <code>Dataset</code>和<code>Iterator</code>的对象，以及如何从中提取数据。</p>
<p>要启动输入管道，您必须定义一个源。例如， 从记忆中的一些张量构建一个<code>Dataset</code>，就可以使用<br><code>tf.data.Dataset.from_tensors()</code>或<br><code>tf.data.Dataset.from_tensor_slices()</code>。或者，如果你的输入 数据在推荐的TFRecord格式磁盘上，你可以构造一个<br><code>tf.data.TFRecordDataset</code>。</p>
<p>一旦你有一个<code>Dataset</code>的对象，你可以转换成一个新的<code>Dataset</code> 链接方法调用<code>tf.data.Dataset</code>对象。例如，你<br>可以应用每元素转换，如<code>Dataset.map()</code>（申请一个 函数到每个元素）和多元素转换，如<br><code>Dataset.batch()</code>。请参阅<code>tf.data.Dataset</code>的文档 为完整的转换列表。</p>
<p>从<code>Dataset</code>中消费数值的最常用方法是制作一个 迭代器对象，一次提供对数据集的一个元素的访问<br>（例如，通过调用<code>Dataset.make_one_shot_iterator()</code>）。一个<br><code>tf.data.Iterator</code>提供两种操作：<code>Iterator.initializer</code>， 它使您能够（重新）初始化迭代器的状态;和<br><code>Iterator.get_next()</code>，它返回对应的<code>tf.Tensor</code>对象 象征性的下一个元素。根据你的用例，你可能会选择一个不同的<br>迭代器类型，下面列出了选项。</p>
<h3><span id="数据集结构">数据集结构</span></h3><p>数据集包含各自具有相同结构的元素。一个元素 包含一个或多个称为组件的<code>tf.Tensor</code>对象。每个组件 <code>tf.DType</code>代表张量中元素的类型，a<br><code>tf.TensorShape</code>代表（可能部分指定）的静态形状 每个元素。<br><code>Dataset.output_types</code>和<code>Dataset.output_shapes</code>属性 允许您检查a的每个组件的推断类型和形状<br>数据集元素。这些属性的嵌套结构映射到结构 一个元素，它可能是单张量，张量元组或嵌套 张量元组。例如：</p>
<pre><code>dataset1 = tf.data.Dataset.from_tensor_slices(tf.random_uniform([4, 10]))
print(dataset1.output_types)  # ==&gt; &quot;tf.float32&quot;
print(dataset1.output_shapes)  # ==&gt; &quot;(10,)&quot;

dataset2 = tf.data.Dataset.from_tensor_slices(
   (tf.random_uniform([4]),
    tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)))
print(dataset2.output_types)  # ==&gt; &quot;(tf.float32, tf.int32)&quot;
print(dataset2.output_shapes)  # ==&gt; &quot;((), (100,))&quot;

dataset3 = tf.data.Dataset.zip((dataset1, dataset2))
print(dataset3.output_types)  # ==&gt; (tf.float32, (tf.float32, tf.int32))
print(dataset3.output_shapes)  # ==&gt; &quot;(10, ((), (100,)))&quot;
</code></pre><p>为一个元素的每个元素命名通常很方便 例如，如果它们表示训练示例的不同特征。此外<br>到元组，可以使用<code>collections.namedtuple</code>或字典映射字符串 张量来代表<code>Dataset</code>的单个元素。</p>
<pre><code>dataset = tf.data.Dataset.from_tensor_slices(
   {&quot;a&quot;: tf.random_uniform([4]),
    &quot;b&quot;: tf.random_uniform([4, 100], maxval=100, dtype=tf.int32)})
print(dataset.output_types)  # ==&gt; &quot;{&apos;a&apos;: tf.float32, &apos;b&apos;: tf.int32}&quot;
print(dataset.output_shapes)  # ==&gt; &quot;{&apos;a&apos;: (), &apos;b&apos;: (100,)}&quot;
</code></pre><p><code>Dataset</code>转换支持任何结构的数据集。使用时<br><code>Dataset.map()</code>，<code>Dataset.flat_map()</code>和<code>Dataset.filter()</code>转化，<br>它将一个函数应用到每个元素，元素的结构决定了 函数的参数：</p>
<pre><code>dataset1 = dataset1.map(lambda x: ...)

dataset2 = dataset2.flat_map(lambda x, y: ...)

# Note: Argument destructuring is not available in Python 3.
dataset3 = dataset3.filter(lambda x, (y, z): ...)
</code></pre><h3><span id="创建一个迭代器">创建一个迭代器</span></h3><p>一旦你建立了一个<code>Dataset</code>来表示你的输入数据，下一步就是 创建一个<code>Iterator</code>来访问该数据集中的元素。 <code>Dataset</code> API<br>目前支持以下迭代器，在增加级别 成熟：</p>
<p>一次性的， initializable， 可重新初始化和 可补给。</p>
<p>一次迭代器是仅支持的最简单的迭代器形式 迭代一次数据集，而不需要显式的初始化。 一次迭代器处理几乎所有现有的基于队列的情况<br>输入管道支持，但不支持参数化。使用 <code>Dataset.range()</code>的示例：</p>
<pre><code>dataset = tf.data.Dataset.range(100)
iterator = dataset.make_one_shot_iterator()
next_element = iterator.get_next()

for i in range(100):
  value = sess.run(next_element)
  assert i == value
</code></pre><p>注意：目前，一次迭代器是唯一可以轻松使用的类型 与<code>Estimator</code>。</p>
<p>一个可初始化的迭代器需要你运行一个显式的 <code>iterator.initializer</code>的使用方法。作为交换 不方便，它使您能够参数化数据集的定义，<br>使用一个或多个可在您喂食的<code>tf.placeholder()</code>张量 初始化迭代器。继续<code>Dataset.range()</code>示例：</p>
<pre><code>max_value = tf.placeholder(tf.int64, shape=[])
dataset = tf.data.Dataset.range(max_value)
iterator = dataset.make_initializable_iterator()
next_element = iterator.get_next()

# Initialize an iterator over a dataset with 10 elements.
sess.run(iterator.initializer, feed_dict={max_value: 10})
for i in range(10):
  value = sess.run(next_element)
  assert i == value

# Initialize the same iterator over a dataset with 100 elements.
sess.run(iterator.initializer, feed_dict={max_value: 100})
for i in range(100):
  value = sess.run(next_element)
  assert i == value
</code></pre><p>可重新初始化的迭代器可以从多个不同的初始化 <code>Dataset</code>物体。例如，您可能有一个培训输入管道 对输入图像使用随机扰动来改善泛化，<br>验证输入管道，用于评估未修改数据的预测。这些 管道通常会使用具有相同的不同<code>Dataset</code>对象 结构（即，每个部件的相同类型和相容的形状）。</p>
<pre><code># Define training and validation datasets with the same structure.
training_dataset = tf.data.Dataset.range(100).map(
    lambda x: x + tf.random_uniform([], -10, 10, tf.int64))
validation_dataset = tf.data.Dataset.range(50)

# A reinitializable iterator is defined by its structure. We could use the
# `output_types` and `output_shapes` properties of either `training_dataset`
# or `validation_dataset` here, because they are compatible.
iterator = Iterator.from_structure(training_dataset.output_types,
                                   training_dataset.output_shapes)
next_element = iterator.get_next()

training_init_op = iterator.make_initializer(training_dataset)
validation_init_op = iterator.make_initializer(validation_dataset)

# Run 20 epochs in which the training dataset is traversed, followed by the
# validation dataset.
for _ in range(20):
  # Initialize an iterator over the training dataset.
  sess.run(training_init_op)
  for _ in range(100):
    sess.run(next_element)

  # Initialize an iterator over the validation dataset.
  sess.run(validation_init_op)
  for _ in range(50):
    sess.run(next_element)
</code></pre><p>可馈入迭代器可与<code>tf.placeholder</code>一起使用进行选择 <code>Iterator</code>在每次<code>tf.Session.run</code>呼叫中使用什么<br><code>feed_dict</code>机制。它提供了与可重新初始化相同的功能 迭代器，但它不要求你从头开始初始化迭代器 在迭代器之间切换时，数据集的数据集。例如，使用相同的<br>从上面的培训和验证的例子，你可以使用 <code>tf.data.Iterator.from_string_handle</code>定义一个可馈送的迭代器<br>这使您可以在两个数据集之间切换：</p>
<pre><code># Define training and validation datasets with the same structure.
training_dataset = tf.data.Dataset.range(100).map(
    lambda x: x + tf.random_uniform([], -10, 10, tf.int64)).repeat()
validation_dataset = tf.data.Dataset.range(50)

# A feedable iterator is defined by a handle placeholder and its structure. We
# could use the `output_types` and `output_shapes` properties of either
# `training_dataset` or `validation_dataset` here, because they have
# identical structure.
handle = tf.placeholder(tf.string, shape=[])
iterator = tf.data.Iterator.from_string_handle(
    handle, training_dataset.output_types, training_dataset.output_shapes)
next_element = iterator.get_next()

# You can use feedable iterators with a variety of different kinds of iterator
# (such as one-shot and initializable iterators).
training_iterator = training_dataset.make_one_shot_iterator()
validation_iterator = validation_dataset.make_initializable_iterator()

# The `Iterator.string_handle()` method returns a tensor that can be evaluated
# and used to feed the `handle` placeholder.
training_handle = sess.run(training_iterator.string_handle())
validation_handle = sess.run(validation_iterator.string_handle())

# Loop forever, alternating between training and validation.
while True:
  # Run 200 steps using the training dataset. Note that the training dataset is
  # infinite, and we resume from where we left off in the previous `while` loop
  # iteration.
  for _ in range(200):
    sess.run(next_element, feed_dict={handle: training_handle})

  # Run one pass over the validation dataset.
  sess.run(validation_iterator.initializer)
  for _ in range(50):
    sess.run(next_element, feed_dict={handle: validation_handle})
</code></pre><h3><span id="从迭代器中消费值">从迭代器中消费值</span></h3><p><code>Iterator.get_next()</code>方法返回一个或多个<code>tf.Tensor</code>对象 对应于迭代器的符号下一个元素。每次这些张量<br>被评估，他们采取底层的下一个元素的值 数据集。 （请注意，像TensorFlow中的其他有状态对象一样，调用<br><code>Iterator.get_next()</code>不会立即推进迭代器。相反，你 必须在TensorFlow表达式中使用返回的<code>tf.Tensor</code>对象，并通过<br><code>tf.Session.run()</code>的表达结果得到下一个元素和 推进迭代器。）</p>
<p>如果迭代器到达数据集的末尾，则执行 <code>Iterator.get_next()</code>将提升<code>tf.errors.OutOfRangeError</code>。<br>在这一点之后，迭代器将处于不可用状态，并且您必须 如果你想进一步使用它，再次初始化它。</p>
<pre><code>dataset = tf.data.Dataset.range(5)
iterator = dataset.make_initializable_iterator()
next_element = iterator.get_next()

# Typically `result` will be the output of a model, or an optimizer&apos;s
# training operation.
result = tf.add(next_element, next_element)

sess.run(iterator.initializer)
print(sess.run(result))  # ==&gt; &quot;0&quot;
print(sess.run(result))  # ==&gt; &quot;2&quot;
print(sess.run(result))  # ==&gt; &quot;4&quot;
print(sess.run(result))  # ==&gt; &quot;6&quot;
print(sess.run(result))  # ==&gt; &quot;8&quot;
try:
  sess.run(result)
except tf.errors.OutOfRangeError:
  print(&quot;End of dataset&quot;)  # ==&gt; &quot;End of dataset&quot;
</code></pre><p><code>try</code>-<code>except</code>程序段中包含“训练循环”的常用模式：</p>
<pre><code>sess.run(iterator.initializer)
while True:
  try:
    sess.run(result)
  except tf.errors.OutOfRangeError:
    break
</code></pre><p>如果数据集的每个元素都有嵌套结构，则返回值为 <code>Iterator.get_next()</code>将是同一个或多个<code>tf.Tensor</code>物件 嵌套结构：</p>
<pre><code>dataset1 = tf.data.Dataset.from_tensor_slices(tf.random_uniform([4, 10]))
dataset2 = tf.data.Dataset.from_tensor_slices((tf.random_uniform([4]), tf.random_uniform([4, 100])))
dataset3 = tf.data.Dataset.zip((dataset1, dataset2))

iterator = dataset3.make_initializable_iterator()

sess.run(iterator.initializer)
next1, (next2, next3) = iterator.get_next()
</code></pre><p>请注意，对<code>next1</code>，<code>next2</code>或<code>next3</code>进行评估将推动 所有组件的迭代器。一个迭代器的典型消费者将包括所有 组件在一个单一的表达。</p>
<h2><span id="读取输入数据">读取输入数据</span></h2><h3><span id="使用numpy数组">使用NumPy数组</span></h3><p>如果所有的输入数据都适合内存，那么创建一个<code>Dataset</code>的最简单的方法就是使用它 从他们是把它们转换成<code>tf.Tensor</code>对象并使用<br><code>Dataset.from_tensor_slices()</code>。</p>
<pre><code># Load the training data into two NumPy arrays, for example using `np.load()`.
with np.load(&quot;/var/data/training_data.npy&quot;) as data:
  features = data[&quot;features&quot;]
  labels = data[&quot;labels&quot;]

# Assume that each row of `features` corresponds to the same row as `labels`.
assert features.shape[0] == labels.shape[0]

dataset = tf.data.Dataset.from_tensor_slices((features, labels))
</code></pre><p>请注意，上面的代码片段将嵌入<code>features</code>和<code>labels</code>阵列 在您的TensorFlow图中作为<code>tf.constant()</code>的操作。这适用于一个<br>小数据集，但浪费内存—因为数组的内容将是 复制多次—可以达到<code>tf.GraphDef</code>的2GB限制 协议缓冲区。</p>
<p>作为替代，您可以根据<code>Dataset</code>定义<code>tf.placeholder()</code> 张量，并在您初始化<code>Iterator</code>时提供NumPy阵列 数据集。</p>
<pre><code># Load the training data into two NumPy arrays, for example using `np.load()`.
with np.load(&quot;/var/data/training_data.npy&quot;) as data:
  features = data[&quot;features&quot;]
  labels = data[&quot;labels&quot;]

# Assume that each row of `features` corresponds to the same row as `labels`.
assert features.shape[0] == labels.shape[0]

features_placeholder = tf.placeholder(features.dtype, features.shape)
labels_placeholder = tf.placeholder(labels.dtype, labels.shape)

dataset = tf.data.Dataset.from_tensor_slices((features_placeholder, labels_placeholder))
# [Other transformations on `dataset`...]
dataset = ...
iterator = dataset.make_initializable_iterator()

sess.run(iterator.initializer, feed_dict={features_placeholder: features,
                                          labels_placeholder: labels})
</code></pre><h3><span id="消费tfrecord数据">消费TFRecord数据</span></h3><p><code>Dataset</code> API支持多种文件格式，以便进行处理 大数据集不适合内存。例如，TFRecord文件格式<br>是许多TensorFlow应用程序使用的简单的面向记录的二进制格式 用于训练数据。 <code>tf.data.TFRecordDataset</code>级可以让您<br>将一个或多个TFRecord文件的内容作为输入的一部分进行流式传输 管道。</p>
<pre><code># Creates a dataset that reads all of the examples from two files.
filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
</code></pre><p><code>filenames</code>初始化程序的<code>TFRecordDataset</code>参数可以是 字符串，字符串列表或<code>tf.Tensor</code>字符串。因此，如果你有<br>两套文件供培训和验证之用，可以使用一个 <code>tf.placeholder(tf.string)</code>来表示文件名，并初始化一个 迭代器从适当的文件名：</p>
<pre><code>filenames = tf.placeholder(tf.string, shape=[None])
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(...)  # Parse the record into tensors.
dataset = dataset.repeat()  # Repeat the input indefinitely.
dataset = dataset.batch(32)
iterator = dataset.make_initializable_iterator()

# You can feed the initializer with the appropriate filenames for the current
# phase of execution, e.g. training vs. validation.

# Initialize `iterator` with training data.
training_filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
sess.run(iterator.initializer, feed_dict={filenames: training_filenames})

# Initialize `iterator` with validation data.
validation_filenames = [&quot;/var/data/validation1.tfrecord&quot;, ...]
sess.run(iterator.initializer, feed_dict={filenames: validation_filenames})
</code></pre><h3><span id="消费文本数据">消费文本数据</span></h3><p>许多数据集分布为一个或多个文本文件。该 <code>tf.data.TextLineDataset</code>提供了一个简单的方法来提取线路<br>一个或多个文本文件。给定一个或多个文件名，<code>TextLineDataset</code>将 产生这些文件的每行一个字符串值的元素。像一个<br><code>TFRecordDataset</code>，<code>TextLineDataset</code>可接受<code>filenames</code>作为<code>tf.Tensor</code><br>您可以通过传递<code>tf.placeholder(tf.string)</code>来进行参数化。</p>
<pre><code>filenames = [&quot;/var/data/file1.txt&quot;, &quot;/var/data/file2.txt&quot;]
dataset = tf.data.TextLineDataset(filenames)
</code></pre><p>默认情况下，<code>TextLineDataset</code>会产生每个文件的每一行，这可能是 不是所希望的，例如，如果文件以标题行或包含开始<br>注释。这些线可以使用<code>Dataset.skip()</code>和 <code>Dataset.filter()</code>转换。将这些转换应用于每个转换<br>我们使用<code>Dataset.flat_map()</code>创建一个嵌套的<code>Dataset</code> 每个文件。</p>
<pre><code>filenames = [&quot;/var/data/file1.txt&quot;, &quot;/var/data/file2.txt&quot;]

dataset = tf.data.Dataset.from_tensor_slices(filenames)

# Use `Dataset.flat_map()` to transform each file as a separate nested dataset,
# and then concatenate their contents sequentially into a single &quot;flat&quot; dataset.
# * Skip the first line (header row).
# * Filter out lines beginning with &quot;#&quot; (comments).
dataset = dataset.flat_map(
    lambda filename: (
        tf.data.TextLineDataset(filename)
        .skip(1)
        .filter(lambda line: tf.not_equal(tf.substr(line, 0, 1), &quot;#&quot;))))
</code></pre><p>有关使用数据集解析CSV文件的完整示例，请参阅<code>imports85.py</code> 在回归的例子。</p>
<h2><span id="用datasetmap预处理数据">用<code>Dataset.map()</code>预处理数据</span></h2><p><code>Dataset.map(f)</code>转换通过应用给定的方法产生一个新的数据集 功能<code>f</code>到输入数据集的每个元素。它基于 该 <code>map()</code>功能<br>这是通常适用于功能列表（和其他结构） 编程语言。功能<code>f</code>使用<code>tf.Tensor</code>对象 表示输入中的单个元素，并返回<code>tf.Tensor</code>对象<br>这将代表新数据集中的单个元素。它的实现使用 标准的TensorFlow操作将一个元素转换成另一个元素。</p>
<p>本节介绍如何使用<code>Dataset.map()</code>的常用示例。</p>
<h3><span id="解析tfexample协议缓冲区信息">解析<code>tf.Example</code>协议缓冲区信息</span></h3><p>许多输入流水线从a中提取<code>tf.train.Example</code>协议缓冲区消息 TFRecord格式的文件（例如，使用<br><code>tf.python_io.TFRecordWriter</code>）。每个<code>tf.train.Example</code>记录包含一个或者一个<br>更多的“功能”，输入管道通常将这些功能转换成 张量。</p>
<pre><code># Transforms a scalar string `example_proto` into a pair of a scalar string and
# a scalar integer, representing an image and its label, respectively.
def _parse_function(example_proto):
  features = {&quot;image&quot;: tf.FixedLenFeature((), tf.string, default_value=&quot;&quot;),
              &quot;label&quot;: tf.FixedLenFeature((), tf.int32, default_value=0)}
  parsed_features = tf.parse_single_example(example_proto, features)
  return parsed_features[&quot;image&quot;], parsed_features[&quot;label&quot;]

# Creates a dataset that reads all of the examples from two files, and extracts
# the image and label features.
filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(_parse_function)
</code></pre><h3><span id="解码图像数据并调整大小">解码图像数据并调整大小</span></h3><p>当在真实世界的图像数据上训练神经网络时，通常是必要的 把不同大小的图像转换成一个通用的大小，以便它们可以 分批成一个固定的大小。</p>
<pre><code># Reads an image from a file, decodes it into a dense tensor, and resizes it
# to a fixed shape.
def _parse_function(filename, label):
  image_string = tf.read_file(filename)
  image_decoded = tf.image.decode_image(image_string)
  image_resized = tf.image.resize_images(image_decoded, [28, 28])
  return image_resized, label

# A vector of filenames.
filenames = tf.constant([&quot;/var/data/image1.jpg&quot;, &quot;/var/data/image2.jpg&quot;, ...])

# `labels[i]` is the label for the image in `filenames[i].
labels = tf.constant([0, 37, ...])

dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))
dataset = dataset.map(_parse_function)
</code></pre><h3><span id="应用tfpy_func的任意python逻辑">应用<code>tf.py_func()</code>的任意Python逻辑</span></h3><p>出于性能原因，我们鼓励您使用TensorFlow操作 尽可能预处理您的数据。但是，它有时是有用的 解析输入数据时调用外部Python库。为此，<br>调用<code>tf.py_func()</code>转换中的<code>Dataset.map()</code>操作。</p>
<pre><code>import cv2

# Use a custom OpenCV function to read the image, instead of the standard
# TensorFlow `tf.read_file()` operation.
def _read_py_function(filename, label):
  image_decoded = cv2.imread(image_string, cv2.IMREAD_GRAYSCALE)
  return image_decoded, label

# Use standard TensorFlow operations to resize the image to a fixed shape.
def _resize_function(image_decoded, label):
  image_decoded.set_shape([None, None, None])
  image_resized = tf.image.resize_images(image_decoded, [28, 28])
  return image_resized, label

filenames = [&quot;/var/data/image1.jpg&quot;, &quot;/var/data/image2.jpg&quot;, ...]
labels = [0, 37, 29, 1, ...]

dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))
dataset = dataset.map(
    lambda filename, label: tuple(tf.py_func(
        _read_py_function, [filename, label], [tf.uint8, label.dtype])))
dataset = dataset.map(_resize_function)
</code></pre><h2><span id="批处理数据集元素">批处理数据集元素</span></h2><h3><span id="简单的配料">简单的配料</span></h3><p><code>n</code>连续数据集元素的最简单的批处理形式 一个单一的元素。 <code>Dataset.batch()</code>转换就是这样做的<br>与<code>tf.stack()</code>操作员相同的约束适用于每个组件 的元素：即对于每个元素i，所有元素必须具有张量 完全相同的形状。</p>
<pre><code>inc_dataset = tf.data.Dataset.range(100)
dec_dataset = tf.data.Dataset.range(0, -100, -1)
dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))
batched_dataset = dataset.batch(4)

iterator = batched_dataset.make_one_shot_iterator()
next_element = iterator.get_next()

print(sess.run(next_element))  # ==&gt; ([0, 1, 2,   3],   [ 0, -1,  -2,  -3])
print(sess.run(next_element))  # ==&gt; ([4, 5, 6,   7],   [-4, -5,  -6,  -7])
print(sess.run(next_element))  # ==&gt; ([8, 9, 10, 11],   [-8, -9, -10, -11])
</code></pre><h3><span id="用填料分批张量">用填料分批张量</span></h3><p>上面的配方适用于所有尺寸相同的张量。但是，很多 模型（例如序列模型）与可能具有不同大小的输入数据一起工作 （例如不同长度的序列）。为了处理这种情况，<br><code>Dataset.padded_batch()</code>转换使您能够批量张量 通过指定一个或多个维度来指定不同的形状 填充。</p>
<pre><code>dataset = tf.data.Dataset.range(100)
dataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))
dataset = dataset.padded_batch(4, padded_shapes=[None])

iterator = dataset.make_one_shot_iterator()
next_element = iterator.get_next()

print(sess.run(next_element))  # ==&gt; [[0, 0, 0], [1, 0, 0], [2, 2, 0], [3, 3, 3]]
print(sess.run(next_element))  # ==&gt; [[4, 4, 4, 4, 0, 0, 0],
                               #      [5, 5, 5, 5, 5, 0, 0],
                               #      [6, 6, 6, 6, 6, 6, 0],
                               #      [7, 7, 7, 7, 7, 7, 7]]
</code></pre><p><code>Dataset.padded_batch()</code>转换允许您设置不同的填充 为每个组件的每个维度，它可能是可变长度（表示<br>在上面的例子中由<code>None</code>）或恒定长度。也有可能 重写填充值，默认为0。</p>
<h2><span id="培训工作流程">培训工作流程</span></h2><h3><span id="处理多个时代">处理多个时代</span></h3><p><code>Dataset</code> API提供了两种主要的方法来处理多个相同的历元 数据。</p>
<p>在多个时期迭代数据集的最简单方法是使用 <code>Dataset.repeat()</code>转换。例如，创建重复的数据集 它的输入为10个时期：</p>
<pre><code>filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(...)
dataset = dataset.repeat(10)
dataset = dataset.batch(32)
</code></pre><p>将不重复应用<code>Dataset.repeat()</code>转换 输入无限期。 <code>Dataset.repeat()</code>转换将其连接起来<br>而不是一个时代的结束和下一个开始的信号 时代。</p>
<p>如果你想在每个纪元结束时收到一个信号，你可以写一个 训练循环捕捉到<code>tf.errors.OutOfRangeError</code>的末尾<br>数据集。在这一点上，你可能会收集一些统计数据（例如验证 错误）的时代。</p>
<pre><code>filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(...)
dataset = dataset.batch(32)
iterator = dataset.make_initializable_iterator()
next_element = iterator.get_next()

# Compute for 100 epochs.
for _ in range(100):
  sess.run(iterator.initializer)
  while True:
    try:
      sess.run(next_element)
    except tf.errors.OutOfRangeError:
      break

  # [Perform end-of-epoch calculations here.]
</code></pre><h3><span id="随机洗牌输入数据">随机洗牌输入数据</span></h3><p><code>Dataset.shuffle()</code>变换随机混洗输入数据集 使用与<code>tf.RandomShuffleQueue</code>类似的算法：它保持固定大小<br>缓冲区并从该缓冲区中随机选择下一个元素。</p>
<pre><code>filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(...)
dataset = dataset.shuffle(buffer_size=10000)
dataset = dataset.batch(32)
dataset = dataset.repeat()
</code></pre><h3><span id="使用高级api">使用高级API</span></h3><p><code>tf.train.MonitoredTrainingSession</code> API简化了运行的许多方面 TensorFlow在分布式设置中。<br><code>MonitoredTrainingSession</code>使用的 <code>tf.errors.OutOfRangeError</code>表示训练已经完成，所以使用它<br>使用<code>Dataset</code> API，我们推荐使用 <code>Dataset.make_one_shot_iterator()</code>。例如：</p>
<pre><code>filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
dataset = tf.data.TFRecordDataset(filenames)
dataset = dataset.map(...)
dataset = dataset.shuffle(buffer_size=10000)
dataset = dataset.batch(32)
dataset = dataset.repeat(num_epochs)
iterator = dataset.make_one_shot_iterator()

next_example, next_label = iterator.get_next()
loss = model_function(next_example, next_label)

training_op = tf.train.AdagradOptimizer(...).minimize(loss)

with tf.train.MonitoredTrainingSession(...) as sess:
  while not sess.should_stop():
    sess.run(training_op)
</code></pre><p>要在<code>Dataset</code>的<code>input_fn</code>中使用<code>tf.estimator.Estimator</code>，我们也<br>推荐使用<code>Dataset.make_one_shot_iterator()</code>。例如：</p>
<pre><code>def dataset_input_fn():
  filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;]
  dataset = tf.data.TFRecordDataset(filenames)

  # Use `tf.parse_single_example()` to extract data from a `tf.Example`
  # protocol buffer, and perform any additional per-record preprocessing.
  def parser(record):
    keys_to_features = {
        &quot;image_data&quot;: tf.FixedLenFeature((), tf.string, default_value=&quot;&quot;),
        &quot;date_time&quot;: tf.FixedLenFeature((), tf.int64, default_value=&quot;&quot;),
        &quot;label&quot;: tf.FixedLenFeature((), tf.int64,
                                    default_value=tf.zeros([], dtype=tf.int64)),
    }
    parsed = tf.parse_single_example(record, keys_to_features)

    # Perform additional preprocessing on the parsed data.
    image = tf.decode_jpeg(parsed[&quot;image_data&quot;])
    image = tf.reshape(image, [299, 299, 1])
    label = tf.cast(parsed[&quot;label&quot;], tf.int32)

    return {&quot;image_data&quot;: image, &quot;date_time&quot;: parsed[&quot;date_time&quot;]}, label

  # Use `Dataset.map()` to build a pair of a feature dictionary and a label
  # tensor for each example.
  dataset = dataset.map(parser)
  dataset = dataset.shuffle(buffer_size=10000)
  dataset = dataset.batch(32)
  dataset = dataset.repeat(num_epochs)
  iterator = dataset.make_one_shot_iterator()

  # `features` is a dictionary in which each value is a batch of values for
  # that feature; `labels` is a batch of labels.
  features, labels = iterator.get_next()
  return features, labels
</code></pre>

        <p style="margin-top:2em; text-align:left; font-weight:bold; font-style: italic;">未经作者同意，本文严禁转载，违者必究！</p>
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/机器学习/">机器学习</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	  <div data-url="https://www.tracholar.top/2018/01/01/datasets/" data-title="导入数据 | 智子" data-tsina="" class="share clearfix">
	  </div>
	
	</div>


</footer>


	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2018/01/01/dev/" title="发展">
  <strong>上一篇：</strong><br/>
  <span>
  发展</span>
</a>
</div>


<div class="next">
<a href="/2018/01/01/tensors/"  title="张量">
 <strong>下一篇：</strong><br/> 
 <span>张量
</span>
</a>
</div>

</nav>

	



</div>

      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">Contents</strong>
 
 <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#undefined"><span class="toc-number">1.</span> <span class="toc-text">导入数据</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">1.1.</span> <span class="toc-text">基本力学</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.1.1.</span> <span class="toc-text">数据集结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.1.2.</span> <span class="toc-text">创建一个迭代器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.1.3.</span> <span class="toc-text">从迭代器中消费值</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">1.2.</span> <span class="toc-text">读取输入数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.2.1.</span> <span class="toc-text">使用NumPy数组</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.2.2.</span> <span class="toc-text">消费TFRecord数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.2.3.</span> <span class="toc-text">消费文本数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">1.3.</span> <span class="toc-text">用Dataset.map()预处理数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.3.1.</span> <span class="toc-text">解析tf.Example协议缓冲区信息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.3.2.</span> <span class="toc-text">解码图像数据并调整大小</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.3.3.</span> <span class="toc-text">应用tf.py_func()的任意Python逻辑</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">1.4.</span> <span class="toc-text">批处理数据集元素</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.4.1.</span> <span class="toc-text">简单的配料</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.4.2.</span> <span class="toc-text">用填料分批张量</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">1.5.</span> <span class="toc-text">培训工作流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.5.1.</span> <span class="toc-text">处理多个时代</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.5.2.</span> <span class="toc-text">随机洗牌输入数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.5.3.</span> <span class="toc-text">使用高级API</span></a></li></ol></li></ol></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- side-bar-ad -->
<ins class="adsbygoogle"
     style="display:block; overflow:hidden;"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="2232545787"
     data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


  


  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/javascript/" title="javascript">javascript<sup>207</sup></a></li>
			
		
			
				<li><a href="/tags/java/" title="java">java<sup>205</sup></a></li>
			
		
			
				<li><a href="/tags/html/" title="html">html<sup>203</sup></a></li>
			
		
			
				<li><a href="/tags/python/" title="python">python<sup>199</sup></a></li>
			
		
			
				<li><a href="/tags/bash/" title="bash">bash<sup>198</sup></a></li>
			
		
			
				<li><a href="/tags/php/" title="php">php<sup>197</sup></a></li>
			
		
			
				<li><a href="/tags/css/" title="css">css<sup>88</sup></a></li>
			
		
			
				<li><a href="/tags/shell/" title="shell">shell<sup>78</sup></a></li>
			
		
			
				<li><a href="/tags/jquery/" title="jquery">jquery<sup>61</sup></a></li>
			
		
			
				<li><a href="/tags/linux/" title="linux">linux<sup>57</sup></a></li>
			
		
			
				<li><a href="/tags/机器学习/" title="机器学习">机器学习<sup>41</sup></a></li>
			
		
			
				<li><a href="/tags/unix/" title="unix">unix<sup>30</sup></a></li>
			
		
			
				<li><a href="/tags/mysql/" title="mysql">mysql<sup>17</sup></a></li>
			
		
			
				<li><a href="/tags/html5/" title="html5">html5<sup>16</sup></a></li>
			
		
			
				<li><a href="/tags/xml/" title="xml">xml<sup>13</sup></a></li>
			
		
			
				<li><a href="/tags/http/" title="http">http<sup>10</sup></a></li>
			
		
			
				<li><a href="/tags/区块链/" title="区块链">区块链<sup>1</sup></a></li>
			
		
			
		
			
		
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">Links</p>
    <ul>
        
          <li>
            
            	<a href="https://tracholar.github.io" target="_blank" title="个人博客">个人博客</a>
            
          </li>
        
    </ul>
</div>

  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS</a>
</div>

</aside>
</div>

    </div>
    <footer><div id="footer" >
	
	
	<section class="info">
		<p> To be or not to be, that is a question. <br/>
			This is my blog,believe it or not.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		
		
		
		
		
		
		
		
		
	</div>
			
		

		<p class="copyright">
		版权所有 © 2018 本站文章未经同意，禁止转载！作者：
		
		<a href="/about" target="_blank" title="zhizi">zhizi</a>
		


		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);

  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      $('.hoverqrcode').hide();
  });
});   
</script>











<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->





<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="Back to Top"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
</html>
